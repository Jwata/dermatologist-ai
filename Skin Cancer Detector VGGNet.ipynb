{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow_vgg'...\n",
      "remote: Counting objects: 113, done.\u001b[K\n",
      "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 113\u001b[K\n",
      "Receiving objects: 100% (113/113), 55.91 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# Operations for floydhub\n",
    "# !git clone https://github.com/machrisaa/tensorflow-vgg tensorflow_vgg\n",
    "# !ln -s /data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "vgg_dir = 'tensorflow_vgg/'\n",
    "vgg_name = 'vgg19'\n",
    "\n",
    "# Make sure vgg exists\n",
    "if not isdir(vgg_dir):\n",
    "    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "vgg_param_file = '{}{}.npy'.format(vgg_dir, vgg_name)\n",
    "if not isfile(vgg_param_file):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc= vgg_name + ' Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/{}.npy'.format(vgg_name),\n",
    "            vgg_param_file,\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg19\n",
    "# from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "classes = [d for d in os.listdir(train_dir) if os.path.isdir(train_dir + d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage.transform import resize\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image\n",
    "\n",
    "def vertical_flip(image):\n",
    "    image = image[::-1, :, :]\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, angle_range=(0, 180)):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.randint(*angle_range)\n",
    "    image = rotate(image, angle)\n",
    "    image = resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: melanoma, 4 / 374 images processed. data count: 20\n",
      "data: train, class: melanoma, 8 / 374 images processed. data count: 40\n",
      "data: train, class: melanoma, 12 / 374 images processed. data count: 60\n",
      "data: train, class: melanoma, 16 / 374 images processed. data count: 80\n",
      "data: train, class: melanoma, 20 / 374 images processed. data count: 100\n",
      "data: train, class: melanoma, 24 / 374 images processed. data count: 120\n",
      "data: train, class: melanoma, 28 / 374 images processed. data count: 140\n",
      "data: train, class: melanoma, 32 / 374 images processed. data count: 160\n",
      "data: train, class: melanoma, 36 / 374 images processed. data count: 180\n",
      "data: train, class: melanoma, 40 / 374 images processed. data count: 200\n",
      "data: train, class: melanoma, 44 / 374 images processed. data count: 220\n",
      "data: train, class: melanoma, 48 / 374 images processed. data count: 240\n",
      "data: train, class: melanoma, 52 / 374 images processed. data count: 260\n",
      "data: train, class: melanoma, 56 / 374 images processed. data count: 280\n",
      "data: train, class: melanoma, 60 / 374 images processed. data count: 300\n",
      "data: train, class: melanoma, 64 / 374 images processed. data count: 320\n",
      "data: train, class: melanoma, 68 / 374 images processed. data count: 340\n",
      "data: train, class: melanoma, 72 / 374 images processed. data count: 360\n",
      "data: train, class: melanoma, 76 / 374 images processed. data count: 380\n",
      "data: train, class: melanoma, 80 / 374 images processed. data count: 400\n",
      "data: train, class: melanoma, 84 / 374 images processed. data count: 420\n",
      "data: train, class: melanoma, 88 / 374 images processed. data count: 440\n",
      "data: train, class: melanoma, 92 / 374 images processed. data count: 460\n",
      "data: train, class: melanoma, 96 / 374 images processed. data count: 480\n",
      "data: train, class: melanoma, 100 / 374 images processed. data count: 500\n",
      "data: train, class: melanoma, 104 / 374 images processed. data count: 520\n",
      "data: train, class: melanoma, 108 / 374 images processed. data count: 540\n",
      "data: train, class: melanoma, 112 / 374 images processed. data count: 560\n",
      "data: train, class: melanoma, 116 / 374 images processed. data count: 580\n",
      "data: train, class: melanoma, 120 / 374 images processed. data count: 600\n",
      "data: train, class: melanoma, 124 / 374 images processed. data count: 620\n",
      "data: train, class: melanoma, 128 / 374 images processed. data count: 640\n",
      "data: train, class: melanoma, 132 / 374 images processed. data count: 660\n",
      "data: train, class: melanoma, 136 / 374 images processed. data count: 680\n",
      "data: train, class: melanoma, 140 / 374 images processed. data count: 700\n",
      "data: train, class: melanoma, 144 / 374 images processed. data count: 720\n",
      "data: train, class: melanoma, 148 / 374 images processed. data count: 740\n",
      "data: train, class: melanoma, 152 / 374 images processed. data count: 760\n",
      "data: train, class: melanoma, 156 / 374 images processed. data count: 780\n",
      "data: train, class: melanoma, 160 / 374 images processed. data count: 800\n",
      "data: train, class: melanoma, 164 / 374 images processed. data count: 820\n",
      "data: train, class: melanoma, 168 / 374 images processed. data count: 840\n",
      "data: train, class: melanoma, 172 / 374 images processed. data count: 860\n",
      "data: train, class: melanoma, 176 / 374 images processed. data count: 880\n",
      "data: train, class: melanoma, 180 / 374 images processed. data count: 900\n",
      "data: train, class: melanoma, 184 / 374 images processed. data count: 920\n",
      "data: train, class: melanoma, 188 / 374 images processed. data count: 940\n",
      "data: train, class: melanoma, 192 / 374 images processed. data count: 960\n",
      "data: train, class: melanoma, 196 / 374 images processed. data count: 980\n",
      "data: train, class: melanoma, 200 / 374 images processed. data count: 1000\n",
      "data: train, class: melanoma, 204 / 374 images processed. data count: 1020\n",
      "data: train, class: melanoma, 208 / 374 images processed. data count: 1040\n",
      "data: train, class: melanoma, 212 / 374 images processed. data count: 1060\n",
      "data: train, class: melanoma, 216 / 374 images processed. data count: 1080\n",
      "data: train, class: melanoma, 220 / 374 images processed. data count: 1100\n",
      "data: train, class: melanoma, 224 / 374 images processed. data count: 1120\n",
      "data: train, class: melanoma, 228 / 374 images processed. data count: 1140\n",
      "data: train, class: melanoma, 232 / 374 images processed. data count: 1160\n",
      "data: train, class: melanoma, 236 / 374 images processed. data count: 1180\n",
      "data: train, class: melanoma, 240 / 374 images processed. data count: 1200\n",
      "data: train, class: melanoma, 244 / 374 images processed. data count: 1220\n",
      "data: train, class: melanoma, 248 / 374 images processed. data count: 1240\n",
      "data: train, class: melanoma, 252 / 374 images processed. data count: 1260\n",
      "data: train, class: melanoma, 256 / 374 images processed. data count: 1280\n",
      "data: train, class: melanoma, 260 / 374 images processed. data count: 1300\n",
      "data: train, class: melanoma, 264 / 374 images processed. data count: 1320\n",
      "data: train, class: melanoma, 268 / 374 images processed. data count: 1340\n",
      "data: train, class: melanoma, 272 / 374 images processed. data count: 1360\n",
      "data: train, class: melanoma, 276 / 374 images processed. data count: 1380\n",
      "data: train, class: melanoma, 280 / 374 images processed. data count: 1400\n",
      "data: train, class: melanoma, 284 / 374 images processed. data count: 1420\n",
      "data: train, class: melanoma, 288 / 374 images processed. data count: 1440\n",
      "data: train, class: melanoma, 292 / 374 images processed. data count: 1460\n",
      "data: train, class: melanoma, 296 / 374 images processed. data count: 1480\n",
      "data: train, class: melanoma, 300 / 374 images processed. data count: 1500\n",
      "data: train, class: melanoma, 304 / 374 images processed. data count: 1520\n",
      "data: train, class: melanoma, 308 / 374 images processed. data count: 1540\n",
      "data: train, class: melanoma, 312 / 374 images processed. data count: 1560\n",
      "data: train, class: melanoma, 316 / 374 images processed. data count: 1580\n",
      "data: train, class: melanoma, 320 / 374 images processed. data count: 1600\n",
      "data: train, class: melanoma, 324 / 374 images processed. data count: 1620\n",
      "data: train, class: melanoma, 328 / 374 images processed. data count: 1640\n",
      "data: train, class: melanoma, 332 / 374 images processed. data count: 1660\n",
      "data: train, class: melanoma, 336 / 374 images processed. data count: 1680\n",
      "data: train, class: melanoma, 340 / 374 images processed. data count: 1700\n",
      "data: train, class: melanoma, 344 / 374 images processed. data count: 1720\n",
      "data: train, class: melanoma, 348 / 374 images processed. data count: 1740\n",
      "data: train, class: melanoma, 352 / 374 images processed. data count: 1760\n",
      "data: train, class: melanoma, 356 / 374 images processed. data count: 1780\n",
      "data: train, class: melanoma, 360 / 374 images processed. data count: 1800\n",
      "data: train, class: melanoma, 364 / 374 images processed. data count: 1820\n",
      "data: train, class: melanoma, 368 / 374 images processed. data count: 1840\n",
      "data: train, class: melanoma, 372 / 374 images processed. data count: 1860\n",
      "data: train, class: melanoma, 374 / 374 images processed. data count: 1870\n",
      "data: train, class: nevus, 20 / 1372 images processed. data count: 1890\n",
      "data: train, class: nevus, 40 / 1372 images processed. data count: 1910\n",
      "data: train, class: nevus, 60 / 1372 images processed. data count: 1930\n",
      "data: train, class: nevus, 80 / 1372 images processed. data count: 1950\n",
      "data: train, class: nevus, 100 / 1372 images processed. data count: 1970\n",
      "data: train, class: nevus, 120 / 1372 images processed. data count: 1990\n",
      "data: train, class: nevus, 140 / 1372 images processed. data count: 2010\n",
      "data: train, class: nevus, 160 / 1372 images processed. data count: 2030\n",
      "data: train, class: nevus, 180 / 1372 images processed. data count: 2050\n",
      "data: train, class: nevus, 200 / 1372 images processed. data count: 2070\n",
      "data: train, class: nevus, 220 / 1372 images processed. data count: 2090\n",
      "data: train, class: nevus, 240 / 1372 images processed. data count: 2110\n",
      "data: train, class: nevus, 260 / 1372 images processed. data count: 2130\n",
      "data: train, class: nevus, 280 / 1372 images processed. data count: 2150\n",
      "data: train, class: nevus, 300 / 1372 images processed. data count: 2170\n",
      "data: train, class: nevus, 320 / 1372 images processed. data count: 2190\n",
      "data: train, class: nevus, 340 / 1372 images processed. data count: 2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: nevus, 360 / 1372 images processed. data count: 2230\n",
      "data: train, class: nevus, 380 / 1372 images processed. data count: 2250\n",
      "data: train, class: nevus, 400 / 1372 images processed. data count: 2270\n",
      "data: train, class: nevus, 420 / 1372 images processed. data count: 2290\n",
      "data: train, class: nevus, 440 / 1372 images processed. data count: 2310\n",
      "data: train, class: nevus, 460 / 1372 images processed. data count: 2330\n",
      "data: train, class: nevus, 480 / 1372 images processed. data count: 2350\n",
      "data: train, class: nevus, 500 / 1372 images processed. data count: 2370\n",
      "data: train, class: nevus, 520 / 1372 images processed. data count: 2390\n",
      "data: train, class: nevus, 540 / 1372 images processed. data count: 2410\n",
      "data: train, class: nevus, 560 / 1372 images processed. data count: 2430\n",
      "data: train, class: nevus, 580 / 1372 images processed. data count: 2450\n",
      "data: train, class: nevus, 600 / 1372 images processed. data count: 2470\n",
      "data: train, class: nevus, 620 / 1372 images processed. data count: 2490\n",
      "data: train, class: nevus, 640 / 1372 images processed. data count: 2510\n",
      "data: train, class: nevus, 660 / 1372 images processed. data count: 2530\n",
      "data: train, class: nevus, 680 / 1372 images processed. data count: 2550\n",
      "data: train, class: nevus, 700 / 1372 images processed. data count: 2570\n",
      "data: train, class: nevus, 720 / 1372 images processed. data count: 2590\n",
      "data: train, class: nevus, 740 / 1372 images processed. data count: 2610\n",
      "data: train, class: nevus, 760 / 1372 images processed. data count: 2630\n",
      "data: train, class: nevus, 780 / 1372 images processed. data count: 2650\n",
      "data: train, class: nevus, 800 / 1372 images processed. data count: 2670\n",
      "data: train, class: nevus, 820 / 1372 images processed. data count: 2690\n",
      "data: train, class: nevus, 840 / 1372 images processed. data count: 2710\n",
      "data: train, class: nevus, 860 / 1372 images processed. data count: 2730\n",
      "data: train, class: nevus, 880 / 1372 images processed. data count: 2750\n",
      "data: train, class: nevus, 900 / 1372 images processed. data count: 2770\n",
      "data: train, class: nevus, 920 / 1372 images processed. data count: 2790\n",
      "data: train, class: nevus, 940 / 1372 images processed. data count: 2810\n",
      "data: train, class: nevus, 960 / 1372 images processed. data count: 2830\n",
      "data: train, class: nevus, 980 / 1372 images processed. data count: 2850\n",
      "data: train, class: nevus, 1000 / 1372 images processed. data count: 2870\n",
      "data: train, class: nevus, 1020 / 1372 images processed. data count: 2890\n",
      "data: train, class: nevus, 1040 / 1372 images processed. data count: 2910\n",
      "data: train, class: nevus, 1060 / 1372 images processed. data count: 2930\n",
      "data: train, class: nevus, 1080 / 1372 images processed. data count: 2950\n",
      "data: train, class: nevus, 1100 / 1372 images processed. data count: 2970\n",
      "data: train, class: nevus, 1120 / 1372 images processed. data count: 2990\n",
      "data: train, class: nevus, 1140 / 1372 images processed. data count: 3010\n",
      "data: train, class: nevus, 1160 / 1372 images processed. data count: 3030\n",
      "data: train, class: nevus, 1180 / 1372 images processed. data count: 3050\n",
      "data: train, class: nevus, 1200 / 1372 images processed. data count: 3070\n",
      "data: train, class: nevus, 1220 / 1372 images processed. data count: 3090\n",
      "data: train, class: nevus, 1240 / 1372 images processed. data count: 3110\n",
      "data: train, class: nevus, 1260 / 1372 images processed. data count: 3130\n",
      "data: train, class: nevus, 1280 / 1372 images processed. data count: 3150\n",
      "data: train, class: nevus, 1300 / 1372 images processed. data count: 3170\n",
      "data: train, class: nevus, 1320 / 1372 images processed. data count: 3190\n",
      "data: train, class: nevus, 1340 / 1372 images processed. data count: 3210\n",
      "data: train, class: nevus, 1360 / 1372 images processed. data count: 3230\n",
      "data: train, class: nevus, 1372 / 1372 images processed. data count: 3242\n",
      "data: train, class: seborrheic_keratosis, 4 / 254 images processed. data count: 3262\n",
      "data: train, class: seborrheic_keratosis, 8 / 254 images processed. data count: 3282\n",
      "data: train, class: seborrheic_keratosis, 12 / 254 images processed. data count: 3302\n",
      "data: train, class: seborrheic_keratosis, 16 / 254 images processed. data count: 3322\n",
      "data: train, class: seborrheic_keratosis, 20 / 254 images processed. data count: 3342\n",
      "data: train, class: seborrheic_keratosis, 24 / 254 images processed. data count: 3362\n",
      "data: train, class: seborrheic_keratosis, 28 / 254 images processed. data count: 3382\n",
      "data: train, class: seborrheic_keratosis, 32 / 254 images processed. data count: 3402\n",
      "data: train, class: seborrheic_keratosis, 36 / 254 images processed. data count: 3422\n",
      "data: train, class: seborrheic_keratosis, 40 / 254 images processed. data count: 3442\n",
      "data: train, class: seborrheic_keratosis, 44 / 254 images processed. data count: 3462\n",
      "data: train, class: seborrheic_keratosis, 48 / 254 images processed. data count: 3482\n",
      "data: train, class: seborrheic_keratosis, 52 / 254 images processed. data count: 3502\n",
      "data: train, class: seborrheic_keratosis, 56 / 254 images processed. data count: 3522\n",
      "data: train, class: seborrheic_keratosis, 60 / 254 images processed. data count: 3542\n",
      "data: train, class: seborrheic_keratosis, 64 / 254 images processed. data count: 3562\n",
      "data: train, class: seborrheic_keratosis, 68 / 254 images processed. data count: 3582\n",
      "data: train, class: seborrheic_keratosis, 72 / 254 images processed. data count: 3602\n",
      "data: train, class: seborrheic_keratosis, 76 / 254 images processed. data count: 3622\n",
      "data: train, class: seborrheic_keratosis, 80 / 254 images processed. data count: 3642\n",
      "data: train, class: seborrheic_keratosis, 84 / 254 images processed. data count: 3662\n",
      "data: train, class: seborrheic_keratosis, 88 / 254 images processed. data count: 3682\n",
      "data: train, class: seborrheic_keratosis, 92 / 254 images processed. data count: 3702\n",
      "data: train, class: seborrheic_keratosis, 96 / 254 images processed. data count: 3722\n",
      "data: train, class: seborrheic_keratosis, 100 / 254 images processed. data count: 3742\n",
      "data: train, class: seborrheic_keratosis, 104 / 254 images processed. data count: 3762\n",
      "data: train, class: seborrheic_keratosis, 108 / 254 images processed. data count: 3782\n",
      "data: train, class: seborrheic_keratosis, 112 / 254 images processed. data count: 3802\n",
      "data: train, class: seborrheic_keratosis, 116 / 254 images processed. data count: 3822\n",
      "data: train, class: seborrheic_keratosis, 120 / 254 images processed. data count: 3842\n",
      "data: train, class: seborrheic_keratosis, 124 / 254 images processed. data count: 3862\n",
      "data: train, class: seborrheic_keratosis, 128 / 254 images processed. data count: 3882\n",
      "data: train, class: seborrheic_keratosis, 132 / 254 images processed. data count: 3902\n",
      "data: train, class: seborrheic_keratosis, 136 / 254 images processed. data count: 3922\n",
      "data: train, class: seborrheic_keratosis, 140 / 254 images processed. data count: 3942\n",
      "data: train, class: seborrheic_keratosis, 144 / 254 images processed. data count: 3962\n",
      "data: train, class: seborrheic_keratosis, 148 / 254 images processed. data count: 3982\n",
      "data: train, class: seborrheic_keratosis, 152 / 254 images processed. data count: 4002\n",
      "data: train, class: seborrheic_keratosis, 156 / 254 images processed. data count: 4022\n",
      "data: train, class: seborrheic_keratosis, 160 / 254 images processed. data count: 4042\n",
      "data: train, class: seborrheic_keratosis, 164 / 254 images processed. data count: 4062\n",
      "data: train, class: seborrheic_keratosis, 168 / 254 images processed. data count: 4082\n",
      "data: train, class: seborrheic_keratosis, 172 / 254 images processed. data count: 4102\n",
      "data: train, class: seborrheic_keratosis, 176 / 254 images processed. data count: 4122\n",
      "data: train, class: seborrheic_keratosis, 180 / 254 images processed. data count: 4142\n",
      "data: train, class: seborrheic_keratosis, 184 / 254 images processed. data count: 4162\n",
      "data: train, class: seborrheic_keratosis, 188 / 254 images processed. data count: 4182\n",
      "data: train, class: seborrheic_keratosis, 192 / 254 images processed. data count: 4202\n",
      "data: train, class: seborrheic_keratosis, 196 / 254 images processed. data count: 4222\n",
      "data: train, class: seborrheic_keratosis, 200 / 254 images processed. data count: 4242\n",
      "data: train, class: seborrheic_keratosis, 204 / 254 images processed. data count: 4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: seborrheic_keratosis, 208 / 254 images processed. data count: 4282\n",
      "data: train, class: seborrheic_keratosis, 212 / 254 images processed. data count: 4302\n",
      "data: train, class: seborrheic_keratosis, 216 / 254 images processed. data count: 4322\n",
      "data: train, class: seborrheic_keratosis, 220 / 254 images processed. data count: 4342\n",
      "data: train, class: seborrheic_keratosis, 224 / 254 images processed. data count: 4362\n",
      "data: train, class: seborrheic_keratosis, 228 / 254 images processed. data count: 4382\n",
      "data: train, class: seborrheic_keratosis, 232 / 254 images processed. data count: 4402\n",
      "data: train, class: seborrheic_keratosis, 236 / 254 images processed. data count: 4422\n",
      "data: train, class: seborrheic_keratosis, 240 / 254 images processed. data count: 4442\n",
      "data: train, class: seborrheic_keratosis, 244 / 254 images processed. data count: 4462\n",
      "data: train, class: seborrheic_keratosis, 248 / 254 images processed. data count: 4482\n",
      "data: train, class: seborrheic_keratosis, 252 / 254 images processed. data count: 4502\n",
      "data: train, class: seborrheic_keratosis, 254 / 254 images processed. data count: 4512\n",
      "data: valid, class: melanoma, 20 / 30 images processed. data count: 20\n",
      "data: valid, class: melanoma, 30 / 30 images processed. data count: 30\n",
      "data: valid, class: nevus, 20 / 78 images processed. data count: 50\n",
      "data: valid, class: nevus, 40 / 78 images processed. data count: 70\n",
      "data: valid, class: nevus, 60 / 78 images processed. data count: 90\n",
      "data: valid, class: nevus, 78 / 78 images processed. data count: 108\n",
      "data: valid, class: seborrheic_keratosis, 20 / 42 images processed. data count: 128\n",
      "data: valid, class: seborrheic_keratosis, 40 / 42 images processed. data count: 148\n",
      "data: valid, class: seborrheic_keratosis, 42 / 42 images processed. data count: 150\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    \n",
    "    codes = None\n",
    "    labels = []\n",
    "    count = 0\n",
    "\n",
    "    for d_type in ['train', 'valid']:\n",
    "        for c in classes:\n",
    "            image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "            files = os.listdir(image_dir)\n",
    "            for i, file in enumerate(files, 1):\n",
    "                # load image and resize it to 224x224\n",
    "                file_path = os.path.join(image_dir, file)\n",
    "                img = utils.load_image(file_path)\n",
    "                batch.append(img.reshape((1, 224, 224, 3)))\n",
    "                labels.append(c)\n",
    "                \n",
    "                # data augumentation for all training data but nevus\n",
    "                if d_type == 'train':\n",
    "                    batch.append(horizontal_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(vertical_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img, angle_range=(-180, 0)).reshape((1,224,224,3)))\n",
    "                    labels.append(c)                  \n",
    "\n",
    "                if (len(batch) >= batch_size) or i == len(files):\n",
    "                    images = np.concatenate(batch)\n",
    "\n",
    "                    feed_dict = {input_: images}\n",
    "                    codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "\n",
    "                    if codes is None:\n",
    "                        codes = codes_batch\n",
    "                    else:\n",
    "                        codes = np.concatenate((codes, codes_batch))\n",
    "\n",
    "                    count += len(batch)\n",
    "                    batch = []\n",
    "                    print('data: {}, class: {}, {} / {} images processed. data count: {}'.format(d_type, c, i, len(files), count))\n",
    "\n",
    "        # write codes to file\n",
    "        with open('{}_{}_codes'.format(vgg_name, d_type), 'w') as f:\n",
    "            codes.tofile(f)\n",
    "            codes = None\n",
    "\n",
    "        # write labels to file\n",
    "        with open('{}_{}_labels'.format(vgg_name, d_type), 'w') as f:\n",
    "            writer = csv.writer(f, delimiter='\\n')\n",
    "            writer.writerow(labels)\n",
    "            labels = []\n",
    "\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read codes and labels from file\n",
    "import csv\n",
    "\n",
    "# train data\n",
    "with open('{}_train_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    train_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_train_codes'.format(vgg_name)) as f:\n",
    "    train_x = np.fromfile(f, dtype=np.float32)\n",
    "    train_x = train_x.reshape((len(train_labels), -1))\n",
    "    \n",
    "# valid data\n",
    "with open('{}_valid_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    valid_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_valid_codes'.format(vgg_name)) as f:\n",
    "    val_x = np.fromfile(f, dtype=np.float32)\n",
    "    val_x = val_x.reshape((len(valid_labels), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = lb.transform(train_labels)\n",
    "val_y = lb.transform(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (10000, 4096) (10000, 3)\n",
      "Validation shapes (x, y): (150, 4096) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, train_y.shape[1]])\n",
    "\n",
    "fc_1 = tf.contrib.layers.fully_connected(inputs_, 512)\n",
    "dropout_1 = tf.contrib.layers.dropout(fc_1)\n",
    "fc_2 = tf.contrib.layers.fully_connected(dropout_1, 128)\n",
    "dropout_2 = tf.contrib.layers.dropout(fc_2)\n",
    "    \n",
    "logits = tf.contrib.layers.fully_connected(dropout_2, train_y.shape[1], activation_fn=None)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001).minimize(cost)\n",
    "\n",
    "predicted = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "train_x_shuffled, train_y_shuffled = sklearn.utils.shuffle(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: checkpoints: File exists\n",
      "Epoch: 1/200 Iteration: 0 Training loss: 4.79246\n",
      "Epoch: 1/200 Iteration: 1 Training loss: 3.98259\n",
      "Epoch: 1/200 Iteration: 2 Training loss: 3.71347\n",
      "Epoch: 1/200 Iteration: 3 Training loss: 3.64130\n",
      "Epoch: 1/200 Iteration: 4 Training loss: 3.55263\n",
      "Epoch: 0/200 Iteration: 5 Validation Acc: 0.4800\n",
      "Epoch: 2/200 Iteration: 5 Training loss: 3.55986\n",
      "Epoch: 2/200 Iteration: 6 Training loss: 3.37187\n",
      "Epoch: 2/200 Iteration: 7 Training loss: 3.22494\n",
      "Epoch: 2/200 Iteration: 8 Training loss: 3.24324\n",
      "Epoch: 2/200 Iteration: 9 Training loss: 2.89744\n",
      "Epoch: 1/200 Iteration: 10 Validation Acc: 0.4000\n",
      "Epoch: 3/200 Iteration: 10 Training loss: 3.07067\n",
      "Epoch: 3/200 Iteration: 11 Training loss: 2.91820\n",
      "Epoch: 3/200 Iteration: 12 Training loss: 2.62414\n",
      "Epoch: 3/200 Iteration: 13 Training loss: 2.69203\n",
      "Epoch: 3/200 Iteration: 14 Training loss: 2.55110\n",
      "Epoch: 2/200 Iteration: 15 Validation Acc: 0.3800\n",
      "Epoch: 4/200 Iteration: 15 Training loss: 2.48756\n",
      "Epoch: 4/200 Iteration: 16 Training loss: 2.37419\n",
      "Epoch: 4/200 Iteration: 17 Training loss: 2.19145\n",
      "Epoch: 4/200 Iteration: 18 Training loss: 2.26262\n",
      "Epoch: 4/200 Iteration: 19 Training loss: 2.11332\n",
      "Epoch: 3/200 Iteration: 20 Validation Acc: 0.4467\n",
      "Epoch: 5/200 Iteration: 20 Training loss: 2.29855\n",
      "Epoch: 5/200 Iteration: 21 Training loss: 2.06787\n",
      "Epoch: 5/200 Iteration: 22 Training loss: 1.96589\n",
      "Epoch: 5/200 Iteration: 23 Training loss: 1.94634\n",
      "Epoch: 5/200 Iteration: 24 Training loss: 1.83460\n",
      "Epoch: 4/200 Iteration: 25 Validation Acc: 0.4733\n",
      "Epoch: 6/200 Iteration: 25 Training loss: 1.85331\n",
      "Epoch: 6/200 Iteration: 26 Training loss: 1.70431\n",
      "Epoch: 6/200 Iteration: 27 Training loss: 1.67680\n",
      "Epoch: 6/200 Iteration: 28 Training loss: 1.69029\n",
      "Epoch: 6/200 Iteration: 29 Training loss: 1.58500\n",
      "Epoch: 5/200 Iteration: 30 Validation Acc: 0.5067\n",
      "Epoch: 7/200 Iteration: 30 Training loss: 1.61801\n",
      "Epoch: 7/200 Iteration: 31 Training loss: 1.51134\n",
      "Epoch: 7/200 Iteration: 32 Training loss: 1.43190\n",
      "Epoch: 7/200 Iteration: 33 Training loss: 1.46056\n",
      "Epoch: 7/200 Iteration: 34 Training loss: 1.45318\n",
      "Epoch: 6/200 Iteration: 35 Validation Acc: 0.4667\n",
      "Epoch: 8/200 Iteration: 35 Training loss: 1.40547\n",
      "Epoch: 8/200 Iteration: 36 Training loss: 1.43460\n",
      "Epoch: 8/200 Iteration: 37 Training loss: 1.31569\n",
      "Epoch: 8/200 Iteration: 38 Training loss: 1.39321\n",
      "Epoch: 8/200 Iteration: 39 Training loss: 1.29557\n",
      "Epoch: 7/200 Iteration: 40 Validation Acc: 0.4800\n",
      "Epoch: 9/200 Iteration: 40 Training loss: 1.36407\n",
      "Epoch: 9/200 Iteration: 41 Training loss: 1.21172\n",
      "Epoch: 9/200 Iteration: 42 Training loss: 1.18194\n",
      "Epoch: 9/200 Iteration: 43 Training loss: 1.25635\n",
      "Epoch: 9/200 Iteration: 44 Training loss: 1.14007\n",
      "Epoch: 8/200 Iteration: 45 Validation Acc: 0.5267\n",
      "Epoch: 10/200 Iteration: 45 Training loss: 1.20474\n",
      "Epoch: 10/200 Iteration: 46 Training loss: 1.21062\n",
      "Epoch: 10/200 Iteration: 47 Training loss: 1.13573\n",
      "Epoch: 10/200 Iteration: 48 Training loss: 1.13206\n",
      "Epoch: 10/200 Iteration: 49 Training loss: 1.07684\n",
      "Epoch: 9/200 Iteration: 50 Validation Acc: 0.5133\n",
      "Epoch: 11/200 Iteration: 50 Training loss: 1.15868\n",
      "Epoch: 11/200 Iteration: 51 Training loss: 1.07910\n",
      "Epoch: 11/200 Iteration: 52 Training loss: 1.04241\n",
      "Epoch: 11/200 Iteration: 53 Training loss: 1.02965\n",
      "Epoch: 11/200 Iteration: 54 Training loss: 0.98732\n",
      "Epoch: 10/200 Iteration: 55 Validation Acc: 0.4667\n",
      "Epoch: 12/200 Iteration: 55 Training loss: 1.07938\n",
      "Epoch: 12/200 Iteration: 56 Training loss: 1.02055\n",
      "Epoch: 12/200 Iteration: 57 Training loss: 0.95198\n",
      "Epoch: 12/200 Iteration: 58 Training loss: 0.96797\n",
      "Epoch: 12/200 Iteration: 59 Training loss: 0.92065\n",
      "Epoch: 11/200 Iteration: 60 Validation Acc: 0.5400\n",
      "Epoch: 13/200 Iteration: 60 Training loss: 1.01033\n",
      "Epoch: 13/200 Iteration: 61 Training loss: 0.94762\n",
      "Epoch: 13/200 Iteration: 62 Training loss: 0.92335\n",
      "Epoch: 13/200 Iteration: 63 Training loss: 0.97669\n",
      "Epoch: 13/200 Iteration: 64 Training loss: 0.91284\n",
      "Epoch: 12/200 Iteration: 65 Validation Acc: 0.5333\n",
      "Epoch: 14/200 Iteration: 65 Training loss: 0.93762\n",
      "Epoch: 14/200 Iteration: 66 Training loss: 0.91815\n",
      "Epoch: 14/200 Iteration: 67 Training loss: 0.88397\n",
      "Epoch: 14/200 Iteration: 68 Training loss: 0.90393\n",
      "Epoch: 14/200 Iteration: 69 Training loss: 0.85997\n",
      "Epoch: 13/200 Iteration: 70 Validation Acc: 0.5133\n",
      "Epoch: 15/200 Iteration: 70 Training loss: 0.89470\n",
      "Epoch: 15/200 Iteration: 71 Training loss: 0.88856\n",
      "Epoch: 15/200 Iteration: 72 Training loss: 0.84071\n",
      "Epoch: 15/200 Iteration: 73 Training loss: 0.87446\n",
      "Epoch: 15/200 Iteration: 74 Training loss: 0.83036\n",
      "Epoch: 14/200 Iteration: 75 Validation Acc: 0.5067\n",
      "Epoch: 16/200 Iteration: 75 Training loss: 0.86856\n",
      "Epoch: 16/200 Iteration: 76 Training loss: 0.85958\n",
      "Epoch: 16/200 Iteration: 77 Training loss: 0.83016\n",
      "Epoch: 16/200 Iteration: 78 Training loss: 0.86370\n",
      "Epoch: 16/200 Iteration: 79 Training loss: 0.81405\n",
      "Epoch: 15/200 Iteration: 80 Validation Acc: 0.5333\n",
      "Epoch: 17/200 Iteration: 80 Training loss: 0.85642\n",
      "Epoch: 17/200 Iteration: 81 Training loss: 0.81310\n",
      "Epoch: 17/200 Iteration: 82 Training loss: 0.84556\n",
      "Epoch: 17/200 Iteration: 83 Training loss: 0.92149\n",
      "Epoch: 17/200 Iteration: 84 Training loss: 0.88642\n",
      "Epoch: 16/200 Iteration: 85 Validation Acc: 0.5333\n",
      "Epoch: 18/200 Iteration: 85 Training loss: 0.95234\n",
      "Epoch: 18/200 Iteration: 86 Training loss: 0.87837\n",
      "Epoch: 18/200 Iteration: 87 Training loss: 0.80899\n",
      "Epoch: 18/200 Iteration: 88 Training loss: 0.83843\n",
      "Epoch: 18/200 Iteration: 89 Training loss: 0.78687\n",
      "Epoch: 17/200 Iteration: 90 Validation Acc: 0.5400\n",
      "Epoch: 19/200 Iteration: 90 Training loss: 0.88511\n",
      "Epoch: 19/200 Iteration: 91 Training loss: 0.85886\n",
      "Epoch: 19/200 Iteration: 92 Training loss: 0.92828\n",
      "Epoch: 19/200 Iteration: 93 Training loss: 0.83851\n",
      "Epoch: 19/200 Iteration: 94 Training loss: 0.82415\n",
      "Epoch: 18/200 Iteration: 95 Validation Acc: 0.6067\n",
      "Epoch: 20/200 Iteration: 95 Training loss: 0.80864\n",
      "Epoch: 20/200 Iteration: 96 Training loss: 0.89475\n",
      "Epoch: 20/200 Iteration: 97 Training loss: 0.81674\n",
      "Epoch: 20/200 Iteration: 98 Training loss: 0.83225\n",
      "Epoch: 20/200 Iteration: 99 Training loss: 0.82016\n",
      "Epoch: 19/200 Iteration: 100 Validation Acc: 0.5000\n",
      "Epoch: 21/200 Iteration: 100 Training loss: 0.91239\n",
      "Epoch: 21/200 Iteration: 101 Training loss: 0.94853\n",
      "Epoch: 21/200 Iteration: 102 Training loss: 0.86810\n",
      "Epoch: 21/200 Iteration: 103 Training loss: 0.85588\n",
      "Epoch: 21/200 Iteration: 104 Training loss: 0.83002\n",
      "Epoch: 20/200 Iteration: 105 Validation Acc: 0.5400\n",
      "Epoch: 22/200 Iteration: 105 Training loss: 0.99723\n",
      "Epoch: 22/200 Iteration: 106 Training loss: 0.96538\n",
      "Epoch: 22/200 Iteration: 107 Training loss: 0.88560\n",
      "Epoch: 22/200 Iteration: 108 Training loss: 0.90247\n",
      "Epoch: 22/200 Iteration: 109 Training loss: 0.91538\n",
      "Epoch: 21/200 Iteration: 110 Validation Acc: 0.5533\n",
      "Epoch: 23/200 Iteration: 110 Training loss: 0.83078\n",
      "Epoch: 23/200 Iteration: 111 Training loss: 0.81164\n",
      "Epoch: 23/200 Iteration: 112 Training loss: 0.79656\n",
      "Epoch: 23/200 Iteration: 113 Training loss: 0.95912\n",
      "Epoch: 23/200 Iteration: 114 Training loss: 0.94684\n",
      "Epoch: 22/200 Iteration: 115 Validation Acc: 0.5000\n",
      "Epoch: 24/200 Iteration: 115 Training loss: 1.12576\n",
      "Epoch: 24/200 Iteration: 116 Training loss: 0.87835\n",
      "Epoch: 24/200 Iteration: 117 Training loss: 0.77572\n",
      "Epoch: 24/200 Iteration: 118 Training loss: 0.79830\n",
      "Epoch: 24/200 Iteration: 119 Training loss: 0.78298\n",
      "Epoch: 23/200 Iteration: 120 Validation Acc: 0.5333\n",
      "Epoch: 25/200 Iteration: 120 Training loss: 0.95066\n",
      "Epoch: 25/200 Iteration: 121 Training loss: 0.93211\n",
      "Epoch: 25/200 Iteration: 122 Training loss: 0.81938\n",
      "Epoch: 25/200 Iteration: 123 Training loss: 0.83405\n",
      "Epoch: 25/200 Iteration: 124 Training loss: 0.73513\n",
      "Epoch: 24/200 Iteration: 125 Validation Acc: 0.5600\n",
      "Epoch: 26/200 Iteration: 125 Training loss: 0.95432\n",
      "Epoch: 26/200 Iteration: 126 Training loss: 0.81184\n",
      "Epoch: 26/200 Iteration: 127 Training loss: 0.78498\n",
      "Epoch: 26/200 Iteration: 128 Training loss: 0.84936\n",
      "Epoch: 26/200 Iteration: 129 Training loss: 0.97300\n",
      "Epoch: 25/200 Iteration: 130 Validation Acc: 0.5467\n",
      "Epoch: 27/200 Iteration: 130 Training loss: 1.02989\n",
      "Epoch: 27/200 Iteration: 131 Training loss: 0.80622\n",
      "Epoch: 27/200 Iteration: 132 Training loss: 0.74187\n",
      "Epoch: 27/200 Iteration: 133 Training loss: 0.75955\n",
      "Epoch: 27/200 Iteration: 134 Training loss: 0.71245\n",
      "Epoch: 26/200 Iteration: 135 Validation Acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/200 Iteration: 135 Training loss: 0.76384\n",
      "Epoch: 28/200 Iteration: 136 Training loss: 0.81519\n",
      "Epoch: 28/200 Iteration: 137 Training loss: 0.83464\n",
      "Epoch: 28/200 Iteration: 138 Training loss: 1.17708\n",
      "Epoch: 28/200 Iteration: 139 Training loss: 1.10830\n",
      "Epoch: 27/200 Iteration: 140 Validation Acc: 0.4667\n",
      "Epoch: 29/200 Iteration: 140 Training loss: 1.62440\n",
      "Epoch: 29/200 Iteration: 141 Training loss: 1.01107\n",
      "Epoch: 29/200 Iteration: 142 Training loss: 0.84105\n",
      "Epoch: 29/200 Iteration: 143 Training loss: 0.80321\n",
      "Epoch: 29/200 Iteration: 144 Training loss: 0.73977\n",
      "Epoch: 28/200 Iteration: 145 Validation Acc: 0.5467\n",
      "Epoch: 30/200 Iteration: 145 Training loss: 0.76020\n",
      "Epoch: 30/200 Iteration: 146 Training loss: 0.72818\n",
      "Epoch: 30/200 Iteration: 147 Training loss: 0.75727\n",
      "Epoch: 30/200 Iteration: 148 Training loss: 0.79500\n",
      "Epoch: 30/200 Iteration: 149 Training loss: 0.77598\n",
      "Epoch: 29/200 Iteration: 150 Validation Acc: 0.6267\n",
      "Epoch: 31/200 Iteration: 150 Training loss: 0.76522\n",
      "Epoch: 31/200 Iteration: 151 Training loss: 0.76395\n",
      "Epoch: 31/200 Iteration: 152 Training loss: 0.82845\n",
      "Epoch: 31/200 Iteration: 153 Training loss: 0.91971\n",
      "Epoch: 31/200 Iteration: 154 Training loss: 0.84125\n",
      "Epoch: 30/200 Iteration: 155 Validation Acc: 0.5400\n",
      "Epoch: 32/200 Iteration: 155 Training loss: 0.83274\n",
      "Epoch: 32/200 Iteration: 156 Training loss: 0.74820\n",
      "Epoch: 32/200 Iteration: 157 Training loss: 0.74933\n",
      "Epoch: 32/200 Iteration: 158 Training loss: 0.96392\n",
      "Epoch: 32/200 Iteration: 159 Training loss: 0.87714\n",
      "Epoch: 31/200 Iteration: 160 Validation Acc: 0.5333\n",
      "Epoch: 33/200 Iteration: 160 Training loss: 0.85183\n",
      "Epoch: 33/200 Iteration: 161 Training loss: 0.81481\n",
      "Epoch: 33/200 Iteration: 162 Training loss: 0.74000\n",
      "Epoch: 33/200 Iteration: 163 Training loss: 0.74154\n",
      "Epoch: 33/200 Iteration: 164 Training loss: 0.72340\n",
      "Epoch: 32/200 Iteration: 165 Validation Acc: 0.6067\n",
      "Epoch: 34/200 Iteration: 165 Training loss: 0.73722\n",
      "Epoch: 34/200 Iteration: 166 Training loss: 0.71806\n",
      "Epoch: 34/200 Iteration: 167 Training loss: 0.75480\n",
      "Epoch: 34/200 Iteration: 168 Training loss: 0.99722\n",
      "Epoch: 34/200 Iteration: 169 Training loss: 0.73039\n",
      "Epoch: 33/200 Iteration: 170 Validation Acc: 0.5733\n",
      "Epoch: 35/200 Iteration: 170 Training loss: 0.71278\n",
      "Epoch: 35/200 Iteration: 171 Training loss: 0.70988\n",
      "Epoch: 35/200 Iteration: 172 Training loss: 0.78106\n",
      "Epoch: 35/200 Iteration: 173 Training loss: 0.80651\n",
      "Epoch: 35/200 Iteration: 174 Training loss: 0.87646\n",
      "Epoch: 34/200 Iteration: 175 Validation Acc: 0.6067\n",
      "Epoch: 36/200 Iteration: 175 Training loss: 0.78862\n",
      "Epoch: 36/200 Iteration: 176 Training loss: 0.78068\n",
      "Epoch: 36/200 Iteration: 177 Training loss: 0.78337\n",
      "Epoch: 36/200 Iteration: 178 Training loss: 0.80055\n",
      "Epoch: 36/200 Iteration: 179 Training loss: 0.73719\n",
      "Epoch: 35/200 Iteration: 180 Validation Acc: 0.5733\n",
      "Epoch: 37/200 Iteration: 180 Training loss: 0.73555\n",
      "Epoch: 37/200 Iteration: 181 Training loss: 0.76352\n",
      "Epoch: 37/200 Iteration: 182 Training loss: 0.78234\n",
      "Epoch: 37/200 Iteration: 183 Training loss: 0.74743\n",
      "Epoch: 37/200 Iteration: 184 Training loss: 0.68937\n",
      "Epoch: 36/200 Iteration: 185 Validation Acc: 0.6133\n",
      "Epoch: 38/200 Iteration: 185 Training loss: 0.66989\n",
      "Epoch: 38/200 Iteration: 186 Training loss: 0.65601\n",
      "Epoch: 38/200 Iteration: 187 Training loss: 0.68638\n",
      "Epoch: 38/200 Iteration: 188 Training loss: 0.82411\n",
      "Epoch: 38/200 Iteration: 189 Training loss: 0.73533\n",
      "Epoch: 37/200 Iteration: 190 Validation Acc: 0.5733\n",
      "Epoch: 39/200 Iteration: 190 Training loss: 0.79801\n",
      "Epoch: 39/200 Iteration: 191 Training loss: 0.72019\n",
      "Epoch: 39/200 Iteration: 192 Training loss: 0.69755\n",
      "Epoch: 39/200 Iteration: 193 Training loss: 0.70570\n",
      "Epoch: 39/200 Iteration: 194 Training loss: 0.64331\n",
      "Epoch: 38/200 Iteration: 195 Validation Acc: 0.6200\n",
      "Epoch: 40/200 Iteration: 195 Training loss: 0.68616\n",
      "Epoch: 40/200 Iteration: 196 Training loss: 0.70512\n",
      "Epoch: 40/200 Iteration: 197 Training loss: 0.71593\n",
      "Epoch: 40/200 Iteration: 198 Training loss: 0.77840\n",
      "Epoch: 40/200 Iteration: 199 Training loss: 0.75123\n",
      "Epoch: 39/200 Iteration: 200 Validation Acc: 0.5667\n",
      "Epoch: 41/200 Iteration: 200 Training loss: 0.78411\n",
      "Epoch: 41/200 Iteration: 201 Training loss: 0.69430\n",
      "Epoch: 41/200 Iteration: 202 Training loss: 0.67156\n",
      "Epoch: 41/200 Iteration: 203 Training loss: 0.69548\n",
      "Epoch: 41/200 Iteration: 204 Training loss: 0.66220\n",
      "Epoch: 40/200 Iteration: 205 Validation Acc: 0.6533\n",
      "Epoch: 42/200 Iteration: 205 Training loss: 0.66744\n",
      "Epoch: 42/200 Iteration: 206 Training loss: 0.75103\n",
      "Epoch: 42/200 Iteration: 207 Training loss: 0.68936\n",
      "Epoch: 42/200 Iteration: 208 Training loss: 0.72591\n",
      "Epoch: 42/200 Iteration: 209 Training loss: 0.68611\n",
      "Epoch: 41/200 Iteration: 210 Validation Acc: 0.5867\n",
      "Epoch: 43/200 Iteration: 210 Training loss: 0.71141\n",
      "Epoch: 43/200 Iteration: 211 Training loss: 0.70624\n",
      "Epoch: 43/200 Iteration: 212 Training loss: 0.71643\n",
      "Epoch: 43/200 Iteration: 213 Training loss: 0.71812\n",
      "Epoch: 43/200 Iteration: 214 Training loss: 0.68038\n",
      "Epoch: 42/200 Iteration: 215 Validation Acc: 0.5800\n",
      "Epoch: 44/200 Iteration: 215 Training loss: 0.64663\n",
      "Epoch: 44/200 Iteration: 216 Training loss: 0.61495\n",
      "Epoch: 44/200 Iteration: 217 Training loss: 0.62726\n",
      "Epoch: 44/200 Iteration: 218 Training loss: 0.76688\n",
      "Epoch: 44/200 Iteration: 219 Training loss: 0.69073\n",
      "Epoch: 43/200 Iteration: 220 Validation Acc: 0.5800\n",
      "Epoch: 45/200 Iteration: 220 Training loss: 0.82931\n",
      "Epoch: 45/200 Iteration: 221 Training loss: 0.79161\n",
      "Epoch: 45/200 Iteration: 222 Training loss: 0.70038\n",
      "Epoch: 45/200 Iteration: 223 Training loss: 0.63398\n",
      "Epoch: 45/200 Iteration: 224 Training loss: 0.63536\n",
      "Epoch: 44/200 Iteration: 225 Validation Acc: 0.6467\n",
      "Epoch: 46/200 Iteration: 225 Training loss: 0.70342\n",
      "Epoch: 46/200 Iteration: 226 Training loss: 0.76838\n",
      "Epoch: 46/200 Iteration: 227 Training loss: 0.72138\n",
      "Epoch: 46/200 Iteration: 228 Training loss: 0.71371\n",
      "Epoch: 46/200 Iteration: 229 Training loss: 0.66440\n",
      "Epoch: 45/200 Iteration: 230 Validation Acc: 0.6000\n",
      "Epoch: 47/200 Iteration: 230 Training loss: 0.66085\n",
      "Epoch: 47/200 Iteration: 231 Training loss: 0.61130\n",
      "Epoch: 47/200 Iteration: 232 Training loss: 0.62149\n",
      "Epoch: 47/200 Iteration: 233 Training loss: 0.62189\n",
      "Epoch: 47/200 Iteration: 234 Training loss: 0.57252\n",
      "Epoch: 46/200 Iteration: 235 Validation Acc: 0.6200\n",
      "Epoch: 48/200 Iteration: 235 Training loss: 0.62679\n",
      "Epoch: 48/200 Iteration: 236 Training loss: 0.70198\n",
      "Epoch: 48/200 Iteration: 237 Training loss: 0.68993\n",
      "Epoch: 48/200 Iteration: 238 Training loss: 0.71324\n",
      "Epoch: 48/200 Iteration: 239 Training loss: 0.65492\n",
      "Epoch: 47/200 Iteration: 240 Validation Acc: 0.5667\n",
      "Epoch: 49/200 Iteration: 240 Training loss: 0.64912\n",
      "Epoch: 49/200 Iteration: 241 Training loss: 0.67398\n",
      "Epoch: 49/200 Iteration: 242 Training loss: 0.69055\n",
      "Epoch: 49/200 Iteration: 243 Training loss: 0.63216\n",
      "Epoch: 49/200 Iteration: 244 Training loss: 0.55416\n",
      "Epoch: 48/200 Iteration: 245 Validation Acc: 0.6867\n",
      "Epoch: 50/200 Iteration: 245 Training loss: 0.57275\n",
      "Epoch: 50/200 Iteration: 246 Training loss: 0.57746\n",
      "Epoch: 50/200 Iteration: 247 Training loss: 0.63062\n",
      "Epoch: 50/200 Iteration: 248 Training loss: 0.67887\n",
      "Epoch: 50/200 Iteration: 249 Training loss: 0.58175\n",
      "Epoch: 49/200 Iteration: 250 Validation Acc: 0.6600\n",
      "Epoch: 51/200 Iteration: 250 Training loss: 0.58128\n",
      "Epoch: 51/200 Iteration: 251 Training loss: 0.58732\n",
      "Epoch: 51/200 Iteration: 252 Training loss: 0.67203\n",
      "Epoch: 51/200 Iteration: 253 Training loss: 0.85255\n",
      "Epoch: 51/200 Iteration: 254 Training loss: 0.64759\n",
      "Epoch: 50/200 Iteration: 255 Validation Acc: 0.5800\n",
      "Epoch: 52/200 Iteration: 255 Training loss: 0.63581\n",
      "Epoch: 52/200 Iteration: 256 Training loss: 0.56792\n",
      "Epoch: 52/200 Iteration: 257 Training loss: 0.55304\n",
      "Epoch: 52/200 Iteration: 258 Training loss: 0.67954\n",
      "Epoch: 52/200 Iteration: 259 Training loss: 0.69753\n",
      "Epoch: 51/200 Iteration: 260 Validation Acc: 0.6200\n",
      "Epoch: 53/200 Iteration: 260 Training loss: 0.63281\n",
      "Epoch: 53/200 Iteration: 261 Training loss: 0.57189\n",
      "Epoch: 53/200 Iteration: 262 Training loss: 0.55737\n",
      "Epoch: 53/200 Iteration: 263 Training loss: 0.60715\n",
      "Epoch: 53/200 Iteration: 264 Training loss: 0.59047\n",
      "Epoch: 52/200 Iteration: 265 Validation Acc: 0.6600\n",
      "Epoch: 54/200 Iteration: 265 Training loss: 0.66051\n",
      "Epoch: 54/200 Iteration: 266 Training loss: 0.61827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/200 Iteration: 267 Training loss: 0.55088\n",
      "Epoch: 54/200 Iteration: 268 Training loss: 0.55518\n",
      "Epoch: 54/200 Iteration: 269 Training loss: 0.54586\n",
      "Epoch: 53/200 Iteration: 270 Validation Acc: 0.6800\n",
      "Epoch: 55/200 Iteration: 270 Training loss: 0.59734\n",
      "Epoch: 55/200 Iteration: 271 Training loss: 0.68161\n",
      "Epoch: 55/200 Iteration: 272 Training loss: 0.69412\n",
      "Epoch: 55/200 Iteration: 273 Training loss: 0.77622\n",
      "Epoch: 55/200 Iteration: 274 Training loss: 0.61714\n",
      "Epoch: 54/200 Iteration: 275 Validation Acc: 0.6200\n",
      "Epoch: 56/200 Iteration: 275 Training loss: 0.54596\n",
      "Epoch: 56/200 Iteration: 276 Training loss: 0.53029\n",
      "Epoch: 56/200 Iteration: 277 Training loss: 0.50688\n",
      "Epoch: 56/200 Iteration: 278 Training loss: 0.53110\n",
      "Epoch: 56/200 Iteration: 279 Training loss: 0.55957\n",
      "Epoch: 55/200 Iteration: 280 Validation Acc: 0.6467\n",
      "Epoch: 57/200 Iteration: 280 Training loss: 0.71577\n",
      "Epoch: 57/200 Iteration: 281 Training loss: 0.63653\n",
      "Epoch: 57/200 Iteration: 282 Training loss: 0.57093\n",
      "Epoch: 57/200 Iteration: 283 Training loss: 0.56624\n",
      "Epoch: 57/200 Iteration: 284 Training loss: 0.53369\n",
      "Epoch: 56/200 Iteration: 285 Validation Acc: 0.6533\n",
      "Epoch: 58/200 Iteration: 285 Training loss: 0.52602\n",
      "Epoch: 58/200 Iteration: 286 Training loss: 0.54905\n",
      "Epoch: 58/200 Iteration: 287 Training loss: 0.61262\n",
      "Epoch: 58/200 Iteration: 288 Training loss: 0.65153\n",
      "Epoch: 58/200 Iteration: 289 Training loss: 0.58363\n",
      "Epoch: 57/200 Iteration: 290 Validation Acc: 0.6067\n",
      "Epoch: 59/200 Iteration: 290 Training loss: 0.55503\n",
      "Epoch: 59/200 Iteration: 291 Training loss: 0.52542\n",
      "Epoch: 59/200 Iteration: 292 Training loss: 0.52815\n",
      "Epoch: 59/200 Iteration: 293 Training loss: 0.58040\n",
      "Epoch: 59/200 Iteration: 294 Training loss: 0.50816\n",
      "Epoch: 58/200 Iteration: 295 Validation Acc: 0.7067\n",
      "Epoch: 60/200 Iteration: 295 Training loss: 0.50604\n",
      "Epoch: 60/200 Iteration: 296 Training loss: 0.49826\n",
      "Epoch: 60/200 Iteration: 297 Training loss: 0.55432\n",
      "Epoch: 60/200 Iteration: 298 Training loss: 0.74760\n",
      "Epoch: 60/200 Iteration: 299 Training loss: 0.73270\n",
      "Epoch: 59/200 Iteration: 300 Validation Acc: 0.5467\n",
      "Epoch: 61/200 Iteration: 300 Training loss: 0.82957\n",
      "Epoch: 61/200 Iteration: 301 Training loss: 0.59378\n",
      "Epoch: 61/200 Iteration: 302 Training loss: 0.50891\n",
      "Epoch: 61/200 Iteration: 303 Training loss: 0.52593\n",
      "Epoch: 61/200 Iteration: 304 Training loss: 0.48495\n",
      "Epoch: 60/200 Iteration: 305 Validation Acc: 0.6733\n",
      "Epoch: 62/200 Iteration: 305 Training loss: 0.55859\n",
      "Epoch: 62/200 Iteration: 306 Training loss: 0.58579\n",
      "Epoch: 62/200 Iteration: 307 Training loss: 0.54910\n",
      "Epoch: 62/200 Iteration: 308 Training loss: 0.51027\n",
      "Epoch: 62/200 Iteration: 309 Training loss: 0.44954\n",
      "Epoch: 61/200 Iteration: 310 Validation Acc: 0.6800\n",
      "Epoch: 63/200 Iteration: 310 Training loss: 0.55005\n",
      "Epoch: 63/200 Iteration: 311 Training loss: 0.56357\n",
      "Epoch: 63/200 Iteration: 312 Training loss: 0.54681\n",
      "Epoch: 63/200 Iteration: 313 Training loss: 0.50176\n",
      "Epoch: 63/200 Iteration: 314 Training loss: 0.44929\n",
      "Epoch: 62/200 Iteration: 315 Validation Acc: 0.6867\n",
      "Epoch: 64/200 Iteration: 315 Training loss: 0.47234\n",
      "Epoch: 64/200 Iteration: 316 Training loss: 0.53002\n",
      "Epoch: 64/200 Iteration: 317 Training loss: 0.82412\n",
      "Epoch: 64/200 Iteration: 318 Training loss: 0.77981\n",
      "Epoch: 64/200 Iteration: 319 Training loss: 0.58082\n",
      "Epoch: 63/200 Iteration: 320 Validation Acc: 0.6067\n",
      "Epoch: 65/200 Iteration: 320 Training loss: 0.51799\n",
      "Epoch: 65/200 Iteration: 321 Training loss: 0.46943\n",
      "Epoch: 65/200 Iteration: 322 Training loss: 0.45115\n",
      "Epoch: 65/200 Iteration: 323 Training loss: 0.49328\n",
      "Epoch: 65/200 Iteration: 324 Training loss: 0.50552\n",
      "Epoch: 64/200 Iteration: 325 Validation Acc: 0.6267\n",
      "Epoch: 66/200 Iteration: 325 Training loss: 0.55759\n",
      "Epoch: 66/200 Iteration: 326 Training loss: 0.49075\n",
      "Epoch: 66/200 Iteration: 327 Training loss: 0.45994\n",
      "Epoch: 66/200 Iteration: 328 Training loss: 0.47721\n",
      "Epoch: 66/200 Iteration: 329 Training loss: 0.43089\n",
      "Epoch: 65/200 Iteration: 330 Validation Acc: 0.6133\n",
      "Epoch: 67/200 Iteration: 330 Training loss: 0.48943\n",
      "Epoch: 67/200 Iteration: 331 Training loss: 0.56182\n",
      "Epoch: 67/200 Iteration: 332 Training loss: 0.64972\n",
      "Epoch: 67/200 Iteration: 333 Training loss: 0.55126\n",
      "Epoch: 67/200 Iteration: 334 Training loss: 0.45106\n",
      "Epoch: 66/200 Iteration: 335 Validation Acc: 0.6400\n",
      "Epoch: 68/200 Iteration: 335 Training loss: 0.45241\n",
      "Epoch: 68/200 Iteration: 336 Training loss: 0.47374\n",
      "Epoch: 68/200 Iteration: 337 Training loss: 0.55556\n",
      "Epoch: 68/200 Iteration: 338 Training loss: 0.59290\n",
      "Epoch: 68/200 Iteration: 339 Training loss: 0.45931\n",
      "Epoch: 67/200 Iteration: 340 Validation Acc: 0.6267\n",
      "Epoch: 69/200 Iteration: 340 Training loss: 0.47355\n",
      "Epoch: 69/200 Iteration: 341 Training loss: 0.44297\n",
      "Epoch: 69/200 Iteration: 342 Training loss: 0.50678\n",
      "Epoch: 69/200 Iteration: 343 Training loss: 0.59192\n",
      "Epoch: 69/200 Iteration: 344 Training loss: 0.55033\n",
      "Epoch: 68/200 Iteration: 345 Validation Acc: 0.7200\n",
      "Epoch: 70/200 Iteration: 345 Training loss: 0.50144\n",
      "Epoch: 70/200 Iteration: 346 Training loss: 0.41788\n",
      "Epoch: 70/200 Iteration: 347 Training loss: 0.43345\n",
      "Epoch: 70/200 Iteration: 348 Training loss: 0.64543\n",
      "Epoch: 70/200 Iteration: 349 Training loss: 0.62428\n",
      "Epoch: 69/200 Iteration: 350 Validation Acc: 0.5933\n",
      "Epoch: 71/200 Iteration: 350 Training loss: 0.56564\n",
      "Epoch: 71/200 Iteration: 351 Training loss: 0.46924\n",
      "Epoch: 71/200 Iteration: 352 Training loss: 0.41154\n",
      "Epoch: 71/200 Iteration: 353 Training loss: 0.44753\n",
      "Epoch: 71/200 Iteration: 354 Training loss: 0.40212\n",
      "Epoch: 70/200 Iteration: 355 Validation Acc: 0.6867\n",
      "Epoch: 72/200 Iteration: 355 Training loss: 0.41704\n",
      "Epoch: 72/200 Iteration: 356 Training loss: 0.43439\n",
      "Epoch: 72/200 Iteration: 357 Training loss: 0.50218\n",
      "Epoch: 72/200 Iteration: 358 Training loss: 0.55218\n",
      "Epoch: 72/200 Iteration: 359 Training loss: 0.52510\n",
      "Epoch: 71/200 Iteration: 360 Validation Acc: 0.6400\n",
      "Epoch: 73/200 Iteration: 360 Training loss: 0.45405\n",
      "Epoch: 73/200 Iteration: 361 Training loss: 0.41278\n",
      "Epoch: 73/200 Iteration: 362 Training loss: 0.42628\n",
      "Epoch: 73/200 Iteration: 363 Training loss: 0.56203\n",
      "Epoch: 73/200 Iteration: 364 Training loss: 0.47955\n",
      "Epoch: 72/200 Iteration: 365 Validation Acc: 0.6133\n",
      "Epoch: 74/200 Iteration: 365 Training loss: 0.50320\n",
      "Epoch: 74/200 Iteration: 366 Training loss: 0.44148\n",
      "Epoch: 74/200 Iteration: 367 Training loss: 0.45688\n",
      "Epoch: 74/200 Iteration: 368 Training loss: 0.44325\n",
      "Epoch: 74/200 Iteration: 369 Training loss: 0.45503\n",
      "Epoch: 73/200 Iteration: 370 Validation Acc: 0.6267\n",
      "Epoch: 75/200 Iteration: 370 Training loss: 0.61659\n",
      "Epoch: 75/200 Iteration: 371 Training loss: 0.60414\n",
      "Epoch: 75/200 Iteration: 372 Training loss: 0.51637\n",
      "Epoch: 75/200 Iteration: 373 Training loss: 0.46189\n",
      "Epoch: 75/200 Iteration: 374 Training loss: 0.42659\n",
      "Epoch: 74/200 Iteration: 375 Validation Acc: 0.6667\n",
      "Epoch: 76/200 Iteration: 375 Training loss: 0.41326\n",
      "Epoch: 76/200 Iteration: 376 Training loss: 0.39360\n",
      "Epoch: 76/200 Iteration: 377 Training loss: 0.41472\n",
      "Epoch: 76/200 Iteration: 378 Training loss: 0.55072\n",
      "Epoch: 76/200 Iteration: 379 Training loss: 0.53322\n",
      "Epoch: 75/200 Iteration: 380 Validation Acc: 0.6200\n",
      "Epoch: 77/200 Iteration: 380 Training loss: 0.50890\n",
      "Epoch: 77/200 Iteration: 381 Training loss: 0.43894\n",
      "Epoch: 77/200 Iteration: 382 Training loss: 0.40036\n",
      "Epoch: 77/200 Iteration: 383 Training loss: 0.40627\n",
      "Epoch: 77/200 Iteration: 384 Training loss: 0.36912\n",
      "Epoch: 76/200 Iteration: 385 Validation Acc: 0.6467\n",
      "Epoch: 78/200 Iteration: 385 Training loss: 0.41491\n",
      "Epoch: 78/200 Iteration: 386 Training loss: 0.41706\n",
      "Epoch: 78/200 Iteration: 387 Training loss: 0.44127\n",
      "Epoch: 78/200 Iteration: 388 Training loss: 0.48503\n",
      "Epoch: 78/200 Iteration: 389 Training loss: 0.43404\n",
      "Epoch: 77/200 Iteration: 390 Validation Acc: 0.6467\n",
      "Epoch: 79/200 Iteration: 390 Training loss: 0.45779\n",
      "Epoch: 79/200 Iteration: 391 Training loss: 0.46146\n",
      "Epoch: 79/200 Iteration: 392 Training loss: 0.49034\n",
      "Epoch: 79/200 Iteration: 393 Training loss: 0.48593\n",
      "Epoch: 79/200 Iteration: 394 Training loss: 0.44111\n",
      "Epoch: 78/200 Iteration: 395 Validation Acc: 0.5933\n",
      "Epoch: 80/200 Iteration: 395 Training loss: 0.43624\n",
      "Epoch: 80/200 Iteration: 396 Training loss: 0.51646\n",
      "Epoch: 80/200 Iteration: 397 Training loss: 0.53661\n",
      "Epoch: 80/200 Iteration: 398 Training loss: 0.51697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/200 Iteration: 399 Training loss: 0.42556\n",
      "Epoch: 79/200 Iteration: 400 Validation Acc: 0.6400\n",
      "Epoch: 81/200 Iteration: 400 Training loss: 0.40652\n",
      "Epoch: 81/200 Iteration: 401 Training loss: 0.37123\n",
      "Epoch: 81/200 Iteration: 402 Training loss: 0.35470\n",
      "Epoch: 81/200 Iteration: 403 Training loss: 0.40832\n",
      "Epoch: 81/200 Iteration: 404 Training loss: 0.43886\n",
      "Epoch: 80/200 Iteration: 405 Validation Acc: 0.6267\n",
      "Epoch: 82/200 Iteration: 405 Training loss: 0.68433\n",
      "Epoch: 82/200 Iteration: 406 Training loss: 0.59047\n",
      "Epoch: 82/200 Iteration: 407 Training loss: 0.44953\n",
      "Epoch: 82/200 Iteration: 408 Training loss: 0.41733\n",
      "Epoch: 82/200 Iteration: 409 Training loss: 0.38410\n",
      "Epoch: 81/200 Iteration: 410 Validation Acc: 0.6733\n",
      "Epoch: 83/200 Iteration: 410 Training loss: 0.39145\n",
      "Epoch: 83/200 Iteration: 411 Training loss: 0.42987\n",
      "Epoch: 83/200 Iteration: 412 Training loss: 0.57967\n",
      "Epoch: 83/200 Iteration: 413 Training loss: 0.65390\n",
      "Epoch: 83/200 Iteration: 414 Training loss: 0.42957\n",
      "Epoch: 82/200 Iteration: 415 Validation Acc: 0.6867\n",
      "Epoch: 84/200 Iteration: 415 Training loss: 0.39601\n",
      "Epoch: 84/200 Iteration: 416 Training loss: 0.35771\n",
      "Epoch: 84/200 Iteration: 417 Training loss: 0.36933\n",
      "Epoch: 84/200 Iteration: 418 Training loss: 0.46125\n",
      "Epoch: 84/200 Iteration: 419 Training loss: 0.44726\n",
      "Epoch: 83/200 Iteration: 420 Validation Acc: 0.6267\n",
      "Epoch: 85/200 Iteration: 420 Training loss: 0.40777\n",
      "Epoch: 85/200 Iteration: 421 Training loss: 0.35559\n",
      "Epoch: 85/200 Iteration: 422 Training loss: 0.33898\n",
      "Epoch: 85/200 Iteration: 423 Training loss: 0.35569\n",
      "Epoch: 85/200 Iteration: 424 Training loss: 0.35574\n",
      "Epoch: 84/200 Iteration: 425 Validation Acc: 0.6133\n",
      "Epoch: 86/200 Iteration: 425 Training loss: 0.46736\n",
      "Epoch: 86/200 Iteration: 426 Training loss: 0.55907\n",
      "Epoch: 86/200 Iteration: 427 Training loss: 0.53271\n",
      "Epoch: 86/200 Iteration: 428 Training loss: 0.54601\n",
      "Epoch: 86/200 Iteration: 429 Training loss: 0.43333\n",
      "Epoch: 85/200 Iteration: 430 Validation Acc: 0.6400\n",
      "Epoch: 87/200 Iteration: 430 Training loss: 0.41295\n",
      "Epoch: 87/200 Iteration: 431 Training loss: 0.34852\n",
      "Epoch: 87/200 Iteration: 432 Training loss: 0.32237\n",
      "Epoch: 87/200 Iteration: 433 Training loss: 0.35563\n",
      "Epoch: 87/200 Iteration: 434 Training loss: 0.34258\n",
      "Epoch: 86/200 Iteration: 435 Validation Acc: 0.6667\n",
      "Epoch: 88/200 Iteration: 435 Training loss: 0.39788\n",
      "Epoch: 88/200 Iteration: 436 Training loss: 0.44623\n",
      "Epoch: 88/200 Iteration: 437 Training loss: 0.46991\n",
      "Epoch: 88/200 Iteration: 438 Training loss: 0.44778\n",
      "Epoch: 88/200 Iteration: 439 Training loss: 0.34479\n",
      "Epoch: 87/200 Iteration: 440 Validation Acc: 0.6600\n",
      "Epoch: 89/200 Iteration: 440 Training loss: 0.34310\n",
      "Epoch: 89/200 Iteration: 441 Training loss: 0.31746\n",
      "Epoch: 89/200 Iteration: 442 Training loss: 0.34817\n",
      "Epoch: 89/200 Iteration: 443 Training loss: 0.35207\n",
      "Epoch: 89/200 Iteration: 444 Training loss: 0.34043\n",
      "Epoch: 88/200 Iteration: 445 Validation Acc: 0.6600\n",
      "Epoch: 90/200 Iteration: 445 Training loss: 0.39360\n",
      "Epoch: 90/200 Iteration: 446 Training loss: 0.50844\n",
      "Epoch: 90/200 Iteration: 447 Training loss: 0.60750\n",
      "Epoch: 90/200 Iteration: 448 Training loss: 0.54646\n",
      "Epoch: 90/200 Iteration: 449 Training loss: 0.40260\n",
      "Epoch: 89/200 Iteration: 450 Validation Acc: 0.6200\n",
      "Epoch: 91/200 Iteration: 450 Training loss: 0.37025\n",
      "Epoch: 91/200 Iteration: 451 Training loss: 0.33011\n",
      "Epoch: 91/200 Iteration: 452 Training loss: 0.35788\n",
      "Epoch: 91/200 Iteration: 453 Training loss: 0.39801\n",
      "Epoch: 91/200 Iteration: 454 Training loss: 0.41729\n",
      "Epoch: 90/200 Iteration: 455 Validation Acc: 0.6333\n",
      "Epoch: 92/200 Iteration: 455 Training loss: 0.41762\n",
      "Epoch: 92/200 Iteration: 456 Training loss: 0.33260\n",
      "Epoch: 92/200 Iteration: 457 Training loss: 0.30646\n",
      "Epoch: 92/200 Iteration: 458 Training loss: 0.32019\n",
      "Epoch: 92/200 Iteration: 459 Training loss: 0.27755\n",
      "Epoch: 91/200 Iteration: 460 Validation Acc: 0.6533\n",
      "Epoch: 93/200 Iteration: 460 Training loss: 0.35071\n",
      "Epoch: 93/200 Iteration: 461 Training loss: 0.40685\n",
      "Epoch: 93/200 Iteration: 462 Training loss: 0.47703\n",
      "Epoch: 93/200 Iteration: 463 Training loss: 0.41167\n",
      "Epoch: 93/200 Iteration: 464 Training loss: 0.32139\n",
      "Epoch: 92/200 Iteration: 465 Validation Acc: 0.6600\n",
      "Epoch: 94/200 Iteration: 465 Training loss: 0.32680\n",
      "Epoch: 94/200 Iteration: 466 Training loss: 0.33803\n",
      "Epoch: 94/200 Iteration: 467 Training loss: 0.42655\n",
      "Epoch: 94/200 Iteration: 468 Training loss: 0.48895\n",
      "Epoch: 94/200 Iteration: 469 Training loss: 0.49541\n",
      "Epoch: 93/200 Iteration: 470 Validation Acc: 0.6467\n",
      "Epoch: 95/200 Iteration: 470 Training loss: 0.49112\n",
      "Epoch: 95/200 Iteration: 471 Training loss: 0.44321\n",
      "Epoch: 95/200 Iteration: 472 Training loss: 0.35791\n",
      "Epoch: 95/200 Iteration: 473 Training loss: 0.36150\n",
      "Epoch: 95/200 Iteration: 474 Training loss: 0.35487\n",
      "Epoch: 94/200 Iteration: 475 Validation Acc: 0.6600\n",
      "Epoch: 96/200 Iteration: 475 Training loss: 0.39417\n",
      "Epoch: 96/200 Iteration: 476 Training loss: 0.33318\n",
      "Epoch: 96/200 Iteration: 477 Training loss: 0.30349\n",
      "Epoch: 96/200 Iteration: 478 Training loss: 0.31532\n",
      "Epoch: 96/200 Iteration: 479 Training loss: 0.31530\n",
      "Epoch: 95/200 Iteration: 480 Validation Acc: 0.6333\n",
      "Epoch: 97/200 Iteration: 480 Training loss: 0.36900\n",
      "Epoch: 97/200 Iteration: 481 Training loss: 0.37752\n",
      "Epoch: 97/200 Iteration: 482 Training loss: 0.40871\n",
      "Epoch: 97/200 Iteration: 483 Training loss: 0.43767\n",
      "Epoch: 97/200 Iteration: 484 Training loss: 0.38507\n",
      "Epoch: 96/200 Iteration: 485 Validation Acc: 0.6533\n",
      "Epoch: 98/200 Iteration: 485 Training loss: 0.36189\n",
      "Epoch: 98/200 Iteration: 486 Training loss: 0.33064\n",
      "Epoch: 98/200 Iteration: 487 Training loss: 0.31304\n",
      "Epoch: 98/200 Iteration: 488 Training loss: 0.33199\n",
      "Epoch: 98/200 Iteration: 489 Training loss: 0.29007\n",
      "Epoch: 97/200 Iteration: 490 Validation Acc: 0.6533\n",
      "Epoch: 99/200 Iteration: 490 Training loss: 0.32582\n",
      "Epoch: 99/200 Iteration: 491 Training loss: 0.32006\n",
      "Epoch: 99/200 Iteration: 492 Training loss: 0.35854\n",
      "Epoch: 99/200 Iteration: 493 Training loss: 0.49440\n",
      "Epoch: 99/200 Iteration: 494 Training loss: 0.45700\n",
      "Epoch: 98/200 Iteration: 495 Validation Acc: 0.5933\n",
      "Epoch: 100/200 Iteration: 495 Training loss: 0.40049\n",
      "Epoch: 100/200 Iteration: 496 Training loss: 0.35424\n",
      "Epoch: 100/200 Iteration: 497 Training loss: 0.30721\n",
      "Epoch: 100/200 Iteration: 498 Training loss: 0.29405\n",
      "Epoch: 100/200 Iteration: 499 Training loss: 0.25615\n",
      "Epoch: 99/200 Iteration: 500 Validation Acc: 0.6667\n",
      "Epoch: 101/200 Iteration: 500 Training loss: 0.26207\n",
      "Epoch: 101/200 Iteration: 501 Training loss: 0.26712\n",
      "Epoch: 101/200 Iteration: 502 Training loss: 0.27347\n",
      "Epoch: 101/200 Iteration: 503 Training loss: 0.27852\n",
      "Epoch: 101/200 Iteration: 504 Training loss: 0.25857\n",
      "Epoch: 100/200 Iteration: 505 Validation Acc: 0.6867\n",
      "Epoch: 102/200 Iteration: 505 Training loss: 0.31679\n",
      "Epoch: 102/200 Iteration: 506 Training loss: 0.36844\n",
      "Epoch: 102/200 Iteration: 507 Training loss: 0.49437\n",
      "Epoch: 102/200 Iteration: 508 Training loss: 0.63296\n",
      "Epoch: 102/200 Iteration: 509 Training loss: 0.42519\n",
      "Epoch: 101/200 Iteration: 510 Validation Acc: 0.6533\n",
      "Epoch: 103/200 Iteration: 510 Training loss: 0.37980\n",
      "Epoch: 103/200 Iteration: 511 Training loss: 0.38501\n",
      "Epoch: 103/200 Iteration: 512 Training loss: 0.48566\n",
      "Epoch: 103/200 Iteration: 513 Training loss: 0.44204\n",
      "Epoch: 103/200 Iteration: 514 Training loss: 0.33446\n",
      "Epoch: 102/200 Iteration: 515 Validation Acc: 0.6400\n",
      "Epoch: 104/200 Iteration: 515 Training loss: 0.30819\n",
      "Epoch: 104/200 Iteration: 516 Training loss: 0.25805\n",
      "Epoch: 104/200 Iteration: 517 Training loss: 0.26736\n",
      "Epoch: 104/200 Iteration: 518 Training loss: 0.36699\n",
      "Epoch: 104/200 Iteration: 519 Training loss: 0.37784\n",
      "Epoch: 103/200 Iteration: 520 Validation Acc: 0.6267\n",
      "Epoch: 105/200 Iteration: 520 Training loss: 0.40768\n",
      "Epoch: 105/200 Iteration: 521 Training loss: 0.32343\n",
      "Epoch: 105/200 Iteration: 522 Training loss: 0.27387\n",
      "Epoch: 105/200 Iteration: 523 Training loss: 0.29947\n",
      "Epoch: 105/200 Iteration: 524 Training loss: 0.28049\n",
      "Epoch: 104/200 Iteration: 525 Validation Acc: 0.6733\n",
      "Epoch: 106/200 Iteration: 525 Training loss: 0.29657\n",
      "Epoch: 106/200 Iteration: 526 Training loss: 0.31752\n",
      "Epoch: 106/200 Iteration: 527 Training loss: 0.44753\n",
      "Epoch: 106/200 Iteration: 528 Training loss: 0.64781\n",
      "Epoch: 106/200 Iteration: 529 Training loss: 0.48302\n",
      "Epoch: 105/200 Iteration: 530 Validation Acc: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/200 Iteration: 530 Training loss: 0.41336\n",
      "Epoch: 107/200 Iteration: 531 Training loss: 0.32847\n",
      "Epoch: 107/200 Iteration: 532 Training loss: 0.27291\n",
      "Epoch: 107/200 Iteration: 533 Training loss: 0.27595\n",
      "Epoch: 107/200 Iteration: 534 Training loss: 0.24448\n",
      "Epoch: 106/200 Iteration: 535 Validation Acc: 0.6267\n",
      "Epoch: 108/200 Iteration: 535 Training loss: 0.26281\n",
      "Epoch: 108/200 Iteration: 536 Training loss: 0.23485\n",
      "Epoch: 108/200 Iteration: 537 Training loss: 0.26329\n",
      "Epoch: 108/200 Iteration: 538 Training loss: 0.33718\n",
      "Epoch: 108/200 Iteration: 539 Training loss: 0.39721\n",
      "Epoch: 107/200 Iteration: 540 Validation Acc: 0.5867\n",
      "Epoch: 109/200 Iteration: 540 Training loss: 0.43488\n",
      "Epoch: 109/200 Iteration: 541 Training loss: 0.37080\n",
      "Epoch: 109/200 Iteration: 542 Training loss: 0.31992\n",
      "Epoch: 109/200 Iteration: 543 Training loss: 0.35536\n",
      "Epoch: 109/200 Iteration: 544 Training loss: 0.31673\n",
      "Epoch: 108/200 Iteration: 545 Validation Acc: 0.6133\n",
      "Epoch: 110/200 Iteration: 545 Training loss: 0.33179\n",
      "Epoch: 110/200 Iteration: 546 Training loss: 0.28452\n",
      "Epoch: 110/200 Iteration: 547 Training loss: 0.26710\n",
      "Epoch: 110/200 Iteration: 548 Training loss: 0.26467\n",
      "Epoch: 110/200 Iteration: 549 Training loss: 0.22089\n",
      "Epoch: 109/200 Iteration: 550 Validation Acc: 0.6067\n",
      "Epoch: 111/200 Iteration: 550 Training loss: 0.24188\n",
      "Epoch: 111/200 Iteration: 551 Training loss: 0.21552\n",
      "Epoch: 111/200 Iteration: 552 Training loss: 0.24237\n",
      "Epoch: 111/200 Iteration: 553 Training loss: 0.26626\n",
      "Epoch: 111/200 Iteration: 554 Training loss: 0.41626\n",
      "Epoch: 110/200 Iteration: 555 Validation Acc: 0.6667\n",
      "Epoch: 112/200 Iteration: 555 Training loss: 0.86034\n",
      "Epoch: 112/200 Iteration: 556 Training loss: 0.72640\n",
      "Epoch: 112/200 Iteration: 557 Training loss: 0.46934\n",
      "Epoch: 112/200 Iteration: 558 Training loss: 0.39054\n",
      "Epoch: 112/200 Iteration: 559 Training loss: 0.30346\n",
      "Epoch: 111/200 Iteration: 560 Validation Acc: 0.7067\n",
      "Epoch: 113/200 Iteration: 560 Training loss: 0.29316\n",
      "Epoch: 113/200 Iteration: 561 Training loss: 0.24008\n",
      "Epoch: 113/200 Iteration: 562 Training loss: 0.25625\n",
      "Epoch: 113/200 Iteration: 563 Training loss: 0.29154\n",
      "Epoch: 113/200 Iteration: 564 Training loss: 0.27218\n",
      "Epoch: 112/200 Iteration: 565 Validation Acc: 0.6333\n",
      "Epoch: 114/200 Iteration: 565 Training loss: 0.28300\n",
      "Epoch: 114/200 Iteration: 566 Training loss: 0.25510\n",
      "Epoch: 114/200 Iteration: 567 Training loss: 0.25025\n",
      "Epoch: 114/200 Iteration: 568 Training loss: 0.24065\n",
      "Epoch: 114/200 Iteration: 569 Training loss: 0.22935\n",
      "Epoch: 113/200 Iteration: 570 Validation Acc: 0.6600\n",
      "Epoch: 115/200 Iteration: 570 Training loss: 0.35253\n",
      "Epoch: 115/200 Iteration: 571 Training loss: 0.39537\n",
      "Epoch: 115/200 Iteration: 572 Training loss: 0.42181\n",
      "Epoch: 115/200 Iteration: 573 Training loss: 0.41882\n",
      "Epoch: 115/200 Iteration: 574 Training loss: 0.43775\n",
      "Epoch: 114/200 Iteration: 575 Validation Acc: 0.6133\n",
      "Epoch: 116/200 Iteration: 575 Training loss: 0.39783\n",
      "Epoch: 116/200 Iteration: 576 Training loss: 0.29223\n",
      "Epoch: 116/200 Iteration: 577 Training loss: 0.24123\n",
      "Epoch: 116/200 Iteration: 578 Training loss: 0.25525\n",
      "Epoch: 116/200 Iteration: 579 Training loss: 0.24187\n",
      "Epoch: 115/200 Iteration: 580 Validation Acc: 0.6467\n",
      "Epoch: 117/200 Iteration: 580 Training loss: 0.29601\n",
      "Epoch: 117/200 Iteration: 581 Training loss: 0.26743\n",
      "Epoch: 117/200 Iteration: 582 Training loss: 0.25966\n",
      "Epoch: 117/200 Iteration: 583 Training loss: 0.26184\n",
      "Epoch: 117/200 Iteration: 584 Training loss: 0.26970\n",
      "Epoch: 116/200 Iteration: 585 Validation Acc: 0.6533\n",
      "Epoch: 118/200 Iteration: 585 Training loss: 0.36419\n",
      "Epoch: 118/200 Iteration: 586 Training loss: 0.26102\n",
      "Epoch: 118/200 Iteration: 587 Training loss: 0.24137\n",
      "Epoch: 118/200 Iteration: 588 Training loss: 0.23221\n",
      "Epoch: 118/200 Iteration: 589 Training loss: 0.20779\n",
      "Epoch: 117/200 Iteration: 590 Validation Acc: 0.6467\n",
      "Epoch: 119/200 Iteration: 590 Training loss: 0.23864\n",
      "Epoch: 119/200 Iteration: 591 Training loss: 0.28524\n",
      "Epoch: 119/200 Iteration: 592 Training loss: 0.47084\n",
      "Epoch: 119/200 Iteration: 593 Training loss: 0.51657\n",
      "Epoch: 119/200 Iteration: 594 Training loss: 0.40188\n",
      "Epoch: 118/200 Iteration: 595 Validation Acc: 0.6533\n",
      "Epoch: 120/200 Iteration: 595 Training loss: 0.34958\n",
      "Epoch: 120/200 Iteration: 596 Training loss: 0.31137\n",
      "Epoch: 120/200 Iteration: 597 Training loss: 0.28127\n",
      "Epoch: 120/200 Iteration: 598 Training loss: 0.28859\n",
      "Epoch: 120/200 Iteration: 599 Training loss: 0.24331\n",
      "Epoch: 119/200 Iteration: 600 Validation Acc: 0.7067\n",
      "Epoch: 121/200 Iteration: 600 Training loss: 0.25157\n",
      "Epoch: 121/200 Iteration: 601 Training loss: 0.22769\n",
      "Epoch: 121/200 Iteration: 602 Training loss: 0.22468\n",
      "Epoch: 121/200 Iteration: 603 Training loss: 0.22882\n",
      "Epoch: 121/200 Iteration: 604 Training loss: 0.21692\n",
      "Epoch: 120/200 Iteration: 605 Validation Acc: 0.6800\n",
      "Epoch: 122/200 Iteration: 605 Training loss: 0.23840\n",
      "Epoch: 122/200 Iteration: 606 Training loss: 0.27338\n",
      "Epoch: 122/200 Iteration: 607 Training loss: 0.37101\n",
      "Epoch: 122/200 Iteration: 608 Training loss: 0.47802\n",
      "Epoch: 122/200 Iteration: 609 Training loss: 0.37205\n",
      "Epoch: 121/200 Iteration: 610 Validation Acc: 0.6133\n",
      "Epoch: 123/200 Iteration: 610 Training loss: 0.28521\n",
      "Epoch: 123/200 Iteration: 611 Training loss: 0.21611\n",
      "Epoch: 123/200 Iteration: 612 Training loss: 0.22022\n",
      "Epoch: 123/200 Iteration: 613 Training loss: 0.28659\n",
      "Epoch: 123/200 Iteration: 614 Training loss: 0.29833\n",
      "Epoch: 122/200 Iteration: 615 Validation Acc: 0.6467\n",
      "Epoch: 124/200 Iteration: 615 Training loss: 0.31448\n",
      "Epoch: 124/200 Iteration: 616 Training loss: 0.27424\n",
      "Epoch: 124/200 Iteration: 617 Training loss: 0.29312\n",
      "Epoch: 124/200 Iteration: 618 Training loss: 0.29844\n",
      "Epoch: 124/200 Iteration: 619 Training loss: 0.24181\n",
      "Epoch: 123/200 Iteration: 620 Validation Acc: 0.6733\n",
      "Epoch: 125/200 Iteration: 620 Training loss: 0.22742\n",
      "Epoch: 125/200 Iteration: 621 Training loss: 0.21214\n",
      "Epoch: 125/200 Iteration: 622 Training loss: 0.23512\n",
      "Epoch: 125/200 Iteration: 623 Training loss: 0.25937\n",
      "Epoch: 125/200 Iteration: 624 Training loss: 0.24302\n",
      "Epoch: 124/200 Iteration: 625 Validation Acc: 0.6200\n",
      "Epoch: 126/200 Iteration: 625 Training loss: 0.27133\n",
      "Epoch: 126/200 Iteration: 626 Training loss: 0.34454\n",
      "Epoch: 126/200 Iteration: 627 Training loss: 0.64186\n",
      "Epoch: 126/200 Iteration: 628 Training loss: 0.51587\n",
      "Epoch: 126/200 Iteration: 629 Training loss: 0.41081\n",
      "Epoch: 125/200 Iteration: 630 Validation Acc: 0.6400\n",
      "Epoch: 127/200 Iteration: 630 Training loss: 0.41684\n",
      "Epoch: 127/200 Iteration: 631 Training loss: 0.27376\n",
      "Epoch: 127/200 Iteration: 632 Training loss: 0.21499\n",
      "Epoch: 127/200 Iteration: 633 Training loss: 0.23286\n",
      "Epoch: 127/200 Iteration: 634 Training loss: 0.21785\n",
      "Epoch: 126/200 Iteration: 635 Validation Acc: 0.6400\n",
      "Epoch: 128/200 Iteration: 635 Training loss: 0.24881\n",
      "Epoch: 128/200 Iteration: 636 Training loss: 0.22330\n",
      "Epoch: 128/200 Iteration: 637 Training loss: 0.22146\n",
      "Epoch: 128/200 Iteration: 638 Training loss: 0.22716\n",
      "Epoch: 128/200 Iteration: 639 Training loss: 0.19692\n",
      "Epoch: 127/200 Iteration: 640 Validation Acc: 0.6933\n",
      "Epoch: 129/200 Iteration: 640 Training loss: 0.19415\n",
      "Epoch: 129/200 Iteration: 641 Training loss: 0.18787\n",
      "Epoch: 129/200 Iteration: 642 Training loss: 0.21048\n",
      "Epoch: 129/200 Iteration: 643 Training loss: 0.26325\n",
      "Epoch: 129/200 Iteration: 644 Training loss: 0.32555\n",
      "Epoch: 128/200 Iteration: 645 Validation Acc: 0.7000\n",
      "Epoch: 130/200 Iteration: 645 Training loss: 0.37231\n",
      "Epoch: 130/200 Iteration: 646 Training loss: 0.30282\n",
      "Epoch: 130/200 Iteration: 647 Training loss: 0.26189\n",
      "Epoch: 130/200 Iteration: 648 Training loss: 0.21701\n",
      "Epoch: 130/200 Iteration: 649 Training loss: 0.18571\n",
      "Epoch: 129/200 Iteration: 650 Validation Acc: 0.6667\n",
      "Epoch: 131/200 Iteration: 650 Training loss: 0.19958\n",
      "Epoch: 131/200 Iteration: 651 Training loss: 0.20615\n",
      "Epoch: 131/200 Iteration: 652 Training loss: 0.27059\n",
      "Epoch: 131/200 Iteration: 653 Training loss: 0.38551\n",
      "Epoch: 131/200 Iteration: 654 Training loss: 0.29403\n",
      "Epoch: 130/200 Iteration: 655 Validation Acc: 0.6333\n",
      "Epoch: 132/200 Iteration: 655 Training loss: 0.28295\n",
      "Epoch: 132/200 Iteration: 656 Training loss: 0.28228\n",
      "Epoch: 132/200 Iteration: 657 Training loss: 0.37713\n",
      "Epoch: 132/200 Iteration: 658 Training loss: 0.35750\n",
      "Epoch: 132/200 Iteration: 659 Training loss: 0.26427\n",
      "Epoch: 131/200 Iteration: 660 Validation Acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133/200 Iteration: 660 Training loss: 0.23335\n",
      "Epoch: 133/200 Iteration: 661 Training loss: 0.20268\n",
      "Epoch: 133/200 Iteration: 662 Training loss: 0.21280\n",
      "Epoch: 133/200 Iteration: 663 Training loss: 0.26080\n",
      "Epoch: 133/200 Iteration: 664 Training loss: 0.23568\n",
      "Epoch: 132/200 Iteration: 665 Validation Acc: 0.6200\n",
      "Epoch: 134/200 Iteration: 665 Training loss: 0.25542\n",
      "Epoch: 134/200 Iteration: 666 Training loss: 0.21819\n",
      "Epoch: 134/200 Iteration: 667 Training loss: 0.20817\n",
      "Epoch: 134/200 Iteration: 668 Training loss: 0.20798\n",
      "Epoch: 134/200 Iteration: 669 Training loss: 0.18078\n",
      "Epoch: 133/200 Iteration: 670 Validation Acc: 0.6800\n",
      "Epoch: 135/200 Iteration: 670 Training loss: 0.22496\n",
      "Epoch: 135/200 Iteration: 671 Training loss: 0.19126\n",
      "Epoch: 135/200 Iteration: 672 Training loss: 0.20262\n",
      "Epoch: 135/200 Iteration: 673 Training loss: 0.19960\n",
      "Epoch: 135/200 Iteration: 674 Training loss: 0.21265\n",
      "Epoch: 134/200 Iteration: 675 Validation Acc: 0.6400\n",
      "Epoch: 136/200 Iteration: 675 Training loss: 0.27331\n",
      "Epoch: 136/200 Iteration: 676 Training loss: 0.44629\n",
      "Epoch: 136/200 Iteration: 677 Training loss: 0.77822\n",
      "Epoch: 136/200 Iteration: 678 Training loss: 1.16584\n",
      "Epoch: 136/200 Iteration: 679 Training loss: 0.43654\n",
      "Epoch: 135/200 Iteration: 680 Validation Acc: 0.6533\n",
      "Epoch: 137/200 Iteration: 680 Training loss: 0.35393\n",
      "Epoch: 137/200 Iteration: 681 Training loss: 0.27735\n",
      "Epoch: 137/200 Iteration: 682 Training loss: 0.25900\n",
      "Epoch: 137/200 Iteration: 683 Training loss: 0.23583\n",
      "Epoch: 137/200 Iteration: 684 Training loss: 0.19250\n",
      "Epoch: 136/200 Iteration: 685 Validation Acc: 0.6800\n",
      "Epoch: 138/200 Iteration: 685 Training loss: 0.20665\n",
      "Epoch: 138/200 Iteration: 686 Training loss: 0.18547\n",
      "Epoch: 138/200 Iteration: 687 Training loss: 0.18784\n",
      "Epoch: 138/200 Iteration: 688 Training loss: 0.19897\n",
      "Epoch: 138/200 Iteration: 689 Training loss: 0.17950\n",
      "Epoch: 137/200 Iteration: 690 Validation Acc: 0.6600\n",
      "Epoch: 139/200 Iteration: 690 Training loss: 0.22482\n",
      "Epoch: 139/200 Iteration: 691 Training loss: 0.20164\n",
      "Epoch: 139/200 Iteration: 692 Training loss: 0.18029\n",
      "Epoch: 139/200 Iteration: 693 Training loss: 0.18448\n",
      "Epoch: 139/200 Iteration: 694 Training loss: 0.16845\n",
      "Epoch: 138/200 Iteration: 695 Validation Acc: 0.6467\n",
      "Epoch: 140/200 Iteration: 695 Training loss: 0.16450\n",
      "Epoch: 140/200 Iteration: 696 Training loss: 0.16079\n",
      "Epoch: 140/200 Iteration: 697 Training loss: 0.18677\n",
      "Epoch: 140/200 Iteration: 698 Training loss: 0.22277\n",
      "Epoch: 140/200 Iteration: 699 Training loss: 0.24237\n",
      "Epoch: 139/200 Iteration: 700 Validation Acc: 0.6600\n",
      "Epoch: 141/200 Iteration: 700 Training loss: 0.29540\n",
      "Epoch: 141/200 Iteration: 701 Training loss: 0.23561\n",
      "Epoch: 141/200 Iteration: 702 Training loss: 0.23682\n",
      "Epoch: 141/200 Iteration: 703 Training loss: 0.22619\n",
      "Epoch: 141/200 Iteration: 704 Training loss: 0.19697\n",
      "Epoch: 140/200 Iteration: 705 Validation Acc: 0.6133\n",
      "Epoch: 142/200 Iteration: 705 Training loss: 0.19382\n",
      "Epoch: 142/200 Iteration: 706 Training loss: 0.18097\n",
      "Epoch: 142/200 Iteration: 707 Training loss: 0.21745\n",
      "Epoch: 142/200 Iteration: 708 Training loss: 0.26536\n",
      "Epoch: 142/200 Iteration: 709 Training loss: 0.33101\n",
      "Epoch: 141/200 Iteration: 710 Validation Acc: 0.6267\n",
      "Epoch: 143/200 Iteration: 710 Training loss: 0.42031\n",
      "Epoch: 143/200 Iteration: 711 Training loss: 0.33293\n",
      "Epoch: 143/200 Iteration: 712 Training loss: 0.29464\n",
      "Epoch: 143/200 Iteration: 713 Training loss: 0.24034\n",
      "Epoch: 143/200 Iteration: 714 Training loss: 0.18773\n",
      "Epoch: 142/200 Iteration: 715 Validation Acc: 0.6933\n",
      "Epoch: 144/200 Iteration: 715 Training loss: 0.17658\n",
      "Epoch: 144/200 Iteration: 716 Training loss: 0.15878\n",
      "Epoch: 144/200 Iteration: 717 Training loss: 0.16741\n",
      "Epoch: 144/200 Iteration: 718 Training loss: 0.21668\n",
      "Epoch: 144/200 Iteration: 719 Training loss: 0.19333\n",
      "Epoch: 143/200 Iteration: 720 Validation Acc: 0.6400\n",
      "Epoch: 145/200 Iteration: 720 Training loss: 0.26971\n",
      "Epoch: 145/200 Iteration: 721 Training loss: 0.42104\n",
      "Epoch: 145/200 Iteration: 722 Training loss: 0.51364\n",
      "Epoch: 145/200 Iteration: 723 Training loss: 0.41036\n",
      "Epoch: 145/200 Iteration: 724 Training loss: 0.26467\n",
      "Epoch: 144/200 Iteration: 725 Validation Acc: 0.6200\n",
      "Epoch: 146/200 Iteration: 725 Training loss: 0.24321\n",
      "Epoch: 146/200 Iteration: 726 Training loss: 0.19594\n",
      "Epoch: 146/200 Iteration: 727 Training loss: 0.17199\n",
      "Epoch: 146/200 Iteration: 728 Training loss: 0.18362\n",
      "Epoch: 146/200 Iteration: 729 Training loss: 0.18727\n",
      "Epoch: 145/200 Iteration: 730 Validation Acc: 0.6933\n",
      "Epoch: 147/200 Iteration: 730 Training loss: 0.19140\n",
      "Epoch: 147/200 Iteration: 731 Training loss: 0.21027\n",
      "Epoch: 147/200 Iteration: 732 Training loss: 0.23053\n",
      "Epoch: 147/200 Iteration: 733 Training loss: 0.25247\n",
      "Epoch: 147/200 Iteration: 734 Training loss: 0.22461\n",
      "Epoch: 146/200 Iteration: 735 Validation Acc: 0.6467\n",
      "Epoch: 148/200 Iteration: 735 Training loss: 0.25556\n",
      "Epoch: 148/200 Iteration: 736 Training loss: 0.20729\n",
      "Epoch: 148/200 Iteration: 737 Training loss: 0.19120\n",
      "Epoch: 148/200 Iteration: 738 Training loss: 0.18834\n",
      "Epoch: 148/200 Iteration: 739 Training loss: 0.16858\n",
      "Epoch: 147/200 Iteration: 740 Validation Acc: 0.6533\n",
      "Epoch: 149/200 Iteration: 740 Training loss: 0.17578\n",
      "Epoch: 149/200 Iteration: 741 Training loss: 0.16705\n",
      "Epoch: 149/200 Iteration: 742 Training loss: 0.18429\n",
      "Epoch: 149/200 Iteration: 743 Training loss: 0.28798\n",
      "Epoch: 149/200 Iteration: 744 Training loss: 0.31102\n",
      "Epoch: 148/200 Iteration: 745 Validation Acc: 0.6200\n",
      "Epoch: 150/200 Iteration: 745 Training loss: 0.40402\n",
      "Epoch: 150/200 Iteration: 746 Training loss: 0.43688\n",
      "Epoch: 150/200 Iteration: 747 Training loss: 0.51029\n",
      "Epoch: 150/200 Iteration: 748 Training loss: 0.30223\n",
      "Epoch: 150/200 Iteration: 749 Training loss: 0.22330\n",
      "Epoch: 149/200 Iteration: 750 Validation Acc: 0.6400\n",
      "Epoch: 151/200 Iteration: 750 Training loss: 0.19200\n",
      "Epoch: 151/200 Iteration: 751 Training loss: 0.16278\n",
      "Epoch: 151/200 Iteration: 752 Training loss: 0.17210\n",
      "Epoch: 151/200 Iteration: 753 Training loss: 0.18740\n",
      "Epoch: 151/200 Iteration: 754 Training loss: 0.17938\n",
      "Epoch: 150/200 Iteration: 755 Validation Acc: 0.6933\n",
      "Epoch: 152/200 Iteration: 755 Training loss: 0.17732\n",
      "Epoch: 152/200 Iteration: 756 Training loss: 0.14918\n",
      "Epoch: 152/200 Iteration: 757 Training loss: 0.18696\n",
      "Epoch: 152/200 Iteration: 758 Training loss: 0.25912\n",
      "Epoch: 152/200 Iteration: 759 Training loss: 0.30801\n",
      "Epoch: 151/200 Iteration: 760 Validation Acc: 0.6667\n",
      "Epoch: 153/200 Iteration: 760 Training loss: 0.37606\n",
      "Epoch: 153/200 Iteration: 761 Training loss: 0.29445\n",
      "Epoch: 153/200 Iteration: 762 Training loss: 0.24860\n",
      "Epoch: 153/200 Iteration: 763 Training loss: 0.23617\n",
      "Epoch: 153/200 Iteration: 764 Training loss: 0.17024\n",
      "Epoch: 152/200 Iteration: 765 Validation Acc: 0.6600\n",
      "Epoch: 154/200 Iteration: 765 Training loss: 0.16661\n",
      "Epoch: 154/200 Iteration: 766 Training loss: 0.14409\n",
      "Epoch: 154/200 Iteration: 767 Training loss: 0.15691\n",
      "Epoch: 154/200 Iteration: 768 Training loss: 0.17221\n",
      "Epoch: 154/200 Iteration: 769 Training loss: 0.17146\n",
      "Epoch: 153/200 Iteration: 770 Validation Acc: 0.6733\n",
      "Epoch: 155/200 Iteration: 770 Training loss: 0.18236\n",
      "Epoch: 155/200 Iteration: 771 Training loss: 0.19060\n",
      "Epoch: 155/200 Iteration: 772 Training loss: 0.19327\n",
      "Epoch: 155/200 Iteration: 773 Training loss: 0.18368\n",
      "Epoch: 155/200 Iteration: 774 Training loss: 0.20387\n",
      "Epoch: 154/200 Iteration: 775 Validation Acc: 0.6467\n",
      "Epoch: 156/200 Iteration: 775 Training loss: 0.23847\n",
      "Epoch: 156/200 Iteration: 776 Training loss: 0.30745\n",
      "Epoch: 156/200 Iteration: 777 Training loss: 0.39272\n",
      "Epoch: 156/200 Iteration: 778 Training loss: 0.44288\n",
      "Epoch: 156/200 Iteration: 779 Training loss: 0.31596\n",
      "Epoch: 155/200 Iteration: 780 Validation Acc: 0.6867\n",
      "Epoch: 157/200 Iteration: 780 Training loss: 0.25131\n",
      "Epoch: 157/200 Iteration: 781 Training loss: 0.19745\n",
      "Epoch: 157/200 Iteration: 782 Training loss: 0.16810\n",
      "Epoch: 157/200 Iteration: 783 Training loss: 0.17284\n",
      "Epoch: 157/200 Iteration: 784 Training loss: 0.16732\n",
      "Epoch: 156/200 Iteration: 785 Validation Acc: 0.6333\n",
      "Epoch: 158/200 Iteration: 785 Training loss: 0.21108\n",
      "Epoch: 158/200 Iteration: 786 Training loss: 0.19182\n",
      "Epoch: 158/200 Iteration: 787 Training loss: 0.17171\n",
      "Epoch: 158/200 Iteration: 788 Training loss: 0.15688\n",
      "Epoch: 158/200 Iteration: 789 Training loss: 0.14468\n",
      "Epoch: 157/200 Iteration: 790 Validation Acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159/200 Iteration: 790 Training loss: 0.13555\n",
      "Epoch: 159/200 Iteration: 791 Training loss: 0.13805\n",
      "Epoch: 159/200 Iteration: 792 Training loss: 0.15332\n",
      "Epoch: 159/200 Iteration: 793 Training loss: 0.18491\n",
      "Epoch: 159/200 Iteration: 794 Training loss: 0.21175\n",
      "Epoch: 158/200 Iteration: 795 Validation Acc: 0.6533\n",
      "Epoch: 160/200 Iteration: 795 Training loss: 0.26171\n",
      "Epoch: 160/200 Iteration: 796 Training loss: 0.29752\n",
      "Epoch: 160/200 Iteration: 797 Training loss: 0.36227\n",
      "Epoch: 160/200 Iteration: 798 Training loss: 0.79201\n",
      "Epoch: 160/200 Iteration: 799 Training loss: 0.45897\n",
      "Epoch: 159/200 Iteration: 800 Validation Acc: 0.6133\n",
      "Epoch: 161/200 Iteration: 800 Training loss: 0.36252\n",
      "Epoch: 161/200 Iteration: 801 Training loss: 0.23458\n",
      "Epoch: 161/200 Iteration: 802 Training loss: 0.18659\n",
      "Epoch: 161/200 Iteration: 803 Training loss: 0.18833\n",
      "Epoch: 161/200 Iteration: 804 Training loss: 0.16194\n",
      "Epoch: 160/200 Iteration: 805 Validation Acc: 0.6600\n",
      "Epoch: 162/200 Iteration: 805 Training loss: 0.15914\n",
      "Epoch: 162/200 Iteration: 806 Training loss: 0.13348\n",
      "Epoch: 162/200 Iteration: 807 Training loss: 0.13911\n",
      "Epoch: 162/200 Iteration: 808 Training loss: 0.16809\n",
      "Epoch: 162/200 Iteration: 809 Training loss: 0.16171\n",
      "Epoch: 161/200 Iteration: 810 Validation Acc: 0.6400\n",
      "Epoch: 163/200 Iteration: 810 Training loss: 0.18028\n",
      "Epoch: 163/200 Iteration: 811 Training loss: 0.18542\n",
      "Epoch: 163/200 Iteration: 812 Training loss: 0.16047\n",
      "Epoch: 163/200 Iteration: 813 Training loss: 0.19000\n",
      "Epoch: 163/200 Iteration: 814 Training loss: 0.16208\n",
      "Epoch: 162/200 Iteration: 815 Validation Acc: 0.6467\n",
      "Epoch: 164/200 Iteration: 815 Training loss: 0.16262\n",
      "Epoch: 164/200 Iteration: 816 Training loss: 0.16149\n",
      "Epoch: 164/200 Iteration: 817 Training loss: 0.18266\n",
      "Epoch: 164/200 Iteration: 818 Training loss: 0.20254\n",
      "Epoch: 164/200 Iteration: 819 Training loss: 0.25225\n",
      "Epoch: 163/200 Iteration: 820 Validation Acc: 0.6067\n",
      "Epoch: 165/200 Iteration: 820 Training loss: 0.22429\n",
      "Epoch: 165/200 Iteration: 821 Training loss: 0.24564\n",
      "Epoch: 165/200 Iteration: 822 Training loss: 0.21612\n",
      "Epoch: 165/200 Iteration: 823 Training loss: 0.22945\n",
      "Epoch: 165/200 Iteration: 824 Training loss: 0.17719\n",
      "Epoch: 164/200 Iteration: 825 Validation Acc: 0.6400\n",
      "Epoch: 166/200 Iteration: 825 Training loss: 0.25847\n",
      "Epoch: 166/200 Iteration: 826 Training loss: 0.21311\n",
      "Epoch: 166/200 Iteration: 827 Training loss: 0.18932\n",
      "Epoch: 166/200 Iteration: 828 Training loss: 0.18061\n",
      "Epoch: 166/200 Iteration: 829 Training loss: 0.16840\n",
      "Epoch: 165/200 Iteration: 830 Validation Acc: 0.6800\n",
      "Epoch: 167/200 Iteration: 830 Training loss: 0.24905\n",
      "Epoch: 167/200 Iteration: 831 Training loss: 0.31292\n",
      "Epoch: 167/200 Iteration: 832 Training loss: 0.32848\n",
      "Epoch: 167/200 Iteration: 833 Training loss: 0.27216\n",
      "Epoch: 167/200 Iteration: 834 Training loss: 0.16850\n",
      "Epoch: 166/200 Iteration: 835 Validation Acc: 0.6067\n",
      "Epoch: 168/200 Iteration: 835 Training loss: 0.15067\n",
      "Epoch: 168/200 Iteration: 836 Training loss: 0.13191\n",
      "Epoch: 168/200 Iteration: 837 Training loss: 0.13789\n",
      "Epoch: 168/200 Iteration: 838 Training loss: 0.14556\n",
      "Epoch: 168/200 Iteration: 839 Training loss: 0.13656\n",
      "Epoch: 167/200 Iteration: 840 Validation Acc: 0.6467\n",
      "Epoch: 169/200 Iteration: 840 Training loss: 0.16320\n",
      "Epoch: 169/200 Iteration: 841 Training loss: 0.14696\n",
      "Epoch: 169/200 Iteration: 842 Training loss: 0.21537\n",
      "Epoch: 169/200 Iteration: 843 Training loss: 0.40590\n",
      "Epoch: 169/200 Iteration: 844 Training loss: 0.52055\n",
      "Epoch: 168/200 Iteration: 845 Validation Acc: 0.6467\n",
      "Epoch: 170/200 Iteration: 845 Training loss: 0.66337\n",
      "Epoch: 170/200 Iteration: 846 Training loss: 0.31878\n",
      "Epoch: 170/200 Iteration: 847 Training loss: 0.22086\n",
      "Epoch: 170/200 Iteration: 848 Training loss: 0.19433\n",
      "Epoch: 170/200 Iteration: 849 Training loss: 0.16368\n",
      "Epoch: 169/200 Iteration: 850 Validation Acc: 0.6133\n",
      "Epoch: 171/200 Iteration: 850 Training loss: 0.15369\n",
      "Epoch: 171/200 Iteration: 851 Training loss: 0.14406\n",
      "Epoch: 171/200 Iteration: 852 Training loss: 0.14043\n",
      "Epoch: 171/200 Iteration: 853 Training loss: 0.16894\n",
      "Epoch: 171/200 Iteration: 854 Training loss: 0.15367\n",
      "Epoch: 170/200 Iteration: 855 Validation Acc: 0.6467\n",
      "Epoch: 172/200 Iteration: 855 Training loss: 0.14056\n",
      "Epoch: 172/200 Iteration: 856 Training loss: 0.13529\n",
      "Epoch: 172/200 Iteration: 857 Training loss: 0.13906\n",
      "Epoch: 172/200 Iteration: 858 Training loss: 0.14121\n",
      "Epoch: 172/200 Iteration: 859 Training loss: 0.14112\n",
      "Epoch: 171/200 Iteration: 860 Validation Acc: 0.6533\n",
      "Epoch: 173/200 Iteration: 860 Training loss: 0.12215\n",
      "Epoch: 173/200 Iteration: 861 Training loss: 0.11903\n",
      "Epoch: 173/200 Iteration: 862 Training loss: 0.18845\n",
      "Epoch: 173/200 Iteration: 863 Training loss: 0.35937\n",
      "Epoch: 173/200 Iteration: 864 Training loss: 0.30136\n",
      "Epoch: 172/200 Iteration: 865 Validation Acc: 0.6533\n",
      "Epoch: 174/200 Iteration: 865 Training loss: 0.25881\n",
      "Epoch: 174/200 Iteration: 866 Training loss: 0.21728\n",
      "Epoch: 174/200 Iteration: 867 Training loss: 0.21586\n",
      "Epoch: 174/200 Iteration: 868 Training loss: 0.19364\n",
      "Epoch: 174/200 Iteration: 869 Training loss: 0.16688\n",
      "Epoch: 173/200 Iteration: 870 Validation Acc: 0.6600\n",
      "Epoch: 175/200 Iteration: 870 Training loss: 0.14313\n",
      "Epoch: 175/200 Iteration: 871 Training loss: 0.12194\n",
      "Epoch: 175/200 Iteration: 872 Training loss: 0.13361\n",
      "Epoch: 175/200 Iteration: 873 Training loss: 0.15285\n",
      "Epoch: 175/200 Iteration: 874 Training loss: 0.13553\n",
      "Epoch: 174/200 Iteration: 875 Validation Acc: 0.6800\n",
      "Epoch: 176/200 Iteration: 875 Training loss: 0.14603\n",
      "Epoch: 176/200 Iteration: 876 Training loss: 0.11644\n",
      "Epoch: 176/200 Iteration: 877 Training loss: 0.13241\n",
      "Epoch: 176/200 Iteration: 878 Training loss: 0.20094\n",
      "Epoch: 176/200 Iteration: 879 Training loss: 0.24191\n",
      "Epoch: 175/200 Iteration: 880 Validation Acc: 0.6800\n",
      "Epoch: 177/200 Iteration: 880 Training loss: 0.40725\n",
      "Epoch: 177/200 Iteration: 881 Training loss: 0.58778\n",
      "Epoch: 177/200 Iteration: 882 Training loss: 0.84432\n",
      "Epoch: 177/200 Iteration: 883 Training loss: 0.40584\n",
      "Epoch: 177/200 Iteration: 884 Training loss: 0.28552\n",
      "Epoch: 176/200 Iteration: 885 Validation Acc: 0.6533\n",
      "Epoch: 178/200 Iteration: 885 Training loss: 0.24677\n",
      "Epoch: 178/200 Iteration: 886 Training loss: 0.17485\n",
      "Epoch: 178/200 Iteration: 887 Training loss: 0.15652\n",
      "Epoch: 178/200 Iteration: 888 Training loss: 0.16454\n",
      "Epoch: 178/200 Iteration: 889 Training loss: 0.13819\n",
      "Epoch: 177/200 Iteration: 890 Validation Acc: 0.6400\n",
      "Epoch: 179/200 Iteration: 890 Training loss: 0.13147\n",
      "Epoch: 179/200 Iteration: 891 Training loss: 0.12018\n",
      "Epoch: 179/200 Iteration: 892 Training loss: 0.13834\n",
      "Epoch: 179/200 Iteration: 893 Training loss: 0.16315\n",
      "Epoch: 179/200 Iteration: 894 Training loss: 0.14106\n",
      "Epoch: 178/200 Iteration: 895 Validation Acc: 0.6600\n",
      "Epoch: 180/200 Iteration: 895 Training loss: 0.14106\n",
      "Epoch: 180/200 Iteration: 896 Training loss: 0.13072\n",
      "Epoch: 180/200 Iteration: 897 Training loss: 0.11743\n",
      "Epoch: 180/200 Iteration: 898 Training loss: 0.13838\n",
      "Epoch: 180/200 Iteration: 899 Training loss: 0.12177\n",
      "Epoch: 179/200 Iteration: 900 Validation Acc: 0.6400\n",
      "Epoch: 181/200 Iteration: 900 Training loss: 0.17303\n",
      "Epoch: 181/200 Iteration: 901 Training loss: 0.25428\n",
      "Epoch: 181/200 Iteration: 902 Training loss: 0.32880\n",
      "Epoch: 181/200 Iteration: 903 Training loss: 0.32280\n",
      "Epoch: 181/200 Iteration: 904 Training loss: 0.28338\n",
      "Epoch: 180/200 Iteration: 905 Validation Acc: 0.6733\n",
      "Epoch: 182/200 Iteration: 905 Training loss: 0.20847\n",
      "Epoch: 182/200 Iteration: 906 Training loss: 0.14579\n",
      "Epoch: 182/200 Iteration: 907 Training loss: 0.14840\n",
      "Epoch: 182/200 Iteration: 908 Training loss: 0.14186\n",
      "Epoch: 182/200 Iteration: 909 Training loss: 0.13216\n",
      "Epoch: 181/200 Iteration: 910 Validation Acc: 0.6533\n",
      "Epoch: 183/200 Iteration: 910 Training loss: 0.14483\n",
      "Epoch: 183/200 Iteration: 911 Training loss: 0.13290\n",
      "Epoch: 183/200 Iteration: 912 Training loss: 0.14420\n",
      "Epoch: 183/200 Iteration: 913 Training loss: 0.17860\n",
      "Epoch: 183/200 Iteration: 914 Training loss: 0.17735\n",
      "Epoch: 182/200 Iteration: 915 Validation Acc: 0.6800\n",
      "Epoch: 184/200 Iteration: 915 Training loss: 0.17815\n",
      "Epoch: 184/200 Iteration: 916 Training loss: 0.14198\n",
      "Epoch: 184/200 Iteration: 917 Training loss: 0.14055\n",
      "Epoch: 184/200 Iteration: 918 Training loss: 0.17570\n",
      "Epoch: 184/200 Iteration: 919 Training loss: 0.21145\n",
      "Epoch: 183/200 Iteration: 920 Validation Acc: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185/200 Iteration: 920 Training loss: 0.18087\n",
      "Epoch: 185/200 Iteration: 921 Training loss: 0.19412\n",
      "Epoch: 185/200 Iteration: 922 Training loss: 0.18582\n",
      "Epoch: 185/200 Iteration: 923 Training loss: 0.24822\n",
      "Epoch: 185/200 Iteration: 924 Training loss: 0.21198\n",
      "Epoch: 184/200 Iteration: 925 Validation Acc: 0.6400\n",
      "Epoch: 186/200 Iteration: 925 Training loss: 0.19233\n",
      "Epoch: 186/200 Iteration: 926 Training loss: 0.13224\n",
      "Epoch: 186/200 Iteration: 927 Training loss: 0.12952\n",
      "Epoch: 186/200 Iteration: 928 Training loss: 0.13270\n",
      "Epoch: 186/200 Iteration: 929 Training loss: 0.11399\n",
      "Epoch: 185/200 Iteration: 930 Validation Acc: 0.6533\n",
      "Epoch: 187/200 Iteration: 930 Training loss: 0.13242\n",
      "Epoch: 187/200 Iteration: 931 Training loss: 0.13721\n",
      "Epoch: 187/200 Iteration: 932 Training loss: 0.17943\n",
      "Epoch: 187/200 Iteration: 933 Training loss: 0.21733\n",
      "Epoch: 187/200 Iteration: 934 Training loss: 0.18053\n",
      "Epoch: 186/200 Iteration: 935 Validation Acc: 0.6067\n",
      "Epoch: 188/200 Iteration: 935 Training loss: 0.20699\n",
      "Epoch: 188/200 Iteration: 936 Training loss: 0.15755\n",
      "Epoch: 188/200 Iteration: 937 Training loss: 0.20093\n",
      "Epoch: 188/200 Iteration: 938 Training loss: 0.22775\n",
      "Epoch: 188/200 Iteration: 939 Training loss: 0.22050\n",
      "Epoch: 187/200 Iteration: 940 Validation Acc: 0.6467\n",
      "Epoch: 189/200 Iteration: 940 Training loss: 0.20268\n",
      "Epoch: 189/200 Iteration: 941 Training loss: 0.20881\n",
      "Epoch: 189/200 Iteration: 942 Training loss: 0.20826\n",
      "Epoch: 189/200 Iteration: 943 Training loss: 0.22029\n",
      "Epoch: 189/200 Iteration: 944 Training loss: 0.16652\n",
      "Epoch: 188/200 Iteration: 945 Validation Acc: 0.6267\n",
      "Epoch: 190/200 Iteration: 945 Training loss: 0.14576\n",
      "Epoch: 190/200 Iteration: 946 Training loss: 0.11532\n",
      "Epoch: 190/200 Iteration: 947 Training loss: 0.11759\n",
      "Epoch: 190/200 Iteration: 948 Training loss: 0.12185\n",
      "Epoch: 190/200 Iteration: 949 Training loss: 0.14553\n",
      "Epoch: 189/200 Iteration: 950 Validation Acc: 0.6133\n",
      "Epoch: 191/200 Iteration: 950 Training loss: 0.22586\n",
      "Epoch: 191/200 Iteration: 951 Training loss: 0.23252\n",
      "Epoch: 191/200 Iteration: 952 Training loss: 0.21406\n",
      "Epoch: 191/200 Iteration: 953 Training loss: 0.18100\n",
      "Epoch: 191/200 Iteration: 954 Training loss: 0.14983\n",
      "Epoch: 190/200 Iteration: 955 Validation Acc: 0.6400\n",
      "Epoch: 192/200 Iteration: 955 Training loss: 0.14655\n",
      "Epoch: 192/200 Iteration: 956 Training loss: 0.15161\n",
      "Epoch: 192/200 Iteration: 957 Training loss: 0.19200\n",
      "Epoch: 192/200 Iteration: 958 Training loss: 0.21011\n",
      "Epoch: 192/200 Iteration: 959 Training loss: 0.15612\n",
      "Epoch: 191/200 Iteration: 960 Validation Acc: 0.6400\n",
      "Epoch: 193/200 Iteration: 960 Training loss: 0.14080\n",
      "Epoch: 193/200 Iteration: 961 Training loss: 0.11029\n",
      "Epoch: 193/200 Iteration: 962 Training loss: 0.14748\n",
      "Epoch: 193/200 Iteration: 963 Training loss: 0.14099\n",
      "Epoch: 193/200 Iteration: 964 Training loss: 0.16171\n",
      "Epoch: 192/200 Iteration: 965 Validation Acc: 0.6200\n",
      "Epoch: 194/200 Iteration: 965 Training loss: 0.14069\n",
      "Epoch: 194/200 Iteration: 966 Training loss: 0.14942\n",
      "Epoch: 194/200 Iteration: 967 Training loss: 0.16424\n",
      "Epoch: 194/200 Iteration: 968 Training loss: 0.22725\n",
      "Epoch: 194/200 Iteration: 969 Training loss: 0.23812\n",
      "Epoch: 193/200 Iteration: 970 Validation Acc: 0.6400\n",
      "Epoch: 195/200 Iteration: 970 Training loss: 0.31570\n",
      "Epoch: 195/200 Iteration: 971 Training loss: 0.26676\n",
      "Epoch: 195/200 Iteration: 972 Training loss: 0.25625\n",
      "Epoch: 195/200 Iteration: 973 Training loss: 0.21926\n",
      "Epoch: 195/200 Iteration: 974 Training loss: 0.23541\n",
      "Epoch: 194/200 Iteration: 975 Validation Acc: 0.6133\n",
      "Epoch: 196/200 Iteration: 975 Training loss: 0.15994\n",
      "Epoch: 196/200 Iteration: 976 Training loss: 0.12897\n",
      "Epoch: 196/200 Iteration: 977 Training loss: 0.14921\n",
      "Epoch: 196/200 Iteration: 978 Training loss: 0.18035\n",
      "Epoch: 196/200 Iteration: 979 Training loss: 0.13991\n",
      "Epoch: 195/200 Iteration: 980 Validation Acc: 0.6533\n",
      "Epoch: 197/200 Iteration: 980 Training loss: 0.13355\n",
      "Epoch: 197/200 Iteration: 981 Training loss: 0.11338\n",
      "Epoch: 197/200 Iteration: 982 Training loss: 0.12042\n",
      "Epoch: 197/200 Iteration: 983 Training loss: 0.11248\n",
      "Epoch: 197/200 Iteration: 984 Training loss: 0.09958\n",
      "Epoch: 196/200 Iteration: 985 Validation Acc: 0.6533\n",
      "Epoch: 198/200 Iteration: 985 Training loss: 0.11175\n",
      "Epoch: 198/200 Iteration: 986 Training loss: 0.11219\n",
      "Epoch: 198/200 Iteration: 987 Training loss: 0.15733\n",
      "Epoch: 198/200 Iteration: 988 Training loss: 0.21769\n",
      "Epoch: 198/200 Iteration: 989 Training loss: 0.21504\n",
      "Epoch: 197/200 Iteration: 990 Validation Acc: 0.6733\n",
      "Epoch: 199/200 Iteration: 990 Training loss: 0.20174\n",
      "Epoch: 199/200 Iteration: 991 Training loss: 0.19417\n",
      "Epoch: 199/200 Iteration: 992 Training loss: 0.26021\n",
      "Epoch: 199/200 Iteration: 993 Training loss: 0.27880\n",
      "Epoch: 199/200 Iteration: 994 Training loss: 0.22126\n",
      "Epoch: 198/200 Iteration: 995 Validation Acc: 0.6733\n",
      "Epoch: 200/200 Iteration: 995 Training loss: 0.18101\n",
      "Epoch: 200/200 Iteration: 996 Training loss: 0.12705\n",
      "Epoch: 200/200 Iteration: 997 Training loss: 0.11992\n",
      "Epoch: 200/200 Iteration: 998 Training loss: 0.11948\n",
      "Epoch: 200/200 Iteration: 999 Training loss: 0.11069\n",
      "Epoch: 199/200 Iteration: 1000 Validation Acc: 0.6733\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "\n",
    "epochs = 200\n",
    "iteration = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x_shuffled, train_y_shuffled, n_batches=5):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x, labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    saver.save(sess, \"checkpoints/skin_diseases.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/skin_diseases.ckpt\n",
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/melanoma/ISIC_0012258.jpg 0.00204268 0.0625146\n",
      "data/test/melanoma/ISIC_0012356.jpg 0.00703594 0.0762861\n",
      "data/test/melanoma/ISIC_0012369.jpg 6.0923e-06 3.03647e-07\n",
      "data/test/melanoma/ISIC_0012395.jpg 6.60503e-10 1.0\n",
      "data/test/melanoma/ISIC_0012425.jpg 6.03124e-14 1.86998e-11\n",
      "data/test/melanoma/ISIC_0012758.jpg 0.000252329 2.64962e-10\n",
      "data/test/melanoma/ISIC_0012989.jpg 0.999877 5.14157e-17\n",
      "data/test/melanoma/ISIC_0013072.jpg 0.586808 0.0919377\n",
      "data/test/melanoma/ISIC_0013073.jpg 0.899309 0.0992762\n",
      "data/test/melanoma/ISIC_0013242.jpg 0.00076747 0.0850101\n",
      "data/test/melanoma/ISIC_0013277.jpg 0.533598 0.306941\n",
      "data/test/melanoma/ISIC_0013321.jpg 1.60834e-07 1.0\n",
      "data/test/melanoma/ISIC_0013374.jpg 0.998755 0.00102823\n",
      "data/test/melanoma/ISIC_0013411.jpg 7.12369e-07 0.877945\n",
      "data/test/melanoma/ISIC_0013414.jpg 3.69211e-10 0.0133549\n",
      "data/test/melanoma/ISIC_0013455.jpg 0.276062 7.09349e-05\n",
      "data/test/melanoma/ISIC_0013457.jpg 0.999285 0.000101422\n",
      "data/test/melanoma/ISIC_0013459.jpg 0.855813 2.84342e-05\n",
      "data/test/melanoma/ISIC_0013472.jpg 0.585701 0.40941\n",
      "data/test/melanoma/ISIC_0013473.jpg 0.261423 0.738547\n",
      "data: test, class: melanoma, 20 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013565.jpg 0.950553 0.000130463\n",
      "data/test/melanoma/ISIC_0013577.jpg 0.950447 0.00374603\n",
      "data/test/melanoma/ISIC_0013588.jpg 1.23943e-05 0.995391\n",
      "data/test/melanoma/ISIC_0013615.jpg 0.177038 0.257344\n",
      "data/test/melanoma/ISIC_0013617.jpg 0.0134118 0.52671\n",
      "data/test/melanoma/ISIC_0013636.jpg 0.00489814 0.515953\n",
      "data/test/melanoma/ISIC_0013678.jpg 3.74051e-19 1.0\n",
      "data/test/melanoma/ISIC_0013696.jpg 0.0077269 0.701025\n",
      "data/test/melanoma/ISIC_0013733.jpg 0.00126626 0.0940053\n",
      "data/test/melanoma/ISIC_0013739.jpg 6.15955e-08 0.973912\n",
      "data/test/melanoma/ISIC_0013766.jpg 0.0131151 0.00110069\n",
      "data/test/melanoma/ISIC_0013767.jpg 0.0315278 0.664579\n",
      "data/test/melanoma/ISIC_0013813.jpg 0.935317 0.064374\n",
      "data/test/melanoma/ISIC_0013814.jpg 0.294111 0.705728\n",
      "data/test/melanoma/ISIC_0013833.jpg 0.97406 0.0157052\n",
      "data/test/melanoma/ISIC_0013842.jpg 7.54165e-07 0.000293697\n",
      "data/test/melanoma/ISIC_0013867.jpg 0.298782 0.395047\n",
      "data/test/melanoma/ISIC_0013908.jpg 1.43952e-10 1.0\n",
      "data/test/melanoma/ISIC_0013917.jpg 0.000272954 2.89587e-09\n",
      "data/test/melanoma/ISIC_0013925.jpg 0.0152393 0.984733\n",
      "data: test, class: melanoma, 40 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013948.jpg 0.000663441 0.000175071\n",
      "data/test/melanoma/ISIC_0013953.jpg 1.6935e-08 0.981911\n",
      "data/test/melanoma/ISIC_0013987.jpg 0.072277 0.915317\n",
      "data/test/melanoma/ISIC_0013988.jpg 0.000435125 0.999559\n",
      "data/test/melanoma/ISIC_0014027.jpg 1.82757e-11 0.99981\n",
      "data/test/melanoma/ISIC_0014059.jpg 3.34606e-06 1.17795e-07\n",
      "data/test/melanoma/ISIC_0014077.jpg 0.0238062 0.00118664\n",
      "data/test/melanoma/ISIC_0014103.jpg 6.90102e-10 0.000102974\n",
      "data/test/melanoma/ISIC_0014110.jpg 0.302361 0.00751727\n",
      "data/test/melanoma/ISIC_0014129.jpg 0.0633552 0.271305\n",
      "data/test/melanoma/ISIC_0014148.jpg 0.489482 0.124468\n",
      "data/test/melanoma/ISIC_0014160.jpg 0.971752 0.000281178\n",
      "data/test/melanoma/ISIC_0014181.jpg 0.29629 0.385144\n",
      "data/test/melanoma/ISIC_0014186.jpg 7.54317e-06 0.0602489\n",
      "data/test/melanoma/ISIC_0014219.jpg 5.37219e-05 5.38356e-06\n",
      "data/test/melanoma/ISIC_0014221.jpg 3.44138e-11 0.0202154\n",
      "data/test/melanoma/ISIC_0014233.jpg 1.19639e-05 0.000147879\n",
      "data/test/melanoma/ISIC_0014255.jpg 6.35152e-13 4.85581e-16\n",
      "data/test/melanoma/ISIC_0014270.jpg 9.21535e-05 0.00278701\n",
      "data/test/melanoma/ISIC_0014284.jpg 0.00227322 0.520393\n",
      "data: test, class: melanoma, 60 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014288.jpg 0.064299 0.55331\n",
      "data/test/melanoma/ISIC_0014319.jpg 0.0190031 0.000561811\n",
      "data/test/melanoma/ISIC_0014336.jpg 0.738317 0.00273399\n",
      "data/test/melanoma/ISIC_0014349.jpg 0.953573 0.00388247\n",
      "data/test/melanoma/ISIC_0014369.jpg 0.538677 0.0517066\n",
      "data/test/melanoma/ISIC_0014423.jpg 0.00321408 0.948075\n",
      "data/test/melanoma/ISIC_0014434.jpg 0.000230566 0.999148\n",
      "data/test/melanoma/ISIC_0014454.jpg 0.0526655 0.0749157\n",
      "data/test/melanoma/ISIC_0014478.jpg 0.000705606 5.99099e-05\n",
      "data/test/melanoma/ISIC_0014489.jpg 0.997781 2.98536e-05\n",
      "data/test/melanoma/ISIC_0014506.jpg 0.999889 7.79621e-05\n",
      "data/test/melanoma/ISIC_0014513.jpg 0.000571973 0.60761\n",
      "data/test/melanoma/ISIC_0014541.jpg 0.826648 7.00288e-07\n",
      "data/test/melanoma/ISIC_0014542.jpg 9.27186e-06 0.0218138\n",
      "data/test/melanoma/ISIC_0014546.jpg 0.484663 0.0665142\n",
      "data/test/melanoma/ISIC_0014548.jpg 0.325204 0.0452537\n",
      "data/test/melanoma/ISIC_0014559.jpg 0.90781 0.070868\n",
      "data/test/melanoma/ISIC_0014663.jpg 0.0208801 0.940504\n",
      "data/test/melanoma/ISIC_0014666.jpg 0.207231 0.776079\n",
      "data/test/melanoma/ISIC_0014695.jpg 0.999927 7.14695e-05\n",
      "data: test, class: melanoma, 80 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014703.jpg 0.00637564 1.93154e-09\n",
      "data/test/melanoma/ISIC_0014727.jpg 2.46559e-14 9.93759e-18\n",
      "data/test/melanoma/ISIC_0014766.jpg 0.0405294 0.156727\n",
      "data/test/melanoma/ISIC_0014772.jpg 0.0939747 0.00132069\n",
      "data/test/melanoma/ISIC_0014784.jpg 4.44154e-12 0.999974\n",
      "data/test/melanoma/ISIC_0014790.jpg 0.913488 1.98433e-12\n",
      "data/test/melanoma/ISIC_0014800.jpg 0.00639363 0.00172307\n",
      "data/test/melanoma/ISIC_0014826.jpg 0.0025319 3.79941e-07\n",
      "data/test/melanoma/ISIC_0014862.jpg 0.117764 2.29056e-06\n",
      "data/test/melanoma/ISIC_0014872.jpg 8.23213e-05 0.998749\n",
      "data/test/melanoma/ISIC_0014883.jpg 9.19533e-12 4.53256e-23\n",
      "data/test/melanoma/ISIC_0014912.jpg 0.0181636 9.05081e-07\n",
      "data/test/melanoma/ISIC_0014928.jpg 1.11281e-08 5.48028e-09\n",
      "data/test/melanoma/ISIC_0014932.jpg 6.93022e-05 1.09933e-08\n",
      "data/test/melanoma/ISIC_0014963.jpg 0.997094 6.59863e-08\n",
      "data/test/melanoma/ISIC_0014982.jpg 0.00199968 0.00226653\n",
      "data/test/melanoma/ISIC_0015004.jpg 2.44335e-08 1.48676e-08\n",
      "data/test/melanoma/ISIC_0015041.jpg 0.999998 2.08104e-06\n",
      "data/test/melanoma/ISIC_0015046.jpg 5.81395e-15 0.304592\n",
      "data/test/melanoma/ISIC_0015050.jpg 0.999924 6.06287e-05\n",
      "data: test, class: melanoma, 100 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0015071.jpg 1.0 6.27779e-13\n",
      "data/test/melanoma/ISIC_0015115.jpg 0.867587 1.82472e-07\n",
      "data/test/melanoma/ISIC_0015119.jpg 0.0015871 9.39461e-06\n",
      "data/test/melanoma/ISIC_0015127.jpg 0.993417 1.4753e-17\n",
      "data/test/melanoma/ISIC_0015132.jpg 0.989535 0.00036189\n",
      "data/test/melanoma/ISIC_0015133.jpg 0.104114 8.87583e-16\n",
      "data/test/melanoma/ISIC_0015136.jpg 0.158107 0.0232544\n",
      "data/test/melanoma/ISIC_0015142.jpg 0.997501 0.000317605\n",
      "data/test/melanoma/ISIC_0015156.jpg 0.301851 0.268173\n",
      "data/test/melanoma/ISIC_0015163.jpg 0.00470802 0.000306638\n",
      "data/test/melanoma/ISIC_0015167.jpg 0.997692 0.00230856\n",
      "data/test/melanoma/ISIC_0015180.jpg 1.96707e-07 0.999653\n",
      "data/test/melanoma/ISIC_0015185.jpg 1.71593e-09 6.62729e-10\n",
      "data/test/melanoma/ISIC_0015193.jpg 1.24377e-05 0.00108272\n",
      "data/test/melanoma/ISIC_0015206.jpg 1.0 1.3501e-31\n",
      "data/test/melanoma/ISIC_0015229.jpg 0.999997 6.82783e-08\n",
      "data/test/melanoma/ISIC_0015251.jpg 0.00334221 6.89683e-08\n",
      "data: test, class: melanoma, 117 / 117 images processed.\n",
      "data/test/nevus/ISIC_0012092.jpg 0.168025 3.07709e-10\n",
      "data/test/nevus/ISIC_0012095.jpg 7.15566e-08 0.0664127\n",
      "data/test/nevus/ISIC_0012147.jpg 4.96356e-15 2.08654e-13\n",
      "data/test/nevus/ISIC_0012149.jpg 4.74197e-11 0.00198897\n",
      "data/test/nevus/ISIC_0012152.jpg 3.84841e-07 0.999983\n",
      "data/test/nevus/ISIC_0012216.jpg 0.00169633 0.000446885\n",
      "data/test/nevus/ISIC_0012357.jpg 0.184569 0.438115\n",
      "data/test/nevus/ISIC_0012484.jpg 0.172905 0.550691\n",
      "data/test/nevus/ISIC_0012493.jpg 1.06331e-17 5.37241e-25\n",
      "data/test/nevus/ISIC_0012551.jpg 1.54088e-11 0.000152948\n",
      "data/test/nevus/ISIC_0012654.jpg 1.37319e-05 1.43438e-07\n",
      "data/test/nevus/ISIC_0012656.jpg 8.10275e-05 2.34665e-08\n",
      "data/test/nevus/ISIC_0012708.jpg 2.52535e-06 3.85372e-07\n",
      "data/test/nevus/ISIC_0012722.jpg 2.71156e-09 1.90103e-10\n",
      "data/test/nevus/ISIC_0012803.jpg 0.000217202 0.000602383\n",
      "data/test/nevus/ISIC_0012836.jpg 0.000390169 1.05342e-06\n",
      "data/test/nevus/ISIC_0012837.jpg 1.45397e-05 6.22436e-05\n",
      "data/test/nevus/ISIC_0012903.jpg 9.83314e-16 2.39034e-12\n",
      "data/test/nevus/ISIC_0012904.jpg 1.3961e-10 4.58536e-05\n",
      "data/test/nevus/ISIC_0012941.jpg 2.42558e-24 0.999997\n",
      "data: test, class: nevus, 20 / 393 images processed.\n",
      "data/test/nevus/ISIC_0012967.jpg 1.59176e-08 1.04315e-07\n",
      "data/test/nevus/ISIC_0013045.jpg 0.000203157 4.88379e-05\n",
      "data/test/nevus/ISIC_0013070.jpg 1.68045e-06 0.000309005\n",
      "data/test/nevus/ISIC_0013109.jpg 3.31057e-06 0.000171567\n",
      "data/test/nevus/ISIC_0013159.jpg 3.6866e-07 0.961802\n",
      "data/test/nevus/ISIC_0013164.jpg 1.89757e-18 2.39258e-10\n",
      "data/test/nevus/ISIC_0013176.jpg 0.000378712 1.66685e-05\n",
      "data/test/nevus/ISIC_0013191.jpg 2.71303e-11 0.00506772\n",
      "data/test/nevus/ISIC_0013216.jpg 4.29426e-07 0.00069591\n",
      "data/test/nevus/ISIC_0013226.jpg 0.00401471 0.000285371\n",
      "data/test/nevus/ISIC_0013230.jpg 0.000196583 0.00376916\n",
      "data/test/nevus/ISIC_0013269.jpg 0.980187 7.60689e-07\n",
      "data/test/nevus/ISIC_0013291.jpg 0.159104 0.00144488\n",
      "data/test/nevus/ISIC_0013325.jpg 0.0223675 0.0166741\n",
      "data/test/nevus/ISIC_0013399.jpg 3.46323e-23 2.72862e-22\n",
      "data/test/nevus/ISIC_0013416.jpg 5.42741e-27 2.65604e-15\n",
      "data/test/nevus/ISIC_0013511.jpg 0.000668879 0.000132315\n",
      "data/test/nevus/ISIC_0013512.jpg 5.55057e-09 0.947865\n",
      "data/test/nevus/ISIC_0013529.jpg 0.000159205 3.29964e-05\n",
      "data/test/nevus/ISIC_0013600.jpg 0.00170956 6.40003e-06\n",
      "data: test, class: nevus, 40 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0013602.jpg 0.89414 2.6363e-12\n",
      "data/test/nevus/ISIC_0013738.jpg 1.31819e-17 3.1691e-15\n",
      "data/test/nevus/ISIC_0013794.jpg 1.97102e-07 1.34225e-05\n",
      "data/test/nevus/ISIC_0013809.jpg 0.898028 0.00108071\n",
      "data/test/nevus/ISIC_0013891.jpg 5.95804e-07 4.84833e-07\n",
      "data/test/nevus/ISIC_0013897.jpg 0.998271 0.00157174\n",
      "data/test/nevus/ISIC_0013911.jpg 1.53179e-10 1.0\n",
      "data/test/nevus/ISIC_0013966.jpg 0.000429395 0.0163258\n",
      "data/test/nevus/ISIC_0013998.jpg 2.46588e-05 4.06155e-05\n",
      "data/test/nevus/ISIC_0014090.jpg 2.98216e-08 1.9876e-06\n",
      "data/test/nevus/ISIC_0014117.jpg 0.00077733 1.19909e-05\n",
      "data/test/nevus/ISIC_0014470.jpg 1.79728e-07 0.999287\n",
      "data/test/nevus/ISIC_0014675.jpg 2.57421e-12 2.56436e-23\n",
      "data/test/nevus/ISIC_0014677.jpg 3.27962e-18 3.61391e-22\n",
      "data/test/nevus/ISIC_0014687.jpg 2.45273e-07 3.59259e-06\n",
      "data/test/nevus/ISIC_0014693.jpg 8.63434e-05 0.999838\n",
      "data/test/nevus/ISIC_0014697.jpg 7.97103e-21 8.17906e-32\n",
      "data/test/nevus/ISIC_0014698.jpg 1.11887e-16 4.29445e-20\n",
      "data/test/nevus/ISIC_0014720.jpg 3.71059e-05 2.49454e-09\n",
      "data/test/nevus/ISIC_0014725.jpg 1.11037e-08 8.87646e-07\n",
      "data: test, class: nevus, 60 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014728.jpg 7.73967e-24 7.72465e-19\n",
      "data/test/nevus/ISIC_0014729.jpg 0.0203257 0.696769\n",
      "data/test/nevus/ISIC_0014740.jpg 0.994974 0.000345213\n",
      "data/test/nevus/ISIC_0014743.jpg 2.50763e-13 2.0753e-11\n",
      "data/test/nevus/ISIC_0014746.jpg 8.82994e-06 1.0313e-09\n",
      "data/test/nevus/ISIC_0014749.jpg 0.000115025 0.397513\n",
      "data/test/nevus/ISIC_0014753.jpg 0.230592 0.00136322\n",
      "data/test/nevus/ISIC_0014755.jpg 0.841221 0.0139805\n",
      "data/test/nevus/ISIC_0014765.jpg 5.11523e-13 1.89434e-11\n",
      "data/test/nevus/ISIC_0014768.jpg 4.87996e-06 1.81608e-07\n",
      "data/test/nevus/ISIC_0014773.jpg 0.0638437 0.151294\n",
      "data/test/nevus/ISIC_0014780.jpg 5.70546e-13 4.06483e-12\n",
      "data/test/nevus/ISIC_0014786.jpg 1.28214e-08 4.12702e-12\n",
      "data/test/nevus/ISIC_0014787.jpg 1.97019e-06 0.00308396\n",
      "data/test/nevus/ISIC_0014792.jpg 4.75687e-23 0.219619\n",
      "data/test/nevus/ISIC_0014796.jpg 1.47909e-05 7.35109e-08\n",
      "data/test/nevus/ISIC_0014798.jpg 5.53529e-13 5.20337e-08\n",
      "data/test/nevus/ISIC_0014807.jpg 8.61553e-06 1.30986e-09\n",
      "data/test/nevus/ISIC_0014814.jpg 2.71892e-05 7.22876e-09\n",
      "data/test/nevus/ISIC_0014815.jpg 0.000591957 1.25951e-05\n",
      "data: test, class: nevus, 80 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014820.jpg 2.51918e-32 0.0\n",
      "data/test/nevus/ISIC_0014822.jpg 1.62214e-10 8.89395e-07\n",
      "data/test/nevus/ISIC_0014833.jpg 0.11474 4.77661e-05\n",
      "data/test/nevus/ISIC_0014835.jpg 2.82847e-06 2.4171e-10\n",
      "data/test/nevus/ISIC_0014844.jpg 4.49251e-06 1.17527e-06\n",
      "data/test/nevus/ISIC_0014853.jpg 9.41738e-06 2.02414e-09\n",
      "data/test/nevus/ISIC_0014854.jpg 1.61434e-11 4.27702e-10\n",
      "data/test/nevus/ISIC_0014863.jpg 0.000567772 0.000347386\n",
      "data/test/nevus/ISIC_0014867.jpg 2.84061e-08 1.77737e-13\n",
      "data/test/nevus/ISIC_0014868.jpg 2.38822e-10 1.35339e-11\n",
      "data/test/nevus/ISIC_0014876.jpg 1.02593e-26 6.04112e-34\n",
      "data/test/nevus/ISIC_0014879.jpg 2.35985e-12 2.46336e-09\n",
      "data/test/nevus/ISIC_0014901.jpg 6.19374e-06 0.294992\n",
      "data/test/nevus/ISIC_0014907.jpg 5.08128e-18 8.78257e-27\n",
      "data/test/nevus/ISIC_0014910.jpg 1.2153e-07 2.87121e-07\n",
      "data/test/nevus/ISIC_0014921.jpg 6.30676e-14 2.8533e-16\n",
      "data/test/nevus/ISIC_0014927.jpg 0.000182907 4.00356e-07\n",
      "data/test/nevus/ISIC_0014936.jpg 0.000138406 0.000147386\n",
      "data/test/nevus/ISIC_0014938.jpg 2.07567e-09 6.33355e-13\n",
      "data/test/nevus/ISIC_0014940.jpg 9.14224e-13 7.17987e-18\n",
      "data: test, class: nevus, 100 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014941.jpg 5.38178e-07 3.52238e-07\n",
      "data/test/nevus/ISIC_0014942.jpg 4.98632e-27 2.97061e-18\n",
      "data/test/nevus/ISIC_0014943.jpg 4.2606e-08 5.64173e-15\n",
      "data/test/nevus/ISIC_0014944.jpg 4.68537e-07 0.00245631\n",
      "data/test/nevus/ISIC_0014947.jpg 0.999198 4.37022e-10\n",
      "data/test/nevus/ISIC_0014948.jpg 0.773018 0.0811739\n",
      "data/test/nevus/ISIC_0014949.jpg 3.17302e-07 4.04818e-11\n",
      "data/test/nevus/ISIC_0014952.jpg 9.42174e-09 4.82884e-10\n",
      "data/test/nevus/ISIC_0014955.jpg 1.0 0.0\n",
      "data/test/nevus/ISIC_0014956.jpg 6.60471e-05 8.48202e-07\n",
      "data/test/nevus/ISIC_0014957.jpg 2.36214e-13 3.50151e-20\n",
      "data/test/nevus/ISIC_0014958.jpg 2.13291e-10 1.15385e-17\n",
      "data/test/nevus/ISIC_0014959.jpg 4.00288e-17 3.63231e-19\n",
      "data/test/nevus/ISIC_0014961.jpg 4.84192e-06 9.49948e-18\n",
      "data/test/nevus/ISIC_0014962.jpg 5.46648e-24 6.62917e-16\n",
      "data/test/nevus/ISIC_0014964.jpg 0.00610441 3.07918e-10\n",
      "data/test/nevus/ISIC_0014966.jpg 0.000675204 2.97092e-05\n",
      "data/test/nevus/ISIC_0014968.jpg 0.999579 7.14481e-07\n",
      "data/test/nevus/ISIC_0014969.jpg 3.38375e-10 1.0583e-14\n",
      "data/test/nevus/ISIC_0014973.jpg 2.96877e-05 2.43569e-13\n",
      "data: test, class: nevus, 120 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014974.jpg 3.12545e-07 0.000559236\n",
      "data/test/nevus/ISIC_0014977.jpg 3.40968e-09 1.6295e-10\n",
      "data/test/nevus/ISIC_0014992.jpg 1.8213e-07 7.57183e-07\n",
      "data/test/nevus/ISIC_0014994.jpg 2.68787e-12 9.12322e-09\n",
      "data/test/nevus/ISIC_0014998.jpg 8.72623e-06 0.281641\n",
      "data/test/nevus/ISIC_0015002.jpg 3.13757e-20 9.04347e-20\n",
      "data/test/nevus/ISIC_0015003.jpg 0.0048406 0.00219765\n",
      "data/test/nevus/ISIC_0015007.jpg 2.27352e-33 3.03814e-21\n",
      "data/test/nevus/ISIC_0015008.jpg 1.85888e-14 5.35626e-11\n",
      "data/test/nevus/ISIC_0015009.jpg 7.65447e-07 0.913896\n",
      "data/test/nevus/ISIC_0015011.jpg 0.000196144 0.999514\n",
      "data/test/nevus/ISIC_0015013.jpg 0.384595 0.00326947\n",
      "data/test/nevus/ISIC_0015015.jpg 2.52365e-07 1.70752e-14\n",
      "data/test/nevus/ISIC_0015016.jpg 6.5963e-10 1.06212e-10\n",
      "data/test/nevus/ISIC_0015018.jpg 0.00270198 0.000907978\n",
      "data/test/nevus/ISIC_0015019.jpg 0.000808066 0.634346\n",
      "data/test/nevus/ISIC_0015020.jpg 0.373151 0.104279\n",
      "data/test/nevus/ISIC_0015021.jpg 2.85648e-14 9.59499e-13\n",
      "data/test/nevus/ISIC_0015023.jpg 3.32959e-07 1.8189e-14\n",
      "data/test/nevus/ISIC_0015026.jpg 2.28871e-13 2.65353e-18\n",
      "data: test, class: nevus, 140 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015030.jpg 6.12096e-10 5.58211e-08\n",
      "data/test/nevus/ISIC_0015031.jpg 1.84662e-13 1.08549e-11\n",
      "data/test/nevus/ISIC_0015034.jpg 8.35079e-08 9.35037e-08\n",
      "data/test/nevus/ISIC_0015035.jpg 5.44597e-11 5.48415e-10\n",
      "data/test/nevus/ISIC_0015037.jpg 1.07151e-05 2.17241e-05\n",
      "data/test/nevus/ISIC_0015040.jpg 2.38791e-22 1.16606e-20\n",
      "data/test/nevus/ISIC_0015051.jpg 6.67058e-06 3.74468e-07\n",
      "data/test/nevus/ISIC_0015056.jpg 0.214094 0.0265244\n",
      "data/test/nevus/ISIC_0015057.jpg 0.000177542 2.62358e-06\n",
      "data/test/nevus/ISIC_0015060.jpg 0.00369329 3.55823e-07\n",
      "data/test/nevus/ISIC_0015064.jpg 0.000181772 0.64628\n",
      "data/test/nevus/ISIC_0015078.jpg 0.95499 0.0449768\n",
      "data/test/nevus/ISIC_0015089.jpg 8.79504e-35 0.0\n",
      "data/test/nevus/ISIC_0015102.jpg 7.82485e-13 0.999627\n",
      "data/test/nevus/ISIC_0015118.jpg 1.20582e-07 2.81924e-08\n",
      "data/test/nevus/ISIC_0015125.jpg 2.53641e-05 3.00712e-07\n",
      "data/test/nevus/ISIC_0015129.jpg 0.984818 0.0149691\n",
      "data/test/nevus/ISIC_0015130.jpg 0.999794 2.11546e-09\n",
      "data/test/nevus/ISIC_0015139.jpg 1.0 1.24025e-15\n",
      "data/test/nevus/ISIC_0015140.jpg 7.0171e-05 0.00179653\n",
      "data: test, class: nevus, 160 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015146.jpg 1.09568e-29 0.0\n",
      "data/test/nevus/ISIC_0015149.jpg 0.833439 4.48751e-05\n",
      "data/test/nevus/ISIC_0015150.jpg 1.6636e-05 6.98759e-09\n",
      "data/test/nevus/ISIC_0015152.jpg 1.95283e-10 9.28464e-06\n",
      "data/test/nevus/ISIC_0015155.jpg 3.91579e-13 4.09271e-13\n",
      "data/test/nevus/ISIC_0015157.jpg 3.11651e-08 0.40042\n",
      "data/test/nevus/ISIC_0015160.jpg 0.0 4.85866e-28\n",
      "data/test/nevus/ISIC_0015161.jpg 1.84453e-12 0.791965\n",
      "data/test/nevus/ISIC_0015171.jpg 0.00032547 0.554049\n",
      "data/test/nevus/ISIC_0015173.jpg 0.00853114 0.00412615\n",
      "data/test/nevus/ISIC_0015174.jpg 0.00155344 0.000121926\n",
      "data/test/nevus/ISIC_0015175.jpg 1.83381e-11 1.05862e-09\n",
      "data/test/nevus/ISIC_0015176.jpg 0.0100523 0.891977\n",
      "data/test/nevus/ISIC_0015179.jpg 0.0091532 1.36246e-06\n",
      "data/test/nevus/ISIC_0015184.jpg 2.02456e-19 1.00462e-19\n",
      "data/test/nevus/ISIC_0015201.jpg 0.017492 2.3154e-05\n",
      "data/test/nevus/ISIC_0015202.jpg 1.23669e-14 6.07352e-18\n",
      "data/test/nevus/ISIC_0015203.jpg 1.52356e-05 2.757e-07\n",
      "data/test/nevus/ISIC_0015207.jpg 0.00956312 6.22818e-05\n",
      "data/test/nevus/ISIC_0015208.jpg 2.30481e-09 3.16669e-14\n",
      "data: test, class: nevus, 180 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015212.jpg 1.37952e-30 0.0\n",
      "data/test/nevus/ISIC_0015215.jpg 7.66305e-05 7.90351e-07\n",
      "data/test/nevus/ISIC_0015216.jpg 8.26053e-05 7.22541e-17\n",
      "data/test/nevus/ISIC_0015217.jpg 0.000110136 0.00112451\n",
      "data/test/nevus/ISIC_0015218.jpg 8.51614e-13 2.18751e-20\n",
      "data/test/nevus/ISIC_0015223.jpg 3.05107e-16 6.70966e-17\n",
      "data/test/nevus/ISIC_0015224.jpg 1.00623e-09 2.16261e-11\n",
      "data/test/nevus/ISIC_0015226.jpg 4.80635e-09 2.11265e-13\n",
      "data/test/nevus/ISIC_0015232.jpg 3.87385e-05 2.30561e-07\n",
      "data/test/nevus/ISIC_0015237.jpg 0.999883 4.92851e-06\n",
      "data/test/nevus/ISIC_0015241.jpg 1.01683e-08 1.23739e-14\n",
      "data/test/nevus/ISIC_0015244.jpg 1.13105e-06 0.00262702\n",
      "data/test/nevus/ISIC_0015245.jpg 2.92275e-06 0.775582\n",
      "data/test/nevus/ISIC_0015250.jpg 0.0162848 0.000197605\n",
      "data/test/nevus/ISIC_0015254.jpg 0.000452666 2.59077e-05\n",
      "data/test/nevus/ISIC_0015255.jpg 5.05494e-19 5.98128e-16\n",
      "data/test/nevus/ISIC_0015258.jpg 7.48524e-09 0.000496075\n",
      "data/test/nevus/ISIC_0015264.jpg 3.1526e-13 5.09073e-13\n",
      "data/test/nevus/ISIC_0015270.jpg 3.36759e-05 9.70318e-05\n",
      "data/test/nevus/ISIC_0015273.jpg 7.34204e-11 2.15719e-22\n",
      "data: test, class: nevus, 200 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0015274.jpg 0.548173 0.00251342\n",
      "data/test/nevus/ISIC_0015276.jpg 0.00200946 1.13549e-11\n",
      "data/test/nevus/ISIC_0015279.jpg 1.63765e-30 2.05913e-19\n",
      "data/test/nevus/ISIC_0015283.jpg 1.24228e-22 3.26291e-24\n",
      "data/test/nevus/ISIC_0015291.jpg 3.06128e-10 5.11164e-12\n",
      "data/test/nevus/ISIC_0015293.jpg 1.43712e-07 0.0603334\n",
      "data/test/nevus/ISIC_0015298.jpg 6.06262e-10 3.49496e-14\n",
      "data/test/nevus/ISIC_0015309.jpg 1.16359e-12 7.00978e-09\n",
      "data/test/nevus/ISIC_0015310.jpg 7.11825e-14 3.41911e-12\n",
      "data/test/nevus/ISIC_0015311.jpg 0.196296 0.463231\n",
      "data/test/nevus/ISIC_0015312.jpg 1.60593e-05 0.000206785\n",
      "data/test/nevus/ISIC_0015330.jpg 4.48894e-14 6.23708e-25\n",
      "data/test/nevus/ISIC_0015331.jpg 2.41576e-14 2.31003e-13\n",
      "data/test/nevus/ISIC_0015347.jpg 2.30685e-05 1.37014e-08\n",
      "data/test/nevus/ISIC_0015353.jpg 4.85778e-06 0.974104\n",
      "data/test/nevus/ISIC_0015355.jpg 7.99663e-18 2.40351e-10\n",
      "data/test/nevus/ISIC_0015357.jpg 8.22474e-16 2.77651e-20\n",
      "data/test/nevus/ISIC_0015360.jpg 0.00180071 2.91395e-12\n",
      "data/test/nevus/ISIC_0015363.jpg 3.581e-06 8.98215e-09\n",
      "data/test/nevus/ISIC_0015364.jpg 5.61422e-16 1.0\n",
      "data: test, class: nevus, 220 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015368.jpg 0.270108 0.000180489\n",
      "data/test/nevus/ISIC_0015369.jpg 3.95107e-09 5.32095e-12\n",
      "data/test/nevus/ISIC_0015383.jpg 9.42259e-16 5.74845e-19\n",
      "data/test/nevus/ISIC_0015386.jpg 0.00306943 0.00218135\n",
      "data/test/nevus/ISIC_0015390.jpg 0.0480028 0.94598\n",
      "data/test/nevus/ISIC_0015395.jpg 1.51933e-33 4.90435e-13\n",
      "data/test/nevus/ISIC_0015403.jpg 1.0 4.22729e-09\n",
      "data/test/nevus/ISIC_0015404.jpg 0.10906 2.74551e-05\n",
      "data/test/nevus/ISIC_0015411.jpg 1.09061e-18 3.12454e-21\n",
      "data/test/nevus/ISIC_0015412.jpg 0.00623262 9.89225e-08\n",
      "data/test/nevus/ISIC_0015416.jpg 1.04075e-06 2.69893e-05\n",
      "data/test/nevus/ISIC_0015417.jpg 0.564613 0.00146113\n",
      "data/test/nevus/ISIC_0015418.jpg 3.25567e-06 5.36116e-16\n",
      "data/test/nevus/ISIC_0015419.jpg 0.000371562 5.54185e-07\n",
      "data/test/nevus/ISIC_0015436.jpg 9.62676e-08 5.06087e-11\n",
      "data/test/nevus/ISIC_0015440.jpg 4.86785e-10 9.02306e-22\n",
      "data/test/nevus/ISIC_0015447.jpg 1.54634e-07 2.54291e-05\n",
      "data/test/nevus/ISIC_0015455.jpg 0.00141068 2.07604e-08\n",
      "data/test/nevus/ISIC_0015464.jpg 0.607476 0.110337\n",
      "data/test/nevus/ISIC_0015466.jpg 0.390637 5.00754e-06\n",
      "data: test, class: nevus, 240 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015468.jpg 4.89874e-08 1.20945e-08\n",
      "data/test/nevus/ISIC_0015476.jpg 1.98496e-08 5.23002e-24\n",
      "data/test/nevus/ISIC_0015481.jpg 0.0223411 5.20458e-09\n",
      "data/test/nevus/ISIC_0015482.jpg 0.00240805 0.00289028\n",
      "data/test/nevus/ISIC_0015485.jpg 0.134883 0.123575\n",
      "data/test/nevus/ISIC_0015510.jpg 4.15029e-10 3.65461e-14\n",
      "data/test/nevus/ISIC_0015526.jpg 6.73318e-10 1.05919e-16\n",
      "data/test/nevus/ISIC_0015537.jpg 1.38684e-06 0.988971\n",
      "data/test/nevus/ISIC_0015544.jpg 0.222068 0.390142\n",
      "data/test/nevus/ISIC_0015559.jpg 0.0886723 0.00107677\n",
      "data/test/nevus/ISIC_0015563.jpg 9.01521e-05 2.34158e-07\n",
      "data/test/nevus/ISIC_0015566.jpg 1.22772e-08 6.56644e-13\n",
      "data/test/nevus/ISIC_0015568.jpg 0.0145244 0.0022403\n",
      "data/test/nevus/ISIC_0015582.jpg 2.77995e-19 1.06991e-25\n",
      "data/test/nevus/ISIC_0015593.jpg 5.91131e-36 8.32614e-15\n",
      "data/test/nevus/ISIC_0015603.jpg 0.0170248 2.67474e-05\n",
      "data/test/nevus/ISIC_0015607.jpg 0.0042595 0.0620514\n",
      "data/test/nevus/ISIC_0015614.jpg 0.000416068 0.262664\n",
      "data/test/nevus/ISIC_0015617.jpg 0.00727539 0.0147544\n",
      "data/test/nevus/ISIC_0015625.jpg 2.78716e-05 1.69599e-12\n",
      "data: test, class: nevus, 260 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015631.jpg 0.000805781 7.21292e-08\n",
      "data/test/nevus/ISIC_0015636.jpg 0.627354 0.303795\n",
      "data/test/nevus/ISIC_0015638.jpg 1.35048e-13 1.60375e-13\n",
      "data/test/nevus/ISIC_0015641.jpg 2.29104e-10 0.993883\n",
      "data/test/nevus/ISIC_0015645.jpg 1.38388e-07 2.17064e-10\n",
      "data/test/nevus/ISIC_0015936.jpg 0.0105769 0.0159057\n",
      "data/test/nevus/ISIC_0015937.jpg 2.9017e-06 1.14871e-05\n",
      "data/test/nevus/ISIC_0015938.jpg 4.99173e-14 5.39782e-32\n",
      "data/test/nevus/ISIC_0015939.jpg 0.668615 0.00195297\n",
      "data/test/nevus/ISIC_0015940.jpg 3.81781e-06 0.0012815\n",
      "data/test/nevus/ISIC_0015941.jpg 1.46859e-13 9.14252e-07\n",
      "data/test/nevus/ISIC_0015942.jpg 2.76928e-13 1.32948e-07\n",
      "data/test/nevus/ISIC_0015943.jpg 1.55261e-12 0.000693743\n",
      "data/test/nevus/ISIC_0015944.jpg 6.34343e-06 0.999963\n",
      "data/test/nevus/ISIC_0015945.jpg 0.000526136 1.66879e-09\n",
      "data/test/nevus/ISIC_0015946.jpg 0.00132443 0.000561278\n",
      "data/test/nevus/ISIC_0015947.jpg 0.000340868 0.00906546\n",
      "data/test/nevus/ISIC_0015948.jpg 1.17809e-11 8.09519e-15\n",
      "data/test/nevus/ISIC_0015949.jpg 2.43187e-07 9.43302e-05\n",
      "data/test/nevus/ISIC_0015950.jpg 0.0363981 0.0129879\n",
      "data: test, class: nevus, 280 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015951.jpg 2.33386e-10 6.76811e-06\n",
      "data/test/nevus/ISIC_0015952.jpg 0.000201276 2.97084e-05\n",
      "data/test/nevus/ISIC_0015953.jpg 0.000472387 0.996642\n",
      "data/test/nevus/ISIC_0015954.jpg 4.24138e-16 3.52239e-21\n",
      "data/test/nevus/ISIC_0015955.jpg 1.57919e-11 1.64594e-10\n",
      "data/test/nevus/ISIC_0015956.jpg 4.46541e-16 1.09003e-18\n",
      "data/test/nevus/ISIC_0015957.jpg 8.16005e-06 0.999104\n",
      "data/test/nevus/ISIC_0015958.jpg 6.42367e-05 0.0134449\n",
      "data/test/nevus/ISIC_0015959.jpg 1.41025e-14 3.79041e-21\n",
      "data/test/nevus/ISIC_0015960.jpg 0.000257469 4.41763e-10\n",
      "data/test/nevus/ISIC_0015961.jpg 0.00022821 7.3544e-09\n",
      "data/test/nevus/ISIC_0015962.jpg 0.00905839 0.150792\n",
      "data/test/nevus/ISIC_0015963.jpg 9.1109e-24 6.52864e-27\n",
      "data/test/nevus/ISIC_0015964.jpg 7.02389e-17 6.60607e-24\n",
      "data/test/nevus/ISIC_0015965.jpg 2.69093e-05 2.99628e-07\n",
      "data/test/nevus/ISIC_0015966.jpg 4.20171e-07 1.82565e-05\n",
      "data/test/nevus/ISIC_0015967.jpg 5.02246e-08 1.13353e-11\n",
      "data/test/nevus/ISIC_0015968.jpg 0.00950029 0.860372\n",
      "data/test/nevus/ISIC_0015969.jpg 2.32529e-07 2.21855e-06\n",
      "data/test/nevus/ISIC_0015971.jpg 3.01672e-06 2.52609e-05\n",
      "data: test, class: nevus, 300 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015972.jpg 4.67877e-19 0.999996\n",
      "data/test/nevus/ISIC_0015973.jpg 5.26837e-21 3.23296e-19\n",
      "data/test/nevus/ISIC_0015974.jpg 1.64286e-12 5.7595e-06\n",
      "data/test/nevus/ISIC_0015975.jpg 3.16878e-05 1.48178e-12\n",
      "data/test/nevus/ISIC_0015976.jpg 8.4165e-06 3.84213e-07\n",
      "data/test/nevus/ISIC_0015978.jpg 5.88694e-19 1.0\n",
      "data/test/nevus/ISIC_0015979.jpg 0.00684821 0.991953\n",
      "data/test/nevus/ISIC_0015980.jpg 6.57261e-10 3.24678e-09\n",
      "data/test/nevus/ISIC_0015981.jpg 0.0364873 0.0400442\n",
      "data/test/nevus/ISIC_0015982.jpg 0.000562776 0.0168419\n",
      "data/test/nevus/ISIC_0015983.jpg 5.4426e-06 0.900205\n",
      "data/test/nevus/ISIC_0015984.jpg 4.0452e-17 0.00694356\n",
      "data/test/nevus/ISIC_0015985.jpg 5.86711e-05 0.00197294\n",
      "data/test/nevus/ISIC_0015986.jpg 0.00357949 0.000817662\n",
      "data/test/nevus/ISIC_0015987.jpg 3.29762e-06 3.94712e-06\n",
      "data/test/nevus/ISIC_0015988.jpg 2.58287e-05 9.745e-06\n",
      "data/test/nevus/ISIC_0015989.jpg 0.000193715 0.0376997\n",
      "data/test/nevus/ISIC_0015990.jpg 0.00239101 4.21576e-09\n",
      "data/test/nevus/ISIC_0015991.jpg 4.74167e-06 3.16532e-05\n",
      "data/test/nevus/ISIC_0015992.jpg 4.34898e-05 2.01532e-11\n",
      "data: test, class: nevus, 320 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015993.jpg 0.00589489 0.0837263\n",
      "data/test/nevus/ISIC_0015994.jpg 7.87498e-06 6.30654e-08\n",
      "data/test/nevus/ISIC_0015995.jpg 0.140193 0.00010672\n",
      "data/test/nevus/ISIC_0015996.jpg 0.00326335 0.000377677\n",
      "data/test/nevus/ISIC_0015997.jpg 2.2704e-05 1.10627e-08\n",
      "data/test/nevus/ISIC_0015998.jpg 0.391671 7.48719e-05\n",
      "data/test/nevus/ISIC_0015999.jpg 6.29337e-05 4.91718e-07\n",
      "data/test/nevus/ISIC_0016000.jpg 3.5479e-08 0.770532\n",
      "data/test/nevus/ISIC_0016001.jpg 0.0292485 0.00593372\n",
      "data/test/nevus/ISIC_0016002.jpg 4.95472e-07 4.51128e-06\n",
      "data/test/nevus/ISIC_0016003.jpg 3.90353e-07 3.03453e-06\n",
      "data/test/nevus/ISIC_0016004.jpg 0.000122179 2.58835e-07\n",
      "data/test/nevus/ISIC_0016005.jpg 1.73548e-11 0.999999\n",
      "data/test/nevus/ISIC_0016006.jpg 0.000630058 0.999344\n",
      "data/test/nevus/ISIC_0016007.jpg 0.312526 0.0188428\n",
      "data/test/nevus/ISIC_0016008.jpg 0.321967 0.00204349\n",
      "data/test/nevus/ISIC_0016009.jpg 8.37435e-08 3.19175e-10\n",
      "data/test/nevus/ISIC_0016011.jpg 5.68216e-13 0.0793461\n",
      "data/test/nevus/ISIC_0016012.jpg 1.25843e-11 3.95049e-12\n",
      "data/test/nevus/ISIC_0016013.jpg 0.00028664 0.993784\n",
      "data: test, class: nevus, 340 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016014.jpg 3.77984e-08 0.000544089\n",
      "data/test/nevus/ISIC_0016015.jpg 1.05521e-13 2.2482e-17\n",
      "data/test/nevus/ISIC_0016016.jpg 0.999994 6.38856e-06\n",
      "data/test/nevus/ISIC_0016017.jpg 9.70544e-11 1.82053e-12\n",
      "data/test/nevus/ISIC_0016018.jpg 5.16687e-13 3.24829e-11\n",
      "data/test/nevus/ISIC_0016019.jpg 0.0122686 0.350666\n",
      "data/test/nevus/ISIC_0016022.jpg 1.23535e-06 0.00152746\n",
      "data/test/nevus/ISIC_0016023.jpg 6.90404e-06 1.41814e-07\n",
      "data/test/nevus/ISIC_0016024.jpg 1.34709e-07 2.92309e-09\n",
      "data/test/nevus/ISIC_0016025.jpg 0.997411 4.1159e-07\n",
      "data/test/nevus/ISIC_0016026.jpg 6.21791e-07 0.997638\n",
      "data/test/nevus/ISIC_0016027.jpg 3.5666e-06 0.999823\n",
      "data/test/nevus/ISIC_0016028.jpg 5.625e-15 1.87301e-06\n",
      "data/test/nevus/ISIC_0016029.jpg 0.000481935 0.000141717\n",
      "data/test/nevus/ISIC_0016030.jpg 1.32476e-05 1.28832e-05\n",
      "data/test/nevus/ISIC_0016031.jpg 1.57784e-21 1.70563e-21\n",
      "data/test/nevus/ISIC_0016033.jpg 2.24742e-07 0.998547\n",
      "data/test/nevus/ISIC_0016034.jpg 1.91522e-05 0.00167333\n",
      "data/test/nevus/ISIC_0016035.jpg 3.709e-12 0.000621545\n",
      "data/test/nevus/ISIC_0016036.jpg 0.00151363 0.000367817\n",
      "data: test, class: nevus, 360 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0016037.jpg 0.00125209 0.000755699\n",
      "data/test/nevus/ISIC_0016038.jpg 5.34933e-11 3.81301e-09\n",
      "data/test/nevus/ISIC_0016040.jpg 0.000252336 0.00344919\n",
      "data/test/nevus/ISIC_0016041.jpg 1.0 8.24922e-15\n",
      "data/test/nevus/ISIC_0016042.jpg 4.01912e-06 0.000268892\n",
      "data/test/nevus/ISIC_0016043.jpg 9.82865e-12 1.48007e-06\n",
      "data/test/nevus/ISIC_0016044.jpg 3.45603e-18 0.000117393\n",
      "data/test/nevus/ISIC_0016045.jpg 0.743939 0.00722481\n",
      "data/test/nevus/ISIC_0016046.jpg 0.236138 0.000124488\n",
      "data/test/nevus/ISIC_0016048.jpg 0.00337243 5.86765e-06\n",
      "data/test/nevus/ISIC_0016049.jpg 0.255361 1.32919e-09\n",
      "data/test/nevus/ISIC_0016050.jpg 0.00392811 0.00283341\n",
      "data/test/nevus/ISIC_0016051.jpg 4.94773e-06 0.00140405\n",
      "data/test/nevus/ISIC_0016052.jpg 0.0172655 0.000213718\n",
      "data/test/nevus/ISIC_0016053.jpg 7.38449e-07 1.91405e-09\n",
      "data/test/nevus/ISIC_0016054.jpg 0.00122573 0.99857\n",
      "data/test/nevus/ISIC_0016055.jpg 7.57024e-06 1.25871e-11\n",
      "data/test/nevus/ISIC_0016056.jpg 0.0951181 0.058071\n",
      "data/test/nevus/ISIC_0016057.jpg 0.000432239 7.42565e-08\n",
      "data/test/nevus/ISIC_0016058.jpg 3.32728e-15 2.93e-11\n",
      "data: test, class: nevus, 380 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016059.jpg 0.000306434 9.37374e-11\n",
      "data/test/nevus/ISIC_0016060.jpg 1.11012e-05 0.782438\n",
      "data/test/nevus/ISIC_0016061.jpg 7.10049e-11 8.07614e-20\n",
      "data/test/nevus/ISIC_0016062.jpg 4.04721e-05 2.32381e-10\n",
      "data/test/nevus/ISIC_0016063.jpg 1.81418e-07 7.62245e-09\n",
      "data/test/nevus/ISIC_0016064.jpg 0.00447657 0.972097\n",
      "data/test/nevus/ISIC_0016065.jpg 2.37382e-05 0.00297369\n",
      "data/test/nevus/ISIC_0016066.jpg 0.504046 0.0517344\n",
      "data/test/nevus/ISIC_0016068.jpg 0.933103 0.00665916\n",
      "data/test/nevus/ISIC_0016069.jpg 7.14035e-06 1.04235e-08\n",
      "data/test/nevus/ISIC_0016070.jpg 9.90375e-12 1.00458e-10\n",
      "data/test/nevus/ISIC_0016071.jpg 0.0625993 0.212584\n",
      "data/test/nevus/ISIC_0016072.jpg 0.569086 0.0256429\n",
      "data: test, class: nevus, 393 / 393 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012086.jpg 6.27057e-05 5.26209e-09\n",
      "data/test/seborrheic_keratosis/ISIC_0012134.jpg 0.000721294 0.99508\n",
      "data/test/seborrheic_keratosis/ISIC_0012136.jpg 2.27472e-05 0.999977\n",
      "data/test/seborrheic_keratosis/ISIC_0012178.jpg 8.17864e-06 0.999951\n",
      "data/test/seborrheic_keratosis/ISIC_0012199.jpg 0.999654 3.37458e-08\n",
      "data/test/seborrheic_keratosis/ISIC_0012207.jpg 3.45235e-06 0.78583\n",
      "data/test/seborrheic_keratosis/ISIC_0012215.jpg 0.145785 0.841417\n",
      "data/test/seborrheic_keratosis/ISIC_0012223.jpg 0.00143819 0.935822\n",
      "data/test/seborrheic_keratosis/ISIC_0012240.jpg 0.000924784 0.995528\n",
      "data/test/seborrheic_keratosis/ISIC_0012248.jpg 1.51692e-07 0.999906\n",
      "data/test/seborrheic_keratosis/ISIC_0012265.jpg 0.00195549 8.149e-09\n",
      "data/test/seborrheic_keratosis/ISIC_0012266.jpg 2.8431e-12 8.57443e-08\n",
      "data/test/seborrheic_keratosis/ISIC_0012272.jpg 1.77538e-06 0.00053518\n",
      "data/test/seborrheic_keratosis/ISIC_0012273.jpg 0.999587 0.000413469\n",
      "data/test/seborrheic_keratosis/ISIC_0012314.jpg 1.38373e-10 3.27785e-16\n",
      "data/test/seborrheic_keratosis/ISIC_0012323.jpg 3.41279e-15 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0012330.jpg 5.55245e-06 2.27379e-10\n",
      "data/test/seborrheic_keratosis/ISIC_0012358.jpg 2.1656e-07 0.0127974\n",
      "data/test/seborrheic_keratosis/ISIC_0012364.jpg 8.6578e-05 3.63706e-05\n",
      "data/test/seborrheic_keratosis/ISIC_0012372.jpg 5.95658e-12 0.999332\n",
      "data: test, class: seborrheic_keratosis, 20 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012375.jpg 0.000301941 0.979657\n",
      "data/test/seborrheic_keratosis/ISIC_0012387.jpg 3.24571e-11 0.160628\n",
      "data/test/seborrheic_keratosis/ISIC_0012388.jpg 2.21668e-06 0.00162544\n",
      "data/test/seborrheic_keratosis/ISIC_0012414.jpg 0.00149281 0.994077\n",
      "data/test/seborrheic_keratosis/ISIC_0012428.jpg 9.28411e-05 0.915901\n",
      "data/test/seborrheic_keratosis/ISIC_0012432.jpg 1.42186e-08 0.950694\n",
      "data/test/seborrheic_keratosis/ISIC_0012447.jpg 1.50834e-10 0.999988\n",
      "data/test/seborrheic_keratosis/ISIC_0012448.jpg 2.77064e-06 0.0311993\n",
      "data/test/seborrheic_keratosis/ISIC_0012510.jpg 0.403834 0.0371376\n",
      "data/test/seborrheic_keratosis/ISIC_0012522.jpg 2.76973e-05 0.00233831\n",
      "data/test/seborrheic_keratosis/ISIC_0012537.jpg 0.985135 0.00674496\n",
      "data/test/seborrheic_keratosis/ISIC_0012548.jpg 0.000430502 0.997268\n",
      "data/test/seborrheic_keratosis/ISIC_0012705.jpg 8.46485e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012757.jpg 5.59316e-09 0.999964\n",
      "data/test/seborrheic_keratosis/ISIC_0012786.jpg 6.9573e-18 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012848.jpg 0.00177464 0.00185226\n",
      "data/test/seborrheic_keratosis/ISIC_0012852.jpg 8.46367e-09 0.991981\n",
      "data/test/seborrheic_keratosis/ISIC_0012928.jpg 2.39143e-09 2.50433e-08\n",
      "data/test/seborrheic_keratosis/ISIC_0012955.jpg 3.80862e-07 0.999917\n",
      "data/test/seborrheic_keratosis/ISIC_0012974.jpg 4.63235e-16 1.0\n",
      "data: test, class: seborrheic_keratosis, 40 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0013030.jpg 6.51249e-12 0.999853\n",
      "data/test/seborrheic_keratosis/ISIC_0013035.jpg 3.07327e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013085.jpg 2.70777e-14 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0013169.jpg 3.01191e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013170.jpg 1.48236e-09 0.999998\n",
      "data/test/seborrheic_keratosis/ISIC_0013203.jpg 9.68058e-12 0.997137\n",
      "data/test/seborrheic_keratosis/ISIC_0013270.jpg 6.31405e-09 3.62835e-06\n",
      "data/test/seborrheic_keratosis/ISIC_0013271.jpg 0.000283455 0.00244076\n",
      "data/test/seborrheic_keratosis/ISIC_0013281.jpg 1.06348e-08 0.999969\n",
      "data/test/seborrheic_keratosis/ISIC_0013319.jpg 0.0781616 0.00378504\n",
      "data/test/seborrheic_keratosis/ISIC_0013393.jpg 0.60397 0.388562\n",
      "data/test/seborrheic_keratosis/ISIC_0013465.jpg 0.00110705 0.796213\n",
      "data/test/seborrheic_keratosis/ISIC_0013673.jpg 2.54048e-09 0.864856\n",
      "data/test/seborrheic_keratosis/ISIC_0013708.jpg 3.33459e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013764.jpg 8.8988e-07 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0013977.jpg 2.99786e-23 8.09762e-19\n",
      "data/test/seborrheic_keratosis/ISIC_0014006.jpg 3.56912e-31 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014177.jpg 6.01593e-15 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014251.jpg 4.24989e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014278.jpg 0.000167373 0.0766143\n",
      "data: test, class: seborrheic_keratosis, 60 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014386.jpg 0.00583893 0.990704\n",
      "data/test/seborrheic_keratosis/ISIC_0014392.jpg 4.1543e-06 0.999182\n",
      "data/test/seborrheic_keratosis/ISIC_0014409.jpg 1.23713e-06 0.01286\n",
      "data/test/seborrheic_keratosis/ISIC_0014419.jpg 0.0616736 0.858968\n",
      "data/test/seborrheic_keratosis/ISIC_0014457.jpg 3.88907e-08 3.88853e-08\n",
      "data/test/seborrheic_keratosis/ISIC_0014474.jpg 8.39614e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014500.jpg 0.246774 0.594963\n",
      "data/test/seborrheic_keratosis/ISIC_0014503.jpg 6.96267e-10 0.0745596\n",
      "data/test/seborrheic_keratosis/ISIC_0014567.jpg 2.64167e-21 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014574.jpg 5.25263e-17 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014575.jpg 1.51048e-21 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014586.jpg 2.31245e-11 2.50185e-11\n",
      "data/test/seborrheic_keratosis/ISIC_0014587.jpg 0.0 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014588.jpg 2.42632e-19 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014590.jpg 0.146992 0.00052808\n",
      "data/test/seborrheic_keratosis/ISIC_0014600.jpg 1.90275e-07 0.76978\n",
      "data/test/seborrheic_keratosis/ISIC_0014619.jpg 0.000237982 0.999762\n",
      "data/test/seborrheic_keratosis/ISIC_0014626.jpg 0.0 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014627.jpg 1.1954e-08 0.999821\n",
      "data/test/seborrheic_keratosis/ISIC_0014629.jpg 7.78203e-18 0.999999\n",
      "data: test, class: seborrheic_keratosis, 80 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014631.jpg 1.04426e-15 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0014634.jpg 8.61166e-14 0.000123101\n",
      "data/test/seborrheic_keratosis/ISIC_0014643.jpg 1.49858e-30 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014644.jpg 0.0710169 0.0552975\n",
      "data/test/seborrheic_keratosis/ISIC_0014645.jpg 2.57798e-14 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014647.jpg 3.45481e-08 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014648.jpg 1.70812e-33 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014649.jpg 7.4565e-11 0.999996\n",
      "data/test/seborrheic_keratosis/ISIC_0014652.jpg 8.10999e-17 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014653.jpg 5.28179e-22 1.0\n",
      "data: test, class: seborrheic_keratosis, 90 / 90 images processed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "predections_csv = open('predections.csv', 'w')\n",
    "writer = csv.writer(predections_csv, lineterminator='\\n')\n",
    "writer.writerow(['Id', 'task_1', 'task_2'])\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "labels_batch = []\n",
    "files_batch = []\n",
    "\n",
    "d_type = 'test'\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    for c in classes:\n",
    "        image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "        files = os.listdir(image_dir)\n",
    "        for i, file in enumerate(files, 1):\n",
    "            # load image and resize it to 224x224\n",
    "            file_path = os.path.join(image_dir, file)\n",
    "            img = utils.load_image(file_path)\n",
    "            \n",
    "            batch.append(img.reshape((1, 224, 224, 3)))\n",
    "            labels_batch.append(c)\n",
    "            files_batch.append(file_path)\n",
    "\n",
    "            if (len(batch) >= batch_size) or i == len(files):\n",
    "                images = np.concatenate(batch)\n",
    "\n",
    "                feed_dict = {input_: images}\n",
    "                codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "                \n",
    "                feed_dict = {inputs_: codes_batch, labels_: lb.transform(labels_batch)}\n",
    "                predections_batch = sess.run(predicted, feed_dict=feed_dict)\n",
    "\n",
    "                for ii in range(len(batch)):\n",
    "                    predection = predections_batch[ii]\n",
    "                    label = labels_batch[ii]\n",
    "                    file_id = files_batch[ii]\n",
    "                    \n",
    "                    p_melanoma = predection[0]\n",
    "                    p_seborrheic_keratosis = predection[2]\n",
    "                    \n",
    "                    print(file_id, p_melanoma, p_seborrheic_keratosis)\n",
    "                    writer.writerow([file_id, p_melanoma, p_seborrheic_keratosis])\n",
    "                    \n",
    "                batch = []\n",
    "                labels_batch = []\n",
    "                files_batch = []\n",
    "                print('data: {}, class: {}, {} / {} images processed.'.format(d_type, c, i, len(files)))\n",
    "                \n",
    "                \n",
    "predections_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
