{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow_vgg'...\n",
      "remote: Counting objects: 113, done.\u001b[K\n",
      "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 113\u001b[K\n",
      "Receiving objects: 100% (113/113), 55.91 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# Operations for floydhub\n",
    "!git clone https://github.com/machrisaa/tensorflow-vgg tensorflow_vgg\n",
    "!ln -s /data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "vgg_dir = 'tensorflow_vgg/'\n",
    "vgg_name = 'vgg19'\n",
    "\n",
    "# Make sure vgg exists\n",
    "if not isdir(vgg_dir):\n",
    "    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "vgg_param_file = '{}{}.npy'.format(vgg_dir, vgg_name)\n",
    "if not isfile(vgg_param_file):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc= vgg_name + ' Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/{}.npy'.format(vgg_name),\n",
    "            vgg_param_file,\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow_vgg import vgg19\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "classes = [d for d in os.listdir(train_dir) if os.path.isdir(train_dir + d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage.transform import resize\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image\n",
    "\n",
    "def vertical_flip(image):\n",
    "    image = image[::-1, :, :]\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, angle_range=(0, 180)):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.randint(*angle_range)\n",
    "    image = rotate(image, angle)\n",
    "    image = resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "batch_size = 10\n",
    "batch = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # vgg = vgg19.Vgg19()\n",
    "    vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    \n",
    "    codes = None\n",
    "    labels = []\n",
    "    count = 0\n",
    "\n",
    "    for d_type in ['train', 'valid', 'test']:\n",
    "        for c in classes:\n",
    "            image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "            files = os.listdir(image_dir)\n",
    "            for i, file in enumerate(files, 1):\n",
    "                # load image and resize it to 224x224\n",
    "                file_path = os.path.join(image_dir, file)\n",
    "                img = utils.load_image(file_path)\n",
    "                batch.append(img.reshape((1, 224, 224, 3)))\n",
    "                labels.append(c)\n",
    "                \n",
    "                # data augumentation for training data\n",
    "                if d_type == 'train':\n",
    "                    batch.append(horizontal_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(vertical_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img, angle_range=(-180, 0)).reshape((1,224,224,3)))\n",
    "                    labels.append(c)                  \n",
    "\n",
    "                if (len(batch) >= batch_size) or i == len(files):\n",
    "                    images = np.concatenate(batch)\n",
    "\n",
    "                    feed_dict = {input_: images}\n",
    "                    codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "\n",
    "                    if codes is None:\n",
    "                        codes = codes_batch\n",
    "                    else:\n",
    "                        codes = np.concatenate((codes, codes_batch))\n",
    "\n",
    "                    count += len(batch)\n",
    "                    batch = []\n",
    "                    print('data: {}, class: {}, {} / {} images processed. data count: {}'.format(d_type, c, i, len(files), count))\n",
    "\n",
    "        # write codes to file\n",
    "        with open('{}_{}_codes'.format(vgg_name, d_type), 'w') as f:\n",
    "            codes.tofile(f)\n",
    "            codes = None\n",
    "\n",
    "        # write labels to file\n",
    "        with open('{}_{}_labels'.format(vgg_name, d_type), 'w') as f:\n",
    "            writer = csv.writer(f, delimiter='\\n')\n",
    "            writer.writerow(labels)\n",
    "            labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read codes and labels from file\n",
    "import csv\n",
    "\n",
    "# train data\n",
    "with open('{}_train_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    train_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_train_codes'.format(vgg_name)) as f:\n",
    "    train_x = np.fromfile(f, dtype=np.float32)\n",
    "    train_x = train_x.reshape((len(train_labels), -1))\n",
    "    \n",
    "# valid data\n",
    "with open('{}_valid_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    valid_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_valid_codes'.format(vgg_name)) as f:\n",
    "    val_x = np.fromfile(f, dtype=np.float32)\n",
    "    val_x = val_x.reshape((len(valid_labels), -1))\n",
    "    \n",
    "# test data\n",
    "with open('{}_test_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    test_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_test_codes'.format(vgg_name)) as f:\n",
    "    test_x = np.fromfile(f, dtype=np.float32)\n",
    "    test_x = test_x.reshape((len(test_labels), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(classes)\n",
    "\n",
    "train_y = lb.transform(train_labels)\n",
    "val_y = lb.transform(valid_labels)\n",
    "test_y = lb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (2000, 4096) (2000, 3)\n",
      "Validation shapes (x, y): (150, 4096) (150, 3)\n",
      "Test shapes (x, y): (600, 4096) (600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, train_y.shape[1]])\n",
    "\n",
    "fc_1 = tf.contrib.layers.fully_connected(inputs_, 512)\n",
    "dropout_1 = tf.contrib.layers.dropout(fc_1)\n",
    "fc_2 = tf.contrib.layers.fully_connected(dropout_1, 128)\n",
    "dropout_2 = tf.contrib.layers.dropout(fc_2)\n",
    "    \n",
    "logits = tf.contrib.layers.fully_connected(dropout_2, train_y.shape[1], activation_fn=None)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(cost)\n",
    "\n",
    "predicted = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n",
      "Epoch: 1/500 Iteration: 0 Training loss: 8.01568\n",
      "Epoch: 1/500 Iteration: 1 Training loss: 6.44547\n",
      "Epoch: 1/500 Iteration: 2 Training loss: 0.55847\n",
      "Epoch: 1/500 Iteration: 3 Training loss: 0.04495\n",
      "Epoch: 1/500 Iteration: 4 Training loss: 50.26734\n",
      "Epoch: 0/500 Iteration: 5 Validation Acc: 0.5200\n",
      "Epoch: 2/500 Iteration: 5 Training loss: 17.40879\n",
      "Epoch: 2/500 Iteration: 6 Training loss: 0.04064\n",
      "Epoch: 2/500 Iteration: 7 Training loss: 0.05108\n",
      "Epoch: 2/500 Iteration: 8 Training loss: 0.15226\n",
      "Epoch: 2/500 Iteration: 9 Training loss: 14.76763\n",
      "Epoch: 1/500 Iteration: 10 Validation Acc: 0.5067\n",
      "Epoch: 3/500 Iteration: 10 Training loss: 4.36388\n",
      "Epoch: 3/500 Iteration: 11 Training loss: 1.37924\n",
      "Epoch: 3/500 Iteration: 12 Training loss: 1.79588\n",
      "Epoch: 3/500 Iteration: 13 Training loss: 2.30511\n",
      "Epoch: 3/500 Iteration: 14 Training loss: 4.15821\n",
      "Epoch: 2/500 Iteration: 15 Validation Acc: 0.3733\n",
      "Epoch: 4/500 Iteration: 15 Training loss: 3.14561\n",
      "Epoch: 4/500 Iteration: 16 Training loss: 2.12299\n",
      "Epoch: 4/500 Iteration: 17 Training loss: 1.98962\n",
      "Epoch: 4/500 Iteration: 18 Training loss: 1.63871\n",
      "Epoch: 4/500 Iteration: 19 Training loss: 3.53883\n",
      "Epoch: 3/500 Iteration: 20 Validation Acc: 0.4067\n",
      "Epoch: 5/500 Iteration: 20 Training loss: 3.14946\n",
      "Epoch: 5/500 Iteration: 21 Training loss: 1.10828\n",
      "Epoch: 5/500 Iteration: 22 Training loss: 0.81070\n",
      "Epoch: 5/500 Iteration: 23 Training loss: 0.63943\n",
      "Epoch: 5/500 Iteration: 24 Training loss: 4.01709\n",
      "Epoch: 4/500 Iteration: 25 Validation Acc: 0.5333\n",
      "Epoch: 6/500 Iteration: 25 Training loss: 2.87456\n",
      "Epoch: 6/500 Iteration: 26 Training loss: 0.60851\n",
      "Epoch: 6/500 Iteration: 27 Training loss: 0.62702\n",
      "Epoch: 6/500 Iteration: 28 Training loss: 0.54153\n",
      "Epoch: 6/500 Iteration: 29 Training loss: 3.36978\n",
      "Epoch: 5/500 Iteration: 30 Validation Acc: 0.4667\n",
      "Epoch: 7/500 Iteration: 30 Training loss: 2.59472\n",
      "Epoch: 7/500 Iteration: 31 Training loss: 0.57467\n",
      "Epoch: 7/500 Iteration: 32 Training loss: 0.58174\n",
      "Epoch: 7/500 Iteration: 33 Training loss: 0.58137\n",
      "Epoch: 7/500 Iteration: 34 Training loss: 2.66619\n",
      "Epoch: 6/500 Iteration: 35 Validation Acc: 0.5067\n",
      "Epoch: 8/500 Iteration: 35 Training loss: 2.23123\n",
      "Epoch: 8/500 Iteration: 36 Training loss: 0.69138\n",
      "Epoch: 8/500 Iteration: 37 Training loss: 0.69508\n",
      "Epoch: 8/500 Iteration: 38 Training loss: 0.74307\n",
      "Epoch: 8/500 Iteration: 39 Training loss: 2.19405\n",
      "Epoch: 7/500 Iteration: 40 Validation Acc: 0.4067\n",
      "Epoch: 9/500 Iteration: 40 Training loss: 1.57520\n",
      "Epoch: 9/500 Iteration: 41 Training loss: 0.70928\n",
      "Epoch: 9/500 Iteration: 42 Training loss: 0.68323\n",
      "Epoch: 9/500 Iteration: 43 Training loss: 0.59974\n",
      "Epoch: 9/500 Iteration: 44 Training loss: 2.05307\n",
      "Epoch: 8/500 Iteration: 45 Validation Acc: 0.4867\n",
      "Epoch: 10/500 Iteration: 45 Training loss: 1.69284\n",
      "Epoch: 10/500 Iteration: 46 Training loss: 0.64920\n",
      "Epoch: 10/500 Iteration: 47 Training loss: 0.60778\n",
      "Epoch: 10/500 Iteration: 48 Training loss: 0.54620\n",
      "Epoch: 10/500 Iteration: 49 Training loss: 1.88411\n",
      "Epoch: 9/500 Iteration: 50 Validation Acc: 0.5133\n",
      "Epoch: 11/500 Iteration: 50 Training loss: 1.43309\n",
      "Epoch: 11/500 Iteration: 51 Training loss: 0.58071\n",
      "Epoch: 11/500 Iteration: 52 Training loss: 0.55393\n",
      "Epoch: 11/500 Iteration: 53 Training loss: 0.53763\n",
      "Epoch: 11/500 Iteration: 54 Training loss: 1.72104\n",
      "Epoch: 10/500 Iteration: 55 Validation Acc: 0.5000\n",
      "Epoch: 12/500 Iteration: 55 Training loss: 1.52129\n",
      "Epoch: 12/500 Iteration: 56 Training loss: 0.51196\n",
      "Epoch: 12/500 Iteration: 57 Training loss: 0.54916\n",
      "Epoch: 12/500 Iteration: 58 Training loss: 0.52638\n",
      "Epoch: 12/500 Iteration: 59 Training loss: 1.74132\n",
      "Epoch: 11/500 Iteration: 60 Validation Acc: 0.5267\n",
      "Epoch: 13/500 Iteration: 60 Training loss: 1.46704\n",
      "Epoch: 13/500 Iteration: 61 Training loss: 0.53590\n",
      "Epoch: 13/500 Iteration: 62 Training loss: 0.51787\n",
      "Epoch: 13/500 Iteration: 63 Training loss: 0.50905\n",
      "Epoch: 13/500 Iteration: 64 Training loss: 1.56908\n",
      "Epoch: 12/500 Iteration: 65 Validation Acc: 0.5467\n",
      "Epoch: 14/500 Iteration: 65 Training loss: 1.20447\n",
      "Epoch: 14/500 Iteration: 66 Training loss: 0.51238\n",
      "Epoch: 14/500 Iteration: 67 Training loss: 0.49332\n",
      "Epoch: 14/500 Iteration: 68 Training loss: 0.54629\n",
      "Epoch: 14/500 Iteration: 69 Training loss: 1.51282\n",
      "Epoch: 13/500 Iteration: 70 Validation Acc: 0.5867\n",
      "Epoch: 15/500 Iteration: 70 Training loss: 1.19682\n",
      "Epoch: 15/500 Iteration: 71 Training loss: 0.55731\n",
      "Epoch: 15/500 Iteration: 72 Training loss: 0.53354\n",
      "Epoch: 15/500 Iteration: 73 Training loss: 0.51162\n",
      "Epoch: 15/500 Iteration: 74 Training loss: 1.50134\n",
      "Epoch: 14/500 Iteration: 75 Validation Acc: 0.5333\n",
      "Epoch: 16/500 Iteration: 75 Training loss: 1.22092\n",
      "Epoch: 16/500 Iteration: 76 Training loss: 0.50747\n",
      "Epoch: 16/500 Iteration: 77 Training loss: 0.55269\n",
      "Epoch: 16/500 Iteration: 78 Training loss: 0.49546\n",
      "Epoch: 16/500 Iteration: 79 Training loss: 1.38585\n",
      "Epoch: 15/500 Iteration: 80 Validation Acc: 0.5333\n",
      "Epoch: 17/500 Iteration: 80 Training loss: 1.18410\n",
      "Epoch: 17/500 Iteration: 81 Training loss: 0.50708\n",
      "Epoch: 17/500 Iteration: 82 Training loss: 0.50732\n",
      "Epoch: 17/500 Iteration: 83 Training loss: 0.48180\n",
      "Epoch: 17/500 Iteration: 84 Training loss: 1.41746\n",
      "Epoch: 16/500 Iteration: 85 Validation Acc: 0.5467\n",
      "Epoch: 18/500 Iteration: 85 Training loss: 1.05029\n",
      "Epoch: 18/500 Iteration: 86 Training loss: 0.47085\n",
      "Epoch: 18/500 Iteration: 87 Training loss: 0.49155\n",
      "Epoch: 18/500 Iteration: 88 Training loss: 0.46618\n",
      "Epoch: 18/500 Iteration: 89 Training loss: 1.29263\n",
      "Epoch: 17/500 Iteration: 90 Validation Acc: 0.5800\n",
      "Epoch: 19/500 Iteration: 90 Training loss: 1.03397\n",
      "Epoch: 19/500 Iteration: 91 Training loss: 0.51624\n",
      "Epoch: 19/500 Iteration: 92 Training loss: 0.49011\n",
      "Epoch: 19/500 Iteration: 93 Training loss: 0.43905\n",
      "Epoch: 19/500 Iteration: 94 Training loss: 1.38017\n",
      "Epoch: 18/500 Iteration: 95 Validation Acc: 0.5667\n",
      "Epoch: 20/500 Iteration: 95 Training loss: 1.07599\n",
      "Epoch: 20/500 Iteration: 96 Training loss: 0.46208\n",
      "Epoch: 20/500 Iteration: 97 Training loss: 0.42901\n",
      "Epoch: 20/500 Iteration: 98 Training loss: 0.43458\n",
      "Epoch: 20/500 Iteration: 99 Training loss: 1.33417\n",
      "Epoch: 19/500 Iteration: 100 Validation Acc: 0.5533\n",
      "Epoch: 21/500 Iteration: 100 Training loss: 1.03434\n",
      "Epoch: 21/500 Iteration: 101 Training loss: 0.46187\n",
      "Epoch: 21/500 Iteration: 102 Training loss: 0.47015\n",
      "Epoch: 21/500 Iteration: 103 Training loss: 0.45752\n",
      "Epoch: 21/500 Iteration: 104 Training loss: 1.43598\n",
      "Epoch: 20/500 Iteration: 105 Validation Acc: 0.5533\n",
      "Epoch: 22/500 Iteration: 105 Training loss: 1.00273\n",
      "Epoch: 22/500 Iteration: 106 Training loss: 0.43135\n",
      "Epoch: 22/500 Iteration: 107 Training loss: 0.43676\n",
      "Epoch: 22/500 Iteration: 108 Training loss: 0.40509\n",
      "Epoch: 22/500 Iteration: 109 Training loss: 1.37096\n",
      "Epoch: 21/500 Iteration: 110 Validation Acc: 0.5333\n",
      "Epoch: 23/500 Iteration: 110 Training loss: 0.92117\n",
      "Epoch: 23/500 Iteration: 111 Training loss: 0.43070\n",
      "Epoch: 23/500 Iteration: 112 Training loss: 0.43696\n",
      "Epoch: 23/500 Iteration: 113 Training loss: 0.42888\n",
      "Epoch: 23/500 Iteration: 114 Training loss: 1.29276\n",
      "Epoch: 22/500 Iteration: 115 Validation Acc: 0.5667\n",
      "Epoch: 24/500 Iteration: 115 Training loss: 0.87622\n",
      "Epoch: 24/500 Iteration: 116 Training loss: 0.40731\n",
      "Epoch: 24/500 Iteration: 117 Training loss: 0.40909\n",
      "Epoch: 24/500 Iteration: 118 Training loss: 0.39402\n",
      "Epoch: 24/500 Iteration: 119 Training loss: 1.34456\n",
      "Epoch: 23/500 Iteration: 120 Validation Acc: 0.6000\n",
      "Epoch: 25/500 Iteration: 120 Training loss: 0.98914\n",
      "Epoch: 25/500 Iteration: 121 Training loss: 0.37553\n",
      "Epoch: 25/500 Iteration: 122 Training loss: 0.35099\n",
      "Epoch: 25/500 Iteration: 123 Training loss: 0.35393\n",
      "Epoch: 25/500 Iteration: 124 Training loss: 1.33647\n",
      "Epoch: 24/500 Iteration: 125 Validation Acc: 0.5600\n",
      "Epoch: 26/500 Iteration: 125 Training loss: 0.94424\n",
      "Epoch: 26/500 Iteration: 126 Training loss: 0.43381\n",
      "Epoch: 26/500 Iteration: 127 Training loss: 0.39396\n",
      "Epoch: 26/500 Iteration: 128 Training loss: 0.38585\n",
      "Epoch: 26/500 Iteration: 129 Training loss: 1.32791\n",
      "Epoch: 25/500 Iteration: 130 Validation Acc: 0.6067\n",
      "Epoch: 27/500 Iteration: 130 Training loss: 0.86990\n",
      "Epoch: 27/500 Iteration: 131 Training loss: 0.43954\n",
      "Epoch: 27/500 Iteration: 132 Training loss: 0.42818\n",
      "Epoch: 27/500 Iteration: 133 Training loss: 0.40603\n",
      "Epoch: 27/500 Iteration: 134 Training loss: 1.24865\n",
      "Epoch: 26/500 Iteration: 135 Validation Acc: 0.6000\n",
      "Epoch: 28/500 Iteration: 135 Training loss: 0.86607\n",
      "Epoch: 28/500 Iteration: 136 Training loss: 0.43798\n",
      "Epoch: 28/500 Iteration: 137 Training loss: 0.39863\n",
      "Epoch: 28/500 Iteration: 138 Training loss: 0.41359\n",
      "Epoch: 28/500 Iteration: 139 Training loss: 1.19402\n",
      "Epoch: 27/500 Iteration: 140 Validation Acc: 0.5933\n",
      "Epoch: 29/500 Iteration: 140 Training loss: 0.91958\n",
      "Epoch: 29/500 Iteration: 141 Training loss: 0.39702\n",
      "Epoch: 29/500 Iteration: 142 Training loss: 0.38774\n",
      "Epoch: 29/500 Iteration: 143 Training loss: 0.37494\n",
      "Epoch: 29/500 Iteration: 144 Training loss: 1.30035\n",
      "Epoch: 28/500 Iteration: 145 Validation Acc: 0.5933\n",
      "Epoch: 30/500 Iteration: 145 Training loss: 0.92017\n",
      "Epoch: 30/500 Iteration: 146 Training loss: 0.39001\n",
      "Epoch: 30/500 Iteration: 147 Training loss: 0.36061\n",
      "Epoch: 30/500 Iteration: 148 Training loss: 0.35168\n",
      "Epoch: 30/500 Iteration: 149 Training loss: 1.26231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/500 Iteration: 150 Validation Acc: 0.5867\n",
      "Epoch: 31/500 Iteration: 150 Training loss: 0.80016\n",
      "Epoch: 31/500 Iteration: 151 Training loss: 0.34255\n",
      "Epoch: 31/500 Iteration: 152 Training loss: 0.34326\n",
      "Epoch: 31/500 Iteration: 153 Training loss: 0.38091\n",
      "Epoch: 31/500 Iteration: 154 Training loss: 1.29398\n",
      "Epoch: 30/500 Iteration: 155 Validation Acc: 0.5933\n",
      "Epoch: 32/500 Iteration: 155 Training loss: 0.82281\n",
      "Epoch: 32/500 Iteration: 156 Training loss: 0.39666\n",
      "Epoch: 32/500 Iteration: 157 Training loss: 0.37757\n",
      "Epoch: 32/500 Iteration: 158 Training loss: 0.37707\n",
      "Epoch: 32/500 Iteration: 159 Training loss: 1.20556\n",
      "Epoch: 31/500 Iteration: 160 Validation Acc: 0.6067\n",
      "Epoch: 33/500 Iteration: 160 Training loss: 0.83828\n",
      "Epoch: 33/500 Iteration: 161 Training loss: 0.36699\n",
      "Epoch: 33/500 Iteration: 162 Training loss: 0.34710\n",
      "Epoch: 33/500 Iteration: 163 Training loss: 0.35048\n",
      "Epoch: 33/500 Iteration: 164 Training loss: 1.14363\n",
      "Epoch: 32/500 Iteration: 165 Validation Acc: 0.6467\n",
      "Epoch: 34/500 Iteration: 165 Training loss: 0.79242\n",
      "Epoch: 34/500 Iteration: 166 Training loss: 0.34543\n",
      "Epoch: 34/500 Iteration: 167 Training loss: 0.35091\n",
      "Epoch: 34/500 Iteration: 168 Training loss: 0.31935\n",
      "Epoch: 34/500 Iteration: 169 Training loss: 1.27701\n",
      "Epoch: 33/500 Iteration: 170 Validation Acc: 0.6000\n",
      "Epoch: 35/500 Iteration: 170 Training loss: 0.74290\n",
      "Epoch: 35/500 Iteration: 171 Training loss: 0.34459\n",
      "Epoch: 35/500 Iteration: 172 Training loss: 0.32533\n",
      "Epoch: 35/500 Iteration: 173 Training loss: 0.32059\n",
      "Epoch: 35/500 Iteration: 174 Training loss: 1.16549\n",
      "Epoch: 34/500 Iteration: 175 Validation Acc: 0.5800\n",
      "Epoch: 36/500 Iteration: 175 Training loss: 0.80814\n",
      "Epoch: 36/500 Iteration: 176 Training loss: 0.38688\n",
      "Epoch: 36/500 Iteration: 177 Training loss: 0.37315\n",
      "Epoch: 36/500 Iteration: 178 Training loss: 0.33031\n",
      "Epoch: 36/500 Iteration: 179 Training loss: 1.12479\n",
      "Epoch: 35/500 Iteration: 180 Validation Acc: 0.6333\n",
      "Epoch: 37/500 Iteration: 180 Training loss: 0.78755\n",
      "Epoch: 37/500 Iteration: 181 Training loss: 0.31819\n",
      "Epoch: 37/500 Iteration: 182 Training loss: 0.33685\n",
      "Epoch: 37/500 Iteration: 183 Training loss: 0.32572\n",
      "Epoch: 37/500 Iteration: 184 Training loss: 1.13204\n",
      "Epoch: 36/500 Iteration: 185 Validation Acc: 0.5733\n",
      "Epoch: 38/500 Iteration: 185 Training loss: 0.76716\n",
      "Epoch: 38/500 Iteration: 186 Training loss: 0.30972\n",
      "Epoch: 38/500 Iteration: 187 Training loss: 0.31026\n",
      "Epoch: 38/500 Iteration: 188 Training loss: 0.29984\n",
      "Epoch: 38/500 Iteration: 189 Training loss: 1.24007\n",
      "Epoch: 37/500 Iteration: 190 Validation Acc: 0.6067\n",
      "Epoch: 39/500 Iteration: 190 Training loss: 0.72456\n",
      "Epoch: 39/500 Iteration: 191 Training loss: 0.31832\n",
      "Epoch: 39/500 Iteration: 192 Training loss: 0.35151\n",
      "Epoch: 39/500 Iteration: 193 Training loss: 0.31545\n",
      "Epoch: 39/500 Iteration: 194 Training loss: 1.10397\n",
      "Epoch: 38/500 Iteration: 195 Validation Acc: 0.5933\n",
      "Epoch: 40/500 Iteration: 195 Training loss: 0.70131\n",
      "Epoch: 40/500 Iteration: 196 Training loss: 0.34232\n",
      "Epoch: 40/500 Iteration: 197 Training loss: 0.35203\n",
      "Epoch: 40/500 Iteration: 198 Training loss: 0.35491\n",
      "Epoch: 40/500 Iteration: 199 Training loss: 1.14042\n",
      "Epoch: 39/500 Iteration: 200 Validation Acc: 0.6133\n",
      "Epoch: 41/500 Iteration: 200 Training loss: 0.71947\n",
      "Epoch: 41/500 Iteration: 201 Training loss: 0.31319\n",
      "Epoch: 41/500 Iteration: 202 Training loss: 0.29925\n",
      "Epoch: 41/500 Iteration: 203 Training loss: 0.28025\n",
      "Epoch: 41/500 Iteration: 204 Training loss: 1.10268\n",
      "Epoch: 40/500 Iteration: 205 Validation Acc: 0.6067\n",
      "Epoch: 42/500 Iteration: 205 Training loss: 0.70256\n",
      "Epoch: 42/500 Iteration: 206 Training loss: 0.31390\n",
      "Epoch: 42/500 Iteration: 207 Training loss: 0.30482\n",
      "Epoch: 42/500 Iteration: 208 Training loss: 0.32541\n",
      "Epoch: 42/500 Iteration: 209 Training loss: 1.08980\n",
      "Epoch: 41/500 Iteration: 210 Validation Acc: 0.5867\n",
      "Epoch: 43/500 Iteration: 210 Training loss: 0.63954\n",
      "Epoch: 43/500 Iteration: 211 Training loss: 0.31600\n",
      "Epoch: 43/500 Iteration: 212 Training loss: 0.30420\n",
      "Epoch: 43/500 Iteration: 213 Training loss: 0.28011\n",
      "Epoch: 43/500 Iteration: 214 Training loss: 1.07822\n",
      "Epoch: 42/500 Iteration: 215 Validation Acc: 0.6400\n",
      "Epoch: 44/500 Iteration: 215 Training loss: 0.65551\n",
      "Epoch: 44/500 Iteration: 216 Training loss: 0.29651\n",
      "Epoch: 44/500 Iteration: 217 Training loss: 0.30960\n",
      "Epoch: 44/500 Iteration: 218 Training loss: 0.29121\n",
      "Epoch: 44/500 Iteration: 219 Training loss: 1.06131\n",
      "Epoch: 43/500 Iteration: 220 Validation Acc: 0.6333\n",
      "Epoch: 45/500 Iteration: 220 Training loss: 0.63349\n",
      "Epoch: 45/500 Iteration: 221 Training loss: 0.29449\n",
      "Epoch: 45/500 Iteration: 222 Training loss: 0.30688\n",
      "Epoch: 45/500 Iteration: 223 Training loss: 0.28421\n",
      "Epoch: 45/500 Iteration: 224 Training loss: 1.11870\n",
      "Epoch: 44/500 Iteration: 225 Validation Acc: 0.6200\n",
      "Epoch: 46/500 Iteration: 225 Training loss: 0.61426\n",
      "Epoch: 46/500 Iteration: 226 Training loss: 0.30219\n",
      "Epoch: 46/500 Iteration: 227 Training loss: 0.28927\n",
      "Epoch: 46/500 Iteration: 228 Training loss: 0.31994\n",
      "Epoch: 46/500 Iteration: 229 Training loss: 1.08034\n",
      "Epoch: 45/500 Iteration: 230 Validation Acc: 0.6667\n",
      "Epoch: 47/500 Iteration: 230 Training loss: 0.59785\n",
      "Epoch: 47/500 Iteration: 231 Training loss: 0.30779\n",
      "Epoch: 47/500 Iteration: 232 Training loss: 0.28411\n",
      "Epoch: 47/500 Iteration: 233 Training loss: 0.25813\n",
      "Epoch: 47/500 Iteration: 234 Training loss: 1.07315\n",
      "Epoch: 46/500 Iteration: 235 Validation Acc: 0.6400\n",
      "Epoch: 48/500 Iteration: 235 Training loss: 0.62084\n",
      "Epoch: 48/500 Iteration: 236 Training loss: 0.29462\n",
      "Epoch: 48/500 Iteration: 237 Training loss: 0.26928\n",
      "Epoch: 48/500 Iteration: 238 Training loss: 0.26706\n",
      "Epoch: 48/500 Iteration: 239 Training loss: 1.02680\n",
      "Epoch: 47/500 Iteration: 240 Validation Acc: 0.6400\n",
      "Epoch: 49/500 Iteration: 240 Training loss: 0.59660\n",
      "Epoch: 49/500 Iteration: 241 Training loss: 0.30666\n",
      "Epoch: 49/500 Iteration: 242 Training loss: 0.29925\n",
      "Epoch: 49/500 Iteration: 243 Training loss: 0.28477\n",
      "Epoch: 49/500 Iteration: 244 Training loss: 0.99161\n",
      "Epoch: 48/500 Iteration: 245 Validation Acc: 0.5800\n",
      "Epoch: 50/500 Iteration: 245 Training loss: 0.55802\n",
      "Epoch: 50/500 Iteration: 246 Training loss: 0.30046\n",
      "Epoch: 50/500 Iteration: 247 Training loss: 0.28760\n",
      "Epoch: 50/500 Iteration: 248 Training loss: 0.28195\n",
      "Epoch: 50/500 Iteration: 249 Training loss: 0.90136\n",
      "Epoch: 49/500 Iteration: 250 Validation Acc: 0.6333\n",
      "Epoch: 51/500 Iteration: 250 Training loss: 0.56439\n",
      "Epoch: 51/500 Iteration: 251 Training loss: 0.27790\n",
      "Epoch: 51/500 Iteration: 252 Training loss: 0.27226\n",
      "Epoch: 51/500 Iteration: 253 Training loss: 0.23138\n",
      "Epoch: 51/500 Iteration: 254 Training loss: 1.03878\n",
      "Epoch: 50/500 Iteration: 255 Validation Acc: 0.6267\n",
      "Epoch: 52/500 Iteration: 255 Training loss: 0.58467\n",
      "Epoch: 52/500 Iteration: 256 Training loss: 0.26703\n",
      "Epoch: 52/500 Iteration: 257 Training loss: 0.26535\n",
      "Epoch: 52/500 Iteration: 258 Training loss: 0.23901\n",
      "Epoch: 52/500 Iteration: 259 Training loss: 0.96467\n",
      "Epoch: 51/500 Iteration: 260 Validation Acc: 0.6667\n",
      "Epoch: 53/500 Iteration: 260 Training loss: 0.47356\n",
      "Epoch: 53/500 Iteration: 261 Training loss: 0.26380\n",
      "Epoch: 53/500 Iteration: 262 Training loss: 0.25350\n",
      "Epoch: 53/500 Iteration: 263 Training loss: 0.24729\n",
      "Epoch: 53/500 Iteration: 264 Training loss: 0.96163\n",
      "Epoch: 52/500 Iteration: 265 Validation Acc: 0.6400\n",
      "Epoch: 54/500 Iteration: 265 Training loss: 0.55035\n",
      "Epoch: 54/500 Iteration: 266 Training loss: 0.21656\n",
      "Epoch: 54/500 Iteration: 267 Training loss: 0.21652\n",
      "Epoch: 54/500 Iteration: 268 Training loss: 0.25016\n",
      "Epoch: 54/500 Iteration: 269 Training loss: 0.93551\n",
      "Epoch: 53/500 Iteration: 270 Validation Acc: 0.6000\n",
      "Epoch: 55/500 Iteration: 270 Training loss: 0.57552\n",
      "Epoch: 55/500 Iteration: 271 Training loss: 0.24564\n",
      "Epoch: 55/500 Iteration: 272 Training loss: 0.25498\n",
      "Epoch: 55/500 Iteration: 273 Training loss: 0.25285\n",
      "Epoch: 55/500 Iteration: 274 Training loss: 0.94135\n",
      "Epoch: 54/500 Iteration: 275 Validation Acc: 0.6733\n",
      "Epoch: 56/500 Iteration: 275 Training loss: 0.54252\n",
      "Epoch: 56/500 Iteration: 276 Training loss: 0.25863\n",
      "Epoch: 56/500 Iteration: 277 Training loss: 0.27407\n",
      "Epoch: 56/500 Iteration: 278 Training loss: 0.25426\n",
      "Epoch: 56/500 Iteration: 279 Training loss: 0.93952\n",
      "Epoch: 55/500 Iteration: 280 Validation Acc: 0.6533\n",
      "Epoch: 57/500 Iteration: 280 Training loss: 0.46956\n",
      "Epoch: 57/500 Iteration: 281 Training loss: 0.25383\n",
      "Epoch: 57/500 Iteration: 282 Training loss: 0.24456\n",
      "Epoch: 57/500 Iteration: 283 Training loss: 0.22349\n",
      "Epoch: 57/500 Iteration: 284 Training loss: 0.91504\n",
      "Epoch: 56/500 Iteration: 285 Validation Acc: 0.6733\n",
      "Epoch: 58/500 Iteration: 285 Training loss: 0.51419\n",
      "Epoch: 58/500 Iteration: 286 Training loss: 0.22730\n",
      "Epoch: 58/500 Iteration: 287 Training loss: 0.23193\n",
      "Epoch: 58/500 Iteration: 288 Training loss: 0.22735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/500 Iteration: 289 Training loss: 0.90487\n",
      "Epoch: 57/500 Iteration: 290 Validation Acc: 0.6667\n",
      "Epoch: 59/500 Iteration: 290 Training loss: 0.48871\n",
      "Epoch: 59/500 Iteration: 291 Training loss: 0.24844\n",
      "Epoch: 59/500 Iteration: 292 Training loss: 0.25698\n",
      "Epoch: 59/500 Iteration: 293 Training loss: 0.21937\n",
      "Epoch: 59/500 Iteration: 294 Training loss: 0.86012\n",
      "Epoch: 58/500 Iteration: 295 Validation Acc: 0.6600\n",
      "Epoch: 60/500 Iteration: 295 Training loss: 0.50163\n",
      "Epoch: 60/500 Iteration: 296 Training loss: 0.26016\n",
      "Epoch: 60/500 Iteration: 297 Training loss: 0.24302\n",
      "Epoch: 60/500 Iteration: 298 Training loss: 0.24443\n",
      "Epoch: 60/500 Iteration: 299 Training loss: 0.78034\n",
      "Epoch: 59/500 Iteration: 300 Validation Acc: 0.6467\n",
      "Epoch: 61/500 Iteration: 300 Training loss: 0.46607\n",
      "Epoch: 61/500 Iteration: 301 Training loss: 0.21671\n",
      "Epoch: 61/500 Iteration: 302 Training loss: 0.21545\n",
      "Epoch: 61/500 Iteration: 303 Training loss: 0.22016\n",
      "Epoch: 61/500 Iteration: 304 Training loss: 0.83865\n",
      "Epoch: 60/500 Iteration: 305 Validation Acc: 0.6467\n",
      "Epoch: 62/500 Iteration: 305 Training loss: 0.45311\n",
      "Epoch: 62/500 Iteration: 306 Training loss: 0.22664\n",
      "Epoch: 62/500 Iteration: 307 Training loss: 0.22130\n",
      "Epoch: 62/500 Iteration: 308 Training loss: 0.22666\n",
      "Epoch: 62/500 Iteration: 309 Training loss: 0.91829\n",
      "Epoch: 61/500 Iteration: 310 Validation Acc: 0.6733\n",
      "Epoch: 63/500 Iteration: 310 Training loss: 0.44892\n",
      "Epoch: 63/500 Iteration: 311 Training loss: 0.23289\n",
      "Epoch: 63/500 Iteration: 312 Training loss: 0.24736\n",
      "Epoch: 63/500 Iteration: 313 Training loss: 0.22773\n",
      "Epoch: 63/500 Iteration: 314 Training loss: 0.79586\n",
      "Epoch: 62/500 Iteration: 315 Validation Acc: 0.6467\n",
      "Epoch: 64/500 Iteration: 315 Training loss: 0.40988\n",
      "Epoch: 64/500 Iteration: 316 Training loss: 0.21220\n",
      "Epoch: 64/500 Iteration: 317 Training loss: 0.21319\n",
      "Epoch: 64/500 Iteration: 318 Training loss: 0.21457\n",
      "Epoch: 64/500 Iteration: 319 Training loss: 0.80906\n",
      "Epoch: 63/500 Iteration: 320 Validation Acc: 0.6333\n",
      "Epoch: 65/500 Iteration: 320 Training loss: 0.38818\n",
      "Epoch: 65/500 Iteration: 321 Training loss: 0.20796\n",
      "Epoch: 65/500 Iteration: 322 Training loss: 0.20458\n",
      "Epoch: 65/500 Iteration: 323 Training loss: 0.21289\n",
      "Epoch: 65/500 Iteration: 324 Training loss: 0.81514\n",
      "Epoch: 64/500 Iteration: 325 Validation Acc: 0.6200\n",
      "Epoch: 66/500 Iteration: 325 Training loss: 0.43610\n",
      "Epoch: 66/500 Iteration: 326 Training loss: 0.19672\n",
      "Epoch: 66/500 Iteration: 327 Training loss: 0.21533\n",
      "Epoch: 66/500 Iteration: 328 Training loss: 0.21090\n",
      "Epoch: 66/500 Iteration: 329 Training loss: 0.72503\n",
      "Epoch: 65/500 Iteration: 330 Validation Acc: 0.6733\n",
      "Epoch: 67/500 Iteration: 330 Training loss: 0.41674\n",
      "Epoch: 67/500 Iteration: 331 Training loss: 0.20755\n",
      "Epoch: 67/500 Iteration: 332 Training loss: 0.22626\n",
      "Epoch: 67/500 Iteration: 333 Training loss: 0.19412\n",
      "Epoch: 67/500 Iteration: 334 Training loss: 0.75952\n",
      "Epoch: 66/500 Iteration: 335 Validation Acc: 0.6800\n",
      "Epoch: 68/500 Iteration: 335 Training loss: 0.39842\n",
      "Epoch: 68/500 Iteration: 336 Training loss: 0.18239\n",
      "Epoch: 68/500 Iteration: 337 Training loss: 0.19137\n",
      "Epoch: 68/500 Iteration: 338 Training loss: 0.19123\n",
      "Epoch: 68/500 Iteration: 339 Training loss: 0.78927\n",
      "Epoch: 67/500 Iteration: 340 Validation Acc: 0.6600\n",
      "Epoch: 69/500 Iteration: 340 Training loss: 0.35741\n",
      "Epoch: 69/500 Iteration: 341 Training loss: 0.21197\n",
      "Epoch: 69/500 Iteration: 342 Training loss: 0.21285\n",
      "Epoch: 69/500 Iteration: 343 Training loss: 0.17751\n",
      "Epoch: 69/500 Iteration: 344 Training loss: 0.76845\n",
      "Epoch: 68/500 Iteration: 345 Validation Acc: 0.7000\n",
      "Epoch: 70/500 Iteration: 345 Training loss: 0.41615\n",
      "Epoch: 70/500 Iteration: 346 Training loss: 0.18525\n",
      "Epoch: 70/500 Iteration: 347 Training loss: 0.20003\n",
      "Epoch: 70/500 Iteration: 348 Training loss: 0.20097\n",
      "Epoch: 70/500 Iteration: 349 Training loss: 0.72119\n",
      "Epoch: 69/500 Iteration: 350 Validation Acc: 0.6267\n",
      "Epoch: 71/500 Iteration: 350 Training loss: 0.41224\n",
      "Epoch: 71/500 Iteration: 351 Training loss: 0.23702\n",
      "Epoch: 71/500 Iteration: 352 Training loss: 0.21737\n",
      "Epoch: 71/500 Iteration: 353 Training loss: 0.21172\n",
      "Epoch: 71/500 Iteration: 354 Training loss: 0.71976\n",
      "Epoch: 70/500 Iteration: 355 Validation Acc: 0.7067\n",
      "Epoch: 72/500 Iteration: 355 Training loss: 0.34650\n",
      "Epoch: 72/500 Iteration: 356 Training loss: 0.17703\n",
      "Epoch: 72/500 Iteration: 357 Training loss: 0.18288\n",
      "Epoch: 72/500 Iteration: 358 Training loss: 0.15478\n",
      "Epoch: 72/500 Iteration: 359 Training loss: 0.76998\n",
      "Epoch: 71/500 Iteration: 360 Validation Acc: 0.6800\n",
      "Epoch: 73/500 Iteration: 360 Training loss: 0.43067\n",
      "Epoch: 73/500 Iteration: 361 Training loss: 0.19794\n",
      "Epoch: 73/500 Iteration: 362 Training loss: 0.18638\n",
      "Epoch: 73/500 Iteration: 363 Training loss: 0.20441\n",
      "Epoch: 73/500 Iteration: 364 Training loss: 0.64601\n",
      "Epoch: 72/500 Iteration: 365 Validation Acc: 0.6667\n",
      "Epoch: 74/500 Iteration: 365 Training loss: 0.35051\n",
      "Epoch: 74/500 Iteration: 366 Training loss: 0.21478\n",
      "Epoch: 74/500 Iteration: 367 Training loss: 0.20651\n",
      "Epoch: 74/500 Iteration: 368 Training loss: 0.18128\n",
      "Epoch: 74/500 Iteration: 369 Training loss: 0.69756\n",
      "Epoch: 73/500 Iteration: 370 Validation Acc: 0.6333\n",
      "Epoch: 75/500 Iteration: 370 Training loss: 0.37534\n",
      "Epoch: 75/500 Iteration: 371 Training loss: 0.15395\n",
      "Epoch: 75/500 Iteration: 372 Training loss: 0.18318\n",
      "Epoch: 75/500 Iteration: 373 Training loss: 0.15360\n",
      "Epoch: 75/500 Iteration: 374 Training loss: 0.74162\n",
      "Epoch: 74/500 Iteration: 375 Validation Acc: 0.7000\n",
      "Epoch: 76/500 Iteration: 375 Training loss: 0.35339\n",
      "Epoch: 76/500 Iteration: 376 Training loss: 0.16115\n",
      "Epoch: 76/500 Iteration: 377 Training loss: 0.18320\n",
      "Epoch: 76/500 Iteration: 378 Training loss: 0.17784\n",
      "Epoch: 76/500 Iteration: 379 Training loss: 0.64854\n",
      "Epoch: 75/500 Iteration: 380 Validation Acc: 0.6667\n",
      "Epoch: 77/500 Iteration: 380 Training loss: 0.30657\n",
      "Epoch: 77/500 Iteration: 381 Training loss: 0.20140\n",
      "Epoch: 77/500 Iteration: 382 Training loss: 0.21041\n",
      "Epoch: 77/500 Iteration: 383 Training loss: 0.18038\n",
      "Epoch: 77/500 Iteration: 384 Training loss: 0.62335\n",
      "Epoch: 76/500 Iteration: 385 Validation Acc: 0.6867\n",
      "Epoch: 78/500 Iteration: 385 Training loss: 0.32241\n",
      "Epoch: 78/500 Iteration: 386 Training loss: 0.15897\n",
      "Epoch: 78/500 Iteration: 387 Training loss: 0.15598\n",
      "Epoch: 78/500 Iteration: 388 Training loss: 0.14592\n",
      "Epoch: 78/500 Iteration: 389 Training loss: 0.67542\n",
      "Epoch: 77/500 Iteration: 390 Validation Acc: 0.6933\n",
      "Epoch: 79/500 Iteration: 390 Training loss: 0.30329\n",
      "Epoch: 79/500 Iteration: 391 Training loss: 0.15052\n",
      "Epoch: 79/500 Iteration: 392 Training loss: 0.16896\n",
      "Epoch: 79/500 Iteration: 393 Training loss: 0.16420\n",
      "Epoch: 79/500 Iteration: 394 Training loss: 0.59992\n",
      "Epoch: 78/500 Iteration: 395 Validation Acc: 0.7133\n",
      "Epoch: 80/500 Iteration: 395 Training loss: 0.30286\n",
      "Epoch: 80/500 Iteration: 396 Training loss: 0.18075\n",
      "Epoch: 80/500 Iteration: 397 Training loss: 0.18388\n",
      "Epoch: 80/500 Iteration: 398 Training loss: 0.17811\n",
      "Epoch: 80/500 Iteration: 399 Training loss: 0.61034\n",
      "Epoch: 79/500 Iteration: 400 Validation Acc: 0.6933\n",
      "Epoch: 81/500 Iteration: 400 Training loss: 0.36604\n",
      "Epoch: 81/500 Iteration: 401 Training loss: 0.14768\n",
      "Epoch: 81/500 Iteration: 402 Training loss: 0.18301\n",
      "Epoch: 81/500 Iteration: 403 Training loss: 0.15254\n",
      "Epoch: 81/500 Iteration: 404 Training loss: 0.56471\n",
      "Epoch: 80/500 Iteration: 405 Validation Acc: 0.6800\n",
      "Epoch: 82/500 Iteration: 405 Training loss: 0.30163\n",
      "Epoch: 82/500 Iteration: 406 Training loss: 0.16383\n",
      "Epoch: 82/500 Iteration: 407 Training loss: 0.16234\n",
      "Epoch: 82/500 Iteration: 408 Training loss: 0.16030\n",
      "Epoch: 82/500 Iteration: 409 Training loss: 0.63687\n",
      "Epoch: 81/500 Iteration: 410 Validation Acc: 0.6667\n",
      "Epoch: 83/500 Iteration: 410 Training loss: 0.25019\n",
      "Epoch: 83/500 Iteration: 411 Training loss: 0.14302\n",
      "Epoch: 83/500 Iteration: 412 Training loss: 0.14579\n",
      "Epoch: 83/500 Iteration: 413 Training loss: 0.16003\n",
      "Epoch: 83/500 Iteration: 414 Training loss: 0.57839\n",
      "Epoch: 82/500 Iteration: 415 Validation Acc: 0.6533\n",
      "Epoch: 84/500 Iteration: 415 Training loss: 0.26426\n",
      "Epoch: 84/500 Iteration: 416 Training loss: 0.14745\n",
      "Epoch: 84/500 Iteration: 417 Training loss: 0.16665\n",
      "Epoch: 84/500 Iteration: 418 Training loss: 0.16067\n",
      "Epoch: 84/500 Iteration: 419 Training loss: 0.55741\n",
      "Epoch: 83/500 Iteration: 420 Validation Acc: 0.7000\n",
      "Epoch: 85/500 Iteration: 420 Training loss: 0.26236\n",
      "Epoch: 85/500 Iteration: 421 Training loss: 0.16758\n",
      "Epoch: 85/500 Iteration: 422 Training loss: 0.14477\n",
      "Epoch: 85/500 Iteration: 423 Training loss: 0.14143\n",
      "Epoch: 85/500 Iteration: 424 Training loss: 0.51761\n",
      "Epoch: 84/500 Iteration: 425 Validation Acc: 0.6533\n",
      "Epoch: 86/500 Iteration: 425 Training loss: 0.28936\n",
      "Epoch: 86/500 Iteration: 426 Training loss: 0.13658\n",
      "Epoch: 86/500 Iteration: 427 Training loss: 0.16067\n",
      "Epoch: 86/500 Iteration: 428 Training loss: 0.13003\n",
      "Epoch: 86/500 Iteration: 429 Training loss: 0.53175\n",
      "Epoch: 85/500 Iteration: 430 Validation Acc: 0.6133\n",
      "Epoch: 87/500 Iteration: 430 Training loss: 0.25153\n",
      "Epoch: 87/500 Iteration: 431 Training loss: 0.15859\n",
      "Epoch: 87/500 Iteration: 432 Training loss: 0.13193\n",
      "Epoch: 87/500 Iteration: 433 Training loss: 0.11655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/500 Iteration: 434 Training loss: 0.53709\n",
      "Epoch: 86/500 Iteration: 435 Validation Acc: 0.6267\n",
      "Epoch: 88/500 Iteration: 435 Training loss: 0.28612\n",
      "Epoch: 88/500 Iteration: 436 Training loss: 0.15251\n",
      "Epoch: 88/500 Iteration: 437 Training loss: 0.13637\n",
      "Epoch: 88/500 Iteration: 438 Training loss: 0.12868\n",
      "Epoch: 88/500 Iteration: 439 Training loss: 0.48542\n",
      "Epoch: 87/500 Iteration: 440 Validation Acc: 0.6933\n",
      "Epoch: 89/500 Iteration: 440 Training loss: 0.24604\n",
      "Epoch: 89/500 Iteration: 441 Training loss: 0.12488\n",
      "Epoch: 89/500 Iteration: 442 Training loss: 0.14139\n",
      "Epoch: 89/500 Iteration: 443 Training loss: 0.09948\n",
      "Epoch: 89/500 Iteration: 444 Training loss: 0.51406\n",
      "Epoch: 88/500 Iteration: 445 Validation Acc: 0.6667\n",
      "Epoch: 90/500 Iteration: 445 Training loss: 0.25758\n",
      "Epoch: 90/500 Iteration: 446 Training loss: 0.12573\n",
      "Epoch: 90/500 Iteration: 447 Training loss: 0.14764\n",
      "Epoch: 90/500 Iteration: 448 Training loss: 0.12845\n",
      "Epoch: 90/500 Iteration: 449 Training loss: 0.49613\n",
      "Epoch: 89/500 Iteration: 450 Validation Acc: 0.7000\n",
      "Epoch: 91/500 Iteration: 450 Training loss: 0.21744\n",
      "Epoch: 91/500 Iteration: 451 Training loss: 0.12591\n",
      "Epoch: 91/500 Iteration: 452 Training loss: 0.14898\n",
      "Epoch: 91/500 Iteration: 453 Training loss: 0.13762\n",
      "Epoch: 91/500 Iteration: 454 Training loss: 0.51968\n",
      "Epoch: 90/500 Iteration: 455 Validation Acc: 0.6867\n",
      "Epoch: 92/500 Iteration: 455 Training loss: 0.25972\n",
      "Epoch: 92/500 Iteration: 456 Training loss: 0.12473\n",
      "Epoch: 92/500 Iteration: 457 Training loss: 0.12651\n",
      "Epoch: 92/500 Iteration: 458 Training loss: 0.14093\n",
      "Epoch: 92/500 Iteration: 459 Training loss: 0.53291\n",
      "Epoch: 91/500 Iteration: 460 Validation Acc: 0.6800\n",
      "Epoch: 93/500 Iteration: 460 Training loss: 0.22378\n",
      "Epoch: 93/500 Iteration: 461 Training loss: 0.12850\n",
      "Epoch: 93/500 Iteration: 462 Training loss: 0.14786\n",
      "Epoch: 93/500 Iteration: 463 Training loss: 0.13406\n",
      "Epoch: 93/500 Iteration: 464 Training loss: 0.46987\n",
      "Epoch: 92/500 Iteration: 465 Validation Acc: 0.6533\n",
      "Epoch: 94/500 Iteration: 465 Training loss: 0.21613\n",
      "Epoch: 94/500 Iteration: 466 Training loss: 0.11338\n",
      "Epoch: 94/500 Iteration: 467 Training loss: 0.11774\n",
      "Epoch: 94/500 Iteration: 468 Training loss: 0.11347\n",
      "Epoch: 94/500 Iteration: 469 Training loss: 0.50852\n",
      "Epoch: 93/500 Iteration: 470 Validation Acc: 0.6867\n",
      "Epoch: 95/500 Iteration: 470 Training loss: 0.23789\n",
      "Epoch: 95/500 Iteration: 471 Training loss: 0.12118\n",
      "Epoch: 95/500 Iteration: 472 Training loss: 0.11328\n",
      "Epoch: 95/500 Iteration: 473 Training loss: 0.11984\n",
      "Epoch: 95/500 Iteration: 474 Training loss: 0.41422\n",
      "Epoch: 94/500 Iteration: 475 Validation Acc: 0.6733\n",
      "Epoch: 96/500 Iteration: 475 Training loss: 0.20142\n",
      "Epoch: 96/500 Iteration: 476 Training loss: 0.14253\n",
      "Epoch: 96/500 Iteration: 477 Training loss: 0.12744\n",
      "Epoch: 96/500 Iteration: 478 Training loss: 0.11808\n",
      "Epoch: 96/500 Iteration: 479 Training loss: 0.47584\n",
      "Epoch: 95/500 Iteration: 480 Validation Acc: 0.6667\n",
      "Epoch: 97/500 Iteration: 480 Training loss: 0.20112\n",
      "Epoch: 97/500 Iteration: 481 Training loss: 0.09799\n",
      "Epoch: 97/500 Iteration: 482 Training loss: 0.12350\n",
      "Epoch: 97/500 Iteration: 483 Training loss: 0.12473\n",
      "Epoch: 97/500 Iteration: 484 Training loss: 0.49417\n",
      "Epoch: 96/500 Iteration: 485 Validation Acc: 0.6533\n",
      "Epoch: 98/500 Iteration: 485 Training loss: 0.22181\n",
      "Epoch: 98/500 Iteration: 486 Training loss: 0.12761\n",
      "Epoch: 98/500 Iteration: 487 Training loss: 0.12099\n",
      "Epoch: 98/500 Iteration: 488 Training loss: 0.12673\n",
      "Epoch: 98/500 Iteration: 489 Training loss: 0.44865\n",
      "Epoch: 97/500 Iteration: 490 Validation Acc: 0.7000\n",
      "Epoch: 99/500 Iteration: 490 Training loss: 0.21454\n",
      "Epoch: 99/500 Iteration: 491 Training loss: 0.11913\n",
      "Epoch: 99/500 Iteration: 492 Training loss: 0.12435\n",
      "Epoch: 99/500 Iteration: 493 Training loss: 0.11733\n",
      "Epoch: 99/500 Iteration: 494 Training loss: 0.41512\n",
      "Epoch: 98/500 Iteration: 495 Validation Acc: 0.6400\n",
      "Epoch: 100/500 Iteration: 495 Training loss: 0.21471\n",
      "Epoch: 100/500 Iteration: 496 Training loss: 0.09910\n",
      "Epoch: 100/500 Iteration: 497 Training loss: 0.10550\n",
      "Epoch: 100/500 Iteration: 498 Training loss: 0.11159\n",
      "Epoch: 100/500 Iteration: 499 Training loss: 0.46067\n",
      "Epoch: 99/500 Iteration: 500 Validation Acc: 0.6467\n",
      "Epoch: 101/500 Iteration: 500 Training loss: 0.18708\n",
      "Epoch: 101/500 Iteration: 501 Training loss: 0.09815\n",
      "Epoch: 101/500 Iteration: 502 Training loss: 0.13168\n",
      "Epoch: 101/500 Iteration: 503 Training loss: 0.11089\n",
      "Epoch: 101/500 Iteration: 504 Training loss: 0.37718\n",
      "Epoch: 100/500 Iteration: 505 Validation Acc: 0.6800\n",
      "Epoch: 102/500 Iteration: 505 Training loss: 0.19621\n",
      "Epoch: 102/500 Iteration: 506 Training loss: 0.11830\n",
      "Epoch: 102/500 Iteration: 507 Training loss: 0.10851\n",
      "Epoch: 102/500 Iteration: 508 Training loss: 0.09464\n",
      "Epoch: 102/500 Iteration: 509 Training loss: 0.51594\n",
      "Epoch: 101/500 Iteration: 510 Validation Acc: 0.6800\n",
      "Epoch: 103/500 Iteration: 510 Training loss: 0.18795\n",
      "Epoch: 103/500 Iteration: 511 Training loss: 0.09130\n",
      "Epoch: 103/500 Iteration: 512 Training loss: 0.10939\n",
      "Epoch: 103/500 Iteration: 513 Training loss: 0.09473\n",
      "Epoch: 103/500 Iteration: 514 Training loss: 0.43190\n",
      "Epoch: 102/500 Iteration: 515 Validation Acc: 0.6667\n",
      "Epoch: 104/500 Iteration: 515 Training loss: 0.18835\n",
      "Epoch: 104/500 Iteration: 516 Training loss: 0.10269\n",
      "Epoch: 104/500 Iteration: 517 Training loss: 0.10845\n",
      "Epoch: 104/500 Iteration: 518 Training loss: 0.10803\n",
      "Epoch: 104/500 Iteration: 519 Training loss: 0.35060\n",
      "Epoch: 103/500 Iteration: 520 Validation Acc: 0.6933\n",
      "Epoch: 105/500 Iteration: 520 Training loss: 0.19692\n",
      "Epoch: 105/500 Iteration: 521 Training loss: 0.10447\n",
      "Epoch: 105/500 Iteration: 522 Training loss: 0.08492\n",
      "Epoch: 105/500 Iteration: 523 Training loss: 0.09919\n",
      "Epoch: 105/500 Iteration: 524 Training loss: 0.37018\n",
      "Epoch: 104/500 Iteration: 525 Validation Acc: 0.6667\n",
      "Epoch: 106/500 Iteration: 525 Training loss: 0.17057\n",
      "Epoch: 106/500 Iteration: 526 Training loss: 0.09047\n",
      "Epoch: 106/500 Iteration: 527 Training loss: 0.10324\n",
      "Epoch: 106/500 Iteration: 528 Training loss: 0.10315\n",
      "Epoch: 106/500 Iteration: 529 Training loss: 0.37295\n",
      "Epoch: 105/500 Iteration: 530 Validation Acc: 0.6867\n",
      "Epoch: 107/500 Iteration: 530 Training loss: 0.15807\n",
      "Epoch: 107/500 Iteration: 531 Training loss: 0.10355\n",
      "Epoch: 107/500 Iteration: 532 Training loss: 0.12319\n",
      "Epoch: 107/500 Iteration: 533 Training loss: 0.10495\n",
      "Epoch: 107/500 Iteration: 534 Training loss: 0.33836\n",
      "Epoch: 106/500 Iteration: 535 Validation Acc: 0.6733\n",
      "Epoch: 108/500 Iteration: 535 Training loss: 0.18405\n",
      "Epoch: 108/500 Iteration: 536 Training loss: 0.08777\n",
      "Epoch: 108/500 Iteration: 537 Training loss: 0.08632\n",
      "Epoch: 108/500 Iteration: 538 Training loss: 0.09440\n",
      "Epoch: 108/500 Iteration: 539 Training loss: 0.46617\n",
      "Epoch: 107/500 Iteration: 540 Validation Acc: 0.7067\n",
      "Epoch: 109/500 Iteration: 540 Training loss: 0.15212\n",
      "Epoch: 109/500 Iteration: 541 Training loss: 0.09392\n",
      "Epoch: 109/500 Iteration: 542 Training loss: 0.12485\n",
      "Epoch: 109/500 Iteration: 543 Training loss: 0.12826\n",
      "Epoch: 109/500 Iteration: 544 Training loss: 0.27247\n",
      "Epoch: 108/500 Iteration: 545 Validation Acc: 0.6733\n",
      "Epoch: 110/500 Iteration: 545 Training loss: 0.16378\n",
      "Epoch: 110/500 Iteration: 546 Training loss: 0.10349\n",
      "Epoch: 110/500 Iteration: 547 Training loss: 0.11054\n",
      "Epoch: 110/500 Iteration: 548 Training loss: 0.07374\n",
      "Epoch: 110/500 Iteration: 549 Training loss: 0.37249\n",
      "Epoch: 109/500 Iteration: 550 Validation Acc: 0.6933\n",
      "Epoch: 111/500 Iteration: 550 Training loss: 0.21107\n",
      "Epoch: 111/500 Iteration: 551 Training loss: 0.09615\n",
      "Epoch: 111/500 Iteration: 552 Training loss: 0.09223\n",
      "Epoch: 111/500 Iteration: 553 Training loss: 0.07893\n",
      "Epoch: 111/500 Iteration: 554 Training loss: 0.36228\n",
      "Epoch: 110/500 Iteration: 555 Validation Acc: 0.6733\n",
      "Epoch: 112/500 Iteration: 555 Training loss: 0.14880\n",
      "Epoch: 112/500 Iteration: 556 Training loss: 0.09864\n",
      "Epoch: 112/500 Iteration: 557 Training loss: 0.09666\n",
      "Epoch: 112/500 Iteration: 558 Training loss: 0.07636\n",
      "Epoch: 112/500 Iteration: 559 Training loss: 0.33165\n",
      "Epoch: 111/500 Iteration: 560 Validation Acc: 0.6733\n",
      "Epoch: 113/500 Iteration: 560 Training loss: 0.15255\n",
      "Epoch: 113/500 Iteration: 561 Training loss: 0.07779\n",
      "Epoch: 113/500 Iteration: 562 Training loss: 0.07372\n",
      "Epoch: 113/500 Iteration: 563 Training loss: 0.07981\n",
      "Epoch: 113/500 Iteration: 564 Training loss: 0.31003\n",
      "Epoch: 112/500 Iteration: 565 Validation Acc: 0.6600\n",
      "Epoch: 114/500 Iteration: 565 Training loss: 0.15905\n",
      "Epoch: 114/500 Iteration: 566 Training loss: 0.08403\n",
      "Epoch: 114/500 Iteration: 567 Training loss: 0.09366\n",
      "Epoch: 114/500 Iteration: 568 Training loss: 0.10547\n",
      "Epoch: 114/500 Iteration: 569 Training loss: 0.31755\n",
      "Epoch: 113/500 Iteration: 570 Validation Acc: 0.7200\n",
      "Epoch: 115/500 Iteration: 570 Training loss: 0.14943\n",
      "Epoch: 115/500 Iteration: 571 Training loss: 0.08087\n",
      "Epoch: 115/500 Iteration: 572 Training loss: 0.09006\n",
      "Epoch: 115/500 Iteration: 573 Training loss: 0.07268\n",
      "Epoch: 115/500 Iteration: 574 Training loss: 0.30184\n",
      "Epoch: 114/500 Iteration: 575 Validation Acc: 0.7133\n",
      "Epoch: 116/500 Iteration: 575 Training loss: 0.13459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116/500 Iteration: 576 Training loss: 0.06978\n",
      "Epoch: 116/500 Iteration: 577 Training loss: 0.07101\n",
      "Epoch: 116/500 Iteration: 578 Training loss: 0.07932\n",
      "Epoch: 116/500 Iteration: 579 Training loss: 0.29200\n",
      "Epoch: 115/500 Iteration: 580 Validation Acc: 0.6800\n",
      "Epoch: 117/500 Iteration: 580 Training loss: 0.13300\n",
      "Epoch: 117/500 Iteration: 581 Training loss: 0.07158\n",
      "Epoch: 117/500 Iteration: 582 Training loss: 0.08458\n",
      "Epoch: 117/500 Iteration: 583 Training loss: 0.07524\n",
      "Epoch: 117/500 Iteration: 584 Training loss: 0.29108\n",
      "Epoch: 116/500 Iteration: 585 Validation Acc: 0.6933\n",
      "Epoch: 118/500 Iteration: 585 Training loss: 0.12594\n",
      "Epoch: 118/500 Iteration: 586 Training loss: 0.06089\n",
      "Epoch: 118/500 Iteration: 587 Training loss: 0.06786\n",
      "Epoch: 118/500 Iteration: 588 Training loss: 0.06580\n",
      "Epoch: 118/500 Iteration: 589 Training loss: 0.28232\n",
      "Epoch: 117/500 Iteration: 590 Validation Acc: 0.7067\n",
      "Epoch: 119/500 Iteration: 590 Training loss: 0.16448\n",
      "Epoch: 119/500 Iteration: 591 Training loss: 0.06549\n",
      "Epoch: 119/500 Iteration: 592 Training loss: 0.09164\n",
      "Epoch: 119/500 Iteration: 593 Training loss: 0.07082\n",
      "Epoch: 119/500 Iteration: 594 Training loss: 0.23421\n",
      "Epoch: 118/500 Iteration: 595 Validation Acc: 0.7000\n",
      "Epoch: 120/500 Iteration: 595 Training loss: 0.13942\n",
      "Epoch: 120/500 Iteration: 596 Training loss: 0.06951\n",
      "Epoch: 120/500 Iteration: 597 Training loss: 0.07530\n",
      "Epoch: 120/500 Iteration: 598 Training loss: 0.06563\n",
      "Epoch: 120/500 Iteration: 599 Training loss: 0.33773\n",
      "Epoch: 119/500 Iteration: 600 Validation Acc: 0.6867\n",
      "Epoch: 121/500 Iteration: 600 Training loss: 0.13117\n",
      "Epoch: 121/500 Iteration: 601 Training loss: 0.06272\n",
      "Epoch: 121/500 Iteration: 602 Training loss: 0.08690\n",
      "Epoch: 121/500 Iteration: 603 Training loss: 0.06972\n",
      "Epoch: 121/500 Iteration: 604 Training loss: 0.23467\n",
      "Epoch: 120/500 Iteration: 605 Validation Acc: 0.6733\n",
      "Epoch: 122/500 Iteration: 605 Training loss: 0.12051\n",
      "Epoch: 122/500 Iteration: 606 Training loss: 0.07233\n",
      "Epoch: 122/500 Iteration: 607 Training loss: 0.07804\n",
      "Epoch: 122/500 Iteration: 608 Training loss: 0.05800\n",
      "Epoch: 122/500 Iteration: 609 Training loss: 0.28103\n",
      "Epoch: 121/500 Iteration: 610 Validation Acc: 0.6600\n",
      "Epoch: 123/500 Iteration: 610 Training loss: 0.13033\n",
      "Epoch: 123/500 Iteration: 611 Training loss: 0.06736\n",
      "Epoch: 123/500 Iteration: 612 Training loss: 0.07339\n",
      "Epoch: 123/500 Iteration: 613 Training loss: 0.06054\n",
      "Epoch: 123/500 Iteration: 614 Training loss: 0.26948\n",
      "Epoch: 122/500 Iteration: 615 Validation Acc: 0.6867\n",
      "Epoch: 124/500 Iteration: 615 Training loss: 0.13686\n",
      "Epoch: 124/500 Iteration: 616 Training loss: 0.05729\n",
      "Epoch: 124/500 Iteration: 617 Training loss: 0.07143\n",
      "Epoch: 124/500 Iteration: 618 Training loss: 0.05235\n",
      "Epoch: 124/500 Iteration: 619 Training loss: 0.21032\n",
      "Epoch: 123/500 Iteration: 620 Validation Acc: 0.6733\n",
      "Epoch: 125/500 Iteration: 620 Training loss: 0.11031\n",
      "Epoch: 125/500 Iteration: 621 Training loss: 0.06686\n",
      "Epoch: 125/500 Iteration: 622 Training loss: 0.09052\n",
      "Epoch: 125/500 Iteration: 623 Training loss: 0.06855\n",
      "Epoch: 125/500 Iteration: 624 Training loss: 0.25660\n",
      "Epoch: 124/500 Iteration: 625 Validation Acc: 0.6533\n",
      "Epoch: 126/500 Iteration: 625 Training loss: 0.11350\n",
      "Epoch: 126/500 Iteration: 626 Training loss: 0.04569\n",
      "Epoch: 126/500 Iteration: 627 Training loss: 0.06340\n",
      "Epoch: 126/500 Iteration: 628 Training loss: 0.05030\n",
      "Epoch: 126/500 Iteration: 629 Training loss: 0.22261\n",
      "Epoch: 125/500 Iteration: 630 Validation Acc: 0.7200\n",
      "Epoch: 127/500 Iteration: 630 Training loss: 0.12666\n",
      "Epoch: 127/500 Iteration: 631 Training loss: 0.06852\n",
      "Epoch: 127/500 Iteration: 632 Training loss: 0.07191\n",
      "Epoch: 127/500 Iteration: 633 Training loss: 0.06406\n",
      "Epoch: 127/500 Iteration: 634 Training loss: 0.21489\n",
      "Epoch: 126/500 Iteration: 635 Validation Acc: 0.6800\n",
      "Epoch: 128/500 Iteration: 635 Training loss: 0.10581\n",
      "Epoch: 128/500 Iteration: 636 Training loss: 0.05490\n",
      "Epoch: 128/500 Iteration: 637 Training loss: 0.07359\n",
      "Epoch: 128/500 Iteration: 638 Training loss: 0.06116\n",
      "Epoch: 128/500 Iteration: 639 Training loss: 0.24175\n",
      "Epoch: 127/500 Iteration: 640 Validation Acc: 0.6667\n",
      "Epoch: 129/500 Iteration: 640 Training loss: 0.11985\n",
      "Epoch: 129/500 Iteration: 641 Training loss: 0.06087\n",
      "Epoch: 129/500 Iteration: 642 Training loss: 0.06561\n",
      "Epoch: 129/500 Iteration: 643 Training loss: 0.05682\n",
      "Epoch: 129/500 Iteration: 644 Training loss: 0.18573\n",
      "Epoch: 128/500 Iteration: 645 Validation Acc: 0.7000\n",
      "Epoch: 130/500 Iteration: 645 Training loss: 0.09718\n",
      "Epoch: 130/500 Iteration: 646 Training loss: 0.05116\n",
      "Epoch: 130/500 Iteration: 647 Training loss: 0.05397\n",
      "Epoch: 130/500 Iteration: 648 Training loss: 0.05847\n",
      "Epoch: 130/500 Iteration: 649 Training loss: 0.22609\n",
      "Epoch: 129/500 Iteration: 650 Validation Acc: 0.6733\n",
      "Epoch: 131/500 Iteration: 650 Training loss: 0.09071\n",
      "Epoch: 131/500 Iteration: 651 Training loss: 0.06621\n",
      "Epoch: 131/500 Iteration: 652 Training loss: 0.06011\n",
      "Epoch: 131/500 Iteration: 653 Training loss: 0.06371\n",
      "Epoch: 131/500 Iteration: 654 Training loss: 0.21947\n",
      "Epoch: 130/500 Iteration: 655 Validation Acc: 0.7000\n",
      "Epoch: 132/500 Iteration: 655 Training loss: 0.11870\n",
      "Epoch: 132/500 Iteration: 656 Training loss: 0.06084\n",
      "Epoch: 132/500 Iteration: 657 Training loss: 0.05569\n",
      "Epoch: 132/500 Iteration: 658 Training loss: 0.05380\n",
      "Epoch: 132/500 Iteration: 659 Training loss: 0.22297\n",
      "Epoch: 131/500 Iteration: 660 Validation Acc: 0.7133\n",
      "Epoch: 133/500 Iteration: 660 Training loss: 0.09341\n",
      "Epoch: 133/500 Iteration: 661 Training loss: 0.05273\n",
      "Epoch: 133/500 Iteration: 662 Training loss: 0.06119\n",
      "Epoch: 133/500 Iteration: 663 Training loss: 0.04659\n",
      "Epoch: 133/500 Iteration: 664 Training loss: 0.19171\n",
      "Epoch: 132/500 Iteration: 665 Validation Acc: 0.6600\n",
      "Epoch: 134/500 Iteration: 665 Training loss: 0.09640\n",
      "Epoch: 134/500 Iteration: 666 Training loss: 0.05951\n",
      "Epoch: 134/500 Iteration: 667 Training loss: 0.04696\n",
      "Epoch: 134/500 Iteration: 668 Training loss: 0.05767\n",
      "Epoch: 134/500 Iteration: 669 Training loss: 0.20589\n",
      "Epoch: 133/500 Iteration: 670 Validation Acc: 0.7000\n",
      "Epoch: 135/500 Iteration: 670 Training loss: 0.13072\n",
      "Epoch: 135/500 Iteration: 671 Training loss: 0.05851\n",
      "Epoch: 135/500 Iteration: 672 Training loss: 0.04648\n",
      "Epoch: 135/500 Iteration: 673 Training loss: 0.05180\n",
      "Epoch: 135/500 Iteration: 674 Training loss: 0.15880\n",
      "Epoch: 134/500 Iteration: 675 Validation Acc: 0.6733\n",
      "Epoch: 136/500 Iteration: 675 Training loss: 0.11466\n",
      "Epoch: 136/500 Iteration: 676 Training loss: 0.05446\n",
      "Epoch: 136/500 Iteration: 677 Training loss: 0.04706\n",
      "Epoch: 136/500 Iteration: 678 Training loss: 0.04704\n",
      "Epoch: 136/500 Iteration: 679 Training loss: 0.22371\n",
      "Epoch: 135/500 Iteration: 680 Validation Acc: 0.7000\n",
      "Epoch: 137/500 Iteration: 680 Training loss: 0.07511\n",
      "Epoch: 137/500 Iteration: 681 Training loss: 0.03889\n",
      "Epoch: 137/500 Iteration: 682 Training loss: 0.05697\n",
      "Epoch: 137/500 Iteration: 683 Training loss: 0.04851\n",
      "Epoch: 137/500 Iteration: 684 Training loss: 0.16184\n",
      "Epoch: 136/500 Iteration: 685 Validation Acc: 0.6733\n",
      "Epoch: 138/500 Iteration: 685 Training loss: 0.08677\n",
      "Epoch: 138/500 Iteration: 686 Training loss: 0.06113\n",
      "Epoch: 138/500 Iteration: 687 Training loss: 0.05033\n",
      "Epoch: 138/500 Iteration: 688 Training loss: 0.04367\n",
      "Epoch: 138/500 Iteration: 689 Training loss: 0.22685\n",
      "Epoch: 137/500 Iteration: 690 Validation Acc: 0.7000\n",
      "Epoch: 139/500 Iteration: 690 Training loss: 0.09866\n",
      "Epoch: 139/500 Iteration: 691 Training loss: 0.05300\n",
      "Epoch: 139/500 Iteration: 692 Training loss: 0.06204\n",
      "Epoch: 139/500 Iteration: 693 Training loss: 0.05523\n",
      "Epoch: 139/500 Iteration: 694 Training loss: 0.18532\n",
      "Epoch: 138/500 Iteration: 695 Validation Acc: 0.6733\n",
      "Epoch: 140/500 Iteration: 695 Training loss: 0.07716\n",
      "Epoch: 140/500 Iteration: 696 Training loss: 0.04040\n",
      "Epoch: 140/500 Iteration: 697 Training loss: 0.05683\n",
      "Epoch: 140/500 Iteration: 698 Training loss: 0.03960\n",
      "Epoch: 140/500 Iteration: 699 Training loss: 0.20903\n",
      "Epoch: 139/500 Iteration: 700 Validation Acc: 0.6600\n",
      "Epoch: 141/500 Iteration: 700 Training loss: 0.10689\n",
      "Epoch: 141/500 Iteration: 701 Training loss: 0.04288\n",
      "Epoch: 141/500 Iteration: 702 Training loss: 0.05330\n",
      "Epoch: 141/500 Iteration: 703 Training loss: 0.05556\n",
      "Epoch: 141/500 Iteration: 704 Training loss: 0.15965\n",
      "Epoch: 140/500 Iteration: 705 Validation Acc: 0.6667\n",
      "Epoch: 142/500 Iteration: 705 Training loss: 0.06462\n",
      "Epoch: 142/500 Iteration: 706 Training loss: 0.04492\n",
      "Epoch: 142/500 Iteration: 707 Training loss: 0.04080\n",
      "Epoch: 142/500 Iteration: 708 Training loss: 0.03399\n",
      "Epoch: 142/500 Iteration: 709 Training loss: 0.18440\n",
      "Epoch: 141/500 Iteration: 710 Validation Acc: 0.6733\n",
      "Epoch: 143/500 Iteration: 710 Training loss: 0.14221\n",
      "Epoch: 143/500 Iteration: 711 Training loss: 0.04056\n",
      "Epoch: 143/500 Iteration: 712 Training loss: 0.04725\n",
      "Epoch: 143/500 Iteration: 713 Training loss: 0.04367\n",
      "Epoch: 143/500 Iteration: 714 Training loss: 0.16143\n",
      "Epoch: 142/500 Iteration: 715 Validation Acc: 0.6600\n",
      "Epoch: 144/500 Iteration: 715 Training loss: 0.07055\n",
      "Epoch: 144/500 Iteration: 716 Training loss: 0.06558\n",
      "Epoch: 144/500 Iteration: 717 Training loss: 0.05108\n",
      "Epoch: 144/500 Iteration: 718 Training loss: 0.03354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144/500 Iteration: 719 Training loss: 0.26059\n",
      "Epoch: 143/500 Iteration: 720 Validation Acc: 0.6867\n",
      "Epoch: 145/500 Iteration: 720 Training loss: 0.11520\n",
      "Epoch: 145/500 Iteration: 721 Training loss: 0.04167\n",
      "Epoch: 145/500 Iteration: 722 Training loss: 0.04840\n",
      "Epoch: 145/500 Iteration: 723 Training loss: 0.05227\n",
      "Epoch: 145/500 Iteration: 724 Training loss: 0.15847\n",
      "Epoch: 144/500 Iteration: 725 Validation Acc: 0.6733\n",
      "Epoch: 146/500 Iteration: 725 Training loss: 0.11884\n",
      "Epoch: 146/500 Iteration: 726 Training loss: 0.05398\n",
      "Epoch: 146/500 Iteration: 727 Training loss: 0.06113\n",
      "Epoch: 146/500 Iteration: 728 Training loss: 0.06285\n",
      "Epoch: 146/500 Iteration: 729 Training loss: 0.16020\n",
      "Epoch: 145/500 Iteration: 730 Validation Acc: 0.6667\n",
      "Epoch: 147/500 Iteration: 730 Training loss: 0.07430\n",
      "Epoch: 147/500 Iteration: 731 Training loss: 0.03625\n",
      "Epoch: 147/500 Iteration: 732 Training loss: 0.04269\n",
      "Epoch: 147/500 Iteration: 733 Training loss: 0.04377\n",
      "Epoch: 147/500 Iteration: 734 Training loss: 0.20603\n",
      "Epoch: 146/500 Iteration: 735 Validation Acc: 0.6533\n",
      "Epoch: 148/500 Iteration: 735 Training loss: 0.11186\n",
      "Epoch: 148/500 Iteration: 736 Training loss: 0.03967\n",
      "Epoch: 148/500 Iteration: 737 Training loss: 0.06441\n",
      "Epoch: 148/500 Iteration: 738 Training loss: 0.05763\n",
      "Epoch: 148/500 Iteration: 739 Training loss: 0.13669\n",
      "Epoch: 147/500 Iteration: 740 Validation Acc: 0.6933\n",
      "Epoch: 149/500 Iteration: 740 Training loss: 0.10265\n",
      "Epoch: 149/500 Iteration: 741 Training loss: 0.06984\n",
      "Epoch: 149/500 Iteration: 742 Training loss: 0.04248\n",
      "Epoch: 149/500 Iteration: 743 Training loss: 0.03751\n",
      "Epoch: 149/500 Iteration: 744 Training loss: 0.20435\n",
      "Epoch: 148/500 Iteration: 745 Validation Acc: 0.6867\n",
      "Epoch: 150/500 Iteration: 745 Training loss: 0.06110\n",
      "Epoch: 150/500 Iteration: 746 Training loss: 0.03241\n",
      "Epoch: 150/500 Iteration: 747 Training loss: 0.03635\n",
      "Epoch: 150/500 Iteration: 748 Training loss: 0.05003\n",
      "Epoch: 150/500 Iteration: 749 Training loss: 0.13493\n",
      "Epoch: 149/500 Iteration: 750 Validation Acc: 0.6867\n",
      "Epoch: 151/500 Iteration: 750 Training loss: 0.09004\n",
      "Epoch: 151/500 Iteration: 751 Training loss: 0.04035\n",
      "Epoch: 151/500 Iteration: 752 Training loss: 0.04565\n",
      "Epoch: 151/500 Iteration: 753 Training loss: 0.04312\n",
      "Epoch: 151/500 Iteration: 754 Training loss: 0.17948\n",
      "Epoch: 150/500 Iteration: 755 Validation Acc: 0.7000\n",
      "Epoch: 152/500 Iteration: 755 Training loss: 0.08603\n",
      "Epoch: 152/500 Iteration: 756 Training loss: 0.03201\n",
      "Epoch: 152/500 Iteration: 757 Training loss: 0.03819\n",
      "Epoch: 152/500 Iteration: 758 Training loss: 0.03630\n",
      "Epoch: 152/500 Iteration: 759 Training loss: 0.14648\n",
      "Epoch: 151/500 Iteration: 760 Validation Acc: 0.6667\n",
      "Epoch: 153/500 Iteration: 760 Training loss: 0.07215\n",
      "Epoch: 153/500 Iteration: 761 Training loss: 0.04048\n",
      "Epoch: 153/500 Iteration: 762 Training loss: 0.04818\n",
      "Epoch: 153/500 Iteration: 763 Training loss: 0.04136\n",
      "Epoch: 153/500 Iteration: 764 Training loss: 0.13301\n",
      "Epoch: 152/500 Iteration: 765 Validation Acc: 0.6867\n",
      "Epoch: 154/500 Iteration: 765 Training loss: 0.07899\n",
      "Epoch: 154/500 Iteration: 766 Training loss: 0.03985\n",
      "Epoch: 154/500 Iteration: 767 Training loss: 0.03172\n",
      "Epoch: 154/500 Iteration: 768 Training loss: 0.03302\n",
      "Epoch: 154/500 Iteration: 769 Training loss: 0.13277\n",
      "Epoch: 153/500 Iteration: 770 Validation Acc: 0.7000\n",
      "Epoch: 155/500 Iteration: 770 Training loss: 0.07748\n",
      "Epoch: 155/500 Iteration: 771 Training loss: 0.03111\n",
      "Epoch: 155/500 Iteration: 772 Training loss: 0.03048\n",
      "Epoch: 155/500 Iteration: 773 Training loss: 0.02999\n",
      "Epoch: 155/500 Iteration: 774 Training loss: 0.14798\n",
      "Epoch: 154/500 Iteration: 775 Validation Acc: 0.6867\n",
      "Epoch: 156/500 Iteration: 775 Training loss: 0.05495\n",
      "Epoch: 156/500 Iteration: 776 Training loss: 0.02071\n",
      "Epoch: 156/500 Iteration: 777 Training loss: 0.04172\n",
      "Epoch: 156/500 Iteration: 778 Training loss: 0.03787\n",
      "Epoch: 156/500 Iteration: 779 Training loss: 0.15866\n",
      "Epoch: 155/500 Iteration: 780 Validation Acc: 0.6400\n",
      "Epoch: 157/500 Iteration: 780 Training loss: 0.07531\n",
      "Epoch: 157/500 Iteration: 781 Training loss: 0.02951\n",
      "Epoch: 157/500 Iteration: 782 Training loss: 0.03532\n",
      "Epoch: 157/500 Iteration: 783 Training loss: 0.02621\n",
      "Epoch: 157/500 Iteration: 784 Training loss: 0.12366\n",
      "Epoch: 156/500 Iteration: 785 Validation Acc: 0.6933\n",
      "Epoch: 158/500 Iteration: 785 Training loss: 0.07378\n",
      "Epoch: 158/500 Iteration: 786 Training loss: 0.03339\n",
      "Epoch: 158/500 Iteration: 787 Training loss: 0.03273\n",
      "Epoch: 158/500 Iteration: 788 Training loss: 0.03823\n",
      "Epoch: 158/500 Iteration: 789 Training loss: 0.13430\n",
      "Epoch: 157/500 Iteration: 790 Validation Acc: 0.6667\n",
      "Epoch: 159/500 Iteration: 790 Training loss: 0.07714\n",
      "Epoch: 159/500 Iteration: 791 Training loss: 0.03054\n",
      "Epoch: 159/500 Iteration: 792 Training loss: 0.02788\n",
      "Epoch: 159/500 Iteration: 793 Training loss: 0.04151\n",
      "Epoch: 159/500 Iteration: 794 Training loss: 0.15563\n",
      "Epoch: 158/500 Iteration: 795 Validation Acc: 0.6867\n",
      "Epoch: 160/500 Iteration: 795 Training loss: 0.05181\n",
      "Epoch: 160/500 Iteration: 796 Training loss: 0.04512\n",
      "Epoch: 160/500 Iteration: 797 Training loss: 0.05038\n",
      "Epoch: 160/500 Iteration: 798 Training loss: 0.04332\n",
      "Epoch: 160/500 Iteration: 799 Training loss: 0.13304\n",
      "Epoch: 159/500 Iteration: 800 Validation Acc: 0.6867\n",
      "Epoch: 161/500 Iteration: 800 Training loss: 0.06975\n",
      "Epoch: 161/500 Iteration: 801 Training loss: 0.02973\n",
      "Epoch: 161/500 Iteration: 802 Training loss: 0.03306\n",
      "Epoch: 161/500 Iteration: 803 Training loss: 0.03343\n",
      "Epoch: 161/500 Iteration: 804 Training loss: 0.12794\n",
      "Epoch: 160/500 Iteration: 805 Validation Acc: 0.6667\n",
      "Epoch: 162/500 Iteration: 805 Training loss: 0.04389\n",
      "Epoch: 162/500 Iteration: 806 Training loss: 0.03451\n",
      "Epoch: 162/500 Iteration: 807 Training loss: 0.03388\n",
      "Epoch: 162/500 Iteration: 808 Training loss: 0.03611\n",
      "Epoch: 162/500 Iteration: 809 Training loss: 0.13705\n",
      "Epoch: 161/500 Iteration: 810 Validation Acc: 0.6667\n",
      "Epoch: 163/500 Iteration: 810 Training loss: 0.07398\n",
      "Epoch: 163/500 Iteration: 811 Training loss: 0.04140\n",
      "Epoch: 163/500 Iteration: 812 Training loss: 0.02921\n",
      "Epoch: 163/500 Iteration: 813 Training loss: 0.02672\n",
      "Epoch: 163/500 Iteration: 814 Training loss: 0.10858\n",
      "Epoch: 162/500 Iteration: 815 Validation Acc: 0.7133\n",
      "Epoch: 164/500 Iteration: 815 Training loss: 0.04893\n",
      "Epoch: 164/500 Iteration: 816 Training loss: 0.03556\n",
      "Epoch: 164/500 Iteration: 817 Training loss: 0.02396\n",
      "Epoch: 164/500 Iteration: 818 Training loss: 0.02589\n",
      "Epoch: 164/500 Iteration: 819 Training loss: 0.14823\n",
      "Epoch: 163/500 Iteration: 820 Validation Acc: 0.6800\n",
      "Epoch: 165/500 Iteration: 820 Training loss: 0.04670\n",
      "Epoch: 165/500 Iteration: 821 Training loss: 0.02808\n",
      "Epoch: 165/500 Iteration: 822 Training loss: 0.03433\n",
      "Epoch: 165/500 Iteration: 823 Training loss: 0.02589\n",
      "Epoch: 165/500 Iteration: 824 Training loss: 0.08545\n",
      "Epoch: 164/500 Iteration: 825 Validation Acc: 0.6267\n",
      "Epoch: 166/500 Iteration: 825 Training loss: 0.07267\n",
      "Epoch: 166/500 Iteration: 826 Training loss: 0.03368\n",
      "Epoch: 166/500 Iteration: 827 Training loss: 0.02376\n",
      "Epoch: 166/500 Iteration: 828 Training loss: 0.02724\n",
      "Epoch: 166/500 Iteration: 829 Training loss: 0.13019\n",
      "Epoch: 165/500 Iteration: 830 Validation Acc: 0.7000\n",
      "Epoch: 167/500 Iteration: 830 Training loss: 0.05964\n",
      "Epoch: 167/500 Iteration: 831 Training loss: 0.02326\n",
      "Epoch: 167/500 Iteration: 832 Training loss: 0.03080\n",
      "Epoch: 167/500 Iteration: 833 Training loss: 0.03644\n",
      "Epoch: 167/500 Iteration: 834 Training loss: 0.08839\n",
      "Epoch: 166/500 Iteration: 835 Validation Acc: 0.6933\n",
      "Epoch: 168/500 Iteration: 835 Training loss: 0.06324\n",
      "Epoch: 168/500 Iteration: 836 Training loss: 0.03040\n",
      "Epoch: 168/500 Iteration: 837 Training loss: 0.02796\n",
      "Epoch: 168/500 Iteration: 838 Training loss: 0.02793\n",
      "Epoch: 168/500 Iteration: 839 Training loss: 0.10313\n",
      "Epoch: 167/500 Iteration: 840 Validation Acc: 0.6733\n",
      "Epoch: 169/500 Iteration: 840 Training loss: 0.05873\n",
      "Epoch: 169/500 Iteration: 841 Training loss: 0.01901\n",
      "Epoch: 169/500 Iteration: 842 Training loss: 0.02595\n",
      "Epoch: 169/500 Iteration: 843 Training loss: 0.02111\n",
      "Epoch: 169/500 Iteration: 844 Training loss: 0.11271\n",
      "Epoch: 168/500 Iteration: 845 Validation Acc: 0.6667\n",
      "Epoch: 170/500 Iteration: 845 Training loss: 0.04651\n",
      "Epoch: 170/500 Iteration: 846 Training loss: 0.03311\n",
      "Epoch: 170/500 Iteration: 847 Training loss: 0.02903\n",
      "Epoch: 170/500 Iteration: 848 Training loss: 0.02737\n",
      "Epoch: 170/500 Iteration: 849 Training loss: 0.07702\n",
      "Epoch: 169/500 Iteration: 850 Validation Acc: 0.7133\n",
      "Epoch: 171/500 Iteration: 850 Training loss: 0.03941\n",
      "Epoch: 171/500 Iteration: 851 Training loss: 0.03333\n",
      "Epoch: 171/500 Iteration: 852 Training loss: 0.02596\n",
      "Epoch: 171/500 Iteration: 853 Training loss: 0.02710\n",
      "Epoch: 171/500 Iteration: 854 Training loss: 0.11797\n",
      "Epoch: 170/500 Iteration: 855 Validation Acc: 0.6933\n",
      "Epoch: 172/500 Iteration: 855 Training loss: 0.06419\n",
      "Epoch: 172/500 Iteration: 856 Training loss: 0.02351\n",
      "Epoch: 172/500 Iteration: 857 Training loss: 0.02886\n",
      "Epoch: 172/500 Iteration: 858 Training loss: 0.02790\n",
      "Epoch: 172/500 Iteration: 859 Training loss: 0.10824\n",
      "Epoch: 171/500 Iteration: 860 Validation Acc: 0.6867\n",
      "Epoch: 173/500 Iteration: 860 Training loss: 0.04097\n",
      "Epoch: 173/500 Iteration: 861 Training loss: 0.02580\n",
      "Epoch: 173/500 Iteration: 862 Training loss: 0.03551\n",
      "Epoch: 173/500 Iteration: 863 Training loss: 0.02753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173/500 Iteration: 864 Training loss: 0.10229\n",
      "Epoch: 172/500 Iteration: 865 Validation Acc: 0.6867\n",
      "Epoch: 174/500 Iteration: 865 Training loss: 0.04409\n",
      "Epoch: 174/500 Iteration: 866 Training loss: 0.01899\n",
      "Epoch: 174/500 Iteration: 867 Training loss: 0.02044\n",
      "Epoch: 174/500 Iteration: 868 Training loss: 0.01846\n",
      "Epoch: 174/500 Iteration: 869 Training loss: 0.10691\n",
      "Epoch: 173/500 Iteration: 870 Validation Acc: 0.6933\n",
      "Epoch: 175/500 Iteration: 870 Training loss: 0.06313\n",
      "Epoch: 175/500 Iteration: 871 Training loss: 0.01510\n",
      "Epoch: 175/500 Iteration: 872 Training loss: 0.02624\n",
      "Epoch: 175/500 Iteration: 873 Training loss: 0.02425\n",
      "Epoch: 175/500 Iteration: 874 Training loss: 0.05723\n",
      "Epoch: 174/500 Iteration: 875 Validation Acc: 0.6733\n",
      "Epoch: 176/500 Iteration: 875 Training loss: 0.04596\n",
      "Epoch: 176/500 Iteration: 876 Training loss: 0.02436\n",
      "Epoch: 176/500 Iteration: 877 Training loss: 0.03022\n",
      "Epoch: 176/500 Iteration: 878 Training loss: 0.02223\n",
      "Epoch: 176/500 Iteration: 879 Training loss: 0.13305\n",
      "Epoch: 175/500 Iteration: 880 Validation Acc: 0.6733\n",
      "Epoch: 177/500 Iteration: 880 Training loss: 0.05271\n",
      "Epoch: 177/500 Iteration: 881 Training loss: 0.02062\n",
      "Epoch: 177/500 Iteration: 882 Training loss: 0.01570\n",
      "Epoch: 177/500 Iteration: 883 Training loss: 0.02828\n",
      "Epoch: 177/500 Iteration: 884 Training loss: 0.11352\n",
      "Epoch: 176/500 Iteration: 885 Validation Acc: 0.7133\n",
      "Epoch: 178/500 Iteration: 885 Training loss: 0.04944\n",
      "Epoch: 178/500 Iteration: 886 Training loss: 0.03675\n",
      "Epoch: 178/500 Iteration: 887 Training loss: 0.02856\n",
      "Epoch: 178/500 Iteration: 888 Training loss: 0.02975\n",
      "Epoch: 178/500 Iteration: 889 Training loss: 0.07237\n",
      "Epoch: 177/500 Iteration: 890 Validation Acc: 0.7067\n",
      "Epoch: 179/500 Iteration: 890 Training loss: 0.03703\n",
      "Epoch: 179/500 Iteration: 891 Training loss: 0.03178\n",
      "Epoch: 179/500 Iteration: 892 Training loss: 0.02662\n",
      "Epoch: 179/500 Iteration: 893 Training loss: 0.03343\n",
      "Epoch: 179/500 Iteration: 894 Training loss: 0.13314\n",
      "Epoch: 178/500 Iteration: 895 Validation Acc: 0.6933\n",
      "Epoch: 180/500 Iteration: 895 Training loss: 0.06428\n",
      "Epoch: 180/500 Iteration: 896 Training loss: 0.02852\n",
      "Epoch: 180/500 Iteration: 897 Training loss: 0.02969\n",
      "Epoch: 180/500 Iteration: 898 Training loss: 0.03289\n",
      "Epoch: 180/500 Iteration: 899 Training loss: 0.07302\n",
      "Epoch: 179/500 Iteration: 900 Validation Acc: 0.6600\n",
      "Epoch: 181/500 Iteration: 900 Training loss: 0.06281\n",
      "Epoch: 181/500 Iteration: 901 Training loss: 0.03072\n",
      "Epoch: 181/500 Iteration: 902 Training loss: 0.02525\n",
      "Epoch: 181/500 Iteration: 903 Training loss: 0.03121\n",
      "Epoch: 181/500 Iteration: 904 Training loss: 0.14212\n",
      "Epoch: 180/500 Iteration: 905 Validation Acc: 0.7067\n",
      "Epoch: 182/500 Iteration: 905 Training loss: 0.05676\n",
      "Epoch: 182/500 Iteration: 906 Training loss: 0.01775\n",
      "Epoch: 182/500 Iteration: 907 Training loss: 0.02604\n",
      "Epoch: 182/500 Iteration: 908 Training loss: 0.02847\n",
      "Epoch: 182/500 Iteration: 909 Training loss: 0.07794\n",
      "Epoch: 181/500 Iteration: 910 Validation Acc: 0.7133\n",
      "Epoch: 183/500 Iteration: 910 Training loss: 0.05665\n",
      "Epoch: 183/500 Iteration: 911 Training loss: 0.02392\n",
      "Epoch: 183/500 Iteration: 912 Training loss: 0.03010\n",
      "Epoch: 183/500 Iteration: 913 Training loss: 0.02156\n",
      "Epoch: 183/500 Iteration: 914 Training loss: 0.11048\n",
      "Epoch: 182/500 Iteration: 915 Validation Acc: 0.6667\n",
      "Epoch: 184/500 Iteration: 915 Training loss: 0.03971\n",
      "Epoch: 184/500 Iteration: 916 Training loss: 0.02114\n",
      "Epoch: 184/500 Iteration: 917 Training loss: 0.02564\n",
      "Epoch: 184/500 Iteration: 918 Training loss: 0.01708\n",
      "Epoch: 184/500 Iteration: 919 Training loss: 0.07748\n",
      "Epoch: 183/500 Iteration: 920 Validation Acc: 0.6333\n",
      "Epoch: 185/500 Iteration: 920 Training loss: 0.04652\n",
      "Epoch: 185/500 Iteration: 921 Training loss: 0.02861\n",
      "Epoch: 185/500 Iteration: 922 Training loss: 0.02798\n",
      "Epoch: 185/500 Iteration: 923 Training loss: 0.02724\n",
      "Epoch: 185/500 Iteration: 924 Training loss: 0.04964\n",
      "Epoch: 184/500 Iteration: 925 Validation Acc: 0.6733\n",
      "Epoch: 186/500 Iteration: 925 Training loss: 0.04671\n",
      "Epoch: 186/500 Iteration: 926 Training loss: 0.01585\n",
      "Epoch: 186/500 Iteration: 927 Training loss: 0.02127\n",
      "Epoch: 186/500 Iteration: 928 Training loss: 0.01956\n",
      "Epoch: 186/500 Iteration: 929 Training loss: 0.09275\n",
      "Epoch: 185/500 Iteration: 930 Validation Acc: 0.7067\n",
      "Epoch: 187/500 Iteration: 930 Training loss: 0.02546\n",
      "Epoch: 187/500 Iteration: 931 Training loss: 0.03024\n",
      "Epoch: 187/500 Iteration: 932 Training loss: 0.03205\n",
      "Epoch: 187/500 Iteration: 933 Training loss: 0.01708\n",
      "Epoch: 187/500 Iteration: 934 Training loss: 0.07820\n",
      "Epoch: 186/500 Iteration: 935 Validation Acc: 0.6667\n",
      "Epoch: 188/500 Iteration: 935 Training loss: 0.03617\n",
      "Epoch: 188/500 Iteration: 936 Training loss: 0.01903\n",
      "Epoch: 188/500 Iteration: 937 Training loss: 0.01606\n",
      "Epoch: 188/500 Iteration: 938 Training loss: 0.01625\n",
      "Epoch: 188/500 Iteration: 939 Training loss: 0.07948\n",
      "Epoch: 187/500 Iteration: 940 Validation Acc: 0.6867\n",
      "Epoch: 189/500 Iteration: 940 Training loss: 0.06290\n",
      "Epoch: 189/500 Iteration: 941 Training loss: 0.01532\n",
      "Epoch: 189/500 Iteration: 942 Training loss: 0.02466\n",
      "Epoch: 189/500 Iteration: 943 Training loss: 0.02327\n",
      "Epoch: 189/500 Iteration: 944 Training loss: 0.05739\n",
      "Epoch: 188/500 Iteration: 945 Validation Acc: 0.6800\n",
      "Epoch: 190/500 Iteration: 945 Training loss: 0.03677\n",
      "Epoch: 190/500 Iteration: 946 Training loss: 0.01480\n",
      "Epoch: 190/500 Iteration: 947 Training loss: 0.01855\n",
      "Epoch: 190/500 Iteration: 948 Training loss: 0.01719\n",
      "Epoch: 190/500 Iteration: 949 Training loss: 0.10202\n",
      "Epoch: 189/500 Iteration: 950 Validation Acc: 0.6800\n",
      "Epoch: 191/500 Iteration: 950 Training loss: 0.05055\n",
      "Epoch: 191/500 Iteration: 951 Training loss: 0.01546\n",
      "Epoch: 191/500 Iteration: 952 Training loss: 0.02659\n",
      "Epoch: 191/500 Iteration: 953 Training loss: 0.02408\n",
      "Epoch: 191/500 Iteration: 954 Training loss: 0.08162\n",
      "Epoch: 190/500 Iteration: 955 Validation Acc: 0.6800\n",
      "Epoch: 192/500 Iteration: 955 Training loss: 0.03927\n",
      "Epoch: 192/500 Iteration: 956 Training loss: 0.02018\n",
      "Epoch: 192/500 Iteration: 957 Training loss: 0.02901\n",
      "Epoch: 192/500 Iteration: 958 Training loss: 0.02088\n",
      "Epoch: 192/500 Iteration: 959 Training loss: 0.07481\n",
      "Epoch: 191/500 Iteration: 960 Validation Acc: 0.7200\n",
      "Epoch: 193/500 Iteration: 960 Training loss: 0.04716\n",
      "Epoch: 193/500 Iteration: 961 Training loss: 0.01715\n",
      "Epoch: 193/500 Iteration: 962 Training loss: 0.01355\n",
      "Epoch: 193/500 Iteration: 963 Training loss: 0.01986\n",
      "Epoch: 193/500 Iteration: 964 Training loss: 0.06613\n",
      "Epoch: 192/500 Iteration: 965 Validation Acc: 0.6933\n",
      "Epoch: 194/500 Iteration: 965 Training loss: 0.03086\n",
      "Epoch: 194/500 Iteration: 966 Training loss: 0.02865\n",
      "Epoch: 194/500 Iteration: 967 Training loss: 0.01992\n",
      "Epoch: 194/500 Iteration: 968 Training loss: 0.01903\n",
      "Epoch: 194/500 Iteration: 969 Training loss: 0.07139\n",
      "Epoch: 193/500 Iteration: 970 Validation Acc: 0.6800\n",
      "Epoch: 195/500 Iteration: 970 Training loss: 0.05968\n",
      "Epoch: 195/500 Iteration: 971 Training loss: 0.01792\n",
      "Epoch: 195/500 Iteration: 972 Training loss: 0.01843\n",
      "Epoch: 195/500 Iteration: 973 Training loss: 0.01741\n",
      "Epoch: 195/500 Iteration: 974 Training loss: 0.08082\n",
      "Epoch: 194/500 Iteration: 975 Validation Acc: 0.7000\n",
      "Epoch: 196/500 Iteration: 975 Training loss: 0.03969\n",
      "Epoch: 196/500 Iteration: 976 Training loss: 0.02408\n",
      "Epoch: 196/500 Iteration: 977 Training loss: 0.01573\n",
      "Epoch: 196/500 Iteration: 978 Training loss: 0.02806\n",
      "Epoch: 196/500 Iteration: 979 Training loss: 0.05711\n",
      "Epoch: 195/500 Iteration: 980 Validation Acc: 0.6600\n",
      "Epoch: 197/500 Iteration: 980 Training loss: 0.04589\n",
      "Epoch: 197/500 Iteration: 981 Training loss: 0.02021\n",
      "Epoch: 197/500 Iteration: 982 Training loss: 0.01244\n",
      "Epoch: 197/500 Iteration: 983 Training loss: 0.02429\n",
      "Epoch: 197/500 Iteration: 984 Training loss: 0.09831\n",
      "Epoch: 196/500 Iteration: 985 Validation Acc: 0.6733\n",
      "Epoch: 198/500 Iteration: 985 Training loss: 0.03690\n",
      "Epoch: 198/500 Iteration: 986 Training loss: 0.01731\n",
      "Epoch: 198/500 Iteration: 987 Training loss: 0.02143\n",
      "Epoch: 198/500 Iteration: 988 Training loss: 0.01649\n",
      "Epoch: 198/500 Iteration: 989 Training loss: 0.06520\n",
      "Epoch: 197/500 Iteration: 990 Validation Acc: 0.6600\n",
      "Epoch: 199/500 Iteration: 990 Training loss: 0.04765\n",
      "Epoch: 199/500 Iteration: 991 Training loss: 0.03318\n",
      "Epoch: 199/500 Iteration: 992 Training loss: 0.02296\n",
      "Epoch: 199/500 Iteration: 993 Training loss: 0.02669\n",
      "Epoch: 199/500 Iteration: 994 Training loss: 0.05858\n",
      "Epoch: 198/500 Iteration: 995 Validation Acc: 0.6800\n",
      "Epoch: 200/500 Iteration: 995 Training loss: 0.02949\n",
      "Epoch: 200/500 Iteration: 996 Training loss: 0.01381\n",
      "Epoch: 200/500 Iteration: 997 Training loss: 0.02471\n",
      "Epoch: 200/500 Iteration: 998 Training loss: 0.01225\n",
      "Epoch: 200/500 Iteration: 999 Training loss: 0.06136\n",
      "Epoch: 199/500 Iteration: 1000 Validation Acc: 0.6867\n",
      "Epoch: 201/500 Iteration: 1000 Training loss: 0.04608\n",
      "Epoch: 201/500 Iteration: 1001 Training loss: 0.02019\n",
      "Epoch: 201/500 Iteration: 1002 Training loss: 0.01925\n",
      "Epoch: 201/500 Iteration: 1003 Training loss: 0.01793\n",
      "Epoch: 201/500 Iteration: 1004 Training loss: 0.05272\n",
      "Epoch: 200/500 Iteration: 1005 Validation Acc: 0.6933\n",
      "Epoch: 202/500 Iteration: 1005 Training loss: 0.04401\n",
      "Epoch: 202/500 Iteration: 1006 Training loss: 0.01925\n",
      "Epoch: 202/500 Iteration: 1007 Training loss: 0.01572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202/500 Iteration: 1008 Training loss: 0.01262\n",
      "Epoch: 202/500 Iteration: 1009 Training loss: 0.06833\n",
      "Epoch: 201/500 Iteration: 1010 Validation Acc: 0.6733\n",
      "Epoch: 203/500 Iteration: 1010 Training loss: 0.02584\n",
      "Epoch: 203/500 Iteration: 1011 Training loss: 0.01900\n",
      "Epoch: 203/500 Iteration: 1012 Training loss: 0.01446\n",
      "Epoch: 203/500 Iteration: 1013 Training loss: 0.01579\n",
      "Epoch: 203/500 Iteration: 1014 Training loss: 0.07793\n",
      "Epoch: 202/500 Iteration: 1015 Validation Acc: 0.6867\n",
      "Epoch: 204/500 Iteration: 1015 Training loss: 0.04920\n",
      "Epoch: 204/500 Iteration: 1016 Training loss: 0.01635\n",
      "Epoch: 204/500 Iteration: 1017 Training loss: 0.02336\n",
      "Epoch: 204/500 Iteration: 1018 Training loss: 0.01331\n",
      "Epoch: 204/500 Iteration: 1019 Training loss: 0.06312\n",
      "Epoch: 203/500 Iteration: 1020 Validation Acc: 0.6600\n",
      "Epoch: 205/500 Iteration: 1020 Training loss: 0.03319\n",
      "Epoch: 205/500 Iteration: 1021 Training loss: 0.01791\n",
      "Epoch: 205/500 Iteration: 1022 Training loss: 0.01867\n",
      "Epoch: 205/500 Iteration: 1023 Training loss: 0.02068\n",
      "Epoch: 205/500 Iteration: 1024 Training loss: 0.07668\n",
      "Epoch: 204/500 Iteration: 1025 Validation Acc: 0.7000\n",
      "Epoch: 206/500 Iteration: 1025 Training loss: 0.02459\n",
      "Epoch: 206/500 Iteration: 1026 Training loss: 0.02381\n",
      "Epoch: 206/500 Iteration: 1027 Training loss: 0.02747\n",
      "Epoch: 206/500 Iteration: 1028 Training loss: 0.01987\n",
      "Epoch: 206/500 Iteration: 1029 Training loss: 0.06077\n",
      "Epoch: 205/500 Iteration: 1030 Validation Acc: 0.6867\n",
      "Epoch: 207/500 Iteration: 1030 Training loss: 0.03351\n",
      "Epoch: 207/500 Iteration: 1031 Training loss: 0.01557\n",
      "Epoch: 207/500 Iteration: 1032 Training loss: 0.01011\n",
      "Epoch: 207/500 Iteration: 1033 Training loss: 0.01704\n",
      "Epoch: 207/500 Iteration: 1034 Training loss: 0.05697\n",
      "Epoch: 206/500 Iteration: 1035 Validation Acc: 0.6667\n",
      "Epoch: 208/500 Iteration: 1035 Training loss: 0.03607\n",
      "Epoch: 208/500 Iteration: 1036 Training loss: 0.01569\n",
      "Epoch: 208/500 Iteration: 1037 Training loss: 0.01497\n",
      "Epoch: 208/500 Iteration: 1038 Training loss: 0.01981\n",
      "Epoch: 208/500 Iteration: 1039 Training loss: 0.05811\n",
      "Epoch: 207/500 Iteration: 1040 Validation Acc: 0.6800\n",
      "Epoch: 209/500 Iteration: 1040 Training loss: 0.03800\n",
      "Epoch: 209/500 Iteration: 1041 Training loss: 0.00968\n",
      "Epoch: 209/500 Iteration: 1042 Training loss: 0.01597\n",
      "Epoch: 209/500 Iteration: 1043 Training loss: 0.01698\n",
      "Epoch: 209/500 Iteration: 1044 Training loss: 0.05688\n",
      "Epoch: 208/500 Iteration: 1045 Validation Acc: 0.6533\n",
      "Epoch: 210/500 Iteration: 1045 Training loss: 0.02700\n",
      "Epoch: 210/500 Iteration: 1046 Training loss: 0.02153\n",
      "Epoch: 210/500 Iteration: 1047 Training loss: 0.02086\n",
      "Epoch: 210/500 Iteration: 1048 Training loss: 0.01524\n",
      "Epoch: 210/500 Iteration: 1049 Training loss: 0.05516\n",
      "Epoch: 209/500 Iteration: 1050 Validation Acc: 0.7000\n",
      "Epoch: 211/500 Iteration: 1050 Training loss: 0.03269\n",
      "Epoch: 211/500 Iteration: 1051 Training loss: 0.00897\n",
      "Epoch: 211/500 Iteration: 1052 Training loss: 0.01023\n",
      "Epoch: 211/500 Iteration: 1053 Training loss: 0.00969\n",
      "Epoch: 211/500 Iteration: 1054 Training loss: 0.05649\n",
      "Epoch: 210/500 Iteration: 1055 Validation Acc: 0.6800\n",
      "Epoch: 212/500 Iteration: 1055 Training loss: 0.03473\n",
      "Epoch: 212/500 Iteration: 1056 Training loss: 0.00772\n",
      "Epoch: 212/500 Iteration: 1057 Training loss: 0.01365\n",
      "Epoch: 212/500 Iteration: 1058 Training loss: 0.02078\n",
      "Epoch: 212/500 Iteration: 1059 Training loss: 0.03753\n",
      "Epoch: 211/500 Iteration: 1060 Validation Acc: 0.7067\n",
      "Epoch: 213/500 Iteration: 1060 Training loss: 0.04113\n",
      "Epoch: 213/500 Iteration: 1061 Training loss: 0.02887\n",
      "Epoch: 213/500 Iteration: 1062 Training loss: 0.02628\n",
      "Epoch: 213/500 Iteration: 1063 Training loss: 0.01727\n",
      "Epoch: 213/500 Iteration: 1064 Training loss: 0.05303\n",
      "Epoch: 212/500 Iteration: 1065 Validation Acc: 0.6867\n",
      "Epoch: 214/500 Iteration: 1065 Training loss: 0.03859\n",
      "Epoch: 214/500 Iteration: 1066 Training loss: 0.02303\n",
      "Epoch: 214/500 Iteration: 1067 Training loss: 0.01083\n",
      "Epoch: 214/500 Iteration: 1068 Training loss: 0.01006\n",
      "Epoch: 214/500 Iteration: 1069 Training loss: 0.06265\n",
      "Epoch: 213/500 Iteration: 1070 Validation Acc: 0.6400\n",
      "Epoch: 215/500 Iteration: 1070 Training loss: 0.04275\n",
      "Epoch: 215/500 Iteration: 1071 Training loss: 0.01813\n",
      "Epoch: 215/500 Iteration: 1072 Training loss: 0.02696\n",
      "Epoch: 215/500 Iteration: 1073 Training loss: 0.01282\n",
      "Epoch: 215/500 Iteration: 1074 Training loss: 0.04982\n",
      "Epoch: 214/500 Iteration: 1075 Validation Acc: 0.6733\n",
      "Epoch: 216/500 Iteration: 1075 Training loss: 0.03199\n",
      "Epoch: 216/500 Iteration: 1076 Training loss: 0.00922\n",
      "Epoch: 216/500 Iteration: 1077 Training loss: 0.01387\n",
      "Epoch: 216/500 Iteration: 1078 Training loss: 0.01507\n",
      "Epoch: 216/500 Iteration: 1079 Training loss: 0.06757\n",
      "Epoch: 215/500 Iteration: 1080 Validation Acc: 0.6733\n",
      "Epoch: 217/500 Iteration: 1080 Training loss: 0.03309\n",
      "Epoch: 217/500 Iteration: 1081 Training loss: 0.01550\n",
      "Epoch: 217/500 Iteration: 1082 Training loss: 0.03518\n",
      "Epoch: 217/500 Iteration: 1083 Training loss: 0.01908\n",
      "Epoch: 217/500 Iteration: 1084 Training loss: 0.04458\n",
      "Epoch: 216/500 Iteration: 1085 Validation Acc: 0.6933\n",
      "Epoch: 218/500 Iteration: 1085 Training loss: 0.02358\n",
      "Epoch: 218/500 Iteration: 1086 Training loss: 0.00786\n",
      "Epoch: 218/500 Iteration: 1087 Training loss: 0.01850\n",
      "Epoch: 218/500 Iteration: 1088 Training loss: 0.01682\n",
      "Epoch: 218/500 Iteration: 1089 Training loss: 0.07418\n",
      "Epoch: 217/500 Iteration: 1090 Validation Acc: 0.6667\n",
      "Epoch: 219/500 Iteration: 1090 Training loss: 0.02315\n",
      "Epoch: 219/500 Iteration: 1091 Training loss: 0.02932\n",
      "Epoch: 219/500 Iteration: 1092 Training loss: 0.02964\n",
      "Epoch: 219/500 Iteration: 1093 Training loss: 0.01545\n",
      "Epoch: 219/500 Iteration: 1094 Training loss: 0.05180\n",
      "Epoch: 218/500 Iteration: 1095 Validation Acc: 0.6667\n",
      "Epoch: 220/500 Iteration: 1095 Training loss: 0.04827\n",
      "Epoch: 220/500 Iteration: 1096 Training loss: 0.00910\n",
      "Epoch: 220/500 Iteration: 1097 Training loss: 0.01337\n",
      "Epoch: 220/500 Iteration: 1098 Training loss: 0.00993\n",
      "Epoch: 220/500 Iteration: 1099 Training loss: 0.09139\n",
      "Epoch: 219/500 Iteration: 1100 Validation Acc: 0.6800\n",
      "Epoch: 221/500 Iteration: 1100 Training loss: 0.04345\n",
      "Epoch: 221/500 Iteration: 1101 Training loss: 0.02150\n",
      "Epoch: 221/500 Iteration: 1102 Training loss: 0.01181\n",
      "Epoch: 221/500 Iteration: 1103 Training loss: 0.01289\n",
      "Epoch: 221/500 Iteration: 1104 Training loss: 0.05398\n",
      "Epoch: 220/500 Iteration: 1105 Validation Acc: 0.6733\n",
      "Epoch: 222/500 Iteration: 1105 Training loss: 0.02818\n",
      "Epoch: 222/500 Iteration: 1106 Training loss: 0.01401\n",
      "Epoch: 222/500 Iteration: 1107 Training loss: 0.02180\n",
      "Epoch: 222/500 Iteration: 1108 Training loss: 0.01423\n",
      "Epoch: 222/500 Iteration: 1109 Training loss: 0.07996\n",
      "Epoch: 221/500 Iteration: 1110 Validation Acc: 0.6867\n",
      "Epoch: 223/500 Iteration: 1110 Training loss: 0.02697\n",
      "Epoch: 223/500 Iteration: 1111 Training loss: 0.02111\n",
      "Epoch: 223/500 Iteration: 1112 Training loss: 0.02312\n",
      "Epoch: 223/500 Iteration: 1113 Training loss: 0.01490\n",
      "Epoch: 223/500 Iteration: 1114 Training loss: 0.06271\n",
      "Epoch: 222/500 Iteration: 1115 Validation Acc: 0.6667\n",
      "Epoch: 224/500 Iteration: 1115 Training loss: 0.05004\n",
      "Epoch: 224/500 Iteration: 1116 Training loss: 0.01254\n",
      "Epoch: 224/500 Iteration: 1117 Training loss: 0.01313\n",
      "Epoch: 224/500 Iteration: 1118 Training loss: 0.01870\n",
      "Epoch: 224/500 Iteration: 1119 Training loss: 0.06825\n",
      "Epoch: 223/500 Iteration: 1120 Validation Acc: 0.7333\n",
      "Epoch: 225/500 Iteration: 1120 Training loss: 0.03011\n",
      "Epoch: 225/500 Iteration: 1121 Training loss: 0.01279\n",
      "Epoch: 225/500 Iteration: 1122 Training loss: 0.02183\n",
      "Epoch: 225/500 Iteration: 1123 Training loss: 0.01949\n",
      "Epoch: 225/500 Iteration: 1124 Training loss: 0.06584\n",
      "Epoch: 224/500 Iteration: 1125 Validation Acc: 0.6667\n",
      "Epoch: 226/500 Iteration: 1125 Training loss: 0.04206\n",
      "Epoch: 226/500 Iteration: 1126 Training loss: 0.01929\n",
      "Epoch: 226/500 Iteration: 1127 Training loss: 0.02001\n",
      "Epoch: 226/500 Iteration: 1128 Training loss: 0.01599\n",
      "Epoch: 226/500 Iteration: 1129 Training loss: 0.07295\n",
      "Epoch: 225/500 Iteration: 1130 Validation Acc: 0.6600\n",
      "Epoch: 227/500 Iteration: 1130 Training loss: 0.03975\n",
      "Epoch: 227/500 Iteration: 1131 Training loss: 0.00991\n",
      "Epoch: 227/500 Iteration: 1132 Training loss: 0.01700\n",
      "Epoch: 227/500 Iteration: 1133 Training loss: 0.01709\n",
      "Epoch: 227/500 Iteration: 1134 Training loss: 0.07595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 226/500 Iteration: 1135 Validation Acc: 0.6933\n",
      "Epoch: 228/500 Iteration: 1135 Training loss: 0.03622\n",
      "Epoch: 228/500 Iteration: 1136 Training loss: 0.02984\n",
      "Epoch: 228/500 Iteration: 1137 Training loss: 0.01543\n",
      "Epoch: 228/500 Iteration: 1138 Training loss: 0.01563\n",
      "Epoch: 228/500 Iteration: 1139 Training loss: 0.06685\n",
      "Epoch: 227/500 Iteration: 1140 Validation Acc: 0.6467\n",
      "Epoch: 229/500 Iteration: 1140 Training loss: 0.04521\n",
      "Epoch: 229/500 Iteration: 1141 Training loss: 0.02064\n",
      "Epoch: 229/500 Iteration: 1142 Training loss: 0.02458\n",
      "Epoch: 229/500 Iteration: 1143 Training loss: 0.01442\n",
      "Epoch: 229/500 Iteration: 1144 Training loss: 0.08124\n",
      "Epoch: 228/500 Iteration: 1145 Validation Acc: 0.6800\n",
      "Epoch: 230/500 Iteration: 1145 Training loss: 0.03994\n",
      "Epoch: 230/500 Iteration: 1146 Training loss: 0.01541\n",
      "Epoch: 230/500 Iteration: 1147 Training loss: 0.02387\n",
      "Epoch: 230/500 Iteration: 1148 Training loss: 0.01460\n",
      "Epoch: 230/500 Iteration: 1149 Training loss: 0.04755\n",
      "Epoch: 229/500 Iteration: 1150 Validation Acc: 0.6667\n",
      "Epoch: 231/500 Iteration: 1150 Training loss: 0.02794\n",
      "Epoch: 231/500 Iteration: 1151 Training loss: 0.01704\n",
      "Epoch: 231/500 Iteration: 1152 Training loss: 0.02404\n",
      "Epoch: 231/500 Iteration: 1153 Training loss: 0.01373\n",
      "Epoch: 231/500 Iteration: 1154 Training loss: 0.05501\n",
      "Epoch: 230/500 Iteration: 1155 Validation Acc: 0.7000\n",
      "Epoch: 232/500 Iteration: 1155 Training loss: 0.03459\n",
      "Epoch: 232/500 Iteration: 1156 Training loss: 0.00589\n",
      "Epoch: 232/500 Iteration: 1157 Training loss: 0.01788\n",
      "Epoch: 232/500 Iteration: 1158 Training loss: 0.00876\n",
      "Epoch: 232/500 Iteration: 1159 Training loss: 0.06850\n",
      "Epoch: 231/500 Iteration: 1160 Validation Acc: 0.7000\n",
      "Epoch: 233/500 Iteration: 1160 Training loss: 0.04119\n",
      "Epoch: 233/500 Iteration: 1161 Training loss: 0.01636\n",
      "Epoch: 233/500 Iteration: 1162 Training loss: 0.01269\n",
      "Epoch: 233/500 Iteration: 1163 Training loss: 0.01770\n",
      "Epoch: 233/500 Iteration: 1164 Training loss: 0.06406\n",
      "Epoch: 232/500 Iteration: 1165 Validation Acc: 0.6667\n",
      "Epoch: 234/500 Iteration: 1165 Training loss: 0.03364\n",
      "Epoch: 234/500 Iteration: 1166 Training loss: 0.02750\n",
      "Epoch: 234/500 Iteration: 1167 Training loss: 0.01399\n",
      "Epoch: 234/500 Iteration: 1168 Training loss: 0.01950\n",
      "Epoch: 234/500 Iteration: 1169 Training loss: 0.05721\n",
      "Epoch: 233/500 Iteration: 1170 Validation Acc: 0.6867\n",
      "Epoch: 235/500 Iteration: 1170 Training loss: 0.03230\n",
      "Epoch: 235/500 Iteration: 1171 Training loss: 0.02544\n",
      "Epoch: 235/500 Iteration: 1172 Training loss: 0.02376\n",
      "Epoch: 235/500 Iteration: 1173 Training loss: 0.01488\n",
      "Epoch: 235/500 Iteration: 1174 Training loss: 0.06774\n",
      "Epoch: 234/500 Iteration: 1175 Validation Acc: 0.6867\n",
      "Epoch: 236/500 Iteration: 1175 Training loss: 0.02864\n",
      "Epoch: 236/500 Iteration: 1176 Training loss: 0.01096\n",
      "Epoch: 236/500 Iteration: 1177 Training loss: 0.02028\n",
      "Epoch: 236/500 Iteration: 1178 Training loss: 0.01012\n",
      "Epoch: 236/500 Iteration: 1179 Training loss: 0.05234\n",
      "Epoch: 235/500 Iteration: 1180 Validation Acc: 0.6733\n",
      "Epoch: 237/500 Iteration: 1180 Training loss: 0.04328\n",
      "Epoch: 237/500 Iteration: 1181 Training loss: 0.01831\n",
      "Epoch: 237/500 Iteration: 1182 Training loss: 0.02108\n",
      "Epoch: 237/500 Iteration: 1183 Training loss: 0.01709\n",
      "Epoch: 237/500 Iteration: 1184 Training loss: 0.07017\n",
      "Epoch: 236/500 Iteration: 1185 Validation Acc: 0.6667\n",
      "Epoch: 238/500 Iteration: 1185 Training loss: 0.02734\n",
      "Epoch: 238/500 Iteration: 1186 Training loss: 0.00826\n",
      "Epoch: 238/500 Iteration: 1187 Training loss: 0.00678\n",
      "Epoch: 238/500 Iteration: 1188 Training loss: 0.01699\n",
      "Epoch: 238/500 Iteration: 1189 Training loss: 0.04503\n",
      "Epoch: 237/500 Iteration: 1190 Validation Acc: 0.6867\n",
      "Epoch: 239/500 Iteration: 1190 Training loss: 0.03800\n",
      "Epoch: 239/500 Iteration: 1191 Training loss: 0.01635\n",
      "Epoch: 239/500 Iteration: 1192 Training loss: 0.01611\n",
      "Epoch: 239/500 Iteration: 1193 Training loss: 0.01284\n",
      "Epoch: 239/500 Iteration: 1194 Training loss: 0.07033\n",
      "Epoch: 238/500 Iteration: 1195 Validation Acc: 0.6800\n",
      "Epoch: 240/500 Iteration: 1195 Training loss: 0.02862\n",
      "Epoch: 240/500 Iteration: 1196 Training loss: 0.00916\n",
      "Epoch: 240/500 Iteration: 1197 Training loss: 0.01939\n",
      "Epoch: 240/500 Iteration: 1198 Training loss: 0.01111\n",
      "Epoch: 240/500 Iteration: 1199 Training loss: 0.04143\n",
      "Epoch: 239/500 Iteration: 1200 Validation Acc: 0.7133\n",
      "Epoch: 241/500 Iteration: 1200 Training loss: 0.03934\n",
      "Epoch: 241/500 Iteration: 1201 Training loss: 0.01518\n",
      "Epoch: 241/500 Iteration: 1202 Training loss: 0.04404\n",
      "Epoch: 241/500 Iteration: 1203 Training loss: 0.01915\n",
      "Epoch: 241/500 Iteration: 1204 Training loss: 0.05414\n",
      "Epoch: 240/500 Iteration: 1205 Validation Acc: 0.6800\n",
      "Epoch: 242/500 Iteration: 1205 Training loss: 0.02931\n",
      "Epoch: 242/500 Iteration: 1206 Training loss: 0.01029\n",
      "Epoch: 242/500 Iteration: 1207 Training loss: 0.00779\n",
      "Epoch: 242/500 Iteration: 1208 Training loss: 0.01071\n",
      "Epoch: 242/500 Iteration: 1209 Training loss: 0.04586\n",
      "Epoch: 241/500 Iteration: 1210 Validation Acc: 0.6733\n",
      "Epoch: 243/500 Iteration: 1210 Training loss: 0.02782\n",
      "Epoch: 243/500 Iteration: 1211 Training loss: 0.00577\n",
      "Epoch: 243/500 Iteration: 1212 Training loss: 0.01570\n",
      "Epoch: 243/500 Iteration: 1213 Training loss: 0.01852\n",
      "Epoch: 243/500 Iteration: 1214 Training loss: 0.03896\n",
      "Epoch: 242/500 Iteration: 1215 Validation Acc: 0.6600\n",
      "Epoch: 244/500 Iteration: 1215 Training loss: 0.03495\n",
      "Epoch: 244/500 Iteration: 1216 Training loss: 0.01576\n",
      "Epoch: 244/500 Iteration: 1217 Training loss: 0.01452\n",
      "Epoch: 244/500 Iteration: 1218 Training loss: 0.01504\n",
      "Epoch: 244/500 Iteration: 1219 Training loss: 0.04452\n",
      "Epoch: 243/500 Iteration: 1220 Validation Acc: 0.6867\n",
      "Epoch: 245/500 Iteration: 1220 Training loss: 0.02937\n",
      "Epoch: 245/500 Iteration: 1221 Training loss: 0.01747\n",
      "Epoch: 245/500 Iteration: 1222 Training loss: 0.00556\n",
      "Epoch: 245/500 Iteration: 1223 Training loss: 0.00806\n",
      "Epoch: 245/500 Iteration: 1224 Training loss: 0.05009\n",
      "Epoch: 244/500 Iteration: 1225 Validation Acc: 0.6533\n",
      "Epoch: 246/500 Iteration: 1225 Training loss: 0.02787\n",
      "Epoch: 246/500 Iteration: 1226 Training loss: 0.02190\n",
      "Epoch: 246/500 Iteration: 1227 Training loss: 0.01653\n",
      "Epoch: 246/500 Iteration: 1228 Training loss: 0.01264\n",
      "Epoch: 246/500 Iteration: 1229 Training loss: 0.04362\n",
      "Epoch: 245/500 Iteration: 1230 Validation Acc: 0.6800\n",
      "Epoch: 247/500 Iteration: 1230 Training loss: 0.05163\n",
      "Epoch: 247/500 Iteration: 1231 Training loss: 0.01312\n",
      "Epoch: 247/500 Iteration: 1232 Training loss: 0.01352\n",
      "Epoch: 247/500 Iteration: 1233 Training loss: 0.01590\n",
      "Epoch: 247/500 Iteration: 1234 Training loss: 0.05300\n",
      "Epoch: 246/500 Iteration: 1235 Validation Acc: 0.6933\n",
      "Epoch: 248/500 Iteration: 1235 Training loss: 0.04170\n",
      "Epoch: 248/500 Iteration: 1236 Training loss: 0.01558\n",
      "Epoch: 248/500 Iteration: 1237 Training loss: 0.01712\n",
      "Epoch: 248/500 Iteration: 1238 Training loss: 0.01437\n",
      "Epoch: 248/500 Iteration: 1239 Training loss: 0.04920\n",
      "Epoch: 247/500 Iteration: 1240 Validation Acc: 0.7000\n",
      "Epoch: 249/500 Iteration: 1240 Training loss: 0.03733\n",
      "Epoch: 249/500 Iteration: 1241 Training loss: 0.01222\n",
      "Epoch: 249/500 Iteration: 1242 Training loss: 0.01733\n",
      "Epoch: 249/500 Iteration: 1243 Training loss: 0.00951\n",
      "Epoch: 249/500 Iteration: 1244 Training loss: 0.03420\n",
      "Epoch: 248/500 Iteration: 1245 Validation Acc: 0.7000\n",
      "Epoch: 250/500 Iteration: 1245 Training loss: 0.02268\n",
      "Epoch: 250/500 Iteration: 1246 Training loss: 0.00838\n",
      "Epoch: 250/500 Iteration: 1247 Training loss: 0.01053\n",
      "Epoch: 250/500 Iteration: 1248 Training loss: 0.00921\n",
      "Epoch: 250/500 Iteration: 1249 Training loss: 0.06482\n",
      "Epoch: 249/500 Iteration: 1250 Validation Acc: 0.6933\n",
      "Epoch: 251/500 Iteration: 1250 Training loss: 0.02689\n",
      "Epoch: 251/500 Iteration: 1251 Training loss: 0.00736\n",
      "Epoch: 251/500 Iteration: 1252 Training loss: 0.01013\n",
      "Epoch: 251/500 Iteration: 1253 Training loss: 0.01564\n",
      "Epoch: 251/500 Iteration: 1254 Training loss: 0.03684\n",
      "Epoch: 250/500 Iteration: 1255 Validation Acc: 0.6733\n",
      "Epoch: 252/500 Iteration: 1255 Training loss: 0.03719\n",
      "Epoch: 252/500 Iteration: 1256 Training loss: 0.00944\n",
      "Epoch: 252/500 Iteration: 1257 Training loss: 0.01576\n",
      "Epoch: 252/500 Iteration: 1258 Training loss: 0.02453\n",
      "Epoch: 252/500 Iteration: 1259 Training loss: 0.03215\n",
      "Epoch: 251/500 Iteration: 1260 Validation Acc: 0.6667\n",
      "Epoch: 253/500 Iteration: 1260 Training loss: 0.02451\n",
      "Epoch: 253/500 Iteration: 1261 Training loss: 0.01305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253/500 Iteration: 1262 Training loss: 0.02212\n",
      "Epoch: 253/500 Iteration: 1263 Training loss: 0.00556\n",
      "Epoch: 253/500 Iteration: 1264 Training loss: 0.07831\n",
      "Epoch: 252/500 Iteration: 1265 Validation Acc: 0.7067\n",
      "Epoch: 254/500 Iteration: 1265 Training loss: 0.03603\n",
      "Epoch: 254/500 Iteration: 1266 Training loss: 0.00580\n",
      "Epoch: 254/500 Iteration: 1267 Training loss: 0.02016\n",
      "Epoch: 254/500 Iteration: 1268 Training loss: 0.00928\n",
      "Epoch: 254/500 Iteration: 1269 Training loss: 0.04322\n",
      "Epoch: 253/500 Iteration: 1270 Validation Acc: 0.6933\n",
      "Epoch: 255/500 Iteration: 1270 Training loss: 0.02926\n",
      "Epoch: 255/500 Iteration: 1271 Training loss: 0.01795\n",
      "Epoch: 255/500 Iteration: 1272 Training loss: 0.03082\n",
      "Epoch: 255/500 Iteration: 1273 Training loss: 0.01272\n",
      "Epoch: 255/500 Iteration: 1274 Training loss: 0.06708\n",
      "Epoch: 254/500 Iteration: 1275 Validation Acc: 0.6800\n",
      "Epoch: 256/500 Iteration: 1275 Training loss: 0.02125\n",
      "Epoch: 256/500 Iteration: 1276 Training loss: 0.00740\n",
      "Epoch: 256/500 Iteration: 1277 Training loss: 0.00835\n",
      "Epoch: 256/500 Iteration: 1278 Training loss: 0.01810\n",
      "Epoch: 256/500 Iteration: 1279 Training loss: 0.07475\n",
      "Epoch: 255/500 Iteration: 1280 Validation Acc: 0.6533\n",
      "Epoch: 257/500 Iteration: 1280 Training loss: 0.02932\n",
      "Epoch: 257/500 Iteration: 1281 Training loss: 0.02235\n",
      "Epoch: 257/500 Iteration: 1282 Training loss: 0.01789\n",
      "Epoch: 257/500 Iteration: 1283 Training loss: 0.01620\n",
      "Epoch: 257/500 Iteration: 1284 Training loss: 0.04277\n",
      "Epoch: 256/500 Iteration: 1285 Validation Acc: 0.7067\n",
      "Epoch: 258/500 Iteration: 1285 Training loss: 0.02837\n",
      "Epoch: 258/500 Iteration: 1286 Training loss: 0.01983\n",
      "Epoch: 258/500 Iteration: 1287 Training loss: 0.01481\n",
      "Epoch: 258/500 Iteration: 1288 Training loss: 0.02148\n",
      "Epoch: 258/500 Iteration: 1289 Training loss: 0.05469\n",
      "Epoch: 257/500 Iteration: 1290 Validation Acc: 0.6533\n",
      "Epoch: 259/500 Iteration: 1290 Training loss: 0.02646\n",
      "Epoch: 259/500 Iteration: 1291 Training loss: 0.01182\n",
      "Epoch: 259/500 Iteration: 1292 Training loss: 0.00712\n",
      "Epoch: 259/500 Iteration: 1293 Training loss: 0.01784\n",
      "Epoch: 259/500 Iteration: 1294 Training loss: 0.06028\n",
      "Epoch: 258/500 Iteration: 1295 Validation Acc: 0.6667\n",
      "Epoch: 260/500 Iteration: 1295 Training loss: 0.03127\n",
      "Epoch: 260/500 Iteration: 1296 Training loss: 0.01985\n",
      "Epoch: 260/500 Iteration: 1297 Training loss: 0.01399\n",
      "Epoch: 260/500 Iteration: 1298 Training loss: 0.01543\n",
      "Epoch: 260/500 Iteration: 1299 Training loss: 0.04547\n",
      "Epoch: 259/500 Iteration: 1300 Validation Acc: 0.6800\n",
      "Epoch: 261/500 Iteration: 1300 Training loss: 0.03606\n",
      "Epoch: 261/500 Iteration: 1301 Training loss: 0.01061\n",
      "Epoch: 261/500 Iteration: 1302 Training loss: 0.02097\n",
      "Epoch: 261/500 Iteration: 1303 Training loss: 0.01359\n",
      "Epoch: 261/500 Iteration: 1304 Training loss: 0.05739\n",
      "Epoch: 260/500 Iteration: 1305 Validation Acc: 0.6867\n",
      "Epoch: 262/500 Iteration: 1305 Training loss: 0.02147\n",
      "Epoch: 262/500 Iteration: 1306 Training loss: 0.00780\n",
      "Epoch: 262/500 Iteration: 1307 Training loss: 0.01138\n",
      "Epoch: 262/500 Iteration: 1308 Training loss: 0.01019\n",
      "Epoch: 262/500 Iteration: 1309 Training loss: 0.04313\n",
      "Epoch: 261/500 Iteration: 1310 Validation Acc: 0.6667\n",
      "Epoch: 263/500 Iteration: 1310 Training loss: 0.03562\n",
      "Epoch: 263/500 Iteration: 1311 Training loss: 0.00988\n",
      "Epoch: 263/500 Iteration: 1312 Training loss: 0.01140\n",
      "Epoch: 263/500 Iteration: 1313 Training loss: 0.01543\n",
      "Epoch: 263/500 Iteration: 1314 Training loss: 0.02998\n",
      "Epoch: 262/500 Iteration: 1315 Validation Acc: 0.7000\n",
      "Epoch: 264/500 Iteration: 1315 Training loss: 0.02863\n",
      "Epoch: 264/500 Iteration: 1316 Training loss: 0.00766\n",
      "Epoch: 264/500 Iteration: 1317 Training loss: 0.01083\n",
      "Epoch: 264/500 Iteration: 1318 Training loss: 0.00564\n",
      "Epoch: 264/500 Iteration: 1319 Training loss: 0.05514\n",
      "Epoch: 263/500 Iteration: 1320 Validation Acc: 0.7067\n",
      "Epoch: 265/500 Iteration: 1320 Training loss: 0.03016\n",
      "Epoch: 265/500 Iteration: 1321 Training loss: 0.01290\n",
      "Epoch: 265/500 Iteration: 1322 Training loss: 0.00706\n",
      "Epoch: 265/500 Iteration: 1323 Training loss: 0.01942\n",
      "Epoch: 265/500 Iteration: 1324 Training loss: 0.05328\n",
      "Epoch: 264/500 Iteration: 1325 Validation Acc: 0.6733\n",
      "Epoch: 266/500 Iteration: 1325 Training loss: 0.03207\n",
      "Epoch: 266/500 Iteration: 1326 Training loss: 0.01445\n",
      "Epoch: 266/500 Iteration: 1327 Training loss: 0.00877\n",
      "Epoch: 266/500 Iteration: 1328 Training loss: 0.01583\n",
      "Epoch: 266/500 Iteration: 1329 Training loss: 0.02715\n",
      "Epoch: 265/500 Iteration: 1330 Validation Acc: 0.6667\n",
      "Epoch: 267/500 Iteration: 1330 Training loss: 0.02875\n",
      "Epoch: 267/500 Iteration: 1331 Training loss: 0.01496\n",
      "Epoch: 267/500 Iteration: 1332 Training loss: 0.01095\n",
      "Epoch: 267/500 Iteration: 1333 Training loss: 0.00853\n",
      "Epoch: 267/500 Iteration: 1334 Training loss: 0.05476\n",
      "Epoch: 266/500 Iteration: 1335 Validation Acc: 0.6733\n",
      "Epoch: 268/500 Iteration: 1335 Training loss: 0.02377\n",
      "Epoch: 268/500 Iteration: 1336 Training loss: 0.01021\n",
      "Epoch: 268/500 Iteration: 1337 Training loss: 0.01234\n",
      "Epoch: 268/500 Iteration: 1338 Training loss: 0.01232\n",
      "Epoch: 268/500 Iteration: 1339 Training loss: 0.03677\n",
      "Epoch: 267/500 Iteration: 1340 Validation Acc: 0.6733\n",
      "Epoch: 269/500 Iteration: 1340 Training loss: 0.04224\n",
      "Epoch: 269/500 Iteration: 1341 Training loss: 0.01075\n",
      "Epoch: 269/500 Iteration: 1342 Training loss: 0.01119\n",
      "Epoch: 269/500 Iteration: 1343 Training loss: 0.00762\n",
      "Epoch: 269/500 Iteration: 1344 Training loss: 0.03840\n",
      "Epoch: 268/500 Iteration: 1345 Validation Acc: 0.6600\n",
      "Epoch: 270/500 Iteration: 1345 Training loss: 0.01277\n",
      "Epoch: 270/500 Iteration: 1346 Training loss: 0.02773\n",
      "Epoch: 270/500 Iteration: 1347 Training loss: 0.01217\n",
      "Epoch: 270/500 Iteration: 1348 Training loss: 0.01708\n",
      "Epoch: 270/500 Iteration: 1349 Training loss: 0.03913\n",
      "Epoch: 269/500 Iteration: 1350 Validation Acc: 0.6867\n",
      "Epoch: 271/500 Iteration: 1350 Training loss: 0.02885\n",
      "Epoch: 271/500 Iteration: 1351 Training loss: 0.01415\n",
      "Epoch: 271/500 Iteration: 1352 Training loss: 0.00804\n",
      "Epoch: 271/500 Iteration: 1353 Training loss: 0.00596\n",
      "Epoch: 271/500 Iteration: 1354 Training loss: 0.02676\n",
      "Epoch: 270/500 Iteration: 1355 Validation Acc: 0.6733\n",
      "Epoch: 272/500 Iteration: 1355 Training loss: 0.02788\n",
      "Epoch: 272/500 Iteration: 1356 Training loss: 0.01403\n",
      "Epoch: 272/500 Iteration: 1357 Training loss: 0.01081\n",
      "Epoch: 272/500 Iteration: 1358 Training loss: 0.01374\n",
      "Epoch: 272/500 Iteration: 1359 Training loss: 0.03291\n",
      "Epoch: 271/500 Iteration: 1360 Validation Acc: 0.7067\n",
      "Epoch: 273/500 Iteration: 1360 Training loss: 0.03035\n",
      "Epoch: 273/500 Iteration: 1361 Training loss: 0.01437\n",
      "Epoch: 273/500 Iteration: 1362 Training loss: 0.01063\n",
      "Epoch: 273/500 Iteration: 1363 Training loss: 0.00644\n",
      "Epoch: 273/500 Iteration: 1364 Training loss: 0.04681\n",
      "Epoch: 272/500 Iteration: 1365 Validation Acc: 0.7333\n",
      "Epoch: 274/500 Iteration: 1365 Training loss: 0.02241\n",
      "Epoch: 274/500 Iteration: 1366 Training loss: 0.02061\n",
      "Epoch: 274/500 Iteration: 1367 Training loss: 0.00870\n",
      "Epoch: 274/500 Iteration: 1368 Training loss: 0.00643\n",
      "Epoch: 274/500 Iteration: 1369 Training loss: 0.02859\n",
      "Epoch: 273/500 Iteration: 1370 Validation Acc: 0.6733\n",
      "Epoch: 275/500 Iteration: 1370 Training loss: 0.02493\n",
      "Epoch: 275/500 Iteration: 1371 Training loss: 0.01250\n",
      "Epoch: 275/500 Iteration: 1372 Training loss: 0.00966\n",
      "Epoch: 275/500 Iteration: 1373 Training loss: 0.00568\n",
      "Epoch: 275/500 Iteration: 1374 Training loss: 0.03037\n",
      "Epoch: 274/500 Iteration: 1375 Validation Acc: 0.6933\n",
      "Epoch: 276/500 Iteration: 1375 Training loss: 0.00974\n",
      "Epoch: 276/500 Iteration: 1376 Training loss: 0.00475\n",
      "Epoch: 276/500 Iteration: 1377 Training loss: 0.01052\n",
      "Epoch: 276/500 Iteration: 1378 Training loss: 0.01094\n",
      "Epoch: 276/500 Iteration: 1379 Training loss: 0.04840\n",
      "Epoch: 275/500 Iteration: 1380 Validation Acc: 0.6800\n",
      "Epoch: 277/500 Iteration: 1380 Training loss: 0.01984\n",
      "Epoch: 277/500 Iteration: 1381 Training loss: 0.00515\n",
      "Epoch: 277/500 Iteration: 1382 Training loss: 0.00514\n",
      "Epoch: 277/500 Iteration: 1383 Training loss: 0.00463\n",
      "Epoch: 277/500 Iteration: 1384 Training loss: 0.04579\n",
      "Epoch: 276/500 Iteration: 1385 Validation Acc: 0.6533\n",
      "Epoch: 278/500 Iteration: 1385 Training loss: 0.01571\n",
      "Epoch: 278/500 Iteration: 1386 Training loss: 0.01167\n",
      "Epoch: 278/500 Iteration: 1387 Training loss: 0.00748\n",
      "Epoch: 278/500 Iteration: 1388 Training loss: 0.01481\n",
      "Epoch: 278/500 Iteration: 1389 Training loss: 0.03026\n",
      "Epoch: 277/500 Iteration: 1390 Validation Acc: 0.6667\n",
      "Epoch: 279/500 Iteration: 1390 Training loss: 0.03071\n",
      "Epoch: 279/500 Iteration: 1391 Training loss: 0.00810\n",
      "Epoch: 279/500 Iteration: 1392 Training loss: 0.01176\n",
      "Epoch: 279/500 Iteration: 1393 Training loss: 0.01244\n",
      "Epoch: 279/500 Iteration: 1394 Training loss: 0.04206\n",
      "Epoch: 278/500 Iteration: 1395 Validation Acc: 0.6867\n",
      "Epoch: 280/500 Iteration: 1395 Training loss: 0.02317\n",
      "Epoch: 280/500 Iteration: 1396 Training loss: 0.01757\n",
      "Epoch: 280/500 Iteration: 1397 Training loss: 0.01142\n",
      "Epoch: 280/500 Iteration: 1398 Training loss: 0.01214\n",
      "Epoch: 280/500 Iteration: 1399 Training loss: 0.03474\n",
      "Epoch: 279/500 Iteration: 1400 Validation Acc: 0.6667\n",
      "Epoch: 281/500 Iteration: 1400 Training loss: 0.02120\n",
      "Epoch: 281/500 Iteration: 1401 Training loss: 0.00698\n",
      "Epoch: 281/500 Iteration: 1402 Training loss: 0.00469\n",
      "Epoch: 281/500 Iteration: 1403 Training loss: 0.01051\n",
      "Epoch: 281/500 Iteration: 1404 Training loss: 0.03628\n",
      "Epoch: 280/500 Iteration: 1405 Validation Acc: 0.6733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 282/500 Iteration: 1405 Training loss: 0.01351\n",
      "Epoch: 282/500 Iteration: 1406 Training loss: 0.00558\n",
      "Epoch: 282/500 Iteration: 1407 Training loss: 0.00927\n",
      "Epoch: 282/500 Iteration: 1408 Training loss: 0.01806\n",
      "Epoch: 282/500 Iteration: 1409 Training loss: 0.02788\n",
      "Epoch: 281/500 Iteration: 1410 Validation Acc: 0.6667\n",
      "Epoch: 283/500 Iteration: 1410 Training loss: 0.01735\n",
      "Epoch: 283/500 Iteration: 1411 Training loss: 0.01687\n",
      "Epoch: 283/500 Iteration: 1412 Training loss: 0.00869\n",
      "Epoch: 283/500 Iteration: 1413 Training loss: 0.00773\n",
      "Epoch: 283/500 Iteration: 1414 Training loss: 0.03590\n",
      "Epoch: 282/500 Iteration: 1415 Validation Acc: 0.6867\n",
      "Epoch: 284/500 Iteration: 1415 Training loss: 0.04353\n",
      "Epoch: 284/500 Iteration: 1416 Training loss: 0.00530\n",
      "Epoch: 284/500 Iteration: 1417 Training loss: 0.01130\n",
      "Epoch: 284/500 Iteration: 1418 Training loss: 0.00702\n",
      "Epoch: 284/500 Iteration: 1419 Training loss: 0.02474\n",
      "Epoch: 283/500 Iteration: 1420 Validation Acc: 0.6867\n",
      "Epoch: 285/500 Iteration: 1420 Training loss: 0.00849\n",
      "Epoch: 285/500 Iteration: 1421 Training loss: 0.00788\n",
      "Epoch: 285/500 Iteration: 1422 Training loss: 0.00551\n",
      "Epoch: 285/500 Iteration: 1423 Training loss: 0.01578\n",
      "Epoch: 285/500 Iteration: 1424 Training loss: 0.03315\n",
      "Epoch: 284/500 Iteration: 1425 Validation Acc: 0.7067\n",
      "Epoch: 286/500 Iteration: 1425 Training loss: 0.02151\n",
      "Epoch: 286/500 Iteration: 1426 Training loss: 0.01011\n",
      "Epoch: 286/500 Iteration: 1427 Training loss: 0.00887\n",
      "Epoch: 286/500 Iteration: 1428 Training loss: 0.00644\n",
      "Epoch: 286/500 Iteration: 1429 Training loss: 0.05010\n",
      "Epoch: 285/500 Iteration: 1430 Validation Acc: 0.7067\n",
      "Epoch: 287/500 Iteration: 1430 Training loss: 0.01594\n",
      "Epoch: 287/500 Iteration: 1431 Training loss: 0.00870\n",
      "Epoch: 287/500 Iteration: 1432 Training loss: 0.01087\n",
      "Epoch: 287/500 Iteration: 1433 Training loss: 0.01622\n",
      "Epoch: 287/500 Iteration: 1434 Training loss: 0.04533\n",
      "Epoch: 286/500 Iteration: 1435 Validation Acc: 0.6933\n",
      "Epoch: 288/500 Iteration: 1435 Training loss: 0.02214\n",
      "Epoch: 288/500 Iteration: 1436 Training loss: 0.00944\n",
      "Epoch: 288/500 Iteration: 1437 Training loss: 0.01461\n",
      "Epoch: 288/500 Iteration: 1438 Training loss: 0.00817\n",
      "Epoch: 288/500 Iteration: 1439 Training loss: 0.03197\n",
      "Epoch: 287/500 Iteration: 1440 Validation Acc: 0.6933\n",
      "Epoch: 289/500 Iteration: 1440 Training loss: 0.04268\n",
      "Epoch: 289/500 Iteration: 1441 Training loss: 0.00945\n",
      "Epoch: 289/500 Iteration: 1442 Training loss: 0.00628\n",
      "Epoch: 289/500 Iteration: 1443 Training loss: 0.00672\n",
      "Epoch: 289/500 Iteration: 1444 Training loss: 0.05131\n",
      "Epoch: 288/500 Iteration: 1445 Validation Acc: 0.6600\n",
      "Epoch: 290/500 Iteration: 1445 Training loss: 0.01742\n",
      "Epoch: 290/500 Iteration: 1446 Training loss: 0.00586\n",
      "Epoch: 290/500 Iteration: 1447 Training loss: 0.01766\n",
      "Epoch: 290/500 Iteration: 1448 Training loss: 0.01189\n",
      "Epoch: 290/500 Iteration: 1449 Training loss: 0.02751\n",
      "Epoch: 289/500 Iteration: 1450 Validation Acc: 0.6400\n",
      "Epoch: 291/500 Iteration: 1450 Training loss: 0.02057\n",
      "Epoch: 291/500 Iteration: 1451 Training loss: 0.00435\n",
      "Epoch: 291/500 Iteration: 1452 Training loss: 0.00927\n",
      "Epoch: 291/500 Iteration: 1453 Training loss: 0.01117\n",
      "Epoch: 291/500 Iteration: 1454 Training loss: 0.06416\n",
      "Epoch: 290/500 Iteration: 1455 Validation Acc: 0.6533\n",
      "Epoch: 292/500 Iteration: 1455 Training loss: 0.01882\n",
      "Epoch: 292/500 Iteration: 1456 Training loss: 0.00460\n",
      "Epoch: 292/500 Iteration: 1457 Training loss: 0.00765\n",
      "Epoch: 292/500 Iteration: 1458 Training loss: 0.00657\n",
      "Epoch: 292/500 Iteration: 1459 Training loss: 0.02560\n",
      "Epoch: 291/500 Iteration: 1460 Validation Acc: 0.6667\n",
      "Epoch: 293/500 Iteration: 1460 Training loss: 0.01484\n",
      "Epoch: 293/500 Iteration: 1461 Training loss: 0.00641\n",
      "Epoch: 293/500 Iteration: 1462 Training loss: 0.00625\n",
      "Epoch: 293/500 Iteration: 1463 Training loss: 0.01185\n",
      "Epoch: 293/500 Iteration: 1464 Training loss: 0.03929\n",
      "Epoch: 292/500 Iteration: 1465 Validation Acc: 0.6600\n",
      "Epoch: 294/500 Iteration: 1465 Training loss: 0.01867\n",
      "Epoch: 294/500 Iteration: 1466 Training loss: 0.00972\n",
      "Epoch: 294/500 Iteration: 1467 Training loss: 0.01187\n",
      "Epoch: 294/500 Iteration: 1468 Training loss: 0.00498\n",
      "Epoch: 294/500 Iteration: 1469 Training loss: 0.04010\n",
      "Epoch: 293/500 Iteration: 1470 Validation Acc: 0.6800\n",
      "Epoch: 295/500 Iteration: 1470 Training loss: 0.02297\n",
      "Epoch: 295/500 Iteration: 1471 Training loss: 0.00576\n",
      "Epoch: 295/500 Iteration: 1472 Training loss: 0.02319\n",
      "Epoch: 295/500 Iteration: 1473 Training loss: 0.01164\n",
      "Epoch: 295/500 Iteration: 1474 Training loss: 0.02374\n",
      "Epoch: 294/500 Iteration: 1475 Validation Acc: 0.6733\n",
      "Epoch: 296/500 Iteration: 1475 Training loss: 0.03210\n",
      "Epoch: 296/500 Iteration: 1476 Training loss: 0.01275\n",
      "Epoch: 296/500 Iteration: 1477 Training loss: 0.00723\n",
      "Epoch: 296/500 Iteration: 1478 Training loss: 0.00750\n",
      "Epoch: 296/500 Iteration: 1479 Training loss: 0.03836\n",
      "Epoch: 295/500 Iteration: 1480 Validation Acc: 0.6800\n",
      "Epoch: 297/500 Iteration: 1480 Training loss: 0.01378\n",
      "Epoch: 297/500 Iteration: 1481 Training loss: 0.01281\n",
      "Epoch: 297/500 Iteration: 1482 Training loss: 0.00476\n",
      "Epoch: 297/500 Iteration: 1483 Training loss: 0.00590\n",
      "Epoch: 297/500 Iteration: 1484 Training loss: 0.04378\n",
      "Epoch: 296/500 Iteration: 1485 Validation Acc: 0.6867\n",
      "Epoch: 298/500 Iteration: 1485 Training loss: 0.01850\n",
      "Epoch: 298/500 Iteration: 1486 Training loss: 0.00965\n",
      "Epoch: 298/500 Iteration: 1487 Training loss: 0.01196\n",
      "Epoch: 298/500 Iteration: 1488 Training loss: 0.01304\n",
      "Epoch: 298/500 Iteration: 1489 Training loss: 0.03543\n",
      "Epoch: 297/500 Iteration: 1490 Validation Acc: 0.6867\n",
      "Epoch: 299/500 Iteration: 1490 Training loss: 0.02357\n",
      "Epoch: 299/500 Iteration: 1491 Training loss: 0.01825\n",
      "Epoch: 299/500 Iteration: 1492 Training loss: 0.00630\n",
      "Epoch: 299/500 Iteration: 1493 Training loss: 0.00857\n",
      "Epoch: 299/500 Iteration: 1494 Training loss: 0.04063\n",
      "Epoch: 298/500 Iteration: 1495 Validation Acc: 0.6733\n",
      "Epoch: 300/500 Iteration: 1495 Training loss: 0.02599\n",
      "Epoch: 300/500 Iteration: 1496 Training loss: 0.00671\n",
      "Epoch: 300/500 Iteration: 1497 Training loss: 0.00367\n",
      "Epoch: 300/500 Iteration: 1498 Training loss: 0.00998\n",
      "Epoch: 300/500 Iteration: 1499 Training loss: 0.02973\n",
      "Epoch: 299/500 Iteration: 1500 Validation Acc: 0.6800\n",
      "Epoch: 301/500 Iteration: 1500 Training loss: 0.02165\n",
      "Epoch: 301/500 Iteration: 1501 Training loss: 0.00893\n",
      "Epoch: 301/500 Iteration: 1502 Training loss: 0.00861\n",
      "Epoch: 301/500 Iteration: 1503 Training loss: 0.01458\n",
      "Epoch: 301/500 Iteration: 1504 Training loss: 0.03903\n",
      "Epoch: 300/500 Iteration: 1505 Validation Acc: 0.6933\n",
      "Epoch: 302/500 Iteration: 1505 Training loss: 0.02688\n",
      "Epoch: 302/500 Iteration: 1506 Training loss: 0.00938\n",
      "Epoch: 302/500 Iteration: 1507 Training loss: 0.01788\n",
      "Epoch: 302/500 Iteration: 1508 Training loss: 0.00856\n",
      "Epoch: 302/500 Iteration: 1509 Training loss: 0.01547\n",
      "Epoch: 301/500 Iteration: 1510 Validation Acc: 0.6867\n",
      "Epoch: 303/500 Iteration: 1510 Training loss: 0.02368\n",
      "Epoch: 303/500 Iteration: 1511 Training loss: 0.00451\n",
      "Epoch: 303/500 Iteration: 1512 Training loss: 0.01004\n",
      "Epoch: 303/500 Iteration: 1513 Training loss: 0.00483\n",
      "Epoch: 303/500 Iteration: 1514 Training loss: 0.05983\n",
      "Epoch: 302/500 Iteration: 1515 Validation Acc: 0.7133\n",
      "Epoch: 304/500 Iteration: 1515 Training loss: 0.01514\n",
      "Epoch: 304/500 Iteration: 1516 Training loss: 0.00787\n",
      "Epoch: 304/500 Iteration: 1517 Training loss: 0.00723\n",
      "Epoch: 304/500 Iteration: 1518 Training loss: 0.01242\n",
      "Epoch: 304/500 Iteration: 1519 Training loss: 0.03432\n",
      "Epoch: 303/500 Iteration: 1520 Validation Acc: 0.6933\n",
      "Epoch: 305/500 Iteration: 1520 Training loss: 0.02190\n",
      "Epoch: 305/500 Iteration: 1521 Training loss: 0.02099\n",
      "Epoch: 305/500 Iteration: 1522 Training loss: 0.00806\n",
      "Epoch: 305/500 Iteration: 1523 Training loss: 0.01254\n",
      "Epoch: 305/500 Iteration: 1524 Training loss: 0.10246\n",
      "Epoch: 304/500 Iteration: 1525 Validation Acc: 0.7067\n",
      "Epoch: 306/500 Iteration: 1525 Training loss: 0.01084\n",
      "Epoch: 306/500 Iteration: 1526 Training loss: 0.01367\n",
      "Epoch: 306/500 Iteration: 1527 Training loss: 0.00774\n",
      "Epoch: 306/500 Iteration: 1528 Training loss: 0.00690\n",
      "Epoch: 306/500 Iteration: 1529 Training loss: 0.01848\n",
      "Epoch: 305/500 Iteration: 1530 Validation Acc: 0.6533\n",
      "Epoch: 307/500 Iteration: 1530 Training loss: 0.05144\n",
      "Epoch: 307/500 Iteration: 1531 Training loss: 0.00719\n",
      "Epoch: 307/500 Iteration: 1532 Training loss: 0.00595\n",
      "Epoch: 307/500 Iteration: 1533 Training loss: 0.01160\n",
      "Epoch: 307/500 Iteration: 1534 Training loss: 0.03699\n",
      "Epoch: 306/500 Iteration: 1535 Validation Acc: 0.7200\n",
      "Epoch: 308/500 Iteration: 1535 Training loss: 0.01953\n",
      "Epoch: 308/500 Iteration: 1536 Training loss: 0.00977\n",
      "Epoch: 308/500 Iteration: 1537 Training loss: 0.01645\n",
      "Epoch: 308/500 Iteration: 1538 Training loss: 0.01358\n",
      "Epoch: 308/500 Iteration: 1539 Training loss: 0.04554\n",
      "Epoch: 307/500 Iteration: 1540 Validation Acc: 0.6800\n",
      "Epoch: 309/500 Iteration: 1540 Training loss: 0.02418\n",
      "Epoch: 309/500 Iteration: 1541 Training loss: 0.00653\n",
      "Epoch: 309/500 Iteration: 1542 Training loss: 0.00879\n",
      "Epoch: 309/500 Iteration: 1543 Training loss: 0.00985\n",
      "Epoch: 309/500 Iteration: 1544 Training loss: 0.04408\n",
      "Epoch: 308/500 Iteration: 1545 Validation Acc: 0.6867\n",
      "Epoch: 310/500 Iteration: 1545 Training loss: 0.01936\n",
      "Epoch: 310/500 Iteration: 1546 Training loss: 0.00611\n",
      "Epoch: 310/500 Iteration: 1547 Training loss: 0.01628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310/500 Iteration: 1548 Training loss: 0.01838\n",
      "Epoch: 310/500 Iteration: 1549 Training loss: 0.02763\n",
      "Epoch: 309/500 Iteration: 1550 Validation Acc: 0.6600\n",
      "Epoch: 311/500 Iteration: 1550 Training loss: 0.02774\n",
      "Epoch: 311/500 Iteration: 1551 Training loss: 0.01066\n",
      "Epoch: 311/500 Iteration: 1552 Training loss: 0.00814\n",
      "Epoch: 311/500 Iteration: 1553 Training loss: 0.00499\n",
      "Epoch: 311/500 Iteration: 1554 Training loss: 0.05136\n",
      "Epoch: 310/500 Iteration: 1555 Validation Acc: 0.6800\n",
      "Epoch: 312/500 Iteration: 1555 Training loss: 0.01146\n",
      "Epoch: 312/500 Iteration: 1556 Training loss: 0.01659\n",
      "Epoch: 312/500 Iteration: 1557 Training loss: 0.01267\n",
      "Epoch: 312/500 Iteration: 1558 Training loss: 0.01188\n",
      "Epoch: 312/500 Iteration: 1559 Training loss: 0.05709\n",
      "Epoch: 311/500 Iteration: 1560 Validation Acc: 0.6867\n",
      "Epoch: 313/500 Iteration: 1560 Training loss: 0.01794\n",
      "Epoch: 313/500 Iteration: 1561 Training loss: 0.00435\n",
      "Epoch: 313/500 Iteration: 1562 Training loss: 0.01092\n",
      "Epoch: 313/500 Iteration: 1563 Training loss: 0.00708\n",
      "Epoch: 313/500 Iteration: 1564 Training loss: 0.03036\n",
      "Epoch: 312/500 Iteration: 1565 Validation Acc: 0.7200\n",
      "Epoch: 314/500 Iteration: 1565 Training loss: 0.01674\n",
      "Epoch: 314/500 Iteration: 1566 Training loss: 0.00973\n",
      "Epoch: 314/500 Iteration: 1567 Training loss: 0.01145\n",
      "Epoch: 314/500 Iteration: 1568 Training loss: 0.00809\n",
      "Epoch: 314/500 Iteration: 1569 Training loss: 0.02419\n",
      "Epoch: 313/500 Iteration: 1570 Validation Acc: 0.6800\n",
      "Epoch: 315/500 Iteration: 1570 Training loss: 0.02176\n",
      "Epoch: 315/500 Iteration: 1571 Training loss: 0.00991\n",
      "Epoch: 315/500 Iteration: 1572 Training loss: 0.00990\n",
      "Epoch: 315/500 Iteration: 1573 Training loss: 0.00734\n",
      "Epoch: 315/500 Iteration: 1574 Training loss: 0.08149\n",
      "Epoch: 314/500 Iteration: 1575 Validation Acc: 0.6667\n",
      "Epoch: 316/500 Iteration: 1575 Training loss: 0.01626\n",
      "Epoch: 316/500 Iteration: 1576 Training loss: 0.00554\n",
      "Epoch: 316/500 Iteration: 1577 Training loss: 0.01970\n",
      "Epoch: 316/500 Iteration: 1578 Training loss: 0.01706\n",
      "Epoch: 316/500 Iteration: 1579 Training loss: 0.02294\n",
      "Epoch: 315/500 Iteration: 1580 Validation Acc: 0.6733\n",
      "Epoch: 317/500 Iteration: 1580 Training loss: 0.04042\n",
      "Epoch: 317/500 Iteration: 1581 Training loss: 0.01956\n",
      "Epoch: 317/500 Iteration: 1582 Training loss: 0.02179\n",
      "Epoch: 317/500 Iteration: 1583 Training loss: 0.01491\n",
      "Epoch: 317/500 Iteration: 1584 Training loss: 0.07156\n",
      "Epoch: 316/500 Iteration: 1585 Validation Acc: 0.6800\n",
      "Epoch: 318/500 Iteration: 1585 Training loss: 0.03919\n",
      "Epoch: 318/500 Iteration: 1586 Training loss: 0.01177\n",
      "Epoch: 318/500 Iteration: 1587 Training loss: 0.01758\n",
      "Epoch: 318/500 Iteration: 1588 Training loss: 0.01401\n",
      "Epoch: 318/500 Iteration: 1589 Training loss: 0.04113\n",
      "Epoch: 317/500 Iteration: 1590 Validation Acc: 0.6733\n",
      "Epoch: 319/500 Iteration: 1590 Training loss: 0.02488\n",
      "Epoch: 319/500 Iteration: 1591 Training loss: 0.01278\n",
      "Epoch: 319/500 Iteration: 1592 Training loss: 0.01111\n",
      "Epoch: 319/500 Iteration: 1593 Training loss: 0.00990\n",
      "Epoch: 319/500 Iteration: 1594 Training loss: 0.06992\n",
      "Epoch: 318/500 Iteration: 1595 Validation Acc: 0.6800\n",
      "Epoch: 320/500 Iteration: 1595 Training loss: 0.02316\n",
      "Epoch: 320/500 Iteration: 1596 Training loss: 0.01029\n",
      "Epoch: 320/500 Iteration: 1597 Training loss: 0.01443\n",
      "Epoch: 320/500 Iteration: 1598 Training loss: 0.00890\n",
      "Epoch: 320/500 Iteration: 1599 Training loss: 0.02828\n",
      "Epoch: 319/500 Iteration: 1600 Validation Acc: 0.6867\n",
      "Epoch: 321/500 Iteration: 1600 Training loss: 0.02839\n",
      "Epoch: 321/500 Iteration: 1601 Training loss: 0.00679\n",
      "Epoch: 321/500 Iteration: 1602 Training loss: 0.00816\n",
      "Epoch: 321/500 Iteration: 1603 Training loss: 0.01195\n",
      "Epoch: 321/500 Iteration: 1604 Training loss: 0.06438\n",
      "Epoch: 320/500 Iteration: 1605 Validation Acc: 0.6867\n",
      "Epoch: 322/500 Iteration: 1605 Training loss: 0.01083\n",
      "Epoch: 322/500 Iteration: 1606 Training loss: 0.02002\n",
      "Epoch: 322/500 Iteration: 1607 Training loss: 0.00905\n",
      "Epoch: 322/500 Iteration: 1608 Training loss: 0.00772\n",
      "Epoch: 322/500 Iteration: 1609 Training loss: 0.02892\n",
      "Epoch: 321/500 Iteration: 1610 Validation Acc: 0.6867\n",
      "Epoch: 323/500 Iteration: 1610 Training loss: 0.03140\n",
      "Epoch: 323/500 Iteration: 1611 Training loss: 0.00942\n",
      "Epoch: 323/500 Iteration: 1612 Training loss: 0.02387\n",
      "Epoch: 323/500 Iteration: 1613 Training loss: 0.01617\n",
      "Epoch: 323/500 Iteration: 1614 Training loss: 0.04131\n",
      "Epoch: 322/500 Iteration: 1615 Validation Acc: 0.6800\n",
      "Epoch: 324/500 Iteration: 1615 Training loss: 0.01176\n",
      "Epoch: 324/500 Iteration: 1616 Training loss: 0.01577\n",
      "Epoch: 324/500 Iteration: 1617 Training loss: 0.00672\n",
      "Epoch: 324/500 Iteration: 1618 Training loss: 0.00818\n",
      "Epoch: 324/500 Iteration: 1619 Training loss: 0.07804\n",
      "Epoch: 323/500 Iteration: 1620 Validation Acc: 0.7200\n",
      "Epoch: 325/500 Iteration: 1620 Training loss: 0.02655\n",
      "Epoch: 325/500 Iteration: 1621 Training loss: 0.01309\n",
      "Epoch: 325/500 Iteration: 1622 Training loss: 0.01337\n",
      "Epoch: 325/500 Iteration: 1623 Training loss: 0.01914\n",
      "Epoch: 325/500 Iteration: 1624 Training loss: 0.03500\n",
      "Epoch: 324/500 Iteration: 1625 Validation Acc: 0.7000\n",
      "Epoch: 326/500 Iteration: 1625 Training loss: 0.01810\n",
      "Epoch: 326/500 Iteration: 1626 Training loss: 0.01368\n",
      "Epoch: 326/500 Iteration: 1627 Training loss: 0.00613\n",
      "Epoch: 326/500 Iteration: 1628 Training loss: 0.01188\n",
      "Epoch: 326/500 Iteration: 1629 Training loss: 0.05134\n",
      "Epoch: 325/500 Iteration: 1630 Validation Acc: 0.7067\n",
      "Epoch: 327/500 Iteration: 1630 Training loss: 0.02593\n",
      "Epoch: 327/500 Iteration: 1631 Training loss: 0.01459\n",
      "Epoch: 327/500 Iteration: 1632 Training loss: 0.02050\n",
      "Epoch: 327/500 Iteration: 1633 Training loss: 0.00712\n",
      "Epoch: 327/500 Iteration: 1634 Training loss: 0.04156\n",
      "Epoch: 326/500 Iteration: 1635 Validation Acc: 0.6533\n",
      "Epoch: 328/500 Iteration: 1635 Training loss: 0.01651\n",
      "Epoch: 328/500 Iteration: 1636 Training loss: 0.01056\n",
      "Epoch: 328/500 Iteration: 1637 Training loss: 0.01592\n",
      "Epoch: 328/500 Iteration: 1638 Training loss: 0.00455\n",
      "Epoch: 328/500 Iteration: 1639 Training loss: 0.03901\n",
      "Epoch: 327/500 Iteration: 1640 Validation Acc: 0.7200\n",
      "Epoch: 329/500 Iteration: 1640 Training loss: 0.00976\n",
      "Epoch: 329/500 Iteration: 1641 Training loss: 0.00583\n",
      "Epoch: 329/500 Iteration: 1642 Training loss: 0.01133\n",
      "Epoch: 329/500 Iteration: 1643 Training loss: 0.01221\n",
      "Epoch: 329/500 Iteration: 1644 Training loss: 0.04949\n",
      "Epoch: 328/500 Iteration: 1645 Validation Acc: 0.7400\n",
      "Epoch: 330/500 Iteration: 1645 Training loss: 0.01489\n",
      "Epoch: 330/500 Iteration: 1646 Training loss: 0.01380\n",
      "Epoch: 330/500 Iteration: 1647 Training loss: 0.02794\n",
      "Epoch: 330/500 Iteration: 1648 Training loss: 0.01001\n",
      "Epoch: 330/500 Iteration: 1649 Training loss: 0.05976\n",
      "Epoch: 329/500 Iteration: 1650 Validation Acc: 0.7333\n",
      "Epoch: 331/500 Iteration: 1650 Training loss: 0.03071\n",
      "Epoch: 331/500 Iteration: 1651 Training loss: 0.02654\n",
      "Epoch: 331/500 Iteration: 1652 Training loss: 0.00299\n",
      "Epoch: 331/500 Iteration: 1653 Training loss: 0.00675\n",
      "Epoch: 331/500 Iteration: 1654 Training loss: 0.04910\n",
      "Epoch: 330/500 Iteration: 1655 Validation Acc: 0.6867\n",
      "Epoch: 332/500 Iteration: 1655 Training loss: 0.03078\n",
      "Epoch: 332/500 Iteration: 1656 Training loss: 0.00784\n",
      "Epoch: 332/500 Iteration: 1657 Training loss: 0.01241\n",
      "Epoch: 332/500 Iteration: 1658 Training loss: 0.01198\n",
      "Epoch: 332/500 Iteration: 1659 Training loss: 0.02568\n",
      "Epoch: 331/500 Iteration: 1660 Validation Acc: 0.6667\n",
      "Epoch: 333/500 Iteration: 1660 Training loss: 0.03032\n",
      "Epoch: 333/500 Iteration: 1661 Training loss: 0.01644\n",
      "Epoch: 333/500 Iteration: 1662 Training loss: 0.02000\n",
      "Epoch: 333/500 Iteration: 1663 Training loss: 0.01011\n",
      "Epoch: 333/500 Iteration: 1664 Training loss: 0.04989\n",
      "Epoch: 332/500 Iteration: 1665 Validation Acc: 0.7000\n",
      "Epoch: 334/500 Iteration: 1665 Training loss: 0.03296\n",
      "Epoch: 334/500 Iteration: 1666 Training loss: 0.00920\n",
      "Epoch: 334/500 Iteration: 1667 Training loss: 0.00686\n",
      "Epoch: 334/500 Iteration: 1668 Training loss: 0.00507\n",
      "Epoch: 334/500 Iteration: 1669 Training loss: 0.05742\n",
      "Epoch: 333/500 Iteration: 1670 Validation Acc: 0.6667\n",
      "Epoch: 335/500 Iteration: 1670 Training loss: 0.03429\n",
      "Epoch: 335/500 Iteration: 1671 Training loss: 0.00692\n",
      "Epoch: 335/500 Iteration: 1672 Training loss: 0.01504\n",
      "Epoch: 335/500 Iteration: 1673 Training loss: 0.00560\n",
      "Epoch: 335/500 Iteration: 1674 Training loss: 0.01896\n",
      "Epoch: 334/500 Iteration: 1675 Validation Acc: 0.6533\n",
      "Epoch: 336/500 Iteration: 1675 Training loss: 0.01944\n",
      "Epoch: 336/500 Iteration: 1676 Training loss: 0.01684\n",
      "Epoch: 336/500 Iteration: 1677 Training loss: 0.00924\n",
      "Epoch: 336/500 Iteration: 1678 Training loss: 0.00649\n",
      "Epoch: 336/500 Iteration: 1679 Training loss: 0.03881\n",
      "Epoch: 335/500 Iteration: 1680 Validation Acc: 0.6800\n",
      "Epoch: 337/500 Iteration: 1680 Training loss: 0.01312\n",
      "Epoch: 337/500 Iteration: 1681 Training loss: 0.01153\n",
      "Epoch: 337/500 Iteration: 1682 Training loss: 0.01200\n",
      "Epoch: 337/500 Iteration: 1683 Training loss: 0.00507\n",
      "Epoch: 337/500 Iteration: 1684 Training loss: 0.08950\n",
      "Epoch: 336/500 Iteration: 1685 Validation Acc: 0.6800\n",
      "Epoch: 338/500 Iteration: 1685 Training loss: 0.01606\n",
      "Epoch: 338/500 Iteration: 1686 Training loss: 0.01187\n",
      "Epoch: 338/500 Iteration: 1687 Training loss: 0.01183\n",
      "Epoch: 338/500 Iteration: 1688 Training loss: 0.01339\n",
      "Epoch: 338/500 Iteration: 1689 Training loss: 0.02694\n",
      "Epoch: 337/500 Iteration: 1690 Validation Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/500 Iteration: 1690 Training loss: 0.02262\n",
      "Epoch: 339/500 Iteration: 1691 Training loss: 0.01698\n",
      "Epoch: 339/500 Iteration: 1692 Training loss: 0.00576\n",
      "Epoch: 339/500 Iteration: 1693 Training loss: 0.01144\n",
      "Epoch: 339/500 Iteration: 1694 Training loss: 0.08748\n",
      "Epoch: 338/500 Iteration: 1695 Validation Acc: 0.6533\n",
      "Epoch: 340/500 Iteration: 1695 Training loss: 0.02762\n",
      "Epoch: 340/500 Iteration: 1696 Training loss: 0.01305\n",
      "Epoch: 340/500 Iteration: 1697 Training loss: 0.02481\n",
      "Epoch: 340/500 Iteration: 1698 Training loss: 0.00913\n",
      "Epoch: 340/500 Iteration: 1699 Training loss: 0.03745\n",
      "Epoch: 339/500 Iteration: 1700 Validation Acc: 0.6667\n",
      "Epoch: 341/500 Iteration: 1700 Training loss: 0.01912\n",
      "Epoch: 341/500 Iteration: 1701 Training loss: 0.01784\n",
      "Epoch: 341/500 Iteration: 1702 Training loss: 0.03386\n",
      "Epoch: 341/500 Iteration: 1703 Training loss: 0.00868\n",
      "Epoch: 341/500 Iteration: 1704 Training loss: 0.05188\n",
      "Epoch: 340/500 Iteration: 1705 Validation Acc: 0.6600\n",
      "Epoch: 342/500 Iteration: 1705 Training loss: 0.06074\n",
      "Epoch: 342/500 Iteration: 1706 Training loss: 0.00758\n",
      "Epoch: 342/500 Iteration: 1707 Training loss: 0.00731\n",
      "Epoch: 342/500 Iteration: 1708 Training loss: 0.01477\n",
      "Epoch: 342/500 Iteration: 1709 Training loss: 0.02561\n",
      "Epoch: 341/500 Iteration: 1710 Validation Acc: 0.6733\n",
      "Epoch: 343/500 Iteration: 1710 Training loss: 0.01848\n",
      "Epoch: 343/500 Iteration: 1711 Training loss: 0.01914\n",
      "Epoch: 343/500 Iteration: 1712 Training loss: 0.01378\n",
      "Epoch: 343/500 Iteration: 1713 Training loss: 0.02052\n",
      "Epoch: 343/500 Iteration: 1714 Training loss: 0.07665\n",
      "Epoch: 342/500 Iteration: 1715 Validation Acc: 0.6733\n",
      "Epoch: 344/500 Iteration: 1715 Training loss: 0.04202\n",
      "Epoch: 344/500 Iteration: 1716 Training loss: 0.02902\n",
      "Epoch: 344/500 Iteration: 1717 Training loss: 0.02107\n",
      "Epoch: 344/500 Iteration: 1718 Training loss: 0.01398\n",
      "Epoch: 344/500 Iteration: 1719 Training loss: 0.03376\n",
      "Epoch: 343/500 Iteration: 1720 Validation Acc: 0.6733\n",
      "Epoch: 345/500 Iteration: 1720 Training loss: 0.03239\n",
      "Epoch: 345/500 Iteration: 1721 Training loss: 0.00768\n",
      "Epoch: 345/500 Iteration: 1722 Training loss: 0.01805\n",
      "Epoch: 345/500 Iteration: 1723 Training loss: 0.01867\n",
      "Epoch: 345/500 Iteration: 1724 Training loss: 0.09564\n",
      "Epoch: 344/500 Iteration: 1725 Validation Acc: 0.6933\n",
      "Epoch: 346/500 Iteration: 1725 Training loss: 0.02840\n",
      "Epoch: 346/500 Iteration: 1726 Training loss: 0.01984\n",
      "Epoch: 346/500 Iteration: 1727 Training loss: 0.01290\n",
      "Epoch: 346/500 Iteration: 1728 Training loss: 0.04136\n",
      "Epoch: 346/500 Iteration: 1729 Training loss: 0.02855\n",
      "Epoch: 345/500 Iteration: 1730 Validation Acc: 0.6533\n",
      "Epoch: 347/500 Iteration: 1730 Training loss: 0.03350\n",
      "Epoch: 347/500 Iteration: 1731 Training loss: 0.01854\n",
      "Epoch: 347/500 Iteration: 1732 Training loss: 0.01466\n",
      "Epoch: 347/500 Iteration: 1733 Training loss: 0.00772\n",
      "Epoch: 347/500 Iteration: 1734 Training loss: 0.11795\n",
      "Epoch: 346/500 Iteration: 1735 Validation Acc: 0.6667\n",
      "Epoch: 348/500 Iteration: 1735 Training loss: 0.02459\n",
      "Epoch: 348/500 Iteration: 1736 Training loss: 0.01625\n",
      "Epoch: 348/500 Iteration: 1737 Training loss: 0.01923\n",
      "Epoch: 348/500 Iteration: 1738 Training loss: 0.05966\n",
      "Epoch: 348/500 Iteration: 1739 Training loss: 0.04034\n",
      "Epoch: 347/500 Iteration: 1740 Validation Acc: 0.6667\n",
      "Epoch: 349/500 Iteration: 1740 Training loss: 0.03609\n",
      "Epoch: 349/500 Iteration: 1741 Training loss: 0.02831\n",
      "Epoch: 349/500 Iteration: 1742 Training loss: 0.00698\n",
      "Epoch: 349/500 Iteration: 1743 Training loss: 0.01049\n",
      "Epoch: 349/500 Iteration: 1744 Training loss: 0.11297\n",
      "Epoch: 348/500 Iteration: 1745 Validation Acc: 0.6667\n",
      "Epoch: 350/500 Iteration: 1745 Training loss: 0.03878\n",
      "Epoch: 350/500 Iteration: 1746 Training loss: 0.01355\n",
      "Epoch: 350/500 Iteration: 1747 Training loss: 0.03051\n",
      "Epoch: 350/500 Iteration: 1748 Training loss: 0.04491\n",
      "Epoch: 350/500 Iteration: 1749 Training loss: 0.04481\n",
      "Epoch: 349/500 Iteration: 1750 Validation Acc: 0.6733\n",
      "Epoch: 351/500 Iteration: 1750 Training loss: 0.05228\n",
      "Epoch: 351/500 Iteration: 1751 Training loss: 0.02846\n",
      "Epoch: 351/500 Iteration: 1752 Training loss: 0.01193\n",
      "Epoch: 351/500 Iteration: 1753 Training loss: 0.00972\n",
      "Epoch: 351/500 Iteration: 1754 Training loss: 0.10368\n",
      "Epoch: 350/500 Iteration: 1755 Validation Acc: 0.6267\n",
      "Epoch: 352/500 Iteration: 1755 Training loss: 0.05161\n",
      "Epoch: 352/500 Iteration: 1756 Training loss: 0.04489\n",
      "Epoch: 352/500 Iteration: 1757 Training loss: 0.05738\n",
      "Epoch: 352/500 Iteration: 1758 Training loss: 0.03940\n",
      "Epoch: 352/500 Iteration: 1759 Training loss: 0.05142\n",
      "Epoch: 351/500 Iteration: 1760 Validation Acc: 0.6200\n",
      "Epoch: 353/500 Iteration: 1760 Training loss: 0.02522\n",
      "Epoch: 353/500 Iteration: 1761 Training loss: 0.02094\n",
      "Epoch: 353/500 Iteration: 1762 Training loss: 0.01920\n",
      "Epoch: 353/500 Iteration: 1763 Training loss: 0.01680\n",
      "Epoch: 353/500 Iteration: 1764 Training loss: 0.26372\n",
      "Epoch: 352/500 Iteration: 1765 Validation Acc: 0.6933\n",
      "Epoch: 354/500 Iteration: 1765 Training loss: 0.11166\n",
      "Epoch: 354/500 Iteration: 1766 Training loss: 0.11860\n",
      "Epoch: 354/500 Iteration: 1767 Training loss: 0.11847\n",
      "Epoch: 354/500 Iteration: 1768 Training loss: 0.03405\n",
      "Epoch: 354/500 Iteration: 1769 Training loss: 0.24825\n",
      "Epoch: 353/500 Iteration: 1770 Validation Acc: 0.6733\n",
      "Epoch: 355/500 Iteration: 1770 Training loss: 0.02816\n",
      "Epoch: 355/500 Iteration: 1771 Training loss: 0.04732\n",
      "Epoch: 355/500 Iteration: 1772 Training loss: 0.04070\n",
      "Epoch: 355/500 Iteration: 1773 Training loss: 0.02830\n",
      "Epoch: 355/500 Iteration: 1774 Training loss: 0.12245\n",
      "Epoch: 354/500 Iteration: 1775 Validation Acc: 0.6533\n",
      "Epoch: 356/500 Iteration: 1775 Training loss: 0.10735\n",
      "Epoch: 356/500 Iteration: 1776 Training loss: 0.07518\n",
      "Epoch: 356/500 Iteration: 1777 Training loss: 0.05544\n",
      "Epoch: 356/500 Iteration: 1778 Training loss: 0.06741\n",
      "Epoch: 356/500 Iteration: 1779 Training loss: 0.20782\n",
      "Epoch: 355/500 Iteration: 1780 Validation Acc: 0.7067\n",
      "Epoch: 357/500 Iteration: 1780 Training loss: 0.05180\n",
      "Epoch: 357/500 Iteration: 1781 Training loss: 0.04464\n",
      "Epoch: 357/500 Iteration: 1782 Training loss: 0.04955\n",
      "Epoch: 357/500 Iteration: 1783 Training loss: 0.03134\n",
      "Epoch: 357/500 Iteration: 1784 Training loss: 0.35805\n",
      "Epoch: 356/500 Iteration: 1785 Validation Acc: 0.6600\n",
      "Epoch: 358/500 Iteration: 1785 Training loss: 0.19425\n",
      "Epoch: 358/500 Iteration: 1786 Training loss: 0.12688\n",
      "Epoch: 358/500 Iteration: 1787 Training loss: 0.12323\n",
      "Epoch: 358/500 Iteration: 1788 Training loss: 0.07958\n",
      "Epoch: 358/500 Iteration: 1789 Training loss: 0.49898\n",
      "Epoch: 357/500 Iteration: 1790 Validation Acc: 0.7133\n",
      "Epoch: 359/500 Iteration: 1790 Training loss: 0.06525\n",
      "Epoch: 359/500 Iteration: 1791 Training loss: 0.18640\n",
      "Epoch: 359/500 Iteration: 1792 Training loss: 0.08641\n",
      "Epoch: 359/500 Iteration: 1793 Training loss: 0.03751\n",
      "Epoch: 359/500 Iteration: 1794 Training loss: 0.63431\n",
      "Epoch: 358/500 Iteration: 1795 Validation Acc: 0.6400\n",
      "Epoch: 360/500 Iteration: 1795 Training loss: 0.25406\n",
      "Epoch: 360/500 Iteration: 1796 Training loss: 0.35354\n",
      "Epoch: 360/500 Iteration: 1797 Training loss: 0.22158\n",
      "Epoch: 360/500 Iteration: 1798 Training loss: 0.14593\n",
      "Epoch: 360/500 Iteration: 1799 Training loss: 0.74618\n",
      "Epoch: 359/500 Iteration: 1800 Validation Acc: 0.6733\n",
      "Epoch: 361/500 Iteration: 1800 Training loss: 0.32079\n",
      "Epoch: 361/500 Iteration: 1801 Training loss: 0.31286\n",
      "Epoch: 361/500 Iteration: 1802 Training loss: 0.19633\n",
      "Epoch: 361/500 Iteration: 1803 Training loss: 0.07994\n",
      "Epoch: 361/500 Iteration: 1804 Training loss: 1.66011\n",
      "Epoch: 360/500 Iteration: 1805 Validation Acc: 0.6667\n",
      "Epoch: 362/500 Iteration: 1805 Training loss: 0.32482\n",
      "Epoch: 362/500 Iteration: 1806 Training loss: 1.53584\n",
      "Epoch: 362/500 Iteration: 1807 Training loss: 0.30196\n",
      "Epoch: 362/500 Iteration: 1808 Training loss: 0.20444\n",
      "Epoch: 362/500 Iteration: 1809 Training loss: 2.43451\n",
      "Epoch: 361/500 Iteration: 1810 Validation Acc: 0.5800\n",
      "Epoch: 363/500 Iteration: 1810 Training loss: 1.25201\n",
      "Epoch: 363/500 Iteration: 1811 Training loss: 1.04285\n",
      "Epoch: 363/500 Iteration: 1812 Training loss: 0.60172\n",
      "Epoch: 363/500 Iteration: 1813 Training loss: 0.36235\n",
      "Epoch: 363/500 Iteration: 1814 Training loss: 1.51522\n",
      "Epoch: 362/500 Iteration: 1815 Validation Acc: 0.5867\n",
      "Epoch: 364/500 Iteration: 1815 Training loss: 1.22606\n",
      "Epoch: 364/500 Iteration: 1816 Training loss: 0.40616\n",
      "Epoch: 364/500 Iteration: 1817 Training loss: 0.62482\n",
      "Epoch: 364/500 Iteration: 1818 Training loss: 0.46601\n",
      "Epoch: 364/500 Iteration: 1819 Training loss: 0.87884\n",
      "Epoch: 363/500 Iteration: 1820 Validation Acc: 0.5933\n",
      "Epoch: 365/500 Iteration: 1820 Training loss: 0.65126\n",
      "Epoch: 365/500 Iteration: 1821 Training loss: 0.41883\n",
      "Epoch: 365/500 Iteration: 1822 Training loss: 0.40119\n",
      "Epoch: 365/500 Iteration: 1823 Training loss: 0.37278\n",
      "Epoch: 365/500 Iteration: 1824 Training loss: 0.86097\n",
      "Epoch: 364/500 Iteration: 1825 Validation Acc: 0.6000\n",
      "Epoch: 366/500 Iteration: 1825 Training loss: 0.37835\n",
      "Epoch: 366/500 Iteration: 1826 Training loss: 0.32015\n",
      "Epoch: 366/500 Iteration: 1827 Training loss: 0.23897\n",
      "Epoch: 366/500 Iteration: 1828 Training loss: 0.16744\n",
      "Epoch: 366/500 Iteration: 1829 Training loss: 0.79908\n",
      "Epoch: 365/500 Iteration: 1830 Validation Acc: 0.6267\n",
      "Epoch: 367/500 Iteration: 1830 Training loss: 0.51366\n",
      "Epoch: 367/500 Iteration: 1831 Training loss: 0.24490\n",
      "Epoch: 367/500 Iteration: 1832 Training loss: 0.31538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 367/500 Iteration: 1833 Training loss: 0.26182\n",
      "Epoch: 367/500 Iteration: 1834 Training loss: 0.81790\n",
      "Epoch: 366/500 Iteration: 1835 Validation Acc: 0.6267\n",
      "Epoch: 368/500 Iteration: 1835 Training loss: 0.41805\n",
      "Epoch: 368/500 Iteration: 1836 Training loss: 0.23339\n",
      "Epoch: 368/500 Iteration: 1837 Training loss: 0.28184\n",
      "Epoch: 368/500 Iteration: 1838 Training loss: 0.22595\n",
      "Epoch: 368/500 Iteration: 1839 Training loss: 0.45699\n",
      "Epoch: 367/500 Iteration: 1840 Validation Acc: 0.6467\n",
      "Epoch: 369/500 Iteration: 1840 Training loss: 0.34996\n",
      "Epoch: 369/500 Iteration: 1841 Training loss: 0.18486\n",
      "Epoch: 369/500 Iteration: 1842 Training loss: 0.20129\n",
      "Epoch: 369/500 Iteration: 1843 Training loss: 0.16447\n",
      "Epoch: 369/500 Iteration: 1844 Training loss: 0.58118\n",
      "Epoch: 368/500 Iteration: 1845 Validation Acc: 0.6733\n",
      "Epoch: 370/500 Iteration: 1845 Training loss: 0.36183\n",
      "Epoch: 370/500 Iteration: 1846 Training loss: 0.18518\n",
      "Epoch: 370/500 Iteration: 1847 Training loss: 0.23303\n",
      "Epoch: 370/500 Iteration: 1848 Training loss: 0.23536\n",
      "Epoch: 370/500 Iteration: 1849 Training loss: 0.45727\n",
      "Epoch: 369/500 Iteration: 1850 Validation Acc: 0.6800\n",
      "Epoch: 371/500 Iteration: 1850 Training loss: 0.34349\n",
      "Epoch: 371/500 Iteration: 1851 Training loss: 0.16383\n",
      "Epoch: 371/500 Iteration: 1852 Training loss: 0.17274\n",
      "Epoch: 371/500 Iteration: 1853 Training loss: 0.14524\n",
      "Epoch: 371/500 Iteration: 1854 Training loss: 0.56118\n",
      "Epoch: 370/500 Iteration: 1855 Validation Acc: 0.6867\n",
      "Epoch: 372/500 Iteration: 1855 Training loss: 0.28827\n",
      "Epoch: 372/500 Iteration: 1856 Training loss: 0.20526\n",
      "Epoch: 372/500 Iteration: 1857 Training loss: 0.25632\n",
      "Epoch: 372/500 Iteration: 1858 Training loss: 0.22246\n",
      "Epoch: 372/500 Iteration: 1859 Training loss: 0.27984\n",
      "Epoch: 371/500 Iteration: 1860 Validation Acc: 0.6000\n",
      "Epoch: 373/500 Iteration: 1860 Training loss: 0.31093\n",
      "Epoch: 373/500 Iteration: 1861 Training loss: 0.10208\n",
      "Epoch: 373/500 Iteration: 1862 Training loss: 0.12309\n",
      "Epoch: 373/500 Iteration: 1863 Training loss: 0.10932\n",
      "Epoch: 373/500 Iteration: 1864 Training loss: 0.58700\n",
      "Epoch: 372/500 Iteration: 1865 Validation Acc: 0.6733\n",
      "Epoch: 374/500 Iteration: 1865 Training loss: 0.20609\n",
      "Epoch: 374/500 Iteration: 1866 Training loss: 0.13431\n",
      "Epoch: 374/500 Iteration: 1867 Training loss: 0.18396\n",
      "Epoch: 374/500 Iteration: 1868 Training loss: 0.21382\n",
      "Epoch: 374/500 Iteration: 1869 Training loss: 0.25923\n",
      "Epoch: 373/500 Iteration: 1870 Validation Acc: 0.6600\n",
      "Epoch: 375/500 Iteration: 1870 Training loss: 0.26130\n",
      "Epoch: 375/500 Iteration: 1871 Training loss: 0.13937\n",
      "Epoch: 375/500 Iteration: 1872 Training loss: 0.11023\n",
      "Epoch: 375/500 Iteration: 1873 Training loss: 0.09434\n",
      "Epoch: 375/500 Iteration: 1874 Training loss: 0.52893\n",
      "Epoch: 374/500 Iteration: 1875 Validation Acc: 0.6533\n",
      "Epoch: 376/500 Iteration: 1875 Training loss: 0.28076\n",
      "Epoch: 376/500 Iteration: 1876 Training loss: 0.12766\n",
      "Epoch: 376/500 Iteration: 1877 Training loss: 0.19976\n",
      "Epoch: 376/500 Iteration: 1878 Training loss: 0.17062\n",
      "Epoch: 376/500 Iteration: 1879 Training loss: 0.28101\n",
      "Epoch: 375/500 Iteration: 1880 Validation Acc: 0.6867\n",
      "Epoch: 377/500 Iteration: 1880 Training loss: 0.20706\n",
      "Epoch: 377/500 Iteration: 1881 Training loss: 0.13232\n",
      "Epoch: 377/500 Iteration: 1882 Training loss: 0.14495\n",
      "Epoch: 377/500 Iteration: 1883 Training loss: 0.13101\n",
      "Epoch: 377/500 Iteration: 1884 Training loss: 0.51282\n",
      "Epoch: 376/500 Iteration: 1885 Validation Acc: 0.6467\n",
      "Epoch: 378/500 Iteration: 1885 Training loss: 0.35078\n",
      "Epoch: 378/500 Iteration: 1886 Training loss: 0.12259\n",
      "Epoch: 378/500 Iteration: 1887 Training loss: 0.17233\n",
      "Epoch: 378/500 Iteration: 1888 Training loss: 0.18202\n",
      "Epoch: 378/500 Iteration: 1889 Training loss: 0.32017\n",
      "Epoch: 377/500 Iteration: 1890 Validation Acc: 0.6733\n",
      "Epoch: 379/500 Iteration: 1890 Training loss: 0.22615\n",
      "Epoch: 379/500 Iteration: 1891 Training loss: 0.15425\n",
      "Epoch: 379/500 Iteration: 1892 Training loss: 0.15074\n",
      "Epoch: 379/500 Iteration: 1893 Training loss: 0.11687\n",
      "Epoch: 379/500 Iteration: 1894 Training loss: 0.44389\n",
      "Epoch: 378/500 Iteration: 1895 Validation Acc: 0.6800\n",
      "Epoch: 380/500 Iteration: 1895 Training loss: 0.31375\n",
      "Epoch: 380/500 Iteration: 1896 Training loss: 0.11201\n",
      "Epoch: 380/500 Iteration: 1897 Training loss: 0.14665\n",
      "Epoch: 380/500 Iteration: 1898 Training loss: 0.18424\n",
      "Epoch: 380/500 Iteration: 1899 Training loss: 0.23001\n",
      "Epoch: 379/500 Iteration: 1900 Validation Acc: 0.6600\n",
      "Epoch: 381/500 Iteration: 1900 Training loss: 0.24709\n",
      "Epoch: 381/500 Iteration: 1901 Training loss: 0.15386\n",
      "Epoch: 381/500 Iteration: 1902 Training loss: 0.13512\n",
      "Epoch: 381/500 Iteration: 1903 Training loss: 0.09438\n",
      "Epoch: 381/500 Iteration: 1904 Training loss: 0.38897\n",
      "Epoch: 380/500 Iteration: 1905 Validation Acc: 0.6800\n",
      "Epoch: 382/500 Iteration: 1905 Training loss: 0.24373\n",
      "Epoch: 382/500 Iteration: 1906 Training loss: 0.11058\n",
      "Epoch: 382/500 Iteration: 1907 Training loss: 0.09689\n",
      "Epoch: 382/500 Iteration: 1908 Training loss: 0.11089\n",
      "Epoch: 382/500 Iteration: 1909 Training loss: 0.23220\n",
      "Epoch: 381/500 Iteration: 1910 Validation Acc: 0.6733\n",
      "Epoch: 383/500 Iteration: 1910 Training loss: 0.24193\n",
      "Epoch: 383/500 Iteration: 1911 Training loss: 0.10771\n",
      "Epoch: 383/500 Iteration: 1912 Training loss: 0.10113\n",
      "Epoch: 383/500 Iteration: 1913 Training loss: 0.10363\n",
      "Epoch: 383/500 Iteration: 1914 Training loss: 0.32500\n",
      "Epoch: 382/500 Iteration: 1915 Validation Acc: 0.6800\n",
      "Epoch: 384/500 Iteration: 1915 Training loss: 0.24089\n",
      "Epoch: 384/500 Iteration: 1916 Training loss: 0.11442\n",
      "Epoch: 384/500 Iteration: 1917 Training loss: 0.12394\n",
      "Epoch: 384/500 Iteration: 1918 Training loss: 0.12624\n",
      "Epoch: 384/500 Iteration: 1919 Training loss: 0.31321\n",
      "Epoch: 383/500 Iteration: 1920 Validation Acc: 0.7133\n",
      "Epoch: 385/500 Iteration: 1920 Training loss: 0.16782\n",
      "Epoch: 385/500 Iteration: 1921 Training loss: 0.08279\n",
      "Epoch: 385/500 Iteration: 1922 Training loss: 0.09508\n",
      "Epoch: 385/500 Iteration: 1923 Training loss: 0.11223\n",
      "Epoch: 385/500 Iteration: 1924 Training loss: 0.31636\n",
      "Epoch: 384/500 Iteration: 1925 Validation Acc: 0.7400\n",
      "Epoch: 386/500 Iteration: 1925 Training loss: 0.21981\n",
      "Epoch: 386/500 Iteration: 1926 Training loss: 0.11459\n",
      "Epoch: 386/500 Iteration: 1927 Training loss: 0.11316\n",
      "Epoch: 386/500 Iteration: 1928 Training loss: 0.13938\n",
      "Epoch: 386/500 Iteration: 1929 Training loss: 0.23185\n",
      "Epoch: 385/500 Iteration: 1930 Validation Acc: 0.6733\n",
      "Epoch: 387/500 Iteration: 1930 Training loss: 0.17372\n",
      "Epoch: 387/500 Iteration: 1931 Training loss: 0.09459\n",
      "Epoch: 387/500 Iteration: 1932 Training loss: 0.08782\n",
      "Epoch: 387/500 Iteration: 1933 Training loss: 0.07592\n",
      "Epoch: 387/500 Iteration: 1934 Training loss: 0.31878\n",
      "Epoch: 386/500 Iteration: 1935 Validation Acc: 0.6600\n",
      "Epoch: 388/500 Iteration: 1935 Training loss: 0.21396\n",
      "Epoch: 388/500 Iteration: 1936 Training loss: 0.08360\n",
      "Epoch: 388/500 Iteration: 1937 Training loss: 0.09447\n",
      "Epoch: 388/500 Iteration: 1938 Training loss: 0.10276\n",
      "Epoch: 388/500 Iteration: 1939 Training loss: 0.18544\n",
      "Epoch: 387/500 Iteration: 1940 Validation Acc: 0.7000\n",
      "Epoch: 389/500 Iteration: 1940 Training loss: 0.19597\n",
      "Epoch: 389/500 Iteration: 1941 Training loss: 0.08578\n",
      "Epoch: 389/500 Iteration: 1942 Training loss: 0.06174\n",
      "Epoch: 389/500 Iteration: 1943 Training loss: 0.06861\n",
      "Epoch: 389/500 Iteration: 1944 Training loss: 0.34457\n",
      "Epoch: 388/500 Iteration: 1945 Validation Acc: 0.7000\n",
      "Epoch: 390/500 Iteration: 1945 Training loss: 0.15450\n",
      "Epoch: 390/500 Iteration: 1946 Training loss: 0.07469\n",
      "Epoch: 390/500 Iteration: 1947 Training loss: 0.07518\n",
      "Epoch: 390/500 Iteration: 1948 Training loss: 0.07898\n",
      "Epoch: 390/500 Iteration: 1949 Training loss: 0.18407\n",
      "Epoch: 389/500 Iteration: 1950 Validation Acc: 0.7133\n",
      "Epoch: 391/500 Iteration: 1950 Training loss: 0.14321\n",
      "Epoch: 391/500 Iteration: 1951 Training loss: 0.04520\n",
      "Epoch: 391/500 Iteration: 1952 Training loss: 0.05548\n",
      "Epoch: 391/500 Iteration: 1953 Training loss: 0.07213\n",
      "Epoch: 391/500 Iteration: 1954 Training loss: 0.30715\n",
      "Epoch: 390/500 Iteration: 1955 Validation Acc: 0.6267\n",
      "Epoch: 392/500 Iteration: 1955 Training loss: 0.14258\n",
      "Epoch: 392/500 Iteration: 1956 Training loss: 0.06360\n",
      "Epoch: 392/500 Iteration: 1957 Training loss: 0.05705\n",
      "Epoch: 392/500 Iteration: 1958 Training loss: 0.07196\n",
      "Epoch: 392/500 Iteration: 1959 Training loss: 0.20771\n",
      "Epoch: 391/500 Iteration: 1960 Validation Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 393/500 Iteration: 1960 Training loss: 0.18574\n",
      "Epoch: 393/500 Iteration: 1961 Training loss: 0.07040\n",
      "Epoch: 393/500 Iteration: 1962 Training loss: 0.07400\n",
      "Epoch: 393/500 Iteration: 1963 Training loss: 0.08649\n",
      "Epoch: 393/500 Iteration: 1964 Training loss: 0.17507\n",
      "Epoch: 392/500 Iteration: 1965 Validation Acc: 0.6933\n",
      "Epoch: 394/500 Iteration: 1965 Training loss: 0.14539\n",
      "Epoch: 394/500 Iteration: 1966 Training loss: 0.09650\n",
      "Epoch: 394/500 Iteration: 1967 Training loss: 0.05690\n",
      "Epoch: 394/500 Iteration: 1968 Training loss: 0.04755\n",
      "Epoch: 394/500 Iteration: 1969 Training loss: 0.32520\n",
      "Epoch: 393/500 Iteration: 1970 Validation Acc: 0.6867\n",
      "Epoch: 395/500 Iteration: 1970 Training loss: 0.15613\n",
      "Epoch: 395/500 Iteration: 1971 Training loss: 0.07897\n",
      "Epoch: 395/500 Iteration: 1972 Training loss: 0.09435\n",
      "Epoch: 395/500 Iteration: 1973 Training loss: 0.12596\n",
      "Epoch: 395/500 Iteration: 1974 Training loss: 0.19151\n",
      "Epoch: 394/500 Iteration: 1975 Validation Acc: 0.7067\n",
      "Epoch: 396/500 Iteration: 1975 Training loss: 0.12138\n",
      "Epoch: 396/500 Iteration: 1976 Training loss: 0.09560\n",
      "Epoch: 396/500 Iteration: 1977 Training loss: 0.08590\n",
      "Epoch: 396/500 Iteration: 1978 Training loss: 0.08732\n",
      "Epoch: 396/500 Iteration: 1979 Training loss: 0.26867\n",
      "Epoch: 395/500 Iteration: 1980 Validation Acc: 0.6867\n",
      "Epoch: 397/500 Iteration: 1980 Training loss: 0.12870\n",
      "Epoch: 397/500 Iteration: 1981 Training loss: 0.05929\n",
      "Epoch: 397/500 Iteration: 1982 Training loss: 0.06970\n",
      "Epoch: 397/500 Iteration: 1983 Training loss: 0.07013\n",
      "Epoch: 397/500 Iteration: 1984 Training loss: 0.21158\n",
      "Epoch: 396/500 Iteration: 1985 Validation Acc: 0.6800\n",
      "Epoch: 398/500 Iteration: 1985 Training loss: 0.13751\n",
      "Epoch: 398/500 Iteration: 1986 Training loss: 0.07420\n",
      "Epoch: 398/500 Iteration: 1987 Training loss: 0.11387\n",
      "Epoch: 398/500 Iteration: 1988 Training loss: 0.08986\n",
      "Epoch: 398/500 Iteration: 1989 Training loss: 0.20849\n",
      "Epoch: 397/500 Iteration: 1990 Validation Acc: 0.6667\n",
      "Epoch: 399/500 Iteration: 1990 Training loss: 0.15304\n",
      "Epoch: 399/500 Iteration: 1991 Training loss: 0.06083\n",
      "Epoch: 399/500 Iteration: 1992 Training loss: 0.06062\n",
      "Epoch: 399/500 Iteration: 1993 Training loss: 0.05573\n",
      "Epoch: 399/500 Iteration: 1994 Training loss: 0.20526\n",
      "Epoch: 398/500 Iteration: 1995 Validation Acc: 0.7000\n",
      "Epoch: 400/500 Iteration: 1995 Training loss: 0.16424\n",
      "Epoch: 400/500 Iteration: 1996 Training loss: 0.06053\n",
      "Epoch: 400/500 Iteration: 1997 Training loss: 0.06491\n",
      "Epoch: 400/500 Iteration: 1998 Training loss: 0.05956\n",
      "Epoch: 400/500 Iteration: 1999 Training loss: 0.22359\n",
      "Epoch: 399/500 Iteration: 2000 Validation Acc: 0.6933\n",
      "Epoch: 401/500 Iteration: 2000 Training loss: 0.15224\n",
      "Epoch: 401/500 Iteration: 2001 Training loss: 0.05602\n",
      "Epoch: 401/500 Iteration: 2002 Training loss: 0.06038\n",
      "Epoch: 401/500 Iteration: 2003 Training loss: 0.04613\n",
      "Epoch: 401/500 Iteration: 2004 Training loss: 0.16811\n",
      "Epoch: 400/500 Iteration: 2005 Validation Acc: 0.6467\n",
      "Epoch: 402/500 Iteration: 2005 Training loss: 0.09693\n",
      "Epoch: 402/500 Iteration: 2006 Training loss: 0.05467\n",
      "Epoch: 402/500 Iteration: 2007 Training loss: 0.04294\n",
      "Epoch: 402/500 Iteration: 2008 Training loss: 0.05320\n",
      "Epoch: 402/500 Iteration: 2009 Training loss: 0.20759\n",
      "Epoch: 401/500 Iteration: 2010 Validation Acc: 0.6600\n",
      "Epoch: 403/500 Iteration: 2010 Training loss: 0.11858\n",
      "Epoch: 403/500 Iteration: 2011 Training loss: 0.05427\n",
      "Epoch: 403/500 Iteration: 2012 Training loss: 0.06762\n",
      "Epoch: 403/500 Iteration: 2013 Training loss: 0.06279\n",
      "Epoch: 403/500 Iteration: 2014 Training loss: 0.16445\n",
      "Epoch: 402/500 Iteration: 2015 Validation Acc: 0.7067\n",
      "Epoch: 404/500 Iteration: 2015 Training loss: 0.09965\n",
      "Epoch: 404/500 Iteration: 2016 Training loss: 0.04220\n",
      "Epoch: 404/500 Iteration: 2017 Training loss: 0.04458\n",
      "Epoch: 404/500 Iteration: 2018 Training loss: 0.04075\n",
      "Epoch: 404/500 Iteration: 2019 Training loss: 0.16983\n",
      "Epoch: 403/500 Iteration: 2020 Validation Acc: 0.6533\n",
      "Epoch: 405/500 Iteration: 2020 Training loss: 0.10356\n",
      "Epoch: 405/500 Iteration: 2021 Training loss: 0.04182\n",
      "Epoch: 405/500 Iteration: 2022 Training loss: 0.04194\n",
      "Epoch: 405/500 Iteration: 2023 Training loss: 0.04480\n",
      "Epoch: 405/500 Iteration: 2024 Training loss: 0.19734\n",
      "Epoch: 404/500 Iteration: 2025 Validation Acc: 0.6733\n",
      "Epoch: 406/500 Iteration: 2025 Training loss: 0.13603\n",
      "Epoch: 406/500 Iteration: 2026 Training loss: 0.05462\n",
      "Epoch: 406/500 Iteration: 2027 Training loss: 0.07419\n",
      "Epoch: 406/500 Iteration: 2028 Training loss: 0.06525\n",
      "Epoch: 406/500 Iteration: 2029 Training loss: 0.10575\n",
      "Epoch: 405/500 Iteration: 2030 Validation Acc: 0.6667\n",
      "Epoch: 407/500 Iteration: 2030 Training loss: 0.12234\n",
      "Epoch: 407/500 Iteration: 2031 Training loss: 0.03927\n",
      "Epoch: 407/500 Iteration: 2032 Training loss: 0.03601\n",
      "Epoch: 407/500 Iteration: 2033 Training loss: 0.04218\n",
      "Epoch: 407/500 Iteration: 2034 Training loss: 0.21934\n",
      "Epoch: 406/500 Iteration: 2035 Validation Acc: 0.6933\n",
      "Epoch: 408/500 Iteration: 2035 Training loss: 0.09934\n",
      "Epoch: 408/500 Iteration: 2036 Training loss: 0.03968\n",
      "Epoch: 408/500 Iteration: 2037 Training loss: 0.04097\n",
      "Epoch: 408/500 Iteration: 2038 Training loss: 0.05485\n",
      "Epoch: 408/500 Iteration: 2039 Training loss: 0.12583\n",
      "Epoch: 407/500 Iteration: 2040 Validation Acc: 0.6867\n",
      "Epoch: 409/500 Iteration: 2040 Training loss: 0.11776\n",
      "Epoch: 409/500 Iteration: 2041 Training loss: 0.06802\n",
      "Epoch: 409/500 Iteration: 2042 Training loss: 0.05946\n",
      "Epoch: 409/500 Iteration: 2043 Training loss: 0.05199\n",
      "Epoch: 409/500 Iteration: 2044 Training loss: 0.16762\n",
      "Epoch: 408/500 Iteration: 2045 Validation Acc: 0.7067\n",
      "Epoch: 410/500 Iteration: 2045 Training loss: 0.12998\n",
      "Epoch: 410/500 Iteration: 2046 Training loss: 0.04207\n",
      "Epoch: 410/500 Iteration: 2047 Training loss: 0.04355\n",
      "Epoch: 410/500 Iteration: 2048 Training loss: 0.03759\n",
      "Epoch: 410/500 Iteration: 2049 Training loss: 0.15991\n",
      "Epoch: 409/500 Iteration: 2050 Validation Acc: 0.7000\n",
      "Epoch: 411/500 Iteration: 2050 Training loss: 0.11905\n",
      "Epoch: 411/500 Iteration: 2051 Training loss: 0.04103\n",
      "Epoch: 411/500 Iteration: 2052 Training loss: 0.04784\n",
      "Epoch: 411/500 Iteration: 2053 Training loss: 0.03666\n",
      "Epoch: 411/500 Iteration: 2054 Training loss: 0.17278\n",
      "Epoch: 410/500 Iteration: 2055 Validation Acc: 0.7067\n",
      "Epoch: 412/500 Iteration: 2055 Training loss: 0.11594\n",
      "Epoch: 412/500 Iteration: 2056 Training loss: 0.04087\n",
      "Epoch: 412/500 Iteration: 2057 Training loss: 0.05165\n",
      "Epoch: 412/500 Iteration: 2058 Training loss: 0.03712\n",
      "Epoch: 412/500 Iteration: 2059 Training loss: 0.11501\n",
      "Epoch: 411/500 Iteration: 2060 Validation Acc: 0.6600\n",
      "Epoch: 413/500 Iteration: 2060 Training loss: 0.11330\n",
      "Epoch: 413/500 Iteration: 2061 Training loss: 0.03348\n",
      "Epoch: 413/500 Iteration: 2062 Training loss: 0.03886\n",
      "Epoch: 413/500 Iteration: 2063 Training loss: 0.03323\n",
      "Epoch: 413/500 Iteration: 2064 Training loss: 0.13487\n",
      "Epoch: 412/500 Iteration: 2065 Validation Acc: 0.6933\n",
      "Epoch: 414/500 Iteration: 2065 Training loss: 0.09029\n",
      "Epoch: 414/500 Iteration: 2066 Training loss: 0.04801\n",
      "Epoch: 414/500 Iteration: 2067 Training loss: 0.03037\n",
      "Epoch: 414/500 Iteration: 2068 Training loss: 0.03297\n",
      "Epoch: 414/500 Iteration: 2069 Training loss: 0.17364\n",
      "Epoch: 413/500 Iteration: 2070 Validation Acc: 0.6867\n",
      "Epoch: 415/500 Iteration: 2070 Training loss: 0.11146\n",
      "Epoch: 415/500 Iteration: 2071 Training loss: 0.03450\n",
      "Epoch: 415/500 Iteration: 2072 Training loss: 0.05196\n",
      "Epoch: 415/500 Iteration: 2073 Training loss: 0.04322\n",
      "Epoch: 415/500 Iteration: 2074 Training loss: 0.11499\n",
      "Epoch: 414/500 Iteration: 2075 Validation Acc: 0.6733\n",
      "Epoch: 416/500 Iteration: 2075 Training loss: 0.09551\n",
      "Epoch: 416/500 Iteration: 2076 Training loss: 0.04063\n",
      "Epoch: 416/500 Iteration: 2077 Training loss: 0.03118\n",
      "Epoch: 416/500 Iteration: 2078 Training loss: 0.04135\n",
      "Epoch: 416/500 Iteration: 2079 Training loss: 0.12563\n",
      "Epoch: 415/500 Iteration: 2080 Validation Acc: 0.7133\n",
      "Epoch: 417/500 Iteration: 2080 Training loss: 0.07361\n",
      "Epoch: 417/500 Iteration: 2081 Training loss: 0.02711\n",
      "Epoch: 417/500 Iteration: 2082 Training loss: 0.04319\n",
      "Epoch: 417/500 Iteration: 2083 Training loss: 0.03081\n",
      "Epoch: 417/500 Iteration: 2084 Training loss: 0.18925\n",
      "Epoch: 416/500 Iteration: 2085 Validation Acc: 0.7000\n",
      "Epoch: 418/500 Iteration: 2085 Training loss: 0.08817\n",
      "Epoch: 418/500 Iteration: 2086 Training loss: 0.02607\n",
      "Epoch: 418/500 Iteration: 2087 Training loss: 0.04090\n",
      "Epoch: 418/500 Iteration: 2088 Training loss: 0.05554\n",
      "Epoch: 418/500 Iteration: 2089 Training loss: 0.14027\n",
      "Epoch: 417/500 Iteration: 2090 Validation Acc: 0.7000\n",
      "Epoch: 419/500 Iteration: 2090 Training loss: 0.06449\n",
      "Epoch: 419/500 Iteration: 2091 Training loss: 0.03121\n",
      "Epoch: 419/500 Iteration: 2092 Training loss: 0.04217\n",
      "Epoch: 419/500 Iteration: 2093 Training loss: 0.04544\n",
      "Epoch: 419/500 Iteration: 2094 Training loss: 0.16077\n",
      "Epoch: 418/500 Iteration: 2095 Validation Acc: 0.6667\n",
      "Epoch: 420/500 Iteration: 2095 Training loss: 0.09677\n",
      "Epoch: 420/500 Iteration: 2096 Training loss: 0.05044\n",
      "Epoch: 420/500 Iteration: 2097 Training loss: 0.04105\n",
      "Epoch: 420/500 Iteration: 2098 Training loss: 0.03778\n",
      "Epoch: 420/500 Iteration: 2099 Training loss: 0.15634\n",
      "Epoch: 419/500 Iteration: 2100 Validation Acc: 0.6933\n",
      "Epoch: 421/500 Iteration: 2100 Training loss: 0.07988\n",
      "Epoch: 421/500 Iteration: 2101 Training loss: 0.03242\n",
      "Epoch: 421/500 Iteration: 2102 Training loss: 0.02456\n",
      "Epoch: 421/500 Iteration: 2103 Training loss: 0.03001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 421/500 Iteration: 2104 Training loss: 0.12660\n",
      "Epoch: 420/500 Iteration: 2105 Validation Acc: 0.6733\n",
      "Epoch: 422/500 Iteration: 2105 Training loss: 0.08282\n",
      "Epoch: 422/500 Iteration: 2106 Training loss: 0.03473\n",
      "Epoch: 422/500 Iteration: 2107 Training loss: 0.04913\n",
      "Epoch: 422/500 Iteration: 2108 Training loss: 0.04663\n",
      "Epoch: 422/500 Iteration: 2109 Training loss: 0.21524\n",
      "Epoch: 421/500 Iteration: 2110 Validation Acc: 0.6933\n",
      "Epoch: 423/500 Iteration: 2110 Training loss: 0.08825\n",
      "Epoch: 423/500 Iteration: 2111 Training loss: 0.04698\n",
      "Epoch: 423/500 Iteration: 2112 Training loss: 0.04015\n",
      "Epoch: 423/500 Iteration: 2113 Training loss: 0.04033\n",
      "Epoch: 423/500 Iteration: 2114 Training loss: 0.09130\n",
      "Epoch: 422/500 Iteration: 2115 Validation Acc: 0.6467\n",
      "Epoch: 424/500 Iteration: 2115 Training loss: 0.07489\n",
      "Epoch: 424/500 Iteration: 2116 Training loss: 0.04642\n",
      "Epoch: 424/500 Iteration: 2117 Training loss: 0.03745\n",
      "Epoch: 424/500 Iteration: 2118 Training loss: 0.03700\n",
      "Epoch: 424/500 Iteration: 2119 Training loss: 0.18847\n",
      "Epoch: 423/500 Iteration: 2120 Validation Acc: 0.6933\n",
      "Epoch: 425/500 Iteration: 2120 Training loss: 0.11508\n",
      "Epoch: 425/500 Iteration: 2121 Training loss: 0.03358\n",
      "Epoch: 425/500 Iteration: 2122 Training loss: 0.03688\n",
      "Epoch: 425/500 Iteration: 2123 Training loss: 0.05538\n",
      "Epoch: 425/500 Iteration: 2124 Training loss: 0.11202\n",
      "Epoch: 424/500 Iteration: 2125 Validation Acc: 0.6733\n",
      "Epoch: 426/500 Iteration: 2125 Training loss: 0.08381\n",
      "Epoch: 426/500 Iteration: 2126 Training loss: 0.04311\n",
      "Epoch: 426/500 Iteration: 2127 Training loss: 0.03875\n",
      "Epoch: 426/500 Iteration: 2128 Training loss: 0.04383\n",
      "Epoch: 426/500 Iteration: 2129 Training loss: 0.12811\n",
      "Epoch: 425/500 Iteration: 2130 Validation Acc: 0.6667\n",
      "Epoch: 427/500 Iteration: 2130 Training loss: 0.12380\n",
      "Epoch: 427/500 Iteration: 2131 Training loss: 0.04181\n",
      "Epoch: 427/500 Iteration: 2132 Training loss: 0.03304\n",
      "Epoch: 427/500 Iteration: 2133 Training loss: 0.03919\n",
      "Epoch: 427/500 Iteration: 2134 Training loss: 0.14585\n",
      "Epoch: 426/500 Iteration: 2135 Validation Acc: 0.7133\n",
      "Epoch: 428/500 Iteration: 2135 Training loss: 0.08763\n",
      "Epoch: 428/500 Iteration: 2136 Training loss: 0.06457\n",
      "Epoch: 428/500 Iteration: 2137 Training loss: 0.06031\n",
      "Epoch: 428/500 Iteration: 2138 Training loss: 0.04092\n",
      "Epoch: 428/500 Iteration: 2139 Training loss: 0.11214\n",
      "Epoch: 427/500 Iteration: 2140 Validation Acc: 0.6600\n",
      "Epoch: 429/500 Iteration: 2140 Training loss: 0.08699\n",
      "Epoch: 429/500 Iteration: 2141 Training loss: 0.03939\n",
      "Epoch: 429/500 Iteration: 2142 Training loss: 0.04063\n",
      "Epoch: 429/500 Iteration: 2143 Training loss: 0.04141\n",
      "Epoch: 429/500 Iteration: 2144 Training loss: 0.18159\n",
      "Epoch: 428/500 Iteration: 2145 Validation Acc: 0.6933\n",
      "Epoch: 430/500 Iteration: 2145 Training loss: 0.08911\n",
      "Epoch: 430/500 Iteration: 2146 Training loss: 0.02458\n",
      "Epoch: 430/500 Iteration: 2147 Training loss: 0.03523\n",
      "Epoch: 430/500 Iteration: 2148 Training loss: 0.03818\n",
      "Epoch: 430/500 Iteration: 2149 Training loss: 0.12272\n",
      "Epoch: 429/500 Iteration: 2150 Validation Acc: 0.7200\n",
      "Epoch: 431/500 Iteration: 2150 Training loss: 0.09646\n",
      "Epoch: 431/500 Iteration: 2151 Training loss: 0.03427\n",
      "Epoch: 431/500 Iteration: 2152 Training loss: 0.04996\n",
      "Epoch: 431/500 Iteration: 2153 Training loss: 0.03231\n",
      "Epoch: 431/500 Iteration: 2154 Training loss: 0.17701\n",
      "Epoch: 430/500 Iteration: 2155 Validation Acc: 0.7000\n",
      "Epoch: 432/500 Iteration: 2155 Training loss: 0.07553\n",
      "Epoch: 432/500 Iteration: 2156 Training loss: 0.03404\n",
      "Epoch: 432/500 Iteration: 2157 Training loss: 0.03541\n",
      "Epoch: 432/500 Iteration: 2158 Training loss: 0.02970\n",
      "Epoch: 432/500 Iteration: 2159 Training loss: 0.08391\n",
      "Epoch: 431/500 Iteration: 2160 Validation Acc: 0.7200\n",
      "Epoch: 433/500 Iteration: 2160 Training loss: 0.08431\n",
      "Epoch: 433/500 Iteration: 2161 Training loss: 0.04925\n",
      "Epoch: 433/500 Iteration: 2162 Training loss: 0.02534\n",
      "Epoch: 433/500 Iteration: 2163 Training loss: 0.03760\n",
      "Epoch: 433/500 Iteration: 2164 Training loss: 0.17431\n",
      "Epoch: 432/500 Iteration: 2165 Validation Acc: 0.7133\n",
      "Epoch: 434/500 Iteration: 2165 Training loss: 0.08838\n",
      "Epoch: 434/500 Iteration: 2166 Training loss: 0.03498\n",
      "Epoch: 434/500 Iteration: 2167 Training loss: 0.03642\n",
      "Epoch: 434/500 Iteration: 2168 Training loss: 0.02913\n",
      "Epoch: 434/500 Iteration: 2169 Training loss: 0.12710\n",
      "Epoch: 433/500 Iteration: 2170 Validation Acc: 0.6800\n",
      "Epoch: 435/500 Iteration: 2170 Training loss: 0.08517\n",
      "Epoch: 435/500 Iteration: 2171 Training loss: 0.04956\n",
      "Epoch: 435/500 Iteration: 2172 Training loss: 0.04069\n",
      "Epoch: 435/500 Iteration: 2173 Training loss: 0.03348\n",
      "Epoch: 435/500 Iteration: 2174 Training loss: 0.14203\n",
      "Epoch: 434/500 Iteration: 2175 Validation Acc: 0.6467\n",
      "Epoch: 436/500 Iteration: 2175 Training loss: 0.06692\n",
      "Epoch: 436/500 Iteration: 2176 Training loss: 0.02293\n",
      "Epoch: 436/500 Iteration: 2177 Training loss: 0.03136\n",
      "Epoch: 436/500 Iteration: 2178 Training loss: 0.04063\n",
      "Epoch: 436/500 Iteration: 2179 Training loss: 0.12333\n",
      "Epoch: 435/500 Iteration: 2180 Validation Acc: 0.6800\n",
      "Epoch: 437/500 Iteration: 2180 Training loss: 0.07183\n",
      "Epoch: 437/500 Iteration: 2181 Training loss: 0.03047\n",
      "Epoch: 437/500 Iteration: 2182 Training loss: 0.02452\n",
      "Epoch: 437/500 Iteration: 2183 Training loss: 0.02356\n",
      "Epoch: 437/500 Iteration: 2184 Training loss: 0.14656\n",
      "Epoch: 436/500 Iteration: 2185 Validation Acc: 0.7067\n",
      "Epoch: 438/500 Iteration: 2185 Training loss: 0.07195\n",
      "Epoch: 438/500 Iteration: 2186 Training loss: 0.02239\n",
      "Epoch: 438/500 Iteration: 2187 Training loss: 0.03992\n",
      "Epoch: 438/500 Iteration: 2188 Training loss: 0.05262\n",
      "Epoch: 438/500 Iteration: 2189 Training loss: 0.10402\n",
      "Epoch: 437/500 Iteration: 2190 Validation Acc: 0.6733\n",
      "Epoch: 439/500 Iteration: 2190 Training loss: 0.07686\n",
      "Epoch: 439/500 Iteration: 2191 Training loss: 0.06538\n",
      "Epoch: 439/500 Iteration: 2192 Training loss: 0.05063\n",
      "Epoch: 439/500 Iteration: 2193 Training loss: 0.04511\n",
      "Epoch: 439/500 Iteration: 2194 Training loss: 0.11463\n",
      "Epoch: 438/500 Iteration: 2195 Validation Acc: 0.6867\n",
      "Epoch: 440/500 Iteration: 2195 Training loss: 0.08091\n",
      "Epoch: 440/500 Iteration: 2196 Training loss: 0.02015\n",
      "Epoch: 440/500 Iteration: 2197 Training loss: 0.03226\n",
      "Epoch: 440/500 Iteration: 2198 Training loss: 0.02028\n",
      "Epoch: 440/500 Iteration: 2199 Training loss: 0.12627\n",
      "Epoch: 439/500 Iteration: 2200 Validation Acc: 0.6933\n",
      "Epoch: 441/500 Iteration: 2200 Training loss: 0.10820\n",
      "Epoch: 441/500 Iteration: 2201 Training loss: 0.01629\n",
      "Epoch: 441/500 Iteration: 2202 Training loss: 0.03421\n",
      "Epoch: 441/500 Iteration: 2203 Training loss: 0.03598\n",
      "Epoch: 441/500 Iteration: 2204 Training loss: 0.12361\n",
      "Epoch: 440/500 Iteration: 2205 Validation Acc: 0.6867\n",
      "Epoch: 442/500 Iteration: 2205 Training loss: 0.06807\n",
      "Epoch: 442/500 Iteration: 2206 Training loss: 0.02887\n",
      "Epoch: 442/500 Iteration: 2207 Training loss: 0.04847\n",
      "Epoch: 442/500 Iteration: 2208 Training loss: 0.03378\n",
      "Epoch: 442/500 Iteration: 2209 Training loss: 0.09654\n",
      "Epoch: 441/500 Iteration: 2210 Validation Acc: 0.6467\n",
      "Epoch: 443/500 Iteration: 2210 Training loss: 0.07333\n",
      "Epoch: 443/500 Iteration: 2211 Training loss: 0.03063\n",
      "Epoch: 443/500 Iteration: 2212 Training loss: 0.03715\n",
      "Epoch: 443/500 Iteration: 2213 Training loss: 0.02063\n",
      "Epoch: 443/500 Iteration: 2214 Training loss: 0.12304\n",
      "Epoch: 442/500 Iteration: 2215 Validation Acc: 0.6667\n",
      "Epoch: 444/500 Iteration: 2215 Training loss: 0.07458\n",
      "Epoch: 444/500 Iteration: 2216 Training loss: 0.02928\n",
      "Epoch: 444/500 Iteration: 2217 Training loss: 0.04206\n",
      "Epoch: 444/500 Iteration: 2218 Training loss: 0.02743\n",
      "Epoch: 444/500 Iteration: 2219 Training loss: 0.09920\n",
      "Epoch: 443/500 Iteration: 2220 Validation Acc: 0.6600\n",
      "Epoch: 445/500 Iteration: 2220 Training loss: 0.06521\n",
      "Epoch: 445/500 Iteration: 2221 Training loss: 0.03551\n",
      "Epoch: 445/500 Iteration: 2222 Training loss: 0.02577\n",
      "Epoch: 445/500 Iteration: 2223 Training loss: 0.02083\n",
      "Epoch: 445/500 Iteration: 2224 Training loss: 0.11564\n",
      "Epoch: 444/500 Iteration: 2225 Validation Acc: 0.6867\n",
      "Epoch: 446/500 Iteration: 2225 Training loss: 0.08003\n",
      "Epoch: 446/500 Iteration: 2226 Training loss: 0.02692\n",
      "Epoch: 446/500 Iteration: 2227 Training loss: 0.02874\n",
      "Epoch: 446/500 Iteration: 2228 Training loss: 0.04800\n",
      "Epoch: 446/500 Iteration: 2229 Training loss: 0.10595\n",
      "Epoch: 445/500 Iteration: 2230 Validation Acc: 0.6600\n",
      "Epoch: 447/500 Iteration: 2230 Training loss: 0.05796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 447/500 Iteration: 2231 Training loss: 0.02470\n",
      "Epoch: 447/500 Iteration: 2232 Training loss: 0.03746\n",
      "Epoch: 447/500 Iteration: 2233 Training loss: 0.03325\n",
      "Epoch: 447/500 Iteration: 2234 Training loss: 0.10507\n",
      "Epoch: 446/500 Iteration: 2235 Validation Acc: 0.6733\n",
      "Epoch: 448/500 Iteration: 2235 Training loss: 0.10241\n",
      "Epoch: 448/500 Iteration: 2236 Training loss: 0.03678\n",
      "Epoch: 448/500 Iteration: 2237 Training loss: 0.02409\n",
      "Epoch: 448/500 Iteration: 2238 Training loss: 0.01360\n",
      "Epoch: 448/500 Iteration: 2239 Training loss: 0.11253\n",
      "Epoch: 447/500 Iteration: 2240 Validation Acc: 0.6467\n",
      "Epoch: 449/500 Iteration: 2240 Training loss: 0.06620\n",
      "Epoch: 449/500 Iteration: 2241 Training loss: 0.03325\n",
      "Epoch: 449/500 Iteration: 2242 Training loss: 0.02529\n",
      "Epoch: 449/500 Iteration: 2243 Training loss: 0.03857\n",
      "Epoch: 449/500 Iteration: 2244 Training loss: 0.10308\n",
      "Epoch: 448/500 Iteration: 2245 Validation Acc: 0.6733\n",
      "Epoch: 450/500 Iteration: 2245 Training loss: 0.07756\n",
      "Epoch: 450/500 Iteration: 2246 Training loss: 0.02539\n",
      "Epoch: 450/500 Iteration: 2247 Training loss: 0.03582\n",
      "Epoch: 450/500 Iteration: 2248 Training loss: 0.03720\n",
      "Epoch: 450/500 Iteration: 2249 Training loss: 0.11683\n",
      "Epoch: 449/500 Iteration: 2250 Validation Acc: 0.6600\n",
      "Epoch: 451/500 Iteration: 2250 Training loss: 0.08021\n",
      "Epoch: 451/500 Iteration: 2251 Training loss: 0.03011\n",
      "Epoch: 451/500 Iteration: 2252 Training loss: 0.02781\n",
      "Epoch: 451/500 Iteration: 2253 Training loss: 0.03591\n",
      "Epoch: 451/500 Iteration: 2254 Training loss: 0.11329\n",
      "Epoch: 450/500 Iteration: 2255 Validation Acc: 0.7000\n",
      "Epoch: 452/500 Iteration: 2255 Training loss: 0.07886\n",
      "Epoch: 452/500 Iteration: 2256 Training loss: 0.02810\n",
      "Epoch: 452/500 Iteration: 2257 Training loss: 0.04439\n",
      "Epoch: 452/500 Iteration: 2258 Training loss: 0.03022\n",
      "Epoch: 452/500 Iteration: 2259 Training loss: 0.14190\n",
      "Epoch: 451/500 Iteration: 2260 Validation Acc: 0.6400\n",
      "Epoch: 453/500 Iteration: 2260 Training loss: 0.07430\n",
      "Epoch: 453/500 Iteration: 2261 Training loss: 0.03593\n",
      "Epoch: 453/500 Iteration: 2262 Training loss: 0.02961\n",
      "Epoch: 453/500 Iteration: 2263 Training loss: 0.02218\n",
      "Epoch: 453/500 Iteration: 2264 Training loss: 0.08232\n",
      "Epoch: 452/500 Iteration: 2265 Validation Acc: 0.6933\n",
      "Epoch: 454/500 Iteration: 2265 Training loss: 0.07146\n",
      "Epoch: 454/500 Iteration: 2266 Training loss: 0.02348\n",
      "Epoch: 454/500 Iteration: 2267 Training loss: 0.02400\n",
      "Epoch: 454/500 Iteration: 2268 Training loss: 0.02463\n",
      "Epoch: 454/500 Iteration: 2269 Training loss: 0.11468\n",
      "Epoch: 453/500 Iteration: 2270 Validation Acc: 0.6467\n",
      "Epoch: 455/500 Iteration: 2270 Training loss: 0.09419\n",
      "Epoch: 455/500 Iteration: 2271 Training loss: 0.01374\n",
      "Epoch: 455/500 Iteration: 2272 Training loss: 0.02456\n",
      "Epoch: 455/500 Iteration: 2273 Training loss: 0.03453\n",
      "Epoch: 455/500 Iteration: 2274 Training loss: 0.09573\n",
      "Epoch: 454/500 Iteration: 2275 Validation Acc: 0.7000\n",
      "Epoch: 456/500 Iteration: 2275 Training loss: 0.06170\n",
      "Epoch: 456/500 Iteration: 2276 Training loss: 0.04649\n",
      "Epoch: 456/500 Iteration: 2277 Training loss: 0.03992\n",
      "Epoch: 456/500 Iteration: 2278 Training loss: 0.02408\n",
      "Epoch: 456/500 Iteration: 2279 Training loss: 0.10774\n",
      "Epoch: 455/500 Iteration: 2280 Validation Acc: 0.6867\n",
      "Epoch: 457/500 Iteration: 2280 Training loss: 0.08545\n",
      "Epoch: 457/500 Iteration: 2281 Training loss: 0.02218\n",
      "Epoch: 457/500 Iteration: 2282 Training loss: 0.01664\n",
      "Epoch: 457/500 Iteration: 2283 Training loss: 0.02478\n",
      "Epoch: 457/500 Iteration: 2284 Training loss: 0.13050\n",
      "Epoch: 456/500 Iteration: 2285 Validation Acc: 0.7067\n",
      "Epoch: 458/500 Iteration: 2285 Training loss: 0.05297\n",
      "Epoch: 458/500 Iteration: 2286 Training loss: 0.02078\n",
      "Epoch: 458/500 Iteration: 2287 Training loss: 0.02062\n",
      "Epoch: 458/500 Iteration: 2288 Training loss: 0.01491\n",
      "Epoch: 458/500 Iteration: 2289 Training loss: 0.09601\n",
      "Epoch: 457/500 Iteration: 2290 Validation Acc: 0.6667\n",
      "Epoch: 459/500 Iteration: 2290 Training loss: 0.07015\n",
      "Epoch: 459/500 Iteration: 2291 Training loss: 0.03976\n",
      "Epoch: 459/500 Iteration: 2292 Training loss: 0.02710\n",
      "Epoch: 459/500 Iteration: 2293 Training loss: 0.02309\n",
      "Epoch: 459/500 Iteration: 2294 Training loss: 0.09070\n",
      "Epoch: 458/500 Iteration: 2295 Validation Acc: 0.7067\n",
      "Epoch: 460/500 Iteration: 2295 Training loss: 0.06638\n",
      "Epoch: 460/500 Iteration: 2296 Training loss: 0.02590\n",
      "Epoch: 460/500 Iteration: 2297 Training loss: 0.02685\n",
      "Epoch: 460/500 Iteration: 2298 Training loss: 0.01517\n",
      "Epoch: 460/500 Iteration: 2299 Training loss: 0.09860\n",
      "Epoch: 459/500 Iteration: 2300 Validation Acc: 0.6667\n",
      "Epoch: 461/500 Iteration: 2300 Training loss: 0.05636\n",
      "Epoch: 461/500 Iteration: 2301 Training loss: 0.02838\n",
      "Epoch: 461/500 Iteration: 2302 Training loss: 0.01475\n",
      "Epoch: 461/500 Iteration: 2303 Training loss: 0.03166\n",
      "Epoch: 461/500 Iteration: 2304 Training loss: 0.09945\n",
      "Epoch: 460/500 Iteration: 2305 Validation Acc: 0.6600\n",
      "Epoch: 462/500 Iteration: 2305 Training loss: 0.05347\n",
      "Epoch: 462/500 Iteration: 2306 Training loss: 0.02769\n",
      "Epoch: 462/500 Iteration: 2307 Training loss: 0.02118\n",
      "Epoch: 462/500 Iteration: 2308 Training loss: 0.02587\n",
      "Epoch: 462/500 Iteration: 2309 Training loss: 0.06154\n",
      "Epoch: 461/500 Iteration: 2310 Validation Acc: 0.6800\n",
      "Epoch: 463/500 Iteration: 2310 Training loss: 0.07770\n",
      "Epoch: 463/500 Iteration: 2311 Training loss: 0.02993\n",
      "Epoch: 463/500 Iteration: 2312 Training loss: 0.02328\n",
      "Epoch: 463/500 Iteration: 2313 Training loss: 0.01708\n",
      "Epoch: 463/500 Iteration: 2314 Training loss: 0.09410\n",
      "Epoch: 462/500 Iteration: 2315 Validation Acc: 0.6800\n",
      "Epoch: 464/500 Iteration: 2315 Training loss: 0.06296\n",
      "Epoch: 464/500 Iteration: 2316 Training loss: 0.02986\n",
      "Epoch: 464/500 Iteration: 2317 Training loss: 0.03324\n",
      "Epoch: 464/500 Iteration: 2318 Training loss: 0.03366\n",
      "Epoch: 464/500 Iteration: 2319 Training loss: 0.10362\n",
      "Epoch: 463/500 Iteration: 2320 Validation Acc: 0.6667\n",
      "Epoch: 465/500 Iteration: 2320 Training loss: 0.04717\n",
      "Epoch: 465/500 Iteration: 2321 Training loss: 0.01705\n",
      "Epoch: 465/500 Iteration: 2322 Training loss: 0.01971\n",
      "Epoch: 465/500 Iteration: 2323 Training loss: 0.01828\n",
      "Epoch: 465/500 Iteration: 2324 Training loss: 0.09547\n",
      "Epoch: 464/500 Iteration: 2325 Validation Acc: 0.6800\n",
      "Epoch: 466/500 Iteration: 2325 Training loss: 0.08171\n",
      "Epoch: 466/500 Iteration: 2326 Training loss: 0.02977\n",
      "Epoch: 466/500 Iteration: 2327 Training loss: 0.02079\n",
      "Epoch: 466/500 Iteration: 2328 Training loss: 0.04053\n",
      "Epoch: 466/500 Iteration: 2329 Training loss: 0.06538\n",
      "Epoch: 465/500 Iteration: 2330 Validation Acc: 0.6933\n",
      "Epoch: 467/500 Iteration: 2330 Training loss: 0.04578\n",
      "Epoch: 467/500 Iteration: 2331 Training loss: 0.01576\n",
      "Epoch: 467/500 Iteration: 2332 Training loss: 0.00990\n",
      "Epoch: 467/500 Iteration: 2333 Training loss: 0.01788\n",
      "Epoch: 467/500 Iteration: 2334 Training loss: 0.08748\n",
      "Epoch: 466/500 Iteration: 2335 Validation Acc: 0.7000\n",
      "Epoch: 468/500 Iteration: 2335 Training loss: 0.05203\n",
      "Epoch: 468/500 Iteration: 2336 Training loss: 0.02423\n",
      "Epoch: 468/500 Iteration: 2337 Training loss: 0.02338\n",
      "Epoch: 468/500 Iteration: 2338 Training loss: 0.03176\n",
      "Epoch: 468/500 Iteration: 2339 Training loss: 0.07365\n",
      "Epoch: 467/500 Iteration: 2340 Validation Acc: 0.6800\n",
      "Epoch: 469/500 Iteration: 2340 Training loss: 0.04079\n",
      "Epoch: 469/500 Iteration: 2341 Training loss: 0.02213\n",
      "Epoch: 469/500 Iteration: 2342 Training loss: 0.01922\n",
      "Epoch: 469/500 Iteration: 2343 Training loss: 0.02193\n",
      "Epoch: 469/500 Iteration: 2344 Training loss: 0.12299\n",
      "Epoch: 468/500 Iteration: 2345 Validation Acc: 0.6800\n",
      "Epoch: 470/500 Iteration: 2345 Training loss: 0.06289\n",
      "Epoch: 470/500 Iteration: 2346 Training loss: 0.03120\n",
      "Epoch: 470/500 Iteration: 2347 Training loss: 0.02239\n",
      "Epoch: 470/500 Iteration: 2348 Training loss: 0.01887\n",
      "Epoch: 470/500 Iteration: 2349 Training loss: 0.09170\n",
      "Epoch: 469/500 Iteration: 2350 Validation Acc: 0.6933\n",
      "Epoch: 471/500 Iteration: 2350 Training loss: 0.05283\n",
      "Epoch: 471/500 Iteration: 2351 Training loss: 0.02022\n",
      "Epoch: 471/500 Iteration: 2352 Training loss: 0.01137\n",
      "Epoch: 471/500 Iteration: 2353 Training loss: 0.01375\n",
      "Epoch: 471/500 Iteration: 2354 Training loss: 0.08687\n",
      "Epoch: 470/500 Iteration: 2355 Validation Acc: 0.7067\n",
      "Epoch: 472/500 Iteration: 2355 Training loss: 0.06919\n",
      "Epoch: 472/500 Iteration: 2356 Training loss: 0.02521\n",
      "Epoch: 472/500 Iteration: 2357 Training loss: 0.02504\n",
      "Epoch: 472/500 Iteration: 2358 Training loss: 0.03082\n",
      "Epoch: 472/500 Iteration: 2359 Training loss: 0.10055\n",
      "Epoch: 471/500 Iteration: 2360 Validation Acc: 0.6733\n",
      "Epoch: 473/500 Iteration: 2360 Training loss: 0.08846\n",
      "Epoch: 473/500 Iteration: 2361 Training loss: 0.01843\n",
      "Epoch: 473/500 Iteration: 2362 Training loss: 0.02363\n",
      "Epoch: 473/500 Iteration: 2363 Training loss: 0.01854\n",
      "Epoch: 473/500 Iteration: 2364 Training loss: 0.08389\n",
      "Epoch: 472/500 Iteration: 2365 Validation Acc: 0.6600\n",
      "Epoch: 474/500 Iteration: 2365 Training loss: 0.07272\n",
      "Epoch: 474/500 Iteration: 2366 Training loss: 0.02470\n",
      "Epoch: 474/500 Iteration: 2367 Training loss: 0.02016\n",
      "Epoch: 474/500 Iteration: 2368 Training loss: 0.02546\n",
      "Epoch: 474/500 Iteration: 2369 Training loss: 0.12810\n",
      "Epoch: 473/500 Iteration: 2370 Validation Acc: 0.7267\n",
      "Epoch: 475/500 Iteration: 2370 Training loss: 0.04458\n",
      "Epoch: 475/500 Iteration: 2371 Training loss: 0.02031\n",
      "Epoch: 475/500 Iteration: 2372 Training loss: 0.02005\n",
      "Epoch: 475/500 Iteration: 2373 Training loss: 0.03367\n",
      "Epoch: 475/500 Iteration: 2374 Training loss: 0.05337\n",
      "Epoch: 474/500 Iteration: 2375 Validation Acc: 0.7133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 476/500 Iteration: 2375 Training loss: 0.05240\n",
      "Epoch: 476/500 Iteration: 2376 Training loss: 0.04109\n",
      "Epoch: 476/500 Iteration: 2377 Training loss: 0.02145\n",
      "Epoch: 476/500 Iteration: 2378 Training loss: 0.01740\n",
      "Epoch: 476/500 Iteration: 2379 Training loss: 0.14797\n",
      "Epoch: 475/500 Iteration: 2380 Validation Acc: 0.6667\n",
      "Epoch: 477/500 Iteration: 2380 Training loss: 0.07942\n",
      "Epoch: 477/500 Iteration: 2381 Training loss: 0.02105\n",
      "Epoch: 477/500 Iteration: 2382 Training loss: 0.02211\n",
      "Epoch: 477/500 Iteration: 2383 Training loss: 0.02477\n",
      "Epoch: 477/500 Iteration: 2384 Training loss: 0.05111\n",
      "Epoch: 476/500 Iteration: 2385 Validation Acc: 0.7067\n",
      "Epoch: 478/500 Iteration: 2385 Training loss: 0.05960\n",
      "Epoch: 478/500 Iteration: 2386 Training loss: 0.02956\n",
      "Epoch: 478/500 Iteration: 2387 Training loss: 0.02350\n",
      "Epoch: 478/500 Iteration: 2388 Training loss: 0.02398\n",
      "Epoch: 478/500 Iteration: 2389 Training loss: 0.13902\n",
      "Epoch: 477/500 Iteration: 2390 Validation Acc: 0.7000\n",
      "Epoch: 479/500 Iteration: 2390 Training loss: 0.06364\n",
      "Epoch: 479/500 Iteration: 2391 Training loss: 0.01886\n",
      "Epoch: 479/500 Iteration: 2392 Training loss: 0.01619\n",
      "Epoch: 479/500 Iteration: 2393 Training loss: 0.02301\n",
      "Epoch: 479/500 Iteration: 2394 Training loss: 0.10579\n",
      "Epoch: 478/500 Iteration: 2395 Validation Acc: 0.6533\n",
      "Epoch: 480/500 Iteration: 2395 Training loss: 0.09567\n",
      "Epoch: 480/500 Iteration: 2396 Training loss: 0.02271\n",
      "Epoch: 480/500 Iteration: 2397 Training loss: 0.04742\n",
      "Epoch: 480/500 Iteration: 2398 Training loss: 0.03348\n",
      "Epoch: 480/500 Iteration: 2399 Training loss: 0.07509\n",
      "Epoch: 479/500 Iteration: 2400 Validation Acc: 0.6667\n",
      "Epoch: 481/500 Iteration: 2400 Training loss: 0.06474\n",
      "Epoch: 481/500 Iteration: 2401 Training loss: 0.02863\n",
      "Epoch: 481/500 Iteration: 2402 Training loss: 0.03770\n",
      "Epoch: 481/500 Iteration: 2403 Training loss: 0.02464\n",
      "Epoch: 481/500 Iteration: 2404 Training loss: 0.10601\n",
      "Epoch: 480/500 Iteration: 2405 Validation Acc: 0.6867\n",
      "Epoch: 482/500 Iteration: 2405 Training loss: 0.06009\n",
      "Epoch: 482/500 Iteration: 2406 Training loss: 0.01984\n",
      "Epoch: 482/500 Iteration: 2407 Training loss: 0.03303\n",
      "Epoch: 482/500 Iteration: 2408 Training loss: 0.02385\n",
      "Epoch: 482/500 Iteration: 2409 Training loss: 0.07096\n",
      "Epoch: 481/500 Iteration: 2410 Validation Acc: 0.7133\n",
      "Epoch: 483/500 Iteration: 2410 Training loss: 0.05111\n",
      "Epoch: 483/500 Iteration: 2411 Training loss: 0.01673\n",
      "Epoch: 483/500 Iteration: 2412 Training loss: 0.02244\n",
      "Epoch: 483/500 Iteration: 2413 Training loss: 0.02122\n",
      "Epoch: 483/500 Iteration: 2414 Training loss: 0.11779\n",
      "Epoch: 482/500 Iteration: 2415 Validation Acc: 0.6733\n",
      "Epoch: 484/500 Iteration: 2415 Training loss: 0.05274\n",
      "Epoch: 484/500 Iteration: 2416 Training loss: 0.03186\n",
      "Epoch: 484/500 Iteration: 2417 Training loss: 0.03486\n",
      "Epoch: 484/500 Iteration: 2418 Training loss: 0.03075\n",
      "Epoch: 484/500 Iteration: 2419 Training loss: 0.11330\n",
      "Epoch: 483/500 Iteration: 2420 Validation Acc: 0.7067\n",
      "Epoch: 485/500 Iteration: 2420 Training loss: 0.06306\n",
      "Epoch: 485/500 Iteration: 2421 Training loss: 0.01664\n",
      "Epoch: 485/500 Iteration: 2422 Training loss: 0.03442\n",
      "Epoch: 485/500 Iteration: 2423 Training loss: 0.01811\n",
      "Epoch: 485/500 Iteration: 2424 Training loss: 0.08356\n",
      "Epoch: 484/500 Iteration: 2425 Validation Acc: 0.6933\n",
      "Epoch: 486/500 Iteration: 2425 Training loss: 0.05886\n",
      "Epoch: 486/500 Iteration: 2426 Training loss: 0.03302\n",
      "Epoch: 486/500 Iteration: 2427 Training loss: 0.02077\n",
      "Epoch: 486/500 Iteration: 2428 Training loss: 0.02535\n",
      "Epoch: 486/500 Iteration: 2429 Training loss: 0.07514\n",
      "Epoch: 485/500 Iteration: 2430 Validation Acc: 0.7000\n",
      "Epoch: 487/500 Iteration: 2430 Training loss: 0.05574\n",
      "Epoch: 487/500 Iteration: 2431 Training loss: 0.01825\n",
      "Epoch: 487/500 Iteration: 2432 Training loss: 0.01874\n",
      "Epoch: 487/500 Iteration: 2433 Training loss: 0.02517\n",
      "Epoch: 487/500 Iteration: 2434 Training loss: 0.07607\n",
      "Epoch: 486/500 Iteration: 2435 Validation Acc: 0.7200\n",
      "Epoch: 488/500 Iteration: 2435 Training loss: 0.06172\n",
      "Epoch: 488/500 Iteration: 2436 Training loss: 0.02565\n",
      "Epoch: 488/500 Iteration: 2437 Training loss: 0.02210\n",
      "Epoch: 488/500 Iteration: 2438 Training loss: 0.02697\n",
      "Epoch: 488/500 Iteration: 2439 Training loss: 0.08498\n",
      "Epoch: 487/500 Iteration: 2440 Validation Acc: 0.6933\n",
      "Epoch: 489/500 Iteration: 2440 Training loss: 0.04453\n",
      "Epoch: 489/500 Iteration: 2441 Training loss: 0.01234\n",
      "Epoch: 489/500 Iteration: 2442 Training loss: 0.01653\n",
      "Epoch: 489/500 Iteration: 2443 Training loss: 0.01982\n",
      "Epoch: 489/500 Iteration: 2444 Training loss: 0.07086\n",
      "Epoch: 488/500 Iteration: 2445 Validation Acc: 0.6933\n",
      "Epoch: 490/500 Iteration: 2445 Training loss: 0.03555\n",
      "Epoch: 490/500 Iteration: 2446 Training loss: 0.02828\n",
      "Epoch: 490/500 Iteration: 2447 Training loss: 0.02160\n",
      "Epoch: 490/500 Iteration: 2448 Training loss: 0.01264\n",
      "Epoch: 490/500 Iteration: 2449 Training loss: 0.09766\n",
      "Epoch: 489/500 Iteration: 2450 Validation Acc: 0.6800\n",
      "Epoch: 491/500 Iteration: 2450 Training loss: 0.10372\n",
      "Epoch: 491/500 Iteration: 2451 Training loss: 0.02366\n",
      "Epoch: 491/500 Iteration: 2452 Training loss: 0.02361\n",
      "Epoch: 491/500 Iteration: 2453 Training loss: 0.03462\n",
      "Epoch: 491/500 Iteration: 2454 Training loss: 0.09741\n",
      "Epoch: 490/500 Iteration: 2455 Validation Acc: 0.6933\n",
      "Epoch: 492/500 Iteration: 2455 Training loss: 0.03908\n",
      "Epoch: 492/500 Iteration: 2456 Training loss: 0.02530\n",
      "Epoch: 492/500 Iteration: 2457 Training loss: 0.02415\n",
      "Epoch: 492/500 Iteration: 2458 Training loss: 0.02621\n",
      "Epoch: 492/500 Iteration: 2459 Training loss: 0.07183\n",
      "Epoch: 491/500 Iteration: 2460 Validation Acc: 0.7067\n",
      "Epoch: 493/500 Iteration: 2460 Training loss: 0.05930\n",
      "Epoch: 493/500 Iteration: 2461 Training loss: 0.02335\n",
      "Epoch: 493/500 Iteration: 2462 Training loss: 0.02505\n",
      "Epoch: 493/500 Iteration: 2463 Training loss: 0.01789\n",
      "Epoch: 493/500 Iteration: 2464 Training loss: 0.09642\n",
      "Epoch: 492/500 Iteration: 2465 Validation Acc: 0.6933\n",
      "Epoch: 494/500 Iteration: 2465 Training loss: 0.04493\n",
      "Epoch: 494/500 Iteration: 2466 Training loss: 0.01264\n",
      "Epoch: 494/500 Iteration: 2467 Training loss: 0.01718\n",
      "Epoch: 494/500 Iteration: 2468 Training loss: 0.02719\n",
      "Epoch: 494/500 Iteration: 2469 Training loss: 0.07538\n",
      "Epoch: 493/500 Iteration: 2470 Validation Acc: 0.7133\n",
      "Epoch: 495/500 Iteration: 2470 Training loss: 0.07457\n",
      "Epoch: 495/500 Iteration: 2471 Training loss: 0.01833\n",
      "Epoch: 495/500 Iteration: 2472 Training loss: 0.01392\n",
      "Epoch: 495/500 Iteration: 2473 Training loss: 0.01723\n",
      "Epoch: 495/500 Iteration: 2474 Training loss: 0.06952\n",
      "Epoch: 494/500 Iteration: 2475 Validation Acc: 0.7000\n",
      "Epoch: 496/500 Iteration: 2475 Training loss: 0.03797\n",
      "Epoch: 496/500 Iteration: 2476 Training loss: 0.01924\n",
      "Epoch: 496/500 Iteration: 2477 Training loss: 0.01474\n",
      "Epoch: 496/500 Iteration: 2478 Training loss: 0.01550\n",
      "Epoch: 496/500 Iteration: 2479 Training loss: 0.08603\n",
      "Epoch: 495/500 Iteration: 2480 Validation Acc: 0.7200\n",
      "Epoch: 497/500 Iteration: 2480 Training loss: 0.03738\n",
      "Epoch: 497/500 Iteration: 2481 Training loss: 0.02835\n",
      "Epoch: 497/500 Iteration: 2482 Training loss: 0.02341\n",
      "Epoch: 497/500 Iteration: 2483 Training loss: 0.02795\n",
      "Epoch: 497/500 Iteration: 2484 Training loss: 0.06937\n",
      "Epoch: 496/500 Iteration: 2485 Validation Acc: 0.7133\n",
      "Epoch: 498/500 Iteration: 2485 Training loss: 0.05153\n",
      "Epoch: 498/500 Iteration: 2486 Training loss: 0.02804\n",
      "Epoch: 498/500 Iteration: 2487 Training loss: 0.03070\n",
      "Epoch: 498/500 Iteration: 2488 Training loss: 0.01963\n",
      "Epoch: 498/500 Iteration: 2489 Training loss: 0.06572\n",
      "Epoch: 497/500 Iteration: 2490 Validation Acc: 0.7333\n",
      "Epoch: 499/500 Iteration: 2490 Training loss: 0.05289\n",
      "Epoch: 499/500 Iteration: 2491 Training loss: 0.02932\n",
      "Epoch: 499/500 Iteration: 2492 Training loss: 0.01079\n",
      "Epoch: 499/500 Iteration: 2493 Training loss: 0.01528\n",
      "Epoch: 499/500 Iteration: 2494 Training loss: 0.13015\n",
      "Epoch: 498/500 Iteration: 2495 Validation Acc: 0.7000\n",
      "Epoch: 500/500 Iteration: 2495 Training loss: 0.03611\n",
      "Epoch: 500/500 Iteration: 2496 Training loss: 0.01517\n",
      "Epoch: 500/500 Iteration: 2497 Training loss: 0.03751\n",
      "Epoch: 500/500 Iteration: 2498 Training loss: 0.02539\n",
      "Epoch: 500/500 Iteration: 2499 Training loss: 0.08896\n",
      "Epoch: 499/500 Iteration: 2500 Validation Acc: 0.6533\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "\n",
    "epochs = 500\n",
    "iteration = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y, n_batches=5):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x, labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    saver.save(sess, \"checkpoints/skin_diseases.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/skin_diseases.ckpt\n",
      "Test accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
