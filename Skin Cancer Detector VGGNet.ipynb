{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow_vgg'...\n",
      "remote: Counting objects: 113, done.\u001b[K\n",
      "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 113\u001b[K\n",
      "Receiving objects: 100% (113/113), 55.91 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# Operations for floydhub\n",
    "# !git clone https://github.com/machrisaa/tensorflow-vgg tensorflow_vgg\n",
    "# !ln -s /data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "vgg_dir = 'tensorflow_vgg/'\n",
    "vgg_name = 'vgg19'\n",
    "\n",
    "# Make sure vgg exists\n",
    "if not isdir(vgg_dir):\n",
    "    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "vgg_param_file = '{}{}.npy'.format(vgg_dir, vgg_name)\n",
    "if not isfile(vgg_param_file):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc= vgg_name + ' Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/{}.npy'.format(vgg_name),\n",
    "            vgg_param_file,\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg19\n",
    "# from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "classes = [d for d in os.listdir(train_dir) if os.path.isdir(train_dir + d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage.transform import resize\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image\n",
    "\n",
    "def vertical_flip(image):\n",
    "    image = image[::-1, :, :]\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, angle_range=(0, 180)):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.randint(*angle_range)\n",
    "    image = rotate(image, angle)\n",
    "    image = resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: melanoma, 4 / 374 images processed. data count: 20\n",
      "data: train, class: melanoma, 8 / 374 images processed. data count: 40\n",
      "data: train, class: melanoma, 12 / 374 images processed. data count: 60\n",
      "data: train, class: melanoma, 16 / 374 images processed. data count: 80\n",
      "data: train, class: melanoma, 20 / 374 images processed. data count: 100\n",
      "data: train, class: melanoma, 24 / 374 images processed. data count: 120\n",
      "data: train, class: melanoma, 28 / 374 images processed. data count: 140\n",
      "data: train, class: melanoma, 32 / 374 images processed. data count: 160\n",
      "data: train, class: melanoma, 36 / 374 images processed. data count: 180\n",
      "data: train, class: melanoma, 40 / 374 images processed. data count: 200\n",
      "data: train, class: melanoma, 44 / 374 images processed. data count: 220\n",
      "data: train, class: melanoma, 48 / 374 images processed. data count: 240\n",
      "data: train, class: melanoma, 52 / 374 images processed. data count: 260\n",
      "data: train, class: melanoma, 56 / 374 images processed. data count: 280\n",
      "data: train, class: melanoma, 60 / 374 images processed. data count: 300\n",
      "data: train, class: melanoma, 64 / 374 images processed. data count: 320\n",
      "data: train, class: melanoma, 68 / 374 images processed. data count: 340\n",
      "data: train, class: melanoma, 72 / 374 images processed. data count: 360\n",
      "data: train, class: melanoma, 76 / 374 images processed. data count: 380\n",
      "data: train, class: melanoma, 80 / 374 images processed. data count: 400\n",
      "data: train, class: melanoma, 84 / 374 images processed. data count: 420\n",
      "data: train, class: melanoma, 88 / 374 images processed. data count: 440\n",
      "data: train, class: melanoma, 92 / 374 images processed. data count: 460\n",
      "data: train, class: melanoma, 96 / 374 images processed. data count: 480\n",
      "data: train, class: melanoma, 100 / 374 images processed. data count: 500\n",
      "data: train, class: melanoma, 104 / 374 images processed. data count: 520\n",
      "data: train, class: melanoma, 108 / 374 images processed. data count: 540\n",
      "data: train, class: melanoma, 112 / 374 images processed. data count: 560\n",
      "data: train, class: melanoma, 116 / 374 images processed. data count: 580\n",
      "data: train, class: melanoma, 120 / 374 images processed. data count: 600\n",
      "data: train, class: melanoma, 124 / 374 images processed. data count: 620\n",
      "data: train, class: melanoma, 128 / 374 images processed. data count: 640\n",
      "data: train, class: melanoma, 132 / 374 images processed. data count: 660\n",
      "data: train, class: melanoma, 136 / 374 images processed. data count: 680\n",
      "data: train, class: melanoma, 140 / 374 images processed. data count: 700\n",
      "data: train, class: melanoma, 144 / 374 images processed. data count: 720\n",
      "data: train, class: melanoma, 148 / 374 images processed. data count: 740\n",
      "data: train, class: melanoma, 152 / 374 images processed. data count: 760\n",
      "data: train, class: melanoma, 156 / 374 images processed. data count: 780\n",
      "data: train, class: melanoma, 160 / 374 images processed. data count: 800\n",
      "data: train, class: melanoma, 164 / 374 images processed. data count: 820\n",
      "data: train, class: melanoma, 168 / 374 images processed. data count: 840\n",
      "data: train, class: melanoma, 172 / 374 images processed. data count: 860\n",
      "data: train, class: melanoma, 176 / 374 images processed. data count: 880\n",
      "data: train, class: melanoma, 180 / 374 images processed. data count: 900\n",
      "data: train, class: melanoma, 184 / 374 images processed. data count: 920\n",
      "data: train, class: melanoma, 188 / 374 images processed. data count: 940\n",
      "data: train, class: melanoma, 192 / 374 images processed. data count: 960\n",
      "data: train, class: melanoma, 196 / 374 images processed. data count: 980\n",
      "data: train, class: melanoma, 200 / 374 images processed. data count: 1000\n",
      "data: train, class: melanoma, 204 / 374 images processed. data count: 1020\n",
      "data: train, class: melanoma, 208 / 374 images processed. data count: 1040\n",
      "data: train, class: melanoma, 212 / 374 images processed. data count: 1060\n",
      "data: train, class: melanoma, 216 / 374 images processed. data count: 1080\n",
      "data: train, class: melanoma, 220 / 374 images processed. data count: 1100\n",
      "data: train, class: melanoma, 224 / 374 images processed. data count: 1120\n",
      "data: train, class: melanoma, 228 / 374 images processed. data count: 1140\n",
      "data: train, class: melanoma, 232 / 374 images processed. data count: 1160\n",
      "data: train, class: melanoma, 236 / 374 images processed. data count: 1180\n",
      "data: train, class: melanoma, 240 / 374 images processed. data count: 1200\n",
      "data: train, class: melanoma, 244 / 374 images processed. data count: 1220\n",
      "data: train, class: melanoma, 248 / 374 images processed. data count: 1240\n",
      "data: train, class: melanoma, 252 / 374 images processed. data count: 1260\n",
      "data: train, class: melanoma, 256 / 374 images processed. data count: 1280\n",
      "data: train, class: melanoma, 260 / 374 images processed. data count: 1300\n",
      "data: train, class: melanoma, 264 / 374 images processed. data count: 1320\n",
      "data: train, class: melanoma, 268 / 374 images processed. data count: 1340\n",
      "data: train, class: melanoma, 272 / 374 images processed. data count: 1360\n",
      "data: train, class: melanoma, 276 / 374 images processed. data count: 1380\n",
      "data: train, class: melanoma, 280 / 374 images processed. data count: 1400\n",
      "data: train, class: melanoma, 284 / 374 images processed. data count: 1420\n",
      "data: train, class: melanoma, 288 / 374 images processed. data count: 1440\n",
      "data: train, class: melanoma, 292 / 374 images processed. data count: 1460\n",
      "data: train, class: melanoma, 296 / 374 images processed. data count: 1480\n",
      "data: train, class: melanoma, 300 / 374 images processed. data count: 1500\n",
      "data: train, class: melanoma, 304 / 374 images processed. data count: 1520\n",
      "data: train, class: melanoma, 308 / 374 images processed. data count: 1540\n",
      "data: train, class: melanoma, 312 / 374 images processed. data count: 1560\n",
      "data: train, class: melanoma, 316 / 374 images processed. data count: 1580\n",
      "data: train, class: melanoma, 320 / 374 images processed. data count: 1600\n",
      "data: train, class: melanoma, 324 / 374 images processed. data count: 1620\n",
      "data: train, class: melanoma, 328 / 374 images processed. data count: 1640\n",
      "data: train, class: melanoma, 332 / 374 images processed. data count: 1660\n",
      "data: train, class: melanoma, 336 / 374 images processed. data count: 1680\n",
      "data: train, class: melanoma, 340 / 374 images processed. data count: 1700\n",
      "data: train, class: melanoma, 344 / 374 images processed. data count: 1720\n",
      "data: train, class: melanoma, 348 / 374 images processed. data count: 1740\n",
      "data: train, class: melanoma, 352 / 374 images processed. data count: 1760\n",
      "data: train, class: melanoma, 356 / 374 images processed. data count: 1780\n",
      "data: train, class: melanoma, 360 / 374 images processed. data count: 1800\n",
      "data: train, class: melanoma, 364 / 374 images processed. data count: 1820\n",
      "data: train, class: melanoma, 368 / 374 images processed. data count: 1840\n",
      "data: train, class: melanoma, 372 / 374 images processed. data count: 1860\n",
      "data: train, class: melanoma, 374 / 374 images processed. data count: 1870\n",
      "data: train, class: nevus, 20 / 1372 images processed. data count: 1890\n",
      "data: train, class: nevus, 40 / 1372 images processed. data count: 1910\n",
      "data: train, class: nevus, 60 / 1372 images processed. data count: 1930\n",
      "data: train, class: nevus, 80 / 1372 images processed. data count: 1950\n",
      "data: train, class: nevus, 100 / 1372 images processed. data count: 1970\n",
      "data: train, class: nevus, 120 / 1372 images processed. data count: 1990\n",
      "data: train, class: nevus, 140 / 1372 images processed. data count: 2010\n",
      "data: train, class: nevus, 160 / 1372 images processed. data count: 2030\n",
      "data: train, class: nevus, 180 / 1372 images processed. data count: 2050\n",
      "data: train, class: nevus, 200 / 1372 images processed. data count: 2070\n",
      "data: train, class: nevus, 220 / 1372 images processed. data count: 2090\n",
      "data: train, class: nevus, 240 / 1372 images processed. data count: 2110\n",
      "data: train, class: nevus, 260 / 1372 images processed. data count: 2130\n",
      "data: train, class: nevus, 280 / 1372 images processed. data count: 2150\n",
      "data: train, class: nevus, 300 / 1372 images processed. data count: 2170\n",
      "data: train, class: nevus, 320 / 1372 images processed. data count: 2190\n",
      "data: train, class: nevus, 340 / 1372 images processed. data count: 2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: nevus, 360 / 1372 images processed. data count: 2230\n",
      "data: train, class: nevus, 380 / 1372 images processed. data count: 2250\n",
      "data: train, class: nevus, 400 / 1372 images processed. data count: 2270\n",
      "data: train, class: nevus, 420 / 1372 images processed. data count: 2290\n",
      "data: train, class: nevus, 440 / 1372 images processed. data count: 2310\n",
      "data: train, class: nevus, 460 / 1372 images processed. data count: 2330\n",
      "data: train, class: nevus, 480 / 1372 images processed. data count: 2350\n",
      "data: train, class: nevus, 500 / 1372 images processed. data count: 2370\n",
      "data: train, class: nevus, 520 / 1372 images processed. data count: 2390\n",
      "data: train, class: nevus, 540 / 1372 images processed. data count: 2410\n",
      "data: train, class: nevus, 560 / 1372 images processed. data count: 2430\n",
      "data: train, class: nevus, 580 / 1372 images processed. data count: 2450\n",
      "data: train, class: nevus, 600 / 1372 images processed. data count: 2470\n",
      "data: train, class: nevus, 620 / 1372 images processed. data count: 2490\n",
      "data: train, class: nevus, 640 / 1372 images processed. data count: 2510\n",
      "data: train, class: nevus, 660 / 1372 images processed. data count: 2530\n",
      "data: train, class: nevus, 680 / 1372 images processed. data count: 2550\n",
      "data: train, class: nevus, 700 / 1372 images processed. data count: 2570\n",
      "data: train, class: nevus, 720 / 1372 images processed. data count: 2590\n",
      "data: train, class: nevus, 740 / 1372 images processed. data count: 2610\n",
      "data: train, class: nevus, 760 / 1372 images processed. data count: 2630\n",
      "data: train, class: nevus, 780 / 1372 images processed. data count: 2650\n",
      "data: train, class: nevus, 800 / 1372 images processed. data count: 2670\n",
      "data: train, class: nevus, 820 / 1372 images processed. data count: 2690\n",
      "data: train, class: nevus, 840 / 1372 images processed. data count: 2710\n",
      "data: train, class: nevus, 860 / 1372 images processed. data count: 2730\n",
      "data: train, class: nevus, 880 / 1372 images processed. data count: 2750\n",
      "data: train, class: nevus, 900 / 1372 images processed. data count: 2770\n",
      "data: train, class: nevus, 920 / 1372 images processed. data count: 2790\n",
      "data: train, class: nevus, 940 / 1372 images processed. data count: 2810\n",
      "data: train, class: nevus, 960 / 1372 images processed. data count: 2830\n",
      "data: train, class: nevus, 980 / 1372 images processed. data count: 2850\n",
      "data: train, class: nevus, 1000 / 1372 images processed. data count: 2870\n",
      "data: train, class: nevus, 1020 / 1372 images processed. data count: 2890\n",
      "data: train, class: nevus, 1040 / 1372 images processed. data count: 2910\n",
      "data: train, class: nevus, 1060 / 1372 images processed. data count: 2930\n",
      "data: train, class: nevus, 1080 / 1372 images processed. data count: 2950\n",
      "data: train, class: nevus, 1100 / 1372 images processed. data count: 2970\n",
      "data: train, class: nevus, 1120 / 1372 images processed. data count: 2990\n",
      "data: train, class: nevus, 1140 / 1372 images processed. data count: 3010\n",
      "data: train, class: nevus, 1160 / 1372 images processed. data count: 3030\n",
      "data: train, class: nevus, 1180 / 1372 images processed. data count: 3050\n",
      "data: train, class: nevus, 1200 / 1372 images processed. data count: 3070\n",
      "data: train, class: nevus, 1220 / 1372 images processed. data count: 3090\n",
      "data: train, class: nevus, 1240 / 1372 images processed. data count: 3110\n",
      "data: train, class: nevus, 1260 / 1372 images processed. data count: 3130\n",
      "data: train, class: nevus, 1280 / 1372 images processed. data count: 3150\n",
      "data: train, class: nevus, 1300 / 1372 images processed. data count: 3170\n",
      "data: train, class: nevus, 1320 / 1372 images processed. data count: 3190\n",
      "data: train, class: nevus, 1340 / 1372 images processed. data count: 3210\n",
      "data: train, class: nevus, 1360 / 1372 images processed. data count: 3230\n",
      "data: train, class: nevus, 1372 / 1372 images processed. data count: 3242\n",
      "data: train, class: seborrheic_keratosis, 4 / 254 images processed. data count: 3262\n",
      "data: train, class: seborrheic_keratosis, 8 / 254 images processed. data count: 3282\n",
      "data: train, class: seborrheic_keratosis, 12 / 254 images processed. data count: 3302\n",
      "data: train, class: seborrheic_keratosis, 16 / 254 images processed. data count: 3322\n",
      "data: train, class: seborrheic_keratosis, 20 / 254 images processed. data count: 3342\n",
      "data: train, class: seborrheic_keratosis, 24 / 254 images processed. data count: 3362\n",
      "data: train, class: seborrheic_keratosis, 28 / 254 images processed. data count: 3382\n",
      "data: train, class: seborrheic_keratosis, 32 / 254 images processed. data count: 3402\n",
      "data: train, class: seborrheic_keratosis, 36 / 254 images processed. data count: 3422\n",
      "data: train, class: seborrheic_keratosis, 40 / 254 images processed. data count: 3442\n",
      "data: train, class: seborrheic_keratosis, 44 / 254 images processed. data count: 3462\n",
      "data: train, class: seborrheic_keratosis, 48 / 254 images processed. data count: 3482\n",
      "data: train, class: seborrheic_keratosis, 52 / 254 images processed. data count: 3502\n",
      "data: train, class: seborrheic_keratosis, 56 / 254 images processed. data count: 3522\n",
      "data: train, class: seborrheic_keratosis, 60 / 254 images processed. data count: 3542\n",
      "data: train, class: seborrheic_keratosis, 64 / 254 images processed. data count: 3562\n",
      "data: train, class: seborrheic_keratosis, 68 / 254 images processed. data count: 3582\n",
      "data: train, class: seborrheic_keratosis, 72 / 254 images processed. data count: 3602\n",
      "data: train, class: seborrheic_keratosis, 76 / 254 images processed. data count: 3622\n",
      "data: train, class: seborrheic_keratosis, 80 / 254 images processed. data count: 3642\n",
      "data: train, class: seborrheic_keratosis, 84 / 254 images processed. data count: 3662\n",
      "data: train, class: seborrheic_keratosis, 88 / 254 images processed. data count: 3682\n",
      "data: train, class: seborrheic_keratosis, 92 / 254 images processed. data count: 3702\n",
      "data: train, class: seborrheic_keratosis, 96 / 254 images processed. data count: 3722\n",
      "data: train, class: seborrheic_keratosis, 100 / 254 images processed. data count: 3742\n",
      "data: train, class: seborrheic_keratosis, 104 / 254 images processed. data count: 3762\n",
      "data: train, class: seborrheic_keratosis, 108 / 254 images processed. data count: 3782\n",
      "data: train, class: seborrheic_keratosis, 112 / 254 images processed. data count: 3802\n",
      "data: train, class: seborrheic_keratosis, 116 / 254 images processed. data count: 3822\n",
      "data: train, class: seborrheic_keratosis, 120 / 254 images processed. data count: 3842\n",
      "data: train, class: seborrheic_keratosis, 124 / 254 images processed. data count: 3862\n",
      "data: train, class: seborrheic_keratosis, 128 / 254 images processed. data count: 3882\n",
      "data: train, class: seborrheic_keratosis, 132 / 254 images processed. data count: 3902\n",
      "data: train, class: seborrheic_keratosis, 136 / 254 images processed. data count: 3922\n",
      "data: train, class: seborrheic_keratosis, 140 / 254 images processed. data count: 3942\n",
      "data: train, class: seborrheic_keratosis, 144 / 254 images processed. data count: 3962\n",
      "data: train, class: seborrheic_keratosis, 148 / 254 images processed. data count: 3982\n",
      "data: train, class: seborrheic_keratosis, 152 / 254 images processed. data count: 4002\n",
      "data: train, class: seborrheic_keratosis, 156 / 254 images processed. data count: 4022\n",
      "data: train, class: seborrheic_keratosis, 160 / 254 images processed. data count: 4042\n",
      "data: train, class: seborrheic_keratosis, 164 / 254 images processed. data count: 4062\n",
      "data: train, class: seborrheic_keratosis, 168 / 254 images processed. data count: 4082\n",
      "data: train, class: seborrheic_keratosis, 172 / 254 images processed. data count: 4102\n",
      "data: train, class: seborrheic_keratosis, 176 / 254 images processed. data count: 4122\n",
      "data: train, class: seborrheic_keratosis, 180 / 254 images processed. data count: 4142\n",
      "data: train, class: seborrheic_keratosis, 184 / 254 images processed. data count: 4162\n",
      "data: train, class: seborrheic_keratosis, 188 / 254 images processed. data count: 4182\n",
      "data: train, class: seborrheic_keratosis, 192 / 254 images processed. data count: 4202\n",
      "data: train, class: seborrheic_keratosis, 196 / 254 images processed. data count: 4222\n",
      "data: train, class: seborrheic_keratosis, 200 / 254 images processed. data count: 4242\n",
      "data: train, class: seborrheic_keratosis, 204 / 254 images processed. data count: 4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: seborrheic_keratosis, 208 / 254 images processed. data count: 4282\n",
      "data: train, class: seborrheic_keratosis, 212 / 254 images processed. data count: 4302\n",
      "data: train, class: seborrheic_keratosis, 216 / 254 images processed. data count: 4322\n",
      "data: train, class: seborrheic_keratosis, 220 / 254 images processed. data count: 4342\n",
      "data: train, class: seborrheic_keratosis, 224 / 254 images processed. data count: 4362\n",
      "data: train, class: seborrheic_keratosis, 228 / 254 images processed. data count: 4382\n",
      "data: train, class: seborrheic_keratosis, 232 / 254 images processed. data count: 4402\n",
      "data: train, class: seborrheic_keratosis, 236 / 254 images processed. data count: 4422\n",
      "data: train, class: seborrheic_keratosis, 240 / 254 images processed. data count: 4442\n",
      "data: train, class: seborrheic_keratosis, 244 / 254 images processed. data count: 4462\n",
      "data: train, class: seborrheic_keratosis, 248 / 254 images processed. data count: 4482\n",
      "data: train, class: seborrheic_keratosis, 252 / 254 images processed. data count: 4502\n",
      "data: train, class: seborrheic_keratosis, 254 / 254 images processed. data count: 4512\n",
      "data: valid, class: melanoma, 20 / 30 images processed. data count: 20\n",
      "data: valid, class: melanoma, 30 / 30 images processed. data count: 30\n",
      "data: valid, class: nevus, 20 / 78 images processed. data count: 50\n",
      "data: valid, class: nevus, 40 / 78 images processed. data count: 70\n",
      "data: valid, class: nevus, 60 / 78 images processed. data count: 90\n",
      "data: valid, class: nevus, 78 / 78 images processed. data count: 108\n",
      "data: valid, class: seborrheic_keratosis, 20 / 42 images processed. data count: 128\n",
      "data: valid, class: seborrheic_keratosis, 40 / 42 images processed. data count: 148\n",
      "data: valid, class: seborrheic_keratosis, 42 / 42 images processed. data count: 150\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    \n",
    "    codes = None\n",
    "    labels = []\n",
    "    count = 0\n",
    "\n",
    "    for d_type in ['train', 'valid']:\n",
    "        for c in classes:\n",
    "            image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "            files = os.listdir(image_dir)\n",
    "            for i, file in enumerate(files, 1):\n",
    "                # load image and resize it to 224x224\n",
    "                file_path = os.path.join(image_dir, file)\n",
    "                img = utils.load_image(file_path)\n",
    "                batch.append(img.reshape((1, 224, 224, 3)))\n",
    "                labels.append(c)\n",
    "                \n",
    "                # data augumentation for all training data but nevus\n",
    "                if d_type == 'train' and c != 'nevus':\n",
    "                    batch.append(horizontal_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(vertical_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img, angle_range=(-180, 0)).reshape((1,224,224,3)))\n",
    "                    labels.append(c)                  \n",
    "\n",
    "                if (len(batch) >= batch_size) or i == len(files):\n",
    "                    images = np.concatenate(batch)\n",
    "\n",
    "                    feed_dict = {input_: images}\n",
    "                    codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "\n",
    "                    if codes is None:\n",
    "                        codes = codes_batch\n",
    "                    else:\n",
    "                        codes = np.concatenate((codes, codes_batch))\n",
    "\n",
    "                    count += len(batch)\n",
    "                    batch = []\n",
    "                    print('data: {}, class: {}, {} / {} images processed. data count: {}'.format(d_type, c, i, len(files), count))\n",
    "\n",
    "        # write codes to file\n",
    "        with open('{}_{}_codes'.format(vgg_name, d_type), 'w') as f:\n",
    "            codes.tofile(f)\n",
    "            codes = None\n",
    "\n",
    "        # write labels to file\n",
    "        with open('{}_{}_labels'.format(vgg_name, d_type), 'w') as f:\n",
    "            writer = csv.writer(f, delimiter='\\n')\n",
    "            writer.writerow(labels)\n",
    "            labels = []\n",
    "\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read codes and labels from file\n",
    "import csv\n",
    "\n",
    "# train data\n",
    "with open('{}_train_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    train_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_train_codes'.format(vgg_name)) as f:\n",
    "    train_x = np.fromfile(f, dtype=np.float32)\n",
    "    train_x = train_x.reshape((len(train_labels), -1))\n",
    "    \n",
    "# valid data\n",
    "with open('{}_valid_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    valid_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_valid_codes'.format(vgg_name)) as f:\n",
    "    val_x = np.fromfile(f, dtype=np.float32)\n",
    "    val_x = val_x.reshape((len(valid_labels), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = lb.transform(train_labels)\n",
    "val_y = lb.transform(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (4512, 4096) (4512, 3)\n",
      "Validation shapes (x, y): (150, 4096) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, train_y.shape[1]])\n",
    "\n",
    "fc_1 = tf.contrib.layers.fully_connected(inputs_, 512)\n",
    "dropout_1 = tf.contrib.layers.dropout(fc_1)\n",
    "fc_2 = tf.contrib.layers.fully_connected(dropout_1, 128)\n",
    "dropout_2 = tf.contrib.layers.dropout(fc_2)\n",
    "    \n",
    "logits = tf.contrib.layers.fully_connected(dropout_2, train_y.shape[1], activation_fn=None)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001).minimize(cost)\n",
    "\n",
    "predicted = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: checkpoints: File exists\n",
      "Epoch: 1/200 Iteration: 0 Training loss: 5.23779\n",
      "Epoch: 1/200 Iteration: 1 Training loss: 1.97346\n",
      "Epoch: 1/200 Iteration: 2 Training loss: 6.24877\n",
      "Epoch: 1/200 Iteration: 3 Training loss: 5.39357\n",
      "Epoch: 1/200 Iteration: 4 Training loss: 7.22553\n",
      "Epoch: 0/200 Iteration: 5 Validation Acc: 0.3800\n",
      "Epoch: 2/200 Iteration: 5 Training loss: 6.33785\n",
      "Epoch: 2/200 Iteration: 6 Training loss: 2.43058\n",
      "Epoch: 2/200 Iteration: 7 Training loss: 5.21402\n",
      "Epoch: 2/200 Iteration: 8 Training loss: 3.90930\n",
      "Epoch: 2/200 Iteration: 9 Training loss: 4.93757\n",
      "Epoch: 1/200 Iteration: 10 Validation Acc: 0.3667\n",
      "Epoch: 3/200 Iteration: 10 Training loss: 5.60263\n",
      "Epoch: 3/200 Iteration: 11 Training loss: 2.10260\n",
      "Epoch: 3/200 Iteration: 12 Training loss: 4.20100\n",
      "Epoch: 3/200 Iteration: 13 Training loss: 3.14641\n",
      "Epoch: 3/200 Iteration: 14 Training loss: 4.06061\n",
      "Epoch: 2/200 Iteration: 15 Validation Acc: 0.4067\n",
      "Epoch: 4/200 Iteration: 15 Training loss: 4.26958\n",
      "Epoch: 4/200 Iteration: 16 Training loss: 1.96384\n",
      "Epoch: 4/200 Iteration: 17 Training loss: 3.07067\n",
      "Epoch: 4/200 Iteration: 18 Training loss: 2.61326\n",
      "Epoch: 4/200 Iteration: 19 Training loss: 3.48440\n",
      "Epoch: 3/200 Iteration: 20 Validation Acc: 0.3533\n",
      "Epoch: 5/200 Iteration: 20 Training loss: 3.38044\n",
      "Epoch: 5/200 Iteration: 21 Training loss: 1.60074\n",
      "Epoch: 5/200 Iteration: 22 Training loss: 2.65941\n",
      "Epoch: 5/200 Iteration: 23 Training loss: 2.05662\n",
      "Epoch: 5/200 Iteration: 24 Training loss: 2.98884\n",
      "Epoch: 4/200 Iteration: 25 Validation Acc: 0.4067\n",
      "Epoch: 6/200 Iteration: 25 Training loss: 3.14680\n",
      "Epoch: 6/200 Iteration: 26 Training loss: 1.50437\n",
      "Epoch: 6/200 Iteration: 27 Training loss: 2.24466\n",
      "Epoch: 6/200 Iteration: 28 Training loss: 1.99183\n",
      "Epoch: 6/200 Iteration: 29 Training loss: 2.71607\n",
      "Epoch: 5/200 Iteration: 30 Validation Acc: 0.3933\n",
      "Epoch: 7/200 Iteration: 30 Training loss: 2.58833\n",
      "Epoch: 7/200 Iteration: 31 Training loss: 1.43174\n",
      "Epoch: 7/200 Iteration: 32 Training loss: 2.01240\n",
      "Epoch: 7/200 Iteration: 33 Training loss: 1.71886\n",
      "Epoch: 7/200 Iteration: 34 Training loss: 2.34739\n",
      "Epoch: 6/200 Iteration: 35 Validation Acc: 0.3667\n",
      "Epoch: 8/200 Iteration: 35 Training loss: 2.50163\n",
      "Epoch: 8/200 Iteration: 36 Training loss: 1.26570\n",
      "Epoch: 8/200 Iteration: 37 Training loss: 1.73281\n",
      "Epoch: 8/200 Iteration: 38 Training loss: 1.60153\n",
      "Epoch: 8/200 Iteration: 39 Training loss: 2.19941\n",
      "Epoch: 7/200 Iteration: 40 Validation Acc: 0.4133\n",
      "Epoch: 9/200 Iteration: 40 Training loss: 2.04580\n",
      "Epoch: 9/200 Iteration: 41 Training loss: 1.28288\n",
      "Epoch: 9/200 Iteration: 42 Training loss: 1.74565\n",
      "Epoch: 9/200 Iteration: 43 Training loss: 1.46152\n",
      "Epoch: 9/200 Iteration: 44 Training loss: 2.04544\n",
      "Epoch: 8/200 Iteration: 45 Validation Acc: 0.3933\n",
      "Epoch: 10/200 Iteration: 45 Training loss: 1.87057\n",
      "Epoch: 10/200 Iteration: 46 Training loss: 1.09422\n",
      "Epoch: 10/200 Iteration: 47 Training loss: 1.48346\n",
      "Epoch: 10/200 Iteration: 48 Training loss: 1.42196\n",
      "Epoch: 10/200 Iteration: 49 Training loss: 1.83437\n",
      "Epoch: 9/200 Iteration: 50 Validation Acc: 0.3933\n",
      "Epoch: 11/200 Iteration: 50 Training loss: 1.75362\n",
      "Epoch: 11/200 Iteration: 51 Training loss: 1.10360\n",
      "Epoch: 11/200 Iteration: 52 Training loss: 1.42630\n",
      "Epoch: 11/200 Iteration: 53 Training loss: 1.41063\n",
      "Epoch: 11/200 Iteration: 54 Training loss: 1.70481\n",
      "Epoch: 10/200 Iteration: 55 Validation Acc: 0.4000\n",
      "Epoch: 12/200 Iteration: 55 Training loss: 1.71262\n",
      "Epoch: 12/200 Iteration: 56 Training loss: 1.01088\n",
      "Epoch: 12/200 Iteration: 57 Training loss: 1.53271\n",
      "Epoch: 12/200 Iteration: 58 Training loss: 1.31310\n",
      "Epoch: 12/200 Iteration: 59 Training loss: 1.64218\n",
      "Epoch: 11/200 Iteration: 60 Validation Acc: 0.3933\n",
      "Epoch: 13/200 Iteration: 60 Training loss: 1.66904\n",
      "Epoch: 13/200 Iteration: 61 Training loss: 0.95091\n",
      "Epoch: 13/200 Iteration: 62 Training loss: 1.23040\n",
      "Epoch: 13/200 Iteration: 63 Training loss: 1.54411\n",
      "Epoch: 13/200 Iteration: 64 Training loss: 1.65660\n",
      "Epoch: 12/200 Iteration: 65 Validation Acc: 0.3467\n",
      "Epoch: 14/200 Iteration: 65 Training loss: 1.55381\n",
      "Epoch: 14/200 Iteration: 66 Training loss: 0.87331\n",
      "Epoch: 14/200 Iteration: 67 Training loss: 1.46473\n",
      "Epoch: 14/200 Iteration: 68 Training loss: 1.43623\n",
      "Epoch: 14/200 Iteration: 69 Training loss: 1.73473\n",
      "Epoch: 13/200 Iteration: 70 Validation Acc: 0.4133\n",
      "Epoch: 15/200 Iteration: 70 Training loss: 1.69700\n",
      "Epoch: 15/200 Iteration: 71 Training loss: 0.91545\n",
      "Epoch: 15/200 Iteration: 72 Training loss: 1.35628\n",
      "Epoch: 15/200 Iteration: 73 Training loss: 1.42518\n",
      "Epoch: 15/200 Iteration: 74 Training loss: 1.41929\n",
      "Epoch: 14/200 Iteration: 75 Validation Acc: 0.3533\n",
      "Epoch: 16/200 Iteration: 75 Training loss: 2.23671\n",
      "Epoch: 16/200 Iteration: 76 Training loss: 0.76664\n",
      "Epoch: 16/200 Iteration: 77 Training loss: 2.23901\n",
      "Epoch: 16/200 Iteration: 78 Training loss: 1.35183\n",
      "Epoch: 16/200 Iteration: 79 Training loss: 1.42260\n",
      "Epoch: 15/200 Iteration: 80 Validation Acc: 0.3733\n",
      "Epoch: 17/200 Iteration: 80 Training loss: 1.81668\n",
      "Epoch: 17/200 Iteration: 81 Training loss: 0.73765\n",
      "Epoch: 17/200 Iteration: 82 Training loss: 2.52959\n",
      "Epoch: 17/200 Iteration: 83 Training loss: 1.38926\n",
      "Epoch: 17/200 Iteration: 84 Training loss: 1.45126\n",
      "Epoch: 16/200 Iteration: 85 Validation Acc: 0.3067\n",
      "Epoch: 18/200 Iteration: 85 Training loss: 2.69835\n",
      "Epoch: 18/200 Iteration: 86 Training loss: 0.76119\n",
      "Epoch: 18/200 Iteration: 87 Training loss: 1.65072\n",
      "Epoch: 18/200 Iteration: 88 Training loss: 1.65675\n",
      "Epoch: 18/200 Iteration: 89 Training loss: 1.51540\n",
      "Epoch: 17/200 Iteration: 90 Validation Acc: 0.2933\n",
      "Epoch: 19/200 Iteration: 90 Training loss: 2.78219\n",
      "Epoch: 19/200 Iteration: 91 Training loss: 0.95899\n",
      "Epoch: 19/200 Iteration: 92 Training loss: 2.03730\n",
      "Epoch: 19/200 Iteration: 93 Training loss: 1.75083\n",
      "Epoch: 19/200 Iteration: 94 Training loss: 1.35323\n",
      "Epoch: 18/200 Iteration: 95 Validation Acc: 0.3200\n",
      "Epoch: 20/200 Iteration: 95 Training loss: 2.22365\n",
      "Epoch: 20/200 Iteration: 96 Training loss: 1.07247\n",
      "Epoch: 20/200 Iteration: 97 Training loss: 0.98496\n",
      "Epoch: 20/200 Iteration: 98 Training loss: 1.55977\n",
      "Epoch: 20/200 Iteration: 99 Training loss: 1.36940\n",
      "Epoch: 19/200 Iteration: 100 Validation Acc: 0.3400\n",
      "Epoch: 21/200 Iteration: 100 Training loss: 1.26039\n",
      "Epoch: 21/200 Iteration: 101 Training loss: 0.88135\n",
      "Epoch: 21/200 Iteration: 102 Training loss: 1.77573\n",
      "Epoch: 21/200 Iteration: 103 Training loss: 2.01769\n",
      "Epoch: 21/200 Iteration: 104 Training loss: 1.81628\n",
      "Epoch: 20/200 Iteration: 105 Validation Acc: 0.3467\n",
      "Epoch: 22/200 Iteration: 105 Training loss: 3.42329\n",
      "Epoch: 22/200 Iteration: 106 Training loss: 0.65137\n",
      "Epoch: 22/200 Iteration: 107 Training loss: 2.33564\n",
      "Epoch: 22/200 Iteration: 108 Training loss: 2.00634\n",
      "Epoch: 22/200 Iteration: 109 Training loss: 2.28848\n",
      "Epoch: 21/200 Iteration: 110 Validation Acc: 0.3267\n",
      "Epoch: 23/200 Iteration: 110 Training loss: 2.25414\n",
      "Epoch: 23/200 Iteration: 111 Training loss: 0.56514\n",
      "Epoch: 23/200 Iteration: 112 Training loss: 2.80766\n",
      "Epoch: 23/200 Iteration: 113 Training loss: 1.81064\n",
      "Epoch: 23/200 Iteration: 114 Training loss: 1.53570\n",
      "Epoch: 22/200 Iteration: 115 Validation Acc: 0.3800\n",
      "Epoch: 24/200 Iteration: 115 Training loss: 2.95449\n",
      "Epoch: 24/200 Iteration: 116 Training loss: 1.19754\n",
      "Epoch: 24/200 Iteration: 117 Training loss: 1.28390\n",
      "Epoch: 24/200 Iteration: 118 Training loss: 1.84370\n",
      "Epoch: 24/200 Iteration: 119 Training loss: 1.74240\n",
      "Epoch: 23/200 Iteration: 120 Validation Acc: 0.3400\n",
      "Epoch: 25/200 Iteration: 120 Training loss: 2.69587\n",
      "Epoch: 25/200 Iteration: 121 Training loss: 0.93050\n",
      "Epoch: 25/200 Iteration: 122 Training loss: 1.64403\n",
      "Epoch: 25/200 Iteration: 123 Training loss: 1.46782\n",
      "Epoch: 25/200 Iteration: 124 Training loss: 1.96300\n",
      "Epoch: 24/200 Iteration: 125 Validation Acc: 0.3867\n",
      "Epoch: 26/200 Iteration: 125 Training loss: 1.43404\n",
      "Epoch: 26/200 Iteration: 126 Training loss: 0.80438\n",
      "Epoch: 26/200 Iteration: 127 Training loss: 2.32842\n",
      "Epoch: 26/200 Iteration: 128 Training loss: 1.34944\n",
      "Epoch: 26/200 Iteration: 129 Training loss: 2.02216\n",
      "Epoch: 25/200 Iteration: 130 Validation Acc: 0.4333\n",
      "Epoch: 27/200 Iteration: 130 Training loss: 1.74929\n",
      "Epoch: 27/200 Iteration: 131 Training loss: 0.81370\n",
      "Epoch: 27/200 Iteration: 132 Training loss: 1.30693\n",
      "Epoch: 27/200 Iteration: 133 Training loss: 1.58117\n",
      "Epoch: 27/200 Iteration: 134 Training loss: 1.67360\n",
      "Epoch: 26/200 Iteration: 135 Validation Acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/200 Iteration: 135 Training loss: 1.40347\n",
      "Epoch: 28/200 Iteration: 136 Training loss: 0.96117\n",
      "Epoch: 28/200 Iteration: 137 Training loss: 1.31112\n",
      "Epoch: 28/200 Iteration: 138 Training loss: 1.61202\n",
      "Epoch: 28/200 Iteration: 139 Training loss: 1.38262\n",
      "Epoch: 27/200 Iteration: 140 Validation Acc: 0.4467\n",
      "Epoch: 29/200 Iteration: 140 Training loss: 1.29445\n",
      "Epoch: 29/200 Iteration: 141 Training loss: 0.96598\n",
      "Epoch: 29/200 Iteration: 142 Training loss: 1.23411\n",
      "Epoch: 29/200 Iteration: 143 Training loss: 1.43669\n",
      "Epoch: 29/200 Iteration: 144 Training loss: 1.29303\n",
      "Epoch: 28/200 Iteration: 145 Validation Acc: 0.3467\n",
      "Epoch: 30/200 Iteration: 145 Training loss: 2.81606\n",
      "Epoch: 30/200 Iteration: 146 Training loss: 0.76225\n",
      "Epoch: 30/200 Iteration: 147 Training loss: 1.34739\n",
      "Epoch: 30/200 Iteration: 148 Training loss: 1.84082\n",
      "Epoch: 30/200 Iteration: 149 Training loss: 1.39079\n",
      "Epoch: 29/200 Iteration: 150 Validation Acc: 0.4200\n",
      "Epoch: 31/200 Iteration: 150 Training loss: 1.69512\n",
      "Epoch: 31/200 Iteration: 151 Training loss: 0.96016\n",
      "Epoch: 31/200 Iteration: 152 Training loss: 1.88947\n",
      "Epoch: 31/200 Iteration: 153 Training loss: 1.28082\n",
      "Epoch: 31/200 Iteration: 154 Training loss: 2.06301\n",
      "Epoch: 30/200 Iteration: 155 Validation Acc: 0.3800\n",
      "Epoch: 32/200 Iteration: 155 Training loss: 1.38612\n",
      "Epoch: 32/200 Iteration: 156 Training loss: 0.96683\n",
      "Epoch: 32/200 Iteration: 157 Training loss: 1.09782\n",
      "Epoch: 32/200 Iteration: 158 Training loss: 1.27526\n",
      "Epoch: 32/200 Iteration: 159 Training loss: 1.79510\n",
      "Epoch: 31/200 Iteration: 160 Validation Acc: 0.4467\n",
      "Epoch: 33/200 Iteration: 160 Training loss: 1.27494\n",
      "Epoch: 33/200 Iteration: 161 Training loss: 0.81478\n",
      "Epoch: 33/200 Iteration: 162 Training loss: 1.59457\n",
      "Epoch: 33/200 Iteration: 163 Training loss: 1.26650\n",
      "Epoch: 33/200 Iteration: 164 Training loss: 1.64452\n",
      "Epoch: 32/200 Iteration: 165 Validation Acc: 0.3733\n",
      "Epoch: 34/200 Iteration: 165 Training loss: 1.41049\n",
      "Epoch: 34/200 Iteration: 166 Training loss: 0.89619\n",
      "Epoch: 34/200 Iteration: 167 Training loss: 1.16066\n",
      "Epoch: 34/200 Iteration: 168 Training loss: 1.21041\n",
      "Epoch: 34/200 Iteration: 169 Training loss: 1.65161\n",
      "Epoch: 33/200 Iteration: 170 Validation Acc: 0.4600\n",
      "Epoch: 35/200 Iteration: 170 Training loss: 1.14138\n",
      "Epoch: 35/200 Iteration: 171 Training loss: 0.97318\n",
      "Epoch: 35/200 Iteration: 172 Training loss: 1.09563\n",
      "Epoch: 35/200 Iteration: 173 Training loss: 1.16712\n",
      "Epoch: 35/200 Iteration: 174 Training loss: 1.53477\n",
      "Epoch: 34/200 Iteration: 175 Validation Acc: 0.4600\n",
      "Epoch: 36/200 Iteration: 175 Training loss: 1.26495\n",
      "Epoch: 36/200 Iteration: 176 Training loss: 0.96637\n",
      "Epoch: 36/200 Iteration: 177 Training loss: 1.14854\n",
      "Epoch: 36/200 Iteration: 178 Training loss: 1.07731\n",
      "Epoch: 36/200 Iteration: 179 Training loss: 1.45225\n",
      "Epoch: 35/200 Iteration: 180 Validation Acc: 0.4333\n",
      "Epoch: 37/200 Iteration: 180 Training loss: 1.08329\n",
      "Epoch: 37/200 Iteration: 181 Training loss: 0.89966\n",
      "Epoch: 37/200 Iteration: 182 Training loss: 0.99360\n",
      "Epoch: 37/200 Iteration: 183 Training loss: 1.07548\n",
      "Epoch: 37/200 Iteration: 184 Training loss: 1.27900\n",
      "Epoch: 36/200 Iteration: 185 Validation Acc: 0.4000\n",
      "Epoch: 38/200 Iteration: 185 Training loss: 1.00521\n",
      "Epoch: 38/200 Iteration: 186 Training loss: 0.95455\n",
      "Epoch: 38/200 Iteration: 187 Training loss: 1.02179\n",
      "Epoch: 38/200 Iteration: 188 Training loss: 1.16646\n",
      "Epoch: 38/200 Iteration: 189 Training loss: 1.34292\n",
      "Epoch: 37/200 Iteration: 190 Validation Acc: 0.4867\n",
      "Epoch: 39/200 Iteration: 190 Training loss: 1.90195\n",
      "Epoch: 39/200 Iteration: 191 Training loss: 0.83119\n",
      "Epoch: 39/200 Iteration: 192 Training loss: 1.22768\n",
      "Epoch: 39/200 Iteration: 193 Training loss: 1.38054\n",
      "Epoch: 39/200 Iteration: 194 Training loss: 1.42209\n",
      "Epoch: 38/200 Iteration: 195 Validation Acc: 0.4533\n",
      "Epoch: 40/200 Iteration: 195 Training loss: 1.26697\n",
      "Epoch: 40/200 Iteration: 196 Training loss: 0.91633\n",
      "Epoch: 40/200 Iteration: 197 Training loss: 0.94900\n",
      "Epoch: 40/200 Iteration: 198 Training loss: 1.13439\n",
      "Epoch: 40/200 Iteration: 199 Training loss: 1.38896\n",
      "Epoch: 39/200 Iteration: 200 Validation Acc: 0.4800\n",
      "Epoch: 41/200 Iteration: 200 Training loss: 1.01925\n",
      "Epoch: 41/200 Iteration: 201 Training loss: 0.92656\n",
      "Epoch: 41/200 Iteration: 202 Training loss: 0.89072\n",
      "Epoch: 41/200 Iteration: 203 Training loss: 1.10268\n",
      "Epoch: 41/200 Iteration: 204 Training loss: 1.36669\n",
      "Epoch: 40/200 Iteration: 205 Validation Acc: 0.4733\n",
      "Epoch: 42/200 Iteration: 205 Training loss: 0.97498\n",
      "Epoch: 42/200 Iteration: 206 Training loss: 0.87814\n",
      "Epoch: 42/200 Iteration: 207 Training loss: 0.86728\n",
      "Epoch: 42/200 Iteration: 208 Training loss: 1.06412\n",
      "Epoch: 42/200 Iteration: 209 Training loss: 1.25752\n",
      "Epoch: 41/200 Iteration: 210 Validation Acc: 0.5067\n",
      "Epoch: 43/200 Iteration: 210 Training loss: 1.02084\n",
      "Epoch: 43/200 Iteration: 211 Training loss: 0.92191\n",
      "Epoch: 43/200 Iteration: 212 Training loss: 0.92624\n",
      "Epoch: 43/200 Iteration: 213 Training loss: 1.01919\n",
      "Epoch: 43/200 Iteration: 214 Training loss: 1.29765\n",
      "Epoch: 42/200 Iteration: 215 Validation Acc: 0.4333\n",
      "Epoch: 44/200 Iteration: 215 Training loss: 1.01526\n",
      "Epoch: 44/200 Iteration: 216 Training loss: 0.83866\n",
      "Epoch: 44/200 Iteration: 217 Training loss: 1.08793\n",
      "Epoch: 44/200 Iteration: 218 Training loss: 1.02675\n",
      "Epoch: 44/200 Iteration: 219 Training loss: 1.21437\n",
      "Epoch: 43/200 Iteration: 220 Validation Acc: 0.4200\n",
      "Epoch: 45/200 Iteration: 220 Training loss: 1.10491\n",
      "Epoch: 45/200 Iteration: 221 Training loss: 0.90650\n",
      "Epoch: 45/200 Iteration: 222 Training loss: 0.85656\n",
      "Epoch: 45/200 Iteration: 223 Training loss: 1.34557\n",
      "Epoch: 45/200 Iteration: 224 Training loss: 1.37328\n",
      "Epoch: 44/200 Iteration: 225 Validation Acc: 0.4667\n",
      "Epoch: 46/200 Iteration: 225 Training loss: 1.01193\n",
      "Epoch: 46/200 Iteration: 226 Training loss: 0.88610\n",
      "Epoch: 46/200 Iteration: 227 Training loss: 0.88623\n",
      "Epoch: 46/200 Iteration: 228 Training loss: 1.17072\n",
      "Epoch: 46/200 Iteration: 229 Training loss: 1.27331\n",
      "Epoch: 45/200 Iteration: 230 Validation Acc: 0.4533\n",
      "Epoch: 47/200 Iteration: 230 Training loss: 0.96183\n",
      "Epoch: 47/200 Iteration: 231 Training loss: 0.93395\n",
      "Epoch: 47/200 Iteration: 232 Training loss: 0.85200\n",
      "Epoch: 47/200 Iteration: 233 Training loss: 0.98781\n",
      "Epoch: 47/200 Iteration: 234 Training loss: 1.37708\n",
      "Epoch: 46/200 Iteration: 235 Validation Acc: 0.5333\n",
      "Epoch: 48/200 Iteration: 235 Training loss: 0.94949\n",
      "Epoch: 48/200 Iteration: 236 Training loss: 0.90158\n",
      "Epoch: 48/200 Iteration: 237 Training loss: 0.84835\n",
      "Epoch: 48/200 Iteration: 238 Training loss: 1.12960\n",
      "Epoch: 48/200 Iteration: 239 Training loss: 1.37191\n",
      "Epoch: 47/200 Iteration: 240 Validation Acc: 0.5000\n",
      "Epoch: 49/200 Iteration: 240 Training loss: 1.01692\n",
      "Epoch: 49/200 Iteration: 241 Training loss: 0.83393\n",
      "Epoch: 49/200 Iteration: 242 Training loss: 0.97544\n",
      "Epoch: 49/200 Iteration: 243 Training loss: 1.08953\n",
      "Epoch: 49/200 Iteration: 244 Training loss: 1.18562\n",
      "Epoch: 48/200 Iteration: 245 Validation Acc: 0.5000\n",
      "Epoch: 50/200 Iteration: 245 Training loss: 0.94514\n",
      "Epoch: 50/200 Iteration: 246 Training loss: 0.85269\n",
      "Epoch: 50/200 Iteration: 247 Training loss: 0.87998\n",
      "Epoch: 50/200 Iteration: 248 Training loss: 1.01050\n",
      "Epoch: 50/200 Iteration: 249 Training loss: 1.21946\n",
      "Epoch: 49/200 Iteration: 250 Validation Acc: 0.4800\n",
      "Epoch: 51/200 Iteration: 250 Training loss: 0.93627\n",
      "Epoch: 51/200 Iteration: 251 Training loss: 0.86441\n",
      "Epoch: 51/200 Iteration: 252 Training loss: 0.91161\n",
      "Epoch: 51/200 Iteration: 253 Training loss: 1.01735\n",
      "Epoch: 51/200 Iteration: 254 Training loss: 1.16903\n",
      "Epoch: 50/200 Iteration: 255 Validation Acc: 0.4733\n",
      "Epoch: 52/200 Iteration: 255 Training loss: 0.90692\n",
      "Epoch: 52/200 Iteration: 256 Training loss: 0.79327\n",
      "Epoch: 52/200 Iteration: 257 Training loss: 0.90687\n",
      "Epoch: 52/200 Iteration: 258 Training loss: 1.10358\n",
      "Epoch: 52/200 Iteration: 259 Training loss: 1.21641\n",
      "Epoch: 51/200 Iteration: 260 Validation Acc: 0.5200\n",
      "Epoch: 53/200 Iteration: 260 Training loss: 0.89479\n",
      "Epoch: 53/200 Iteration: 261 Training loss: 0.80512\n",
      "Epoch: 53/200 Iteration: 262 Training loss: 0.85434\n",
      "Epoch: 53/200 Iteration: 263 Training loss: 1.02315\n",
      "Epoch: 53/200 Iteration: 264 Training loss: 1.23140\n",
      "Epoch: 52/200 Iteration: 265 Validation Acc: 0.5000\n",
      "Epoch: 54/200 Iteration: 265 Training loss: 0.91597\n",
      "Epoch: 54/200 Iteration: 266 Training loss: 0.90513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/200 Iteration: 267 Training loss: 0.80207\n",
      "Epoch: 54/200 Iteration: 268 Training loss: 1.04284\n",
      "Epoch: 54/200 Iteration: 269 Training loss: 1.13804\n",
      "Epoch: 53/200 Iteration: 270 Validation Acc: 0.4733\n",
      "Epoch: 55/200 Iteration: 270 Training loss: 0.88984\n",
      "Epoch: 55/200 Iteration: 271 Training loss: 0.85937\n",
      "Epoch: 55/200 Iteration: 272 Training loss: 0.77311\n",
      "Epoch: 55/200 Iteration: 273 Training loss: 0.94825\n",
      "Epoch: 55/200 Iteration: 274 Training loss: 1.18981\n",
      "Epoch: 54/200 Iteration: 275 Validation Acc: 0.5667\n",
      "Epoch: 56/200 Iteration: 275 Training loss: 0.85379\n",
      "Epoch: 56/200 Iteration: 276 Training loss: 0.79655\n",
      "Epoch: 56/200 Iteration: 277 Training loss: 0.91052\n",
      "Epoch: 56/200 Iteration: 278 Training loss: 1.00056\n",
      "Epoch: 56/200 Iteration: 279 Training loss: 1.24287\n",
      "Epoch: 55/200 Iteration: 280 Validation Acc: 0.4533\n",
      "Epoch: 57/200 Iteration: 280 Training loss: 0.88537\n",
      "Epoch: 57/200 Iteration: 281 Training loss: 0.83137\n",
      "Epoch: 57/200 Iteration: 282 Training loss: 0.93088\n",
      "Epoch: 57/200 Iteration: 283 Training loss: 0.99657\n",
      "Epoch: 57/200 Iteration: 284 Training loss: 1.15527\n",
      "Epoch: 56/200 Iteration: 285 Validation Acc: 0.5400\n",
      "Epoch: 58/200 Iteration: 285 Training loss: 0.86281\n",
      "Epoch: 58/200 Iteration: 286 Training loss: 0.84239\n",
      "Epoch: 58/200 Iteration: 287 Training loss: 0.71934\n",
      "Epoch: 58/200 Iteration: 288 Training loss: 1.02091\n",
      "Epoch: 58/200 Iteration: 289 Training loss: 1.19489\n",
      "Epoch: 57/200 Iteration: 290 Validation Acc: 0.4333\n",
      "Epoch: 59/200 Iteration: 290 Training loss: 0.85274\n",
      "Epoch: 59/200 Iteration: 291 Training loss: 0.84563\n",
      "Epoch: 59/200 Iteration: 292 Training loss: 0.83890\n",
      "Epoch: 59/200 Iteration: 293 Training loss: 0.98593\n",
      "Epoch: 59/200 Iteration: 294 Training loss: 1.27855\n",
      "Epoch: 58/200 Iteration: 295 Validation Acc: 0.4933\n",
      "Epoch: 60/200 Iteration: 295 Training loss: 0.84705\n",
      "Epoch: 60/200 Iteration: 296 Training loss: 0.84451\n",
      "Epoch: 60/200 Iteration: 297 Training loss: 0.86115\n",
      "Epoch: 60/200 Iteration: 298 Training loss: 0.94362\n",
      "Epoch: 60/200 Iteration: 299 Training loss: 1.08161\n",
      "Epoch: 59/200 Iteration: 300 Validation Acc: 0.5067\n",
      "Epoch: 61/200 Iteration: 300 Training loss: 0.84209\n",
      "Epoch: 61/200 Iteration: 301 Training loss: 0.81468\n",
      "Epoch: 61/200 Iteration: 302 Training loss: 0.80400\n",
      "Epoch: 61/200 Iteration: 303 Training loss: 0.91788\n",
      "Epoch: 61/200 Iteration: 304 Training loss: 1.03130\n",
      "Epoch: 60/200 Iteration: 305 Validation Acc: 0.5400\n",
      "Epoch: 62/200 Iteration: 305 Training loss: 0.86089\n",
      "Epoch: 62/200 Iteration: 306 Training loss: 0.86775\n",
      "Epoch: 62/200 Iteration: 307 Training loss: 0.75070\n",
      "Epoch: 62/200 Iteration: 308 Training loss: 0.87852\n",
      "Epoch: 62/200 Iteration: 309 Training loss: 1.06751\n",
      "Epoch: 61/200 Iteration: 310 Validation Acc: 0.5667\n",
      "Epoch: 63/200 Iteration: 310 Training loss: 0.83421\n",
      "Epoch: 63/200 Iteration: 311 Training loss: 0.82857\n",
      "Epoch: 63/200 Iteration: 312 Training loss: 0.78359\n",
      "Epoch: 63/200 Iteration: 313 Training loss: 0.91050\n",
      "Epoch: 63/200 Iteration: 314 Training loss: 0.98895\n",
      "Epoch: 62/200 Iteration: 315 Validation Acc: 0.5200\n",
      "Epoch: 64/200 Iteration: 315 Training loss: 0.84853\n",
      "Epoch: 64/200 Iteration: 316 Training loss: 0.87211\n",
      "Epoch: 64/200 Iteration: 317 Training loss: 0.74574\n",
      "Epoch: 64/200 Iteration: 318 Training loss: 0.89234\n",
      "Epoch: 64/200 Iteration: 319 Training loss: 1.17431\n",
      "Epoch: 63/200 Iteration: 320 Validation Acc: 0.5067\n",
      "Epoch: 65/200 Iteration: 320 Training loss: 0.81001\n",
      "Epoch: 65/200 Iteration: 321 Training loss: 0.81364\n",
      "Epoch: 65/200 Iteration: 322 Training loss: 0.78197\n",
      "Epoch: 65/200 Iteration: 323 Training loss: 0.91582\n",
      "Epoch: 65/200 Iteration: 324 Training loss: 1.00318\n",
      "Epoch: 64/200 Iteration: 325 Validation Acc: 0.5133\n",
      "Epoch: 66/200 Iteration: 325 Training loss: 0.83230\n",
      "Epoch: 66/200 Iteration: 326 Training loss: 0.83980\n",
      "Epoch: 66/200 Iteration: 327 Training loss: 0.70473\n",
      "Epoch: 66/200 Iteration: 328 Training loss: 1.01276\n",
      "Epoch: 66/200 Iteration: 329 Training loss: 1.01523\n",
      "Epoch: 65/200 Iteration: 330 Validation Acc: 0.5000\n",
      "Epoch: 67/200 Iteration: 330 Training loss: 0.84400\n",
      "Epoch: 67/200 Iteration: 331 Training loss: 0.78959\n",
      "Epoch: 67/200 Iteration: 332 Training loss: 0.87277\n",
      "Epoch: 67/200 Iteration: 333 Training loss: 0.87176\n",
      "Epoch: 67/200 Iteration: 334 Training loss: 1.03221\n",
      "Epoch: 66/200 Iteration: 335 Validation Acc: 0.5000\n",
      "Epoch: 68/200 Iteration: 335 Training loss: 0.84001\n",
      "Epoch: 68/200 Iteration: 336 Training loss: 0.87892\n",
      "Epoch: 68/200 Iteration: 337 Training loss: 0.76361\n",
      "Epoch: 68/200 Iteration: 338 Training loss: 0.85853\n",
      "Epoch: 68/200 Iteration: 339 Training loss: 1.07765\n",
      "Epoch: 67/200 Iteration: 340 Validation Acc: 0.5333\n",
      "Epoch: 69/200 Iteration: 340 Training loss: 0.80841\n",
      "Epoch: 69/200 Iteration: 341 Training loss: 0.81883\n",
      "Epoch: 69/200 Iteration: 342 Training loss: 0.76472\n",
      "Epoch: 69/200 Iteration: 343 Training loss: 0.93238\n",
      "Epoch: 69/200 Iteration: 344 Training loss: 1.00694\n",
      "Epoch: 68/200 Iteration: 345 Validation Acc: 0.5733\n",
      "Epoch: 70/200 Iteration: 345 Training loss: 0.82932\n",
      "Epoch: 70/200 Iteration: 346 Training loss: 0.85335\n",
      "Epoch: 70/200 Iteration: 347 Training loss: 0.69138\n",
      "Epoch: 70/200 Iteration: 348 Training loss: 0.87137\n",
      "Epoch: 70/200 Iteration: 349 Training loss: 0.97060\n",
      "Epoch: 69/200 Iteration: 350 Validation Acc: 0.5333\n",
      "Epoch: 71/200 Iteration: 350 Training loss: 0.80061\n",
      "Epoch: 71/200 Iteration: 351 Training loss: 0.84353\n",
      "Epoch: 71/200 Iteration: 352 Training loss: 0.68447\n",
      "Epoch: 71/200 Iteration: 353 Training loss: 0.88016\n",
      "Epoch: 71/200 Iteration: 354 Training loss: 1.08434\n",
      "Epoch: 70/200 Iteration: 355 Validation Acc: 0.4933\n",
      "Epoch: 72/200 Iteration: 355 Training loss: 0.84137\n",
      "Epoch: 72/200 Iteration: 356 Training loss: 0.83548\n",
      "Epoch: 72/200 Iteration: 357 Training loss: 0.70644\n",
      "Epoch: 72/200 Iteration: 358 Training loss: 0.86231\n",
      "Epoch: 72/200 Iteration: 359 Training loss: 0.93350\n",
      "Epoch: 71/200 Iteration: 360 Validation Acc: 0.4867\n",
      "Epoch: 73/200 Iteration: 360 Training loss: 0.84129\n",
      "Epoch: 73/200 Iteration: 361 Training loss: 0.81596\n",
      "Epoch: 73/200 Iteration: 362 Training loss: 0.72464\n",
      "Epoch: 73/200 Iteration: 363 Training loss: 0.85287\n",
      "Epoch: 73/200 Iteration: 364 Training loss: 1.17132\n",
      "Epoch: 72/200 Iteration: 365 Validation Acc: 0.4467\n",
      "Epoch: 74/200 Iteration: 365 Training loss: 0.79176\n",
      "Epoch: 74/200 Iteration: 366 Training loss: 0.83476\n",
      "Epoch: 74/200 Iteration: 367 Training loss: 0.75963\n",
      "Epoch: 74/200 Iteration: 368 Training loss: 0.89912\n",
      "Epoch: 74/200 Iteration: 369 Training loss: 0.94096\n",
      "Epoch: 73/200 Iteration: 370 Validation Acc: 0.5667\n",
      "Epoch: 75/200 Iteration: 370 Training loss: 0.83150\n",
      "Epoch: 75/200 Iteration: 371 Training loss: 0.86266\n",
      "Epoch: 75/200 Iteration: 372 Training loss: 0.74399\n",
      "Epoch: 75/200 Iteration: 373 Training loss: 0.78109\n",
      "Epoch: 75/200 Iteration: 374 Training loss: 0.87374\n",
      "Epoch: 74/200 Iteration: 375 Validation Acc: 0.5400\n",
      "Epoch: 76/200 Iteration: 375 Training loss: 0.72679\n",
      "Epoch: 76/200 Iteration: 376 Training loss: 0.80535\n",
      "Epoch: 76/200 Iteration: 377 Training loss: 0.80874\n",
      "Epoch: 76/200 Iteration: 378 Training loss: 0.82902\n",
      "Epoch: 76/200 Iteration: 379 Training loss: 0.91540\n",
      "Epoch: 75/200 Iteration: 380 Validation Acc: 0.5667\n",
      "Epoch: 77/200 Iteration: 380 Training loss: 0.78981\n",
      "Epoch: 77/200 Iteration: 381 Training loss: 0.79699\n",
      "Epoch: 77/200 Iteration: 382 Training loss: 0.66304\n",
      "Epoch: 77/200 Iteration: 383 Training loss: 0.83614\n",
      "Epoch: 77/200 Iteration: 384 Training loss: 0.99476\n",
      "Epoch: 76/200 Iteration: 385 Validation Acc: 0.5867\n",
      "Epoch: 78/200 Iteration: 385 Training loss: 0.73973\n",
      "Epoch: 78/200 Iteration: 386 Training loss: 0.82329\n",
      "Epoch: 78/200 Iteration: 387 Training loss: 0.67064\n",
      "Epoch: 78/200 Iteration: 388 Training loss: 0.86108\n",
      "Epoch: 78/200 Iteration: 389 Training loss: 0.97886\n",
      "Epoch: 77/200 Iteration: 390 Validation Acc: 0.5733\n",
      "Epoch: 79/200 Iteration: 390 Training loss: 0.79071\n",
      "Epoch: 79/200 Iteration: 391 Training loss: 0.82054\n",
      "Epoch: 79/200 Iteration: 392 Training loss: 0.68867\n",
      "Epoch: 79/200 Iteration: 393 Training loss: 0.78025\n",
      "Epoch: 79/200 Iteration: 394 Training loss: 0.85413\n",
      "Epoch: 78/200 Iteration: 395 Validation Acc: 0.5600\n",
      "Epoch: 80/200 Iteration: 395 Training loss: 0.77187\n",
      "Epoch: 80/200 Iteration: 396 Training loss: 0.86015\n",
      "Epoch: 80/200 Iteration: 397 Training loss: 0.66836\n",
      "Epoch: 80/200 Iteration: 398 Training loss: 0.79777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/200 Iteration: 399 Training loss: 0.93193\n",
      "Epoch: 79/200 Iteration: 400 Validation Acc: 0.5800\n",
      "Epoch: 81/200 Iteration: 400 Training loss: 0.73594\n",
      "Epoch: 81/200 Iteration: 401 Training loss: 0.76353\n",
      "Epoch: 81/200 Iteration: 402 Training loss: 0.70293\n",
      "Epoch: 81/200 Iteration: 403 Training loss: 0.82544\n",
      "Epoch: 81/200 Iteration: 404 Training loss: 0.87920\n",
      "Epoch: 80/200 Iteration: 405 Validation Acc: 0.5467\n",
      "Epoch: 82/200 Iteration: 405 Training loss: 0.74637\n",
      "Epoch: 82/200 Iteration: 406 Training loss: 0.81496\n",
      "Epoch: 82/200 Iteration: 407 Training loss: 0.66350\n",
      "Epoch: 82/200 Iteration: 408 Training loss: 0.74137\n",
      "Epoch: 82/200 Iteration: 409 Training loss: 0.91872\n",
      "Epoch: 81/200 Iteration: 410 Validation Acc: 0.6400\n",
      "Epoch: 83/200 Iteration: 410 Training loss: 0.75587\n",
      "Epoch: 83/200 Iteration: 411 Training loss: 0.78569\n",
      "Epoch: 83/200 Iteration: 412 Training loss: 0.69100\n",
      "Epoch: 83/200 Iteration: 413 Training loss: 0.71996\n",
      "Epoch: 83/200 Iteration: 414 Training loss: 0.93235\n",
      "Epoch: 82/200 Iteration: 415 Validation Acc: 0.5600\n",
      "Epoch: 84/200 Iteration: 415 Training loss: 0.74847\n",
      "Epoch: 84/200 Iteration: 416 Training loss: 0.78430\n",
      "Epoch: 84/200 Iteration: 417 Training loss: 0.70832\n",
      "Epoch: 84/200 Iteration: 418 Training loss: 0.76921\n",
      "Epoch: 84/200 Iteration: 419 Training loss: 0.92914\n",
      "Epoch: 83/200 Iteration: 420 Validation Acc: 0.5267\n",
      "Epoch: 85/200 Iteration: 420 Training loss: 0.69903\n",
      "Epoch: 85/200 Iteration: 421 Training loss: 0.76719\n",
      "Epoch: 85/200 Iteration: 422 Training loss: 0.71415\n",
      "Epoch: 85/200 Iteration: 423 Training loss: 0.78798\n",
      "Epoch: 85/200 Iteration: 424 Training loss: 0.85246\n",
      "Epoch: 84/200 Iteration: 425 Validation Acc: 0.5733\n",
      "Epoch: 86/200 Iteration: 425 Training loss: 0.72854\n",
      "Epoch: 86/200 Iteration: 426 Training loss: 0.75230\n",
      "Epoch: 86/200 Iteration: 427 Training loss: 0.62300\n",
      "Epoch: 86/200 Iteration: 428 Training loss: 0.82312\n",
      "Epoch: 86/200 Iteration: 429 Training loss: 0.84111\n",
      "Epoch: 85/200 Iteration: 430 Validation Acc: 0.5933\n",
      "Epoch: 87/200 Iteration: 430 Training loss: 0.68388\n",
      "Epoch: 87/200 Iteration: 431 Training loss: 0.78227\n",
      "Epoch: 87/200 Iteration: 432 Training loss: 0.65513\n",
      "Epoch: 87/200 Iteration: 433 Training loss: 0.72377\n",
      "Epoch: 87/200 Iteration: 434 Training loss: 0.82990\n",
      "Epoch: 86/200 Iteration: 435 Validation Acc: 0.5467\n",
      "Epoch: 88/200 Iteration: 435 Training loss: 0.74587\n",
      "Epoch: 88/200 Iteration: 436 Training loss: 0.80135\n",
      "Epoch: 88/200 Iteration: 437 Training loss: 0.62725\n",
      "Epoch: 88/200 Iteration: 438 Training loss: 0.73091\n",
      "Epoch: 88/200 Iteration: 439 Training loss: 0.81767\n",
      "Epoch: 87/200 Iteration: 440 Validation Acc: 0.5733\n",
      "Epoch: 89/200 Iteration: 440 Training loss: 0.68322\n",
      "Epoch: 89/200 Iteration: 441 Training loss: 0.74221\n",
      "Epoch: 89/200 Iteration: 442 Training loss: 0.65067\n",
      "Epoch: 89/200 Iteration: 443 Training loss: 0.69636\n",
      "Epoch: 89/200 Iteration: 444 Training loss: 0.82782\n",
      "Epoch: 88/200 Iteration: 445 Validation Acc: 0.5667\n",
      "Epoch: 90/200 Iteration: 445 Training loss: 0.71646\n",
      "Epoch: 90/200 Iteration: 446 Training loss: 0.76760\n",
      "Epoch: 90/200 Iteration: 447 Training loss: 0.68172\n",
      "Epoch: 90/200 Iteration: 448 Training loss: 0.72948\n",
      "Epoch: 90/200 Iteration: 449 Training loss: 0.81412\n",
      "Epoch: 89/200 Iteration: 450 Validation Acc: 0.6533\n",
      "Epoch: 91/200 Iteration: 450 Training loss: 0.70669\n",
      "Epoch: 91/200 Iteration: 451 Training loss: 0.78457\n",
      "Epoch: 91/200 Iteration: 452 Training loss: 0.58735\n",
      "Epoch: 91/200 Iteration: 453 Training loss: 0.74621\n",
      "Epoch: 91/200 Iteration: 454 Training loss: 0.92547\n",
      "Epoch: 90/200 Iteration: 455 Validation Acc: 0.5133\n",
      "Epoch: 92/200 Iteration: 455 Training loss: 0.68308\n",
      "Epoch: 92/200 Iteration: 456 Training loss: 0.77534\n",
      "Epoch: 92/200 Iteration: 457 Training loss: 0.61567\n",
      "Epoch: 92/200 Iteration: 458 Training loss: 0.72442\n",
      "Epoch: 92/200 Iteration: 459 Training loss: 0.81350\n",
      "Epoch: 91/200 Iteration: 460 Validation Acc: 0.5733\n",
      "Epoch: 93/200 Iteration: 460 Training loss: 0.66354\n",
      "Epoch: 93/200 Iteration: 461 Training loss: 0.74939\n",
      "Epoch: 93/200 Iteration: 462 Training loss: 0.60498\n",
      "Epoch: 93/200 Iteration: 463 Training loss: 0.69339\n",
      "Epoch: 93/200 Iteration: 464 Training loss: 0.73156\n",
      "Epoch: 92/200 Iteration: 465 Validation Acc: 0.5933\n",
      "Epoch: 94/200 Iteration: 465 Training loss: 0.69614\n",
      "Epoch: 94/200 Iteration: 466 Training loss: 0.75283\n",
      "Epoch: 94/200 Iteration: 467 Training loss: 0.67922\n",
      "Epoch: 94/200 Iteration: 468 Training loss: 0.67536\n",
      "Epoch: 94/200 Iteration: 469 Training loss: 0.76302\n",
      "Epoch: 93/200 Iteration: 470 Validation Acc: 0.5933\n",
      "Epoch: 95/200 Iteration: 470 Training loss: 0.74206\n",
      "Epoch: 95/200 Iteration: 471 Training loss: 0.74458\n",
      "Epoch: 95/200 Iteration: 472 Training loss: 0.66265\n",
      "Epoch: 95/200 Iteration: 473 Training loss: 0.66381\n",
      "Epoch: 95/200 Iteration: 474 Training loss: 0.74000\n",
      "Epoch: 94/200 Iteration: 475 Validation Acc: 0.6067\n",
      "Epoch: 96/200 Iteration: 475 Training loss: 0.75858\n",
      "Epoch: 96/200 Iteration: 476 Training loss: 0.71586\n",
      "Epoch: 96/200 Iteration: 477 Training loss: 0.64009\n",
      "Epoch: 96/200 Iteration: 478 Training loss: 0.67359\n",
      "Epoch: 96/200 Iteration: 479 Training loss: 0.73808\n",
      "Epoch: 95/200 Iteration: 480 Validation Acc: 0.6067\n",
      "Epoch: 97/200 Iteration: 480 Training loss: 0.63810\n",
      "Epoch: 97/200 Iteration: 481 Training loss: 0.78431\n",
      "Epoch: 97/200 Iteration: 482 Training loss: 0.63058\n",
      "Epoch: 97/200 Iteration: 483 Training loss: 0.66188\n",
      "Epoch: 97/200 Iteration: 484 Training loss: 0.73667\n",
      "Epoch: 96/200 Iteration: 485 Validation Acc: 0.6133\n",
      "Epoch: 98/200 Iteration: 485 Training loss: 0.65973\n",
      "Epoch: 98/200 Iteration: 486 Training loss: 0.71912\n",
      "Epoch: 98/200 Iteration: 487 Training loss: 0.59786\n",
      "Epoch: 98/200 Iteration: 488 Training loss: 0.66154\n",
      "Epoch: 98/200 Iteration: 489 Training loss: 0.78181\n",
      "Epoch: 97/200 Iteration: 490 Validation Acc: 0.6000\n",
      "Epoch: 99/200 Iteration: 490 Training loss: 0.64534\n",
      "Epoch: 99/200 Iteration: 491 Training loss: 0.68872\n",
      "Epoch: 99/200 Iteration: 492 Training loss: 0.54053\n",
      "Epoch: 99/200 Iteration: 493 Training loss: 0.72152\n",
      "Epoch: 99/200 Iteration: 494 Training loss: 0.82363\n",
      "Epoch: 98/200 Iteration: 495 Validation Acc: 0.6200\n",
      "Epoch: 100/200 Iteration: 495 Training loss: 0.64358\n",
      "Epoch: 100/200 Iteration: 496 Training loss: 0.76319\n",
      "Epoch: 100/200 Iteration: 497 Training loss: 0.54169\n",
      "Epoch: 100/200 Iteration: 498 Training loss: 0.65562\n",
      "Epoch: 100/200 Iteration: 499 Training loss: 0.68073\n",
      "Epoch: 99/200 Iteration: 500 Validation Acc: 0.6533\n",
      "Epoch: 101/200 Iteration: 500 Training loss: 0.63990\n",
      "Epoch: 101/200 Iteration: 501 Training loss: 0.71976\n",
      "Epoch: 101/200 Iteration: 502 Training loss: 0.58439\n",
      "Epoch: 101/200 Iteration: 503 Training loss: 0.60545\n",
      "Epoch: 101/200 Iteration: 504 Training loss: 0.74916\n",
      "Epoch: 100/200 Iteration: 505 Validation Acc: 0.6133\n",
      "Epoch: 102/200 Iteration: 505 Training loss: 0.64263\n",
      "Epoch: 102/200 Iteration: 506 Training loss: 0.72817\n",
      "Epoch: 102/200 Iteration: 507 Training loss: 0.54801\n",
      "Epoch: 102/200 Iteration: 508 Training loss: 0.64541\n",
      "Epoch: 102/200 Iteration: 509 Training loss: 0.77022\n",
      "Epoch: 101/200 Iteration: 510 Validation Acc: 0.6267\n",
      "Epoch: 103/200 Iteration: 510 Training loss: 0.62979\n",
      "Epoch: 103/200 Iteration: 511 Training loss: 0.72647\n",
      "Epoch: 103/200 Iteration: 512 Training loss: 0.53205\n",
      "Epoch: 103/200 Iteration: 513 Training loss: 0.61782\n",
      "Epoch: 103/200 Iteration: 514 Training loss: 0.69285\n",
      "Epoch: 102/200 Iteration: 515 Validation Acc: 0.6267\n",
      "Epoch: 104/200 Iteration: 515 Training loss: 0.67265\n",
      "Epoch: 104/200 Iteration: 516 Training loss: 0.70941\n",
      "Epoch: 104/200 Iteration: 517 Training loss: 0.55822\n",
      "Epoch: 104/200 Iteration: 518 Training loss: 0.62186\n",
      "Epoch: 104/200 Iteration: 519 Training loss: 0.67847\n",
      "Epoch: 103/200 Iteration: 520 Validation Acc: 0.6533\n",
      "Epoch: 105/200 Iteration: 520 Training loss: 0.62494\n",
      "Epoch: 105/200 Iteration: 521 Training loss: 0.68156\n",
      "Epoch: 105/200 Iteration: 522 Training loss: 0.53012\n",
      "Epoch: 105/200 Iteration: 523 Training loss: 0.61264\n",
      "Epoch: 105/200 Iteration: 524 Training loss: 0.61987\n",
      "Epoch: 104/200 Iteration: 525 Validation Acc: 0.5467\n",
      "Epoch: 106/200 Iteration: 525 Training loss: 0.62165\n",
      "Epoch: 106/200 Iteration: 526 Training loss: 0.69655\n",
      "Epoch: 106/200 Iteration: 527 Training loss: 0.54796\n",
      "Epoch: 106/200 Iteration: 528 Training loss: 0.58226\n",
      "Epoch: 106/200 Iteration: 529 Training loss: 0.67154\n",
      "Epoch: 105/200 Iteration: 530 Validation Acc: 0.6267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/200 Iteration: 530 Training loss: 0.66191\n",
      "Epoch: 107/200 Iteration: 531 Training loss: 0.73358\n",
      "Epoch: 107/200 Iteration: 532 Training loss: 0.59311\n",
      "Epoch: 107/200 Iteration: 533 Training loss: 0.58030\n",
      "Epoch: 107/200 Iteration: 534 Training loss: 0.66099\n",
      "Epoch: 106/200 Iteration: 535 Validation Acc: 0.6400\n",
      "Epoch: 108/200 Iteration: 535 Training loss: 0.62214\n",
      "Epoch: 108/200 Iteration: 536 Training loss: 0.67019\n",
      "Epoch: 108/200 Iteration: 537 Training loss: 0.54684\n",
      "Epoch: 108/200 Iteration: 538 Training loss: 0.54169\n",
      "Epoch: 108/200 Iteration: 539 Training loss: 0.73605\n",
      "Epoch: 107/200 Iteration: 540 Validation Acc: 0.6000\n",
      "Epoch: 109/200 Iteration: 540 Training loss: 0.64955\n",
      "Epoch: 109/200 Iteration: 541 Training loss: 0.73554\n",
      "Epoch: 109/200 Iteration: 542 Training loss: 0.52337\n",
      "Epoch: 109/200 Iteration: 543 Training loss: 0.61186\n",
      "Epoch: 109/200 Iteration: 544 Training loss: 0.74748\n",
      "Epoch: 108/200 Iteration: 545 Validation Acc: 0.5533\n",
      "Epoch: 110/200 Iteration: 545 Training loss: 0.60645\n",
      "Epoch: 110/200 Iteration: 546 Training loss: 0.66573\n",
      "Epoch: 110/200 Iteration: 547 Training loss: 0.52732\n",
      "Epoch: 110/200 Iteration: 548 Training loss: 0.61048\n",
      "Epoch: 110/200 Iteration: 549 Training loss: 0.62888\n",
      "Epoch: 109/200 Iteration: 550 Validation Acc: 0.6000\n",
      "Epoch: 111/200 Iteration: 550 Training loss: 0.63594\n",
      "Epoch: 111/200 Iteration: 551 Training loss: 0.75305\n",
      "Epoch: 111/200 Iteration: 552 Training loss: 0.55539\n",
      "Epoch: 111/200 Iteration: 553 Training loss: 0.58090\n",
      "Epoch: 111/200 Iteration: 554 Training loss: 0.61034\n",
      "Epoch: 110/200 Iteration: 555 Validation Acc: 0.6200\n",
      "Epoch: 112/200 Iteration: 555 Training loss: 0.60017\n",
      "Epoch: 112/200 Iteration: 556 Training loss: 0.69674\n",
      "Epoch: 112/200 Iteration: 557 Training loss: 0.59402\n",
      "Epoch: 112/200 Iteration: 558 Training loss: 0.53762\n",
      "Epoch: 112/200 Iteration: 559 Training loss: 0.57241\n",
      "Epoch: 111/200 Iteration: 560 Validation Acc: 0.5333\n",
      "Epoch: 113/200 Iteration: 560 Training loss: 0.63574\n",
      "Epoch: 113/200 Iteration: 561 Training loss: 0.73776\n",
      "Epoch: 113/200 Iteration: 562 Training loss: 0.54111\n",
      "Epoch: 113/200 Iteration: 563 Training loss: 0.59755\n",
      "Epoch: 113/200 Iteration: 564 Training loss: 0.65840\n",
      "Epoch: 112/200 Iteration: 565 Validation Acc: 0.6133\n",
      "Epoch: 114/200 Iteration: 565 Training loss: 0.63154\n",
      "Epoch: 114/200 Iteration: 566 Training loss: 0.71267\n",
      "Epoch: 114/200 Iteration: 567 Training loss: 0.57608\n",
      "Epoch: 114/200 Iteration: 568 Training loss: 0.53989\n",
      "Epoch: 114/200 Iteration: 569 Training loss: 0.64237\n",
      "Epoch: 113/200 Iteration: 570 Validation Acc: 0.6000\n",
      "Epoch: 115/200 Iteration: 570 Training loss: 0.60683\n",
      "Epoch: 115/200 Iteration: 571 Training loss: 0.68668\n",
      "Epoch: 115/200 Iteration: 572 Training loss: 0.51197\n",
      "Epoch: 115/200 Iteration: 573 Training loss: 0.53338\n",
      "Epoch: 115/200 Iteration: 574 Training loss: 0.63826\n",
      "Epoch: 114/200 Iteration: 575 Validation Acc: 0.5800\n",
      "Epoch: 116/200 Iteration: 575 Training loss: 0.55035\n",
      "Epoch: 116/200 Iteration: 576 Training loss: 0.67492\n",
      "Epoch: 116/200 Iteration: 577 Training loss: 0.51093\n",
      "Epoch: 116/200 Iteration: 578 Training loss: 0.56552\n",
      "Epoch: 116/200 Iteration: 579 Training loss: 0.65328\n",
      "Epoch: 115/200 Iteration: 580 Validation Acc: 0.5933\n",
      "Epoch: 117/200 Iteration: 580 Training loss: 0.62150\n",
      "Epoch: 117/200 Iteration: 581 Training loss: 0.66332\n",
      "Epoch: 117/200 Iteration: 582 Training loss: 0.49912\n",
      "Epoch: 117/200 Iteration: 583 Training loss: 0.50018\n",
      "Epoch: 117/200 Iteration: 584 Training loss: 0.63456\n",
      "Epoch: 116/200 Iteration: 585 Validation Acc: 0.6467\n",
      "Epoch: 118/200 Iteration: 585 Training loss: 0.67632\n",
      "Epoch: 118/200 Iteration: 586 Training loss: 0.66280\n",
      "Epoch: 118/200 Iteration: 587 Training loss: 0.50415\n",
      "Epoch: 118/200 Iteration: 588 Training loss: 0.51723\n",
      "Epoch: 118/200 Iteration: 589 Training loss: 0.57615\n",
      "Epoch: 117/200 Iteration: 590 Validation Acc: 0.6200\n",
      "Epoch: 119/200 Iteration: 590 Training loss: 0.64781\n",
      "Epoch: 119/200 Iteration: 591 Training loss: 0.66247\n",
      "Epoch: 119/200 Iteration: 592 Training loss: 0.53130\n",
      "Epoch: 119/200 Iteration: 593 Training loss: 0.52214\n",
      "Epoch: 119/200 Iteration: 594 Training loss: 0.54083\n",
      "Epoch: 118/200 Iteration: 595 Validation Acc: 0.5733\n",
      "Epoch: 120/200 Iteration: 595 Training loss: 0.59286\n",
      "Epoch: 120/200 Iteration: 596 Training loss: 0.70707\n",
      "Epoch: 120/200 Iteration: 597 Training loss: 0.47719\n",
      "Epoch: 120/200 Iteration: 598 Training loss: 0.60330\n",
      "Epoch: 120/200 Iteration: 599 Training loss: 0.67020\n",
      "Epoch: 119/200 Iteration: 600 Validation Acc: 0.5867\n",
      "Epoch: 121/200 Iteration: 600 Training loss: 0.55589\n",
      "Epoch: 121/200 Iteration: 601 Training loss: 0.62502\n",
      "Epoch: 121/200 Iteration: 602 Training loss: 0.50664\n",
      "Epoch: 121/200 Iteration: 603 Training loss: 0.53066\n",
      "Epoch: 121/200 Iteration: 604 Training loss: 0.66438\n",
      "Epoch: 120/200 Iteration: 605 Validation Acc: 0.5800\n",
      "Epoch: 122/200 Iteration: 605 Training loss: 0.61742\n",
      "Epoch: 122/200 Iteration: 606 Training loss: 0.72156\n",
      "Epoch: 122/200 Iteration: 607 Training loss: 0.51019\n",
      "Epoch: 122/200 Iteration: 608 Training loss: 0.48607\n",
      "Epoch: 122/200 Iteration: 609 Training loss: 0.54062\n",
      "Epoch: 121/200 Iteration: 610 Validation Acc: 0.6400\n",
      "Epoch: 123/200 Iteration: 610 Training loss: 0.56037\n",
      "Epoch: 123/200 Iteration: 611 Training loss: 0.64343\n",
      "Epoch: 123/200 Iteration: 612 Training loss: 0.46960\n",
      "Epoch: 123/200 Iteration: 613 Training loss: 0.52541\n",
      "Epoch: 123/200 Iteration: 614 Training loss: 0.57410\n",
      "Epoch: 122/200 Iteration: 615 Validation Acc: 0.6333\n",
      "Epoch: 124/200 Iteration: 615 Training loss: 0.52395\n",
      "Epoch: 124/200 Iteration: 616 Training loss: 0.61653\n",
      "Epoch: 124/200 Iteration: 617 Training loss: 0.47733\n",
      "Epoch: 124/200 Iteration: 618 Training loss: 0.48613\n",
      "Epoch: 124/200 Iteration: 619 Training loss: 0.51496\n",
      "Epoch: 123/200 Iteration: 620 Validation Acc: 0.6800\n",
      "Epoch: 125/200 Iteration: 620 Training loss: 0.59055\n",
      "Epoch: 125/200 Iteration: 621 Training loss: 0.60263\n",
      "Epoch: 125/200 Iteration: 622 Training loss: 0.53497\n",
      "Epoch: 125/200 Iteration: 623 Training loss: 0.43567\n",
      "Epoch: 125/200 Iteration: 624 Training loss: 0.57422\n",
      "Epoch: 124/200 Iteration: 625 Validation Acc: 0.6133\n",
      "Epoch: 126/200 Iteration: 625 Training loss: 0.67897\n",
      "Epoch: 126/200 Iteration: 626 Training loss: 0.63098\n",
      "Epoch: 126/200 Iteration: 627 Training loss: 0.52027\n",
      "Epoch: 126/200 Iteration: 628 Training loss: 0.47121\n",
      "Epoch: 126/200 Iteration: 629 Training loss: 0.48504\n",
      "Epoch: 125/200 Iteration: 630 Validation Acc: 0.6200\n",
      "Epoch: 127/200 Iteration: 630 Training loss: 0.56185\n",
      "Epoch: 127/200 Iteration: 631 Training loss: 0.66552\n",
      "Epoch: 127/200 Iteration: 632 Training loss: 0.45650\n",
      "Epoch: 127/200 Iteration: 633 Training loss: 0.54100\n",
      "Epoch: 127/200 Iteration: 634 Training loss: 0.55776\n",
      "Epoch: 126/200 Iteration: 635 Validation Acc: 0.6067\n",
      "Epoch: 128/200 Iteration: 635 Training loss: 0.50599\n",
      "Epoch: 128/200 Iteration: 636 Training loss: 0.59563\n",
      "Epoch: 128/200 Iteration: 637 Training loss: 0.67557\n",
      "Epoch: 128/200 Iteration: 638 Training loss: 0.52460\n",
      "Epoch: 128/200 Iteration: 639 Training loss: 0.53515\n",
      "Epoch: 127/200 Iteration: 640 Validation Acc: 0.5933\n",
      "Epoch: 129/200 Iteration: 640 Training loss: 0.66925\n",
      "Epoch: 129/200 Iteration: 641 Training loss: 0.65765\n",
      "Epoch: 129/200 Iteration: 642 Training loss: 0.48485\n",
      "Epoch: 129/200 Iteration: 643 Training loss: 0.57099\n",
      "Epoch: 129/200 Iteration: 644 Training loss: 0.61460\n",
      "Epoch: 128/200 Iteration: 645 Validation Acc: 0.6067\n",
      "Epoch: 130/200 Iteration: 645 Training loss: 0.49423\n",
      "Epoch: 130/200 Iteration: 646 Training loss: 0.67325\n",
      "Epoch: 130/200 Iteration: 647 Training loss: 0.48962\n",
      "Epoch: 130/200 Iteration: 648 Training loss: 0.54360\n",
      "Epoch: 130/200 Iteration: 649 Training loss: 0.52495\n",
      "Epoch: 129/200 Iteration: 650 Validation Acc: 0.6600\n",
      "Epoch: 131/200 Iteration: 650 Training loss: 0.47453\n",
      "Epoch: 131/200 Iteration: 651 Training loss: 0.61058\n",
      "Epoch: 131/200 Iteration: 652 Training loss: 0.40518\n",
      "Epoch: 131/200 Iteration: 653 Training loss: 0.45492\n",
      "Epoch: 131/200 Iteration: 654 Training loss: 0.48363\n",
      "Epoch: 130/200 Iteration: 655 Validation Acc: 0.6067\n",
      "Epoch: 132/200 Iteration: 655 Training loss: 0.53056\n",
      "Epoch: 132/200 Iteration: 656 Training loss: 0.63874\n",
      "Epoch: 132/200 Iteration: 657 Training loss: 0.44346\n",
      "Epoch: 132/200 Iteration: 658 Training loss: 0.45539\n",
      "Epoch: 132/200 Iteration: 659 Training loss: 0.45641\n",
      "Epoch: 131/200 Iteration: 660 Validation Acc: 0.6133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133/200 Iteration: 660 Training loss: 0.57894\n",
      "Epoch: 133/200 Iteration: 661 Training loss: 0.58206\n",
      "Epoch: 133/200 Iteration: 662 Training loss: 0.60768\n",
      "Epoch: 133/200 Iteration: 663 Training loss: 0.41993\n",
      "Epoch: 133/200 Iteration: 664 Training loss: 0.52312\n",
      "Epoch: 132/200 Iteration: 665 Validation Acc: 0.6800\n",
      "Epoch: 134/200 Iteration: 665 Training loss: 0.58316\n",
      "Epoch: 134/200 Iteration: 666 Training loss: 0.62601\n",
      "Epoch: 134/200 Iteration: 667 Training loss: 0.43850\n",
      "Epoch: 134/200 Iteration: 668 Training loss: 0.44019\n",
      "Epoch: 134/200 Iteration: 669 Training loss: 0.55851\n",
      "Epoch: 133/200 Iteration: 670 Validation Acc: 0.6067\n",
      "Epoch: 135/200 Iteration: 670 Training loss: 0.56009\n",
      "Epoch: 135/200 Iteration: 671 Training loss: 0.60161\n",
      "Epoch: 135/200 Iteration: 672 Training loss: 0.45597\n",
      "Epoch: 135/200 Iteration: 673 Training loss: 0.44089\n",
      "Epoch: 135/200 Iteration: 674 Training loss: 0.48352\n",
      "Epoch: 134/200 Iteration: 675 Validation Acc: 0.5867\n",
      "Epoch: 136/200 Iteration: 675 Training loss: 0.53789\n",
      "Epoch: 136/200 Iteration: 676 Training loss: 0.63448\n",
      "Epoch: 136/200 Iteration: 677 Training loss: 0.46154\n",
      "Epoch: 136/200 Iteration: 678 Training loss: 0.40488\n",
      "Epoch: 136/200 Iteration: 679 Training loss: 0.42381\n",
      "Epoch: 135/200 Iteration: 680 Validation Acc: 0.6333\n",
      "Epoch: 137/200 Iteration: 680 Training loss: 0.53908\n",
      "Epoch: 137/200 Iteration: 681 Training loss: 0.57711\n",
      "Epoch: 137/200 Iteration: 682 Training loss: 0.42328\n",
      "Epoch: 137/200 Iteration: 683 Training loss: 0.45226\n",
      "Epoch: 137/200 Iteration: 684 Training loss: 0.47964\n",
      "Epoch: 136/200 Iteration: 685 Validation Acc: 0.6333\n",
      "Epoch: 138/200 Iteration: 685 Training loss: 0.55726\n",
      "Epoch: 138/200 Iteration: 686 Training loss: 0.59157\n",
      "Epoch: 138/200 Iteration: 687 Training loss: 0.65410\n",
      "Epoch: 138/200 Iteration: 688 Training loss: 0.46482\n",
      "Epoch: 138/200 Iteration: 689 Training loss: 0.44690\n",
      "Epoch: 137/200 Iteration: 690 Validation Acc: 0.5933\n",
      "Epoch: 139/200 Iteration: 690 Training loss: 0.53200\n",
      "Epoch: 139/200 Iteration: 691 Training loss: 0.69113\n",
      "Epoch: 139/200 Iteration: 692 Training loss: 0.36966\n",
      "Epoch: 139/200 Iteration: 693 Training loss: 0.52601\n",
      "Epoch: 139/200 Iteration: 694 Training loss: 0.50542\n",
      "Epoch: 138/200 Iteration: 695 Validation Acc: 0.6000\n",
      "Epoch: 140/200 Iteration: 695 Training loss: 0.46339\n",
      "Epoch: 140/200 Iteration: 696 Training loss: 0.61049\n",
      "Epoch: 140/200 Iteration: 697 Training loss: 0.46293\n",
      "Epoch: 140/200 Iteration: 698 Training loss: 0.47788\n",
      "Epoch: 140/200 Iteration: 699 Training loss: 0.60337\n",
      "Epoch: 139/200 Iteration: 700 Validation Acc: 0.6067\n",
      "Epoch: 141/200 Iteration: 700 Training loss: 0.49699\n",
      "Epoch: 141/200 Iteration: 701 Training loss: 0.57316\n",
      "Epoch: 141/200 Iteration: 702 Training loss: 0.47310\n",
      "Epoch: 141/200 Iteration: 703 Training loss: 0.44176\n",
      "Epoch: 141/200 Iteration: 704 Training loss: 0.51010\n",
      "Epoch: 140/200 Iteration: 705 Validation Acc: 0.6133\n",
      "Epoch: 142/200 Iteration: 705 Training loss: 0.50388\n",
      "Epoch: 142/200 Iteration: 706 Training loss: 0.54703\n",
      "Epoch: 142/200 Iteration: 707 Training loss: 0.44072\n",
      "Epoch: 142/200 Iteration: 708 Training loss: 0.33722\n",
      "Epoch: 142/200 Iteration: 709 Training loss: 0.44067\n",
      "Epoch: 141/200 Iteration: 710 Validation Acc: 0.6600\n",
      "Epoch: 143/200 Iteration: 710 Training loss: 0.55197\n",
      "Epoch: 143/200 Iteration: 711 Training loss: 0.62375\n",
      "Epoch: 143/200 Iteration: 712 Training loss: 0.43838\n",
      "Epoch: 143/200 Iteration: 713 Training loss: 0.45787\n",
      "Epoch: 143/200 Iteration: 714 Training loss: 0.45601\n",
      "Epoch: 142/200 Iteration: 715 Validation Acc: 0.6133\n",
      "Epoch: 144/200 Iteration: 715 Training loss: 0.45080\n",
      "Epoch: 144/200 Iteration: 716 Training loss: 0.57390\n",
      "Epoch: 144/200 Iteration: 717 Training loss: 0.40525\n",
      "Epoch: 144/200 Iteration: 718 Training loss: 0.39531\n",
      "Epoch: 144/200 Iteration: 719 Training loss: 0.41642\n",
      "Epoch: 143/200 Iteration: 720 Validation Acc: 0.6267\n",
      "Epoch: 145/200 Iteration: 720 Training loss: 0.47750\n",
      "Epoch: 145/200 Iteration: 721 Training loss: 0.50464\n",
      "Epoch: 145/200 Iteration: 722 Training loss: 0.45178\n",
      "Epoch: 145/200 Iteration: 723 Training loss: 0.37842\n",
      "Epoch: 145/200 Iteration: 724 Training loss: 0.42025\n",
      "Epoch: 144/200 Iteration: 725 Validation Acc: 0.6200\n",
      "Epoch: 146/200 Iteration: 725 Training loss: 0.62555\n",
      "Epoch: 146/200 Iteration: 726 Training loss: 0.56166\n",
      "Epoch: 146/200 Iteration: 727 Training loss: 0.43238\n",
      "Epoch: 146/200 Iteration: 728 Training loss: 0.42866\n",
      "Epoch: 146/200 Iteration: 729 Training loss: 0.47252\n",
      "Epoch: 145/200 Iteration: 730 Validation Acc: 0.6267\n",
      "Epoch: 147/200 Iteration: 730 Training loss: 0.49680\n",
      "Epoch: 147/200 Iteration: 731 Training loss: 0.59493\n",
      "Epoch: 147/200 Iteration: 732 Training loss: 0.44144\n",
      "Epoch: 147/200 Iteration: 733 Training loss: 0.37309\n",
      "Epoch: 147/200 Iteration: 734 Training loss: 0.41470\n",
      "Epoch: 146/200 Iteration: 735 Validation Acc: 0.6400\n",
      "Epoch: 148/200 Iteration: 735 Training loss: 0.48710\n",
      "Epoch: 148/200 Iteration: 736 Training loss: 0.54780\n",
      "Epoch: 148/200 Iteration: 737 Training loss: 0.42416\n",
      "Epoch: 148/200 Iteration: 738 Training loss: 0.34850\n",
      "Epoch: 148/200 Iteration: 739 Training loss: 0.45509\n",
      "Epoch: 147/200 Iteration: 740 Validation Acc: 0.6333\n",
      "Epoch: 149/200 Iteration: 740 Training loss: 0.55138\n",
      "Epoch: 149/200 Iteration: 741 Training loss: 0.66106\n",
      "Epoch: 149/200 Iteration: 742 Training loss: 0.41810\n",
      "Epoch: 149/200 Iteration: 743 Training loss: 0.44071\n",
      "Epoch: 149/200 Iteration: 744 Training loss: 0.48378\n",
      "Epoch: 148/200 Iteration: 745 Validation Acc: 0.6200\n",
      "Epoch: 150/200 Iteration: 745 Training loss: 0.43074\n",
      "Epoch: 150/200 Iteration: 746 Training loss: 0.57066\n",
      "Epoch: 150/200 Iteration: 747 Training loss: 0.37797\n",
      "Epoch: 150/200 Iteration: 748 Training loss: 0.41399\n",
      "Epoch: 150/200 Iteration: 749 Training loss: 0.53103\n",
      "Epoch: 149/200 Iteration: 750 Validation Acc: 0.5533\n",
      "Epoch: 151/200 Iteration: 750 Training loss: 0.46124\n",
      "Epoch: 151/200 Iteration: 751 Training loss: 0.59270\n",
      "Epoch: 151/200 Iteration: 752 Training loss: 0.38236\n",
      "Epoch: 151/200 Iteration: 753 Training loss: 0.32949\n",
      "Epoch: 151/200 Iteration: 754 Training loss: 0.43092\n",
      "Epoch: 150/200 Iteration: 755 Validation Acc: 0.6067\n",
      "Epoch: 152/200 Iteration: 755 Training loss: 0.49105\n",
      "Epoch: 152/200 Iteration: 756 Training loss: 0.61238\n",
      "Epoch: 152/200 Iteration: 757 Training loss: 0.37539\n",
      "Epoch: 152/200 Iteration: 758 Training loss: 0.38921\n",
      "Epoch: 152/200 Iteration: 759 Training loss: 0.43484\n",
      "Epoch: 151/200 Iteration: 760 Validation Acc: 0.6267\n",
      "Epoch: 153/200 Iteration: 760 Training loss: 0.52040\n",
      "Epoch: 153/200 Iteration: 761 Training loss: 0.55645\n",
      "Epoch: 153/200 Iteration: 762 Training loss: 0.40882\n",
      "Epoch: 153/200 Iteration: 763 Training loss: 0.32696\n",
      "Epoch: 153/200 Iteration: 764 Training loss: 0.36980\n",
      "Epoch: 152/200 Iteration: 765 Validation Acc: 0.6400\n",
      "Epoch: 154/200 Iteration: 765 Training loss: 0.53902\n",
      "Epoch: 154/200 Iteration: 766 Training loss: 0.51213\n",
      "Epoch: 154/200 Iteration: 767 Training loss: 0.35238\n",
      "Epoch: 154/200 Iteration: 768 Training loss: 0.34807\n",
      "Epoch: 154/200 Iteration: 769 Training loss: 0.40136\n",
      "Epoch: 153/200 Iteration: 770 Validation Acc: 0.6333\n",
      "Epoch: 155/200 Iteration: 770 Training loss: 0.45297\n",
      "Epoch: 155/200 Iteration: 771 Training loss: 0.58484\n",
      "Epoch: 155/200 Iteration: 772 Training loss: 0.39978\n",
      "Epoch: 155/200 Iteration: 773 Training loss: 0.38552\n",
      "Epoch: 155/200 Iteration: 774 Training loss: 0.51021\n",
      "Epoch: 154/200 Iteration: 775 Validation Acc: 0.6000\n",
      "Epoch: 156/200 Iteration: 775 Training loss: 0.46596\n",
      "Epoch: 156/200 Iteration: 776 Training loss: 0.51716\n",
      "Epoch: 156/200 Iteration: 777 Training loss: 0.41611\n",
      "Epoch: 156/200 Iteration: 778 Training loss: 0.36723\n",
      "Epoch: 156/200 Iteration: 779 Training loss: 0.37260\n",
      "Epoch: 155/200 Iteration: 780 Validation Acc: 0.6400\n",
      "Epoch: 157/200 Iteration: 780 Training loss: 0.52859\n",
      "Epoch: 157/200 Iteration: 781 Training loss: 0.49895\n",
      "Epoch: 157/200 Iteration: 782 Training loss: 0.38996\n",
      "Epoch: 157/200 Iteration: 783 Training loss: 0.30217\n",
      "Epoch: 157/200 Iteration: 784 Training loss: 0.37426\n",
      "Epoch: 156/200 Iteration: 785 Validation Acc: 0.6267\n",
      "Epoch: 158/200 Iteration: 785 Training loss: 0.41140\n",
      "Epoch: 158/200 Iteration: 786 Training loss: 0.61520\n",
      "Epoch: 158/200 Iteration: 787 Training loss: 0.33843\n",
      "Epoch: 158/200 Iteration: 788 Training loss: 0.44177\n",
      "Epoch: 158/200 Iteration: 789 Training loss: 0.40804\n",
      "Epoch: 157/200 Iteration: 790 Validation Acc: 0.6133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159/200 Iteration: 790 Training loss: 0.43570\n",
      "Epoch: 159/200 Iteration: 791 Training loss: 0.51331\n",
      "Epoch: 159/200 Iteration: 792 Training loss: 0.38645\n",
      "Epoch: 159/200 Iteration: 793 Training loss: 0.32159\n",
      "Epoch: 159/200 Iteration: 794 Training loss: 0.35257\n",
      "Epoch: 158/200 Iteration: 795 Validation Acc: 0.6400\n",
      "Epoch: 160/200 Iteration: 795 Training loss: 0.45994\n",
      "Epoch: 160/200 Iteration: 796 Training loss: 0.55321\n",
      "Epoch: 160/200 Iteration: 797 Training loss: 0.33705\n",
      "Epoch: 160/200 Iteration: 798 Training loss: 0.34286\n",
      "Epoch: 160/200 Iteration: 799 Training loss: 0.42775\n",
      "Epoch: 159/200 Iteration: 800 Validation Acc: 0.5733\n",
      "Epoch: 161/200 Iteration: 800 Training loss: 0.41229\n",
      "Epoch: 161/200 Iteration: 801 Training loss: 0.49793\n",
      "Epoch: 161/200 Iteration: 802 Training loss: 0.72122\n",
      "Epoch: 161/200 Iteration: 803 Training loss: 0.36119\n",
      "Epoch: 161/200 Iteration: 804 Training loss: 0.32723\n",
      "Epoch: 160/200 Iteration: 805 Validation Acc: 0.6067\n",
      "Epoch: 162/200 Iteration: 805 Training loss: 0.59236\n",
      "Epoch: 162/200 Iteration: 806 Training loss: 0.63182\n",
      "Epoch: 162/200 Iteration: 807 Training loss: 0.34232\n",
      "Epoch: 162/200 Iteration: 808 Training loss: 0.40699\n",
      "Epoch: 162/200 Iteration: 809 Training loss: 0.38037\n",
      "Epoch: 161/200 Iteration: 810 Validation Acc: 0.6200\n",
      "Epoch: 163/200 Iteration: 810 Training loss: 0.44150\n",
      "Epoch: 163/200 Iteration: 811 Training loss: 0.49470\n",
      "Epoch: 163/200 Iteration: 812 Training loss: 0.56230\n",
      "Epoch: 163/200 Iteration: 813 Training loss: 0.33712\n",
      "Epoch: 163/200 Iteration: 814 Training loss: 0.43537\n",
      "Epoch: 162/200 Iteration: 815 Validation Acc: 0.6133\n",
      "Epoch: 164/200 Iteration: 815 Training loss: 0.50184\n",
      "Epoch: 164/200 Iteration: 816 Training loss: 0.54163\n",
      "Epoch: 164/200 Iteration: 817 Training loss: 0.32633\n",
      "Epoch: 164/200 Iteration: 818 Training loss: 0.41217\n",
      "Epoch: 164/200 Iteration: 819 Training loss: 0.48513\n",
      "Epoch: 163/200 Iteration: 820 Validation Acc: 0.5867\n",
      "Epoch: 165/200 Iteration: 820 Training loss: 0.39536\n",
      "Epoch: 165/200 Iteration: 821 Training loss: 0.52232\n",
      "Epoch: 165/200 Iteration: 822 Training loss: 0.33369\n",
      "Epoch: 165/200 Iteration: 823 Training loss: 0.38374\n",
      "Epoch: 165/200 Iteration: 824 Training loss: 0.42138\n",
      "Epoch: 164/200 Iteration: 825 Validation Acc: 0.6200\n",
      "Epoch: 166/200 Iteration: 825 Training loss: 0.41308\n",
      "Epoch: 166/200 Iteration: 826 Training loss: 0.49504\n",
      "Epoch: 166/200 Iteration: 827 Training loss: 0.32981\n",
      "Epoch: 166/200 Iteration: 828 Training loss: 0.34323\n",
      "Epoch: 166/200 Iteration: 829 Training loss: 0.42073\n",
      "Epoch: 165/200 Iteration: 830 Validation Acc: 0.6800\n",
      "Epoch: 167/200 Iteration: 830 Training loss: 0.39473\n",
      "Epoch: 167/200 Iteration: 831 Training loss: 0.51083\n",
      "Epoch: 167/200 Iteration: 832 Training loss: 0.35729\n",
      "Epoch: 167/200 Iteration: 833 Training loss: 0.29899\n",
      "Epoch: 167/200 Iteration: 834 Training loss: 0.35243\n",
      "Epoch: 166/200 Iteration: 835 Validation Acc: 0.6400\n",
      "Epoch: 168/200 Iteration: 835 Training loss: 0.39144\n",
      "Epoch: 168/200 Iteration: 836 Training loss: 0.47457\n",
      "Epoch: 168/200 Iteration: 837 Training loss: 0.31373\n",
      "Epoch: 168/200 Iteration: 838 Training loss: 0.34445\n",
      "Epoch: 168/200 Iteration: 839 Training loss: 0.40741\n",
      "Epoch: 167/200 Iteration: 840 Validation Acc: 0.6333\n",
      "Epoch: 169/200 Iteration: 840 Training loss: 0.38115\n",
      "Epoch: 169/200 Iteration: 841 Training loss: 0.45706\n",
      "Epoch: 169/200 Iteration: 842 Training loss: 0.36729\n",
      "Epoch: 169/200 Iteration: 843 Training loss: 0.31423\n",
      "Epoch: 169/200 Iteration: 844 Training loss: 0.28417\n",
      "Epoch: 168/200 Iteration: 845 Validation Acc: 0.6533\n",
      "Epoch: 170/200 Iteration: 845 Training loss: 0.42933\n",
      "Epoch: 170/200 Iteration: 846 Training loss: 0.42127\n",
      "Epoch: 170/200 Iteration: 847 Training loss: 0.35126\n",
      "Epoch: 170/200 Iteration: 848 Training loss: 0.35399\n",
      "Epoch: 170/200 Iteration: 849 Training loss: 0.29128\n",
      "Epoch: 169/200 Iteration: 850 Validation Acc: 0.6333\n",
      "Epoch: 171/200 Iteration: 850 Training loss: 0.41830\n",
      "Epoch: 171/200 Iteration: 851 Training loss: 0.44950\n",
      "Epoch: 171/200 Iteration: 852 Training loss: 0.32164\n",
      "Epoch: 171/200 Iteration: 853 Training loss: 0.28608\n",
      "Epoch: 171/200 Iteration: 854 Training loss: 0.29745\n",
      "Epoch: 170/200 Iteration: 855 Validation Acc: 0.6000\n",
      "Epoch: 172/200 Iteration: 855 Training loss: 0.42056\n",
      "Epoch: 172/200 Iteration: 856 Training loss: 0.47428\n",
      "Epoch: 172/200 Iteration: 857 Training loss: 0.30013\n",
      "Epoch: 172/200 Iteration: 858 Training loss: 0.29687\n",
      "Epoch: 172/200 Iteration: 859 Training loss: 0.31552\n",
      "Epoch: 171/200 Iteration: 860 Validation Acc: 0.6267\n",
      "Epoch: 173/200 Iteration: 860 Training loss: 0.35233\n",
      "Epoch: 173/200 Iteration: 861 Training loss: 0.53016\n",
      "Epoch: 173/200 Iteration: 862 Training loss: 0.36268\n",
      "Epoch: 173/200 Iteration: 863 Training loss: 0.32559\n",
      "Epoch: 173/200 Iteration: 864 Training loss: 0.54132\n",
      "Epoch: 172/200 Iteration: 865 Validation Acc: 0.5867\n",
      "Epoch: 174/200 Iteration: 865 Training loss: 0.59750\n",
      "Epoch: 174/200 Iteration: 866 Training loss: 0.54473\n",
      "Epoch: 174/200 Iteration: 867 Training loss: 0.46235\n",
      "Epoch: 174/200 Iteration: 868 Training loss: 0.34764\n",
      "Epoch: 174/200 Iteration: 869 Training loss: 0.38729\n",
      "Epoch: 173/200 Iteration: 870 Validation Acc: 0.5733\n",
      "Epoch: 175/200 Iteration: 870 Training loss: 0.41656\n",
      "Epoch: 175/200 Iteration: 871 Training loss: 0.46082\n",
      "Epoch: 175/200 Iteration: 872 Training loss: 0.33829\n",
      "Epoch: 175/200 Iteration: 873 Training loss: 0.32166\n",
      "Epoch: 175/200 Iteration: 874 Training loss: 0.33936\n",
      "Epoch: 174/200 Iteration: 875 Validation Acc: 0.6133\n",
      "Epoch: 176/200 Iteration: 875 Training loss: 0.40145\n",
      "Epoch: 176/200 Iteration: 876 Training loss: 0.48237\n",
      "Epoch: 176/200 Iteration: 877 Training loss: 0.30599\n",
      "Epoch: 176/200 Iteration: 878 Training loss: 0.29894\n",
      "Epoch: 176/200 Iteration: 879 Training loss: 0.33102\n",
      "Epoch: 175/200 Iteration: 880 Validation Acc: 0.6400\n",
      "Epoch: 177/200 Iteration: 880 Training loss: 0.33657\n",
      "Epoch: 177/200 Iteration: 881 Training loss: 0.46881\n",
      "Epoch: 177/200 Iteration: 882 Training loss: 0.30398\n",
      "Epoch: 177/200 Iteration: 883 Training loss: 0.25884\n",
      "Epoch: 177/200 Iteration: 884 Training loss: 0.29567\n",
      "Epoch: 176/200 Iteration: 885 Validation Acc: 0.6333\n",
      "Epoch: 178/200 Iteration: 885 Training loss: 0.44472\n",
      "Epoch: 178/200 Iteration: 886 Training loss: 0.43290\n",
      "Epoch: 178/200 Iteration: 887 Training loss: 0.30567\n",
      "Epoch: 178/200 Iteration: 888 Training loss: 0.29674\n",
      "Epoch: 178/200 Iteration: 889 Training loss: 0.30654\n",
      "Epoch: 177/200 Iteration: 890 Validation Acc: 0.6333\n",
      "Epoch: 179/200 Iteration: 890 Training loss: 0.43980\n",
      "Epoch: 179/200 Iteration: 891 Training loss: 0.41924\n",
      "Epoch: 179/200 Iteration: 892 Training loss: 0.42097\n",
      "Epoch: 179/200 Iteration: 893 Training loss: 0.29289\n",
      "Epoch: 179/200 Iteration: 894 Training loss: 0.28335\n",
      "Epoch: 178/200 Iteration: 895 Validation Acc: 0.6400\n",
      "Epoch: 180/200 Iteration: 895 Training loss: 0.41562\n",
      "Epoch: 180/200 Iteration: 896 Training loss: 0.46614\n",
      "Epoch: 180/200 Iteration: 897 Training loss: 0.30944\n",
      "Epoch: 180/200 Iteration: 898 Training loss: 0.38693\n",
      "Epoch: 180/200 Iteration: 899 Training loss: 0.32463\n",
      "Epoch: 179/200 Iteration: 900 Validation Acc: 0.6000\n",
      "Epoch: 181/200 Iteration: 900 Training loss: 0.35834\n",
      "Epoch: 181/200 Iteration: 901 Training loss: 0.49440\n",
      "Epoch: 181/200 Iteration: 902 Training loss: 0.41917\n",
      "Epoch: 181/200 Iteration: 903 Training loss: 0.29884\n",
      "Epoch: 181/200 Iteration: 904 Training loss: 0.34879\n",
      "Epoch: 180/200 Iteration: 905 Validation Acc: 0.6133\n",
      "Epoch: 182/200 Iteration: 905 Training loss: 0.44644\n",
      "Epoch: 182/200 Iteration: 906 Training loss: 0.45810\n",
      "Epoch: 182/200 Iteration: 907 Training loss: 0.34721\n",
      "Epoch: 182/200 Iteration: 908 Training loss: 0.25996\n",
      "Epoch: 182/200 Iteration: 909 Training loss: 0.39457\n",
      "Epoch: 181/200 Iteration: 910 Validation Acc: 0.5600\n",
      "Epoch: 183/200 Iteration: 910 Training loss: 0.32873\n",
      "Epoch: 183/200 Iteration: 911 Training loss: 0.52083\n",
      "Epoch: 183/200 Iteration: 912 Training loss: 0.31563\n",
      "Epoch: 183/200 Iteration: 913 Training loss: 0.28420\n",
      "Epoch: 183/200 Iteration: 914 Training loss: 0.34931\n",
      "Epoch: 182/200 Iteration: 915 Validation Acc: 0.6267\n",
      "Epoch: 184/200 Iteration: 915 Training loss: 0.34546\n",
      "Epoch: 184/200 Iteration: 916 Training loss: 0.41179\n",
      "Epoch: 184/200 Iteration: 917 Training loss: 0.32329\n",
      "Epoch: 184/200 Iteration: 918 Training loss: 0.24660\n",
      "Epoch: 184/200 Iteration: 919 Training loss: 0.29461\n",
      "Epoch: 183/200 Iteration: 920 Validation Acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185/200 Iteration: 920 Training loss: 0.34342\n",
      "Epoch: 185/200 Iteration: 921 Training loss: 0.36878\n",
      "Epoch: 185/200 Iteration: 922 Training loss: 0.28975\n",
      "Epoch: 185/200 Iteration: 923 Training loss: 0.36602\n",
      "Epoch: 185/200 Iteration: 924 Training loss: 0.37904\n",
      "Epoch: 184/200 Iteration: 925 Validation Acc: 0.6133\n",
      "Epoch: 186/200 Iteration: 925 Training loss: 0.37601\n",
      "Epoch: 186/200 Iteration: 926 Training loss: 0.44336\n",
      "Epoch: 186/200 Iteration: 927 Training loss: 0.25517\n",
      "Epoch: 186/200 Iteration: 928 Training loss: 0.26650\n",
      "Epoch: 186/200 Iteration: 929 Training loss: 0.32292\n",
      "Epoch: 185/200 Iteration: 930 Validation Acc: 0.6533\n",
      "Epoch: 187/200 Iteration: 930 Training loss: 0.37880\n",
      "Epoch: 187/200 Iteration: 931 Training loss: 0.47317\n",
      "Epoch: 187/200 Iteration: 932 Training loss: 0.29082\n",
      "Epoch: 187/200 Iteration: 933 Training loss: 0.26170\n",
      "Epoch: 187/200 Iteration: 934 Training loss: 0.29343\n",
      "Epoch: 186/200 Iteration: 935 Validation Acc: 0.6533\n",
      "Epoch: 188/200 Iteration: 935 Training loss: 0.39658\n",
      "Epoch: 188/200 Iteration: 936 Training loss: 0.37656\n",
      "Epoch: 188/200 Iteration: 937 Training loss: 0.36038\n",
      "Epoch: 188/200 Iteration: 938 Training loss: 0.21376\n",
      "Epoch: 188/200 Iteration: 939 Training loss: 0.25278\n",
      "Epoch: 187/200 Iteration: 940 Validation Acc: 0.6133\n",
      "Epoch: 189/200 Iteration: 940 Training loss: 0.38885\n",
      "Epoch: 189/200 Iteration: 941 Training loss: 0.41991\n",
      "Epoch: 189/200 Iteration: 942 Training loss: 0.25442\n",
      "Epoch: 189/200 Iteration: 943 Training loss: 0.32582\n",
      "Epoch: 189/200 Iteration: 944 Training loss: 0.35845\n",
      "Epoch: 188/200 Iteration: 945 Validation Acc: 0.5667\n",
      "Epoch: 190/200 Iteration: 945 Training loss: 0.33760\n",
      "Epoch: 190/200 Iteration: 946 Training loss: 0.46912\n",
      "Epoch: 190/200 Iteration: 947 Training loss: 0.37201\n",
      "Epoch: 190/200 Iteration: 948 Training loss: 0.29895\n",
      "Epoch: 190/200 Iteration: 949 Training loss: 0.27136\n",
      "Epoch: 189/200 Iteration: 950 Validation Acc: 0.6000\n",
      "Epoch: 191/200 Iteration: 950 Training loss: 0.40853\n",
      "Epoch: 191/200 Iteration: 951 Training loss: 0.40802\n",
      "Epoch: 191/200 Iteration: 952 Training loss: 0.32395\n",
      "Epoch: 191/200 Iteration: 953 Training loss: 0.24535\n",
      "Epoch: 191/200 Iteration: 954 Training loss: 0.29211\n",
      "Epoch: 190/200 Iteration: 955 Validation Acc: 0.6333\n",
      "Epoch: 192/200 Iteration: 955 Training loss: 0.33462\n",
      "Epoch: 192/200 Iteration: 956 Training loss: 0.40619\n",
      "Epoch: 192/200 Iteration: 957 Training loss: 0.29090\n",
      "Epoch: 192/200 Iteration: 958 Training loss: 0.23991\n",
      "Epoch: 192/200 Iteration: 959 Training loss: 0.28164\n",
      "Epoch: 191/200 Iteration: 960 Validation Acc: 0.6400\n",
      "Epoch: 193/200 Iteration: 960 Training loss: 0.37027\n",
      "Epoch: 193/200 Iteration: 961 Training loss: 0.41397\n",
      "Epoch: 193/200 Iteration: 962 Training loss: 0.29519\n",
      "Epoch: 193/200 Iteration: 963 Training loss: 0.23022\n",
      "Epoch: 193/200 Iteration: 964 Training loss: 0.29299\n",
      "Epoch: 192/200 Iteration: 965 Validation Acc: 0.6400\n",
      "Epoch: 194/200 Iteration: 965 Training loss: 0.38256\n",
      "Epoch: 194/200 Iteration: 966 Training loss: 0.35700\n",
      "Epoch: 194/200 Iteration: 967 Training loss: 0.32764\n",
      "Epoch: 194/200 Iteration: 968 Training loss: 0.21240\n",
      "Epoch: 194/200 Iteration: 969 Training loss: 0.26371\n",
      "Epoch: 193/200 Iteration: 970 Validation Acc: 0.6400\n",
      "Epoch: 195/200 Iteration: 970 Training loss: 0.35739\n",
      "Epoch: 195/200 Iteration: 971 Training loss: 0.39964\n",
      "Epoch: 195/200 Iteration: 972 Training loss: 0.31743\n",
      "Epoch: 195/200 Iteration: 973 Training loss: 0.31122\n",
      "Epoch: 195/200 Iteration: 974 Training loss: 0.26684\n",
      "Epoch: 194/200 Iteration: 975 Validation Acc: 0.5800\n",
      "Epoch: 196/200 Iteration: 975 Training loss: 0.37052\n",
      "Epoch: 196/200 Iteration: 976 Training loss: 0.43691\n",
      "Epoch: 196/200 Iteration: 977 Training loss: 0.30646\n",
      "Epoch: 196/200 Iteration: 978 Training loss: 0.26606\n",
      "Epoch: 196/200 Iteration: 979 Training loss: 0.36562\n",
      "Epoch: 195/200 Iteration: 980 Validation Acc: 0.6333\n",
      "Epoch: 197/200 Iteration: 980 Training loss: 0.40785\n",
      "Epoch: 197/200 Iteration: 981 Training loss: 0.42315\n",
      "Epoch: 197/200 Iteration: 982 Training loss: 0.43667\n",
      "Epoch: 197/200 Iteration: 983 Training loss: 0.22704\n",
      "Epoch: 197/200 Iteration: 984 Training loss: 0.37048\n",
      "Epoch: 196/200 Iteration: 985 Validation Acc: 0.6600\n",
      "Epoch: 198/200 Iteration: 985 Training loss: 0.29514\n",
      "Epoch: 198/200 Iteration: 986 Training loss: 0.45185\n",
      "Epoch: 198/200 Iteration: 987 Training loss: 0.28593\n",
      "Epoch: 198/200 Iteration: 988 Training loss: 0.30085\n",
      "Epoch: 198/200 Iteration: 989 Training loss: 0.38835\n",
      "Epoch: 197/200 Iteration: 990 Validation Acc: 0.6000\n",
      "Epoch: 199/200 Iteration: 990 Training loss: 0.31084\n",
      "Epoch: 199/200 Iteration: 991 Training loss: 0.48059\n",
      "Epoch: 199/200 Iteration: 992 Training loss: 0.26910\n",
      "Epoch: 199/200 Iteration: 993 Training loss: 0.30468\n",
      "Epoch: 199/200 Iteration: 994 Training loss: 0.29329\n",
      "Epoch: 198/200 Iteration: 995 Validation Acc: 0.6333\n",
      "Epoch: 200/200 Iteration: 995 Training loss: 0.34194\n",
      "Epoch: 200/200 Iteration: 996 Training loss: 0.41569\n",
      "Epoch: 200/200 Iteration: 997 Training loss: 0.27139\n",
      "Epoch: 200/200 Iteration: 998 Training loss: 0.21541\n",
      "Epoch: 200/200 Iteration: 999 Training loss: 0.24569\n",
      "Epoch: 199/200 Iteration: 1000 Validation Acc: 0.6600\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "\n",
    "epochs = 200\n",
    "iteration = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y, n_batches=5):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x, labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    saver.save(sess, \"checkpoints/skin_diseases.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/skin_diseases.ckpt\n",
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/melanoma/ISIC_0012258.jpg 0.000725993 0.331087\n",
      "data/test/melanoma/ISIC_0012356.jpg 0.00142909 0.00556792\n",
      "data/test/melanoma/ISIC_0012369.jpg 0.22863 1.77707e-07\n",
      "data/test/melanoma/ISIC_0012395.jpg 6.70901e-05 0.999933\n",
      "data/test/melanoma/ISIC_0012425.jpg 5.62137e-07 0.999999\n",
      "data/test/melanoma/ISIC_0012758.jpg 2.93401e-08 1.98698e-15\n",
      "data/test/melanoma/ISIC_0012989.jpg 0.978792 0.000719441\n",
      "data/test/melanoma/ISIC_0013072.jpg 0.319351 0.0164193\n",
      "data/test/melanoma/ISIC_0013073.jpg 0.544621 0.0157498\n",
      "data/test/melanoma/ISIC_0013242.jpg 0.00942027 0.980793\n",
      "data/test/melanoma/ISIC_0013277.jpg 0.0612043 0.938796\n",
      "data/test/melanoma/ISIC_0013321.jpg 3.77578e-19 1.0\n",
      "data/test/melanoma/ISIC_0013374.jpg 0.691017 0.00105499\n",
      "data/test/melanoma/ISIC_0013411.jpg 2.00951e-11 0.782457\n",
      "data/test/melanoma/ISIC_0013414.jpg 2.36086e-12 0.000285833\n",
      "data/test/melanoma/ISIC_0013455.jpg 0.00846896 3.11461e-05\n",
      "data/test/melanoma/ISIC_0013457.jpg 0.748222 0.130268\n",
      "data/test/melanoma/ISIC_0013459.jpg 0.356193 4.71486e-05\n",
      "data/test/melanoma/ISIC_0013472.jpg 0.351317 0.647892\n",
      "data/test/melanoma/ISIC_0013473.jpg 0.00599614 0.994004\n",
      "data: test, class: melanoma, 20 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013565.jpg 0.392729 2.65325e-05\n",
      "data/test/melanoma/ISIC_0013577.jpg 0.000672569 2.42371e-05\n",
      "data/test/melanoma/ISIC_0013588.jpg 1.01619e-08 1.0\n",
      "data/test/melanoma/ISIC_0013615.jpg 0.0210702 0.978926\n",
      "data/test/melanoma/ISIC_0013617.jpg 0.00214379 0.570993\n",
      "data/test/melanoma/ISIC_0013636.jpg 0.297752 0.000306502\n",
      "data/test/melanoma/ISIC_0013678.jpg 3.60199e-07 1.0\n",
      "data/test/melanoma/ISIC_0013696.jpg 1.24496e-05 0.999988\n",
      "data/test/melanoma/ISIC_0013733.jpg 0.122199 0.558455\n",
      "data/test/melanoma/ISIC_0013739.jpg 4.95528e-05 0.99995\n",
      "data/test/melanoma/ISIC_0013766.jpg 0.00476698 3.87848e-12\n",
      "data/test/melanoma/ISIC_0013767.jpg 0.164917 0.0375742\n",
      "data/test/melanoma/ISIC_0013813.jpg 0.789549 0.207637\n",
      "data/test/melanoma/ISIC_0013814.jpg 0.999828 0.000164906\n",
      "data/test/melanoma/ISIC_0013833.jpg 0.431391 0.568572\n",
      "data/test/melanoma/ISIC_0013842.jpg 4.87366e-06 0.999259\n",
      "data/test/melanoma/ISIC_0013867.jpg 0.149239 0.00586826\n",
      "data/test/melanoma/ISIC_0013908.jpg 0.00327823 0.996722\n",
      "data/test/melanoma/ISIC_0013917.jpg 0.0416957 4.44261e-10\n",
      "data/test/melanoma/ISIC_0013925.jpg 0.404991 0.428324\n",
      "data: test, class: melanoma, 40 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013948.jpg 0.756019 0.00584491\n",
      "data/test/melanoma/ISIC_0013953.jpg 9.46561e-05 0.743291\n",
      "data/test/melanoma/ISIC_0013987.jpg 0.273633 0.726363\n",
      "data/test/melanoma/ISIC_0013988.jpg 0.644222 0.315122\n",
      "data/test/melanoma/ISIC_0014027.jpg 1.10971e-09 1.0\n",
      "data/test/melanoma/ISIC_0014059.jpg 3.16294e-07 3.56256e-19\n",
      "data/test/melanoma/ISIC_0014077.jpg 0.519836 0.47993\n",
      "data/test/melanoma/ISIC_0014103.jpg 1.26796e-05 7.71148e-05\n",
      "data/test/melanoma/ISIC_0014110.jpg 0.133439 0.000451878\n",
      "data/test/melanoma/ISIC_0014129.jpg 0.176811 7.49028e-07\n",
      "data/test/melanoma/ISIC_0014148.jpg 0.519554 0.00132688\n",
      "data/test/melanoma/ISIC_0014160.jpg 0.49355 0.0394816\n",
      "data/test/melanoma/ISIC_0014181.jpg 0.535118 0.449295\n",
      "data/test/melanoma/ISIC_0014186.jpg 8.1421e-10 1.0\n",
      "data/test/melanoma/ISIC_0014219.jpg 0.0061044 0.00439888\n",
      "data/test/melanoma/ISIC_0014221.jpg 2.02498e-10 1.0\n",
      "data/test/melanoma/ISIC_0014233.jpg 2.61452e-06 0.999997\n",
      "data/test/melanoma/ISIC_0014255.jpg 7.55299e-19 4.62535e-07\n",
      "data/test/melanoma/ISIC_0014270.jpg 0.00020362 2.80452e-10\n",
      "data/test/melanoma/ISIC_0014284.jpg 0.000379068 0.999575\n",
      "data: test, class: melanoma, 60 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014288.jpg 0.348489 0.50354\n",
      "data/test/melanoma/ISIC_0014319.jpg 0.00245697 0.080493\n",
      "data/test/melanoma/ISIC_0014336.jpg 0.461765 0.470052\n",
      "data/test/melanoma/ISIC_0014349.jpg 0.443105 0.0824531\n",
      "data/test/melanoma/ISIC_0014369.jpg 0.326716 9.04093e-16\n",
      "data/test/melanoma/ISIC_0014423.jpg 0.59428 0.355774\n",
      "data/test/melanoma/ISIC_0014434.jpg 3.80362e-05 0.999621\n",
      "data/test/melanoma/ISIC_0014454.jpg 0.0618015 0.132207\n",
      "data/test/melanoma/ISIC_0014478.jpg 0.0878292 8.76823e-05\n",
      "data/test/melanoma/ISIC_0014489.jpg 0.821891 0.172472\n",
      "data/test/melanoma/ISIC_0014506.jpg 0.765437 0.186981\n",
      "data/test/melanoma/ISIC_0014513.jpg 0.247196 0.229178\n",
      "data/test/melanoma/ISIC_0014541.jpg 0.060204 9.83879e-11\n",
      "data/test/melanoma/ISIC_0014542.jpg 2.38973e-15 1.0\n",
      "data/test/melanoma/ISIC_0014546.jpg 0.619432 0.295577\n",
      "data/test/melanoma/ISIC_0014548.jpg 0.455156 0.000914465\n",
      "data/test/melanoma/ISIC_0014559.jpg 0.855435 0.144519\n",
      "data/test/melanoma/ISIC_0014663.jpg 0.999457 3.75456e-06\n",
      "data/test/melanoma/ISIC_0014666.jpg 0.519328 0.000262127\n",
      "data/test/melanoma/ISIC_0014695.jpg 0.649148 0.26004\n",
      "data: test, class: melanoma, 80 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014703.jpg 0.764491 0.134392\n",
      "data/test/melanoma/ISIC_0014727.jpg 0.184817 0.812658\n",
      "data/test/melanoma/ISIC_0014766.jpg 0.712325 0.287649\n",
      "data/test/melanoma/ISIC_0014772.jpg 0.459967 0.000275319\n",
      "data/test/melanoma/ISIC_0014784.jpg 0.00174902 0.423245\n",
      "data/test/melanoma/ISIC_0014790.jpg 1.8336e-09 0.999974\n",
      "data/test/melanoma/ISIC_0014800.jpg 0.476068 0.00389055\n",
      "data/test/melanoma/ISIC_0014826.jpg 0.0111665 5.02544e-17\n",
      "data/test/melanoma/ISIC_0014862.jpg 0.364873 2.3058e-09\n",
      "data/test/melanoma/ISIC_0014872.jpg 3.69232e-05 0.999963\n",
      "data/test/melanoma/ISIC_0014883.jpg 0.000467133 1.40838e-15\n",
      "data/test/melanoma/ISIC_0014912.jpg 0.432675 0.000465073\n",
      "data/test/melanoma/ISIC_0014928.jpg 3.7118e-05 7.01806e-08\n",
      "data/test/melanoma/ISIC_0014932.jpg 0.128109 2.19607e-11\n",
      "data/test/melanoma/ISIC_0014963.jpg 0.876607 0.00101133\n",
      "data/test/melanoma/ISIC_0014982.jpg 0.437334 0.00213133\n",
      "data/test/melanoma/ISIC_0015004.jpg 0.0974465 4.05551e-07\n",
      "data/test/melanoma/ISIC_0015041.jpg 0.998613 8.6306e-19\n",
      "data/test/melanoma/ISIC_0015046.jpg 0.00015228 1.09919e-09\n",
      "data/test/melanoma/ISIC_0015050.jpg 0.997269 0.000967795\n",
      "data: test, class: melanoma, 100 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0015071.jpg 1.0 4.73241e-23\n",
      "data/test/melanoma/ISIC_0015115.jpg 0.00785525 2.78374e-16\n",
      "data/test/melanoma/ISIC_0015119.jpg 0.585201 0.409661\n",
      "data/test/melanoma/ISIC_0015127.jpg 2.37753e-07 6.49815e-29\n",
      "data/test/melanoma/ISIC_0015132.jpg 0.337623 1.70863e-08\n",
      "data/test/melanoma/ISIC_0015133.jpg 2.0968e-14 3.34609e-25\n",
      "data/test/melanoma/ISIC_0015136.jpg 0.495768 5.53952e-06\n",
      "data/test/melanoma/ISIC_0015142.jpg 0.999783 8.20403e-10\n",
      "data/test/melanoma/ISIC_0015156.jpg 0.20704 9.19149e-10\n",
      "data/test/melanoma/ISIC_0015163.jpg 0.000402908 0.999597\n",
      "data/test/melanoma/ISIC_0015167.jpg 0.998411 0.00157497\n",
      "data/test/melanoma/ISIC_0015180.jpg 6.19867e-05 0.999938\n",
      "data/test/melanoma/ISIC_0015185.jpg 0.0153336 4.53517e-11\n",
      "data/test/melanoma/ISIC_0015193.jpg 0.00208592 5.45811e-11\n",
      "data/test/melanoma/ISIC_0015206.jpg 0.999914 4.43178e-25\n",
      "data/test/melanoma/ISIC_0015229.jpg 0.994274 0.00228453\n",
      "data/test/melanoma/ISIC_0015251.jpg 0.000193189 3.27093e-07\n",
      "data: test, class: melanoma, 117 / 117 images processed.\n",
      "data/test/nevus/ISIC_0012092.jpg 0.105607 7.42559e-12\n",
      "data/test/nevus/ISIC_0012095.jpg 0.00307617 0.996918\n",
      "data/test/nevus/ISIC_0012147.jpg 4.0157e-13 0.0108403\n",
      "data/test/nevus/ISIC_0012149.jpg 6.39629e-20 1.0\n",
      "data/test/nevus/ISIC_0012152.jpg 2.17616e-06 0.998857\n",
      "data/test/nevus/ISIC_0012216.jpg 0.0299761 0.896542\n",
      "data/test/nevus/ISIC_0012357.jpg 0.179367 0.422143\n",
      "data/test/nevus/ISIC_0012484.jpg 0.0229592 0.977029\n",
      "data/test/nevus/ISIC_0012493.jpg 1.90064e-31 6.29316e-14\n",
      "data/test/nevus/ISIC_0012551.jpg 5.14392e-06 0.0085668\n",
      "data/test/nevus/ISIC_0012654.jpg 0.0991915 2.12739e-05\n",
      "data/test/nevus/ISIC_0012656.jpg 0.000317861 1.40637e-17\n",
      "data/test/nevus/ISIC_0012708.jpg 0.312053 9.64937e-15\n",
      "data/test/nevus/ISIC_0012722.jpg 8.98301e-11 0.00497383\n",
      "data/test/nevus/ISIC_0012803.jpg 1.92766e-05 2.132e-11\n",
      "data/test/nevus/ISIC_0012836.jpg 3.94236e-08 6.17988e-05\n",
      "data/test/nevus/ISIC_0012837.jpg 5.04082e-06 0.999995\n",
      "data/test/nevus/ISIC_0012903.jpg 2.18089e-21 0.000638078\n",
      "data/test/nevus/ISIC_0012904.jpg 6.46146e-08 0.999861\n",
      "data/test/nevus/ISIC_0012941.jpg 1.91961e-27 1.0\n",
      "data: test, class: nevus, 20 / 393 images processed.\n",
      "data/test/nevus/ISIC_0012967.jpg 1.76136e-07 0.244394\n",
      "data/test/nevus/ISIC_0013045.jpg 0.264892 4.07691e-10\n",
      "data/test/nevus/ISIC_0013070.jpg 4.06211e-05 2.04036e-08\n",
      "data/test/nevus/ISIC_0013109.jpg 0.00010307 0.469645\n",
      "data/test/nevus/ISIC_0013159.jpg 0.00900149 0.990985\n",
      "data/test/nevus/ISIC_0013164.jpg 3.00934e-09 0.00540882\n",
      "data/test/nevus/ISIC_0013176.jpg 0.0486495 0.175325\n",
      "data/test/nevus/ISIC_0013191.jpg 1.40752e-17 1.50297e-05\n",
      "data/test/nevus/ISIC_0013216.jpg 2.77865e-10 0.900691\n",
      "data/test/nevus/ISIC_0013226.jpg 6.16067e-11 9.83307e-07\n",
      "data/test/nevus/ISIC_0013230.jpg 0.064516 0.0114592\n",
      "data/test/nevus/ISIC_0013269.jpg 0.229909 6.44998e-06\n",
      "data/test/nevus/ISIC_0013291.jpg 0.00635616 2.8647e-08\n",
      "data/test/nevus/ISIC_0013325.jpg 3.22837e-05 1.07435e-05\n",
      "data/test/nevus/ISIC_0013399.jpg 5.25597e-17 0.468282\n",
      "data/test/nevus/ISIC_0013416.jpg 1.23086e-17 4.44387e-09\n",
      "data/test/nevus/ISIC_0013511.jpg 0.854764 0.145051\n",
      "data/test/nevus/ISIC_0013512.jpg 0.00189271 0.144373\n",
      "data/test/nevus/ISIC_0013529.jpg 0.000305898 1.55202e-18\n",
      "data/test/nevus/ISIC_0013600.jpg 0.0444484 0.00215899\n",
      "data: test, class: nevus, 40 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0013602.jpg 0.0669162 0.00363493\n",
      "data/test/nevus/ISIC_0013738.jpg 3.54146e-20 5.16505e-22\n",
      "data/test/nevus/ISIC_0013794.jpg 7.16935e-09 4.24648e-06\n",
      "data/test/nevus/ISIC_0013809.jpg 0.577148 0.0776305\n",
      "data/test/nevus/ISIC_0013891.jpg 0.000167044 8.4778e-08\n",
      "data/test/nevus/ISIC_0013897.jpg 0.483395 0.3725\n",
      "data/test/nevus/ISIC_0013911.jpg 4.27348e-12 1.0\n",
      "data/test/nevus/ISIC_0013966.jpg 4.68383e-05 0.694899\n",
      "data/test/nevus/ISIC_0013998.jpg 0.170739 0.798681\n",
      "data/test/nevus/ISIC_0014090.jpg 2.66999e-09 1.85547e-10\n",
      "data/test/nevus/ISIC_0014117.jpg 0.00150802 8.86536e-05\n",
      "data/test/nevus/ISIC_0014470.jpg 4.62463e-21 1.0\n",
      "data/test/nevus/ISIC_0014675.jpg 2.61704e-32 1.31754e-21\n",
      "data/test/nevus/ISIC_0014677.jpg 7.18602e-21 4.90964e-10\n",
      "data/test/nevus/ISIC_0014687.jpg 0.385991 9.35268e-09\n",
      "data/test/nevus/ISIC_0014693.jpg 0.998253 2.30226e-07\n",
      "data/test/nevus/ISIC_0014697.jpg 1.00752e-29 2.87922e-22\n",
      "data/test/nevus/ISIC_0014698.jpg 0.00222822 2.31295e-12\n",
      "data/test/nevus/ISIC_0014720.jpg 0.0474838 2.85923e-08\n",
      "data/test/nevus/ISIC_0014725.jpg 0.412467 0.0175117\n",
      "data: test, class: nevus, 60 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014728.jpg 0.322791 1.52732e-07\n",
      "data/test/nevus/ISIC_0014729.jpg 0.999987 1.29841e-05\n",
      "data/test/nevus/ISIC_0014740.jpg 0.999101 2.00581e-08\n",
      "data/test/nevus/ISIC_0014743.jpg 9.36433e-19 3.98377e-05\n",
      "data/test/nevus/ISIC_0014746.jpg 0.328006 0.0204175\n",
      "data/test/nevus/ISIC_0014749.jpg 0.135554 0.281594\n",
      "data/test/nevus/ISIC_0014753.jpg 0.42599 0.173166\n",
      "data/test/nevus/ISIC_0014755.jpg 0.16789 1.10857e-05\n",
      "data/test/nevus/ISIC_0014765.jpg 4.14385e-12 4.49642e-22\n",
      "data/test/nevus/ISIC_0014768.jpg 0.000207886 1.16002e-23\n",
      "data/test/nevus/ISIC_0014773.jpg 0.199958 0.0116198\n",
      "data/test/nevus/ISIC_0014780.jpg 0.000292493 8.13022e-06\n",
      "data/test/nevus/ISIC_0014786.jpg 0.425013 0.000743673\n",
      "data/test/nevus/ISIC_0014787.jpg 0.000177956 0.00982994\n",
      "data/test/nevus/ISIC_0014792.jpg 5.20775e-05 0.996771\n",
      "data/test/nevus/ISIC_0014796.jpg 0.235372 2.81524e-05\n",
      "data/test/nevus/ISIC_0014798.jpg 1.04274e-08 4.30047e-10\n",
      "data/test/nevus/ISIC_0014807.jpg 0.0167805 9.69582e-08\n",
      "data/test/nevus/ISIC_0014814.jpg 0.0115796 2.27942e-07\n",
      "data/test/nevus/ISIC_0014815.jpg 0.00235996 1.83934e-07\n",
      "data: test, class: nevus, 80 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014820.jpg 2.91686e-31 2.37719e-29\n",
      "data/test/nevus/ISIC_0014822.jpg 8.37668e-08 1.60684e-18\n",
      "data/test/nevus/ISIC_0014833.jpg 0.321827 5.97824e-08\n",
      "data/test/nevus/ISIC_0014835.jpg 0.000110851 0.084966\n",
      "data/test/nevus/ISIC_0014844.jpg 0.395645 0.0495196\n",
      "data/test/nevus/ISIC_0014853.jpg 6.74201e-05 3.18864e-10\n",
      "data/test/nevus/ISIC_0014854.jpg 0.024051 4.75951e-10\n",
      "data/test/nevus/ISIC_0014863.jpg 1.5816e-05 0.995883\n",
      "data/test/nevus/ISIC_0014867.jpg 0.00102267 2.61006e-14\n",
      "data/test/nevus/ISIC_0014868.jpg 0.0960737 0.00499048\n",
      "data/test/nevus/ISIC_0014876.jpg 2.69909e-26 5.38396e-27\n",
      "data/test/nevus/ISIC_0014879.jpg 2.97971e-07 9.75728e-09\n",
      "data/test/nevus/ISIC_0014901.jpg 0.224072 0.00055003\n",
      "data/test/nevus/ISIC_0014907.jpg 7.88557e-20 6.39657e-15\n",
      "data/test/nevus/ISIC_0014910.jpg 0.0789742 0.466139\n",
      "data/test/nevus/ISIC_0014921.jpg 0.000129272 6.08648e-08\n",
      "data/test/nevus/ISIC_0014927.jpg 0.00710862 9.46506e-08\n",
      "data/test/nevus/ISIC_0014936.jpg 0.417616 0.000212439\n",
      "data/test/nevus/ISIC_0014938.jpg 0.718045 3.62336e-38\n",
      "data/test/nevus/ISIC_0014940.jpg 0.000212073 1.53308e-11\n",
      "data: test, class: nevus, 100 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014941.jpg 0.22536 1.17616e-08\n",
      "data/test/nevus/ISIC_0014942.jpg 1.15432e-17 2.38376e-23\n",
      "data/test/nevus/ISIC_0014943.jpg 1.19452e-12 1.47228e-20\n",
      "data/test/nevus/ISIC_0014944.jpg 3.21486e-06 2.71112e-09\n",
      "data/test/nevus/ISIC_0014947.jpg 2.55313e-05 5.31477e-18\n",
      "data/test/nevus/ISIC_0014948.jpg 0.649672 0.00108392\n",
      "data/test/nevus/ISIC_0014949.jpg 4.62808e-18 0.0\n",
      "data/test/nevus/ISIC_0014952.jpg 0.153851 6.3228e-08\n",
      "data/test/nevus/ISIC_0014955.jpg 1.06634e-08 1.7123e-25\n",
      "data/test/nevus/ISIC_0014956.jpg 0.235135 0.000542863\n",
      "data/test/nevus/ISIC_0014957.jpg 0.454848 0.00039221\n",
      "data/test/nevus/ISIC_0014958.jpg 0.00456846 2.17115e-09\n",
      "data/test/nevus/ISIC_0014959.jpg 2.01083e-33 1.67922e-36\n",
      "data/test/nevus/ISIC_0014961.jpg 0.765818 0.000131031\n",
      "data/test/nevus/ISIC_0014962.jpg 2.02056e-22 1.80719e-08\n",
      "data/test/nevus/ISIC_0014964.jpg 0.134948 4.0799e-13\n",
      "data/test/nevus/ISIC_0014966.jpg 0.000910707 4.25855e-15\n",
      "data/test/nevus/ISIC_0014968.jpg 0.177241 0.000228419\n",
      "data/test/nevus/ISIC_0014969.jpg 1.85773e-07 2.21799e-24\n",
      "data/test/nevus/ISIC_0014973.jpg 0.301151 5.13235e-06\n",
      "data: test, class: nevus, 120 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014974.jpg 7.9148e-10 0.0746705\n",
      "data/test/nevus/ISIC_0014977.jpg 0.000198961 1.56858e-14\n",
      "data/test/nevus/ISIC_0014992.jpg 1.2386e-14 1.23281e-34\n",
      "data/test/nevus/ISIC_0014994.jpg 5.52389e-06 4.59982e-11\n",
      "data/test/nevus/ISIC_0014998.jpg 0.437111 3.84346e-05\n",
      "data/test/nevus/ISIC_0015002.jpg 0.0505918 0.00205558\n",
      "data/test/nevus/ISIC_0015003.jpg 0.0472352 0.00108318\n",
      "data/test/nevus/ISIC_0015007.jpg 4.52342e-12 0.00151558\n",
      "data/test/nevus/ISIC_0015008.jpg 1.13011e-07 1.0\n",
      "data/test/nevus/ISIC_0015009.jpg 1.29089e-09 0.0179\n",
      "data/test/nevus/ISIC_0015011.jpg 0.980342 0.0124706\n",
      "data/test/nevus/ISIC_0015013.jpg 0.585066 0.0528985\n",
      "data/test/nevus/ISIC_0015015.jpg 4.10556e-05 1.07352e-19\n",
      "data/test/nevus/ISIC_0015016.jpg 0.00655356 2.75811e-11\n",
      "data/test/nevus/ISIC_0015018.jpg 0.000106249 1.71596e-08\n",
      "data/test/nevus/ISIC_0015019.jpg 0.676839 0.000313825\n",
      "data/test/nevus/ISIC_0015020.jpg 0.212438 0.506479\n",
      "data/test/nevus/ISIC_0015021.jpg 0.0012771 1.92381e-09\n",
      "data/test/nevus/ISIC_0015023.jpg 3.76338e-09 5.31155e-23\n",
      "data/test/nevus/ISIC_0015026.jpg 2.27962e-05 2.5449e-12\n",
      "data: test, class: nevus, 140 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015030.jpg 0.0044141 0.0010456\n",
      "data/test/nevus/ISIC_0015031.jpg 1.07148e-11 1.0\n",
      "data/test/nevus/ISIC_0015034.jpg 9.19375e-05 1.75657e-15\n",
      "data/test/nevus/ISIC_0015035.jpg 4.2391e-17 4.58046e-11\n",
      "data/test/nevus/ISIC_0015037.jpg 0.417832 0.00188982\n",
      "data/test/nevus/ISIC_0015040.jpg 6.76136e-09 2.68508e-10\n",
      "data/test/nevus/ISIC_0015051.jpg 3.12656e-05 1.25235e-14\n",
      "data/test/nevus/ISIC_0015056.jpg 0.522232 0.108136\n",
      "data/test/nevus/ISIC_0015057.jpg 2.41455e-11 0.00279005\n",
      "data/test/nevus/ISIC_0015060.jpg 0.14351 2.66459e-09\n",
      "data/test/nevus/ISIC_0015064.jpg 0.174721 0.00634582\n",
      "data/test/nevus/ISIC_0015078.jpg 0.0357219 0.964158\n",
      "data/test/nevus/ISIC_0015089.jpg 0.0610545 1.78632e-23\n",
      "data/test/nevus/ISIC_0015102.jpg 2.20715e-05 0.999978\n",
      "data/test/nevus/ISIC_0015118.jpg 0.00637584 0.993499\n",
      "data/test/nevus/ISIC_0015125.jpg 0.00775118 1.93058e-09\n",
      "data/test/nevus/ISIC_0015129.jpg 0.200065 0.799618\n",
      "data/test/nevus/ISIC_0015130.jpg 0.461024 0.468568\n",
      "data/test/nevus/ISIC_0015139.jpg 4.94201e-06 1.37614e-06\n",
      "data/test/nevus/ISIC_0015140.jpg 0.120573 0.00471004\n",
      "data: test, class: nevus, 160 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015146.jpg 9.64118e-10 7.33112e-19\n",
      "data/test/nevus/ISIC_0015149.jpg 0.184302 4.8006e-08\n",
      "data/test/nevus/ISIC_0015150.jpg 2.31136e-07 9.33671e-14\n",
      "data/test/nevus/ISIC_0015152.jpg 3.80328e-14 1.0\n",
      "data/test/nevus/ISIC_0015155.jpg 6.72762e-29 9.29145e-06\n",
      "data/test/nevus/ISIC_0015157.jpg 1.2669e-06 0.0196645\n",
      "data/test/nevus/ISIC_0015160.jpg 0.0 5.09457e-12\n",
      "data/test/nevus/ISIC_0015161.jpg 1.6111e-07 0.981247\n",
      "data/test/nevus/ISIC_0015171.jpg 0.0785421 0.426686\n",
      "data/test/nevus/ISIC_0015173.jpg 0.324571 0.0149573\n",
      "data/test/nevus/ISIC_0015174.jpg 0.0290452 0.000114092\n",
      "data/test/nevus/ISIC_0015175.jpg 6.95768e-11 1.01306e-13\n",
      "data/test/nevus/ISIC_0015176.jpg 0.786407 0.0169524\n",
      "data/test/nevus/ISIC_0015179.jpg 0.225637 1.85094e-08\n",
      "data/test/nevus/ISIC_0015184.jpg 1.04633e-29 2.34279e-25\n",
      "data/test/nevus/ISIC_0015201.jpg 0.222448 0.00129262\n",
      "data/test/nevus/ISIC_0015202.jpg 7.61169e-24 7.49184e-34\n",
      "data/test/nevus/ISIC_0015203.jpg 0.00118915 4.52581e-09\n",
      "data/test/nevus/ISIC_0015207.jpg 0.00266247 9.62627e-23\n",
      "data/test/nevus/ISIC_0015208.jpg 0.359146 1.26015e-07\n",
      "data: test, class: nevus, 180 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015212.jpg 0.0 6.31867e-38\n",
      "data/test/nevus/ISIC_0015215.jpg 6.91811e-08 1.18873e-08\n",
      "data/test/nevus/ISIC_0015216.jpg 1.50342e-08 0.0085064\n",
      "data/test/nevus/ISIC_0015217.jpg 8.25089e-06 3.03719e-05\n",
      "data/test/nevus/ISIC_0015218.jpg 0.0183984 6.3348e-08\n",
      "data/test/nevus/ISIC_0015223.jpg 1.96499e-36 3.05557e-30\n",
      "data/test/nevus/ISIC_0015224.jpg 3.6612e-21 2.48632e-23\n",
      "data/test/nevus/ISIC_0015226.jpg 1.85026e-08 7.03569e-15\n",
      "data/test/nevus/ISIC_0015232.jpg 0.00136802 4.27561e-07\n",
      "data/test/nevus/ISIC_0015237.jpg 0.995257 0.00247353\n",
      "data/test/nevus/ISIC_0015241.jpg 1.36259e-10 5.83911e-11\n",
      "data/test/nevus/ISIC_0015244.jpg 0.0223643 3.31873e-05\n",
      "data/test/nevus/ISIC_0015245.jpg 0.0055834 0.97624\n",
      "data/test/nevus/ISIC_0015250.jpg 0.0251105 0.0926166\n",
      "data/test/nevus/ISIC_0015254.jpg 0.0804711 0.0247033\n",
      "data/test/nevus/ISIC_0015255.jpg 0.000616322 0.945858\n",
      "data/test/nevus/ISIC_0015258.jpg 2.09173e-05 2.44984e-09\n",
      "data/test/nevus/ISIC_0015264.jpg 1.4011e-13 1.91349e-06\n",
      "data/test/nevus/ISIC_0015270.jpg 0.948147 3.79632e-05\n",
      "data/test/nevus/ISIC_0015273.jpg 0.0161274 0.00386377\n",
      "data: test, class: nevus, 200 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0015274.jpg 0.254886 0.474292\n",
      "data/test/nevus/ISIC_0015276.jpg 3.37946e-09 2.23054e-09\n",
      "data/test/nevus/ISIC_0015279.jpg 7.13429e-10 1.0\n",
      "data/test/nevus/ISIC_0015283.jpg 8.99585e-20 3.14631e-14\n",
      "data/test/nevus/ISIC_0015291.jpg 0.320868 0.000322458\n",
      "data/test/nevus/ISIC_0015293.jpg 5.41216e-17 0.000121661\n",
      "data/test/nevus/ISIC_0015298.jpg 0.0520953 3.27184e-08\n",
      "data/test/nevus/ISIC_0015309.jpg 9.47915e-18 0.837622\n",
      "data/test/nevus/ISIC_0015310.jpg 1.29797e-08 0.000473923\n",
      "data/test/nevus/ISIC_0015311.jpg 0.388608 0.0186278\n",
      "data/test/nevus/ISIC_0015312.jpg 0.00327127 7.02959e-12\n",
      "data/test/nevus/ISIC_0015330.jpg 0.0746761 1.15659e-08\n",
      "data/test/nevus/ISIC_0015331.jpg 1.18655e-05 2.88521e-07\n",
      "data/test/nevus/ISIC_0015347.jpg 0.0598554 3.18446e-14\n",
      "data/test/nevus/ISIC_0015353.jpg 0.0213887 0.978325\n",
      "data/test/nevus/ISIC_0015355.jpg 0.52296 8.68735e-07\n",
      "data/test/nevus/ISIC_0015357.jpg 4.27571e-09 2.22094e-15\n",
      "data/test/nevus/ISIC_0015360.jpg 0.135766 2.59087e-14\n",
      "data/test/nevus/ISIC_0015363.jpg 4.12917e-26 1.4406e-17\n",
      "data/test/nevus/ISIC_0015364.jpg 1.51514e-13 0.95316\n",
      "data: test, class: nevus, 220 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015368.jpg 0.00229211 5.20213e-05\n",
      "data/test/nevus/ISIC_0015369.jpg 0.112743 0.000260021\n",
      "data/test/nevus/ISIC_0015383.jpg 4.9726e-12 1.31309e-32\n",
      "data/test/nevus/ISIC_0015386.jpg 0.479074 0.0075291\n",
      "data/test/nevus/ISIC_0015390.jpg 0.00189755 0.998102\n",
      "data/test/nevus/ISIC_0015395.jpg 1.34488e-18 5.07218e-05\n",
      "data/test/nevus/ISIC_0015403.jpg 0.211174 8.80976e-12\n",
      "data/test/nevus/ISIC_0015404.jpg 0.2408 0.14131\n",
      "data/test/nevus/ISIC_0015411.jpg 1.39154e-19 4.16547e-31\n",
      "data/test/nevus/ISIC_0015412.jpg 6.90235e-07 1.42878e-22\n",
      "data/test/nevus/ISIC_0015416.jpg 0.439257 0.00969135\n",
      "data/test/nevus/ISIC_0015417.jpg 0.056571 3.74894e-10\n",
      "data/test/nevus/ISIC_0015418.jpg 8.9192e-15 5.1212e-22\n",
      "data/test/nevus/ISIC_0015419.jpg 0.0124365 0.00225548\n",
      "data/test/nevus/ISIC_0015436.jpg 8.30037e-09 4.68678e-16\n",
      "data/test/nevus/ISIC_0015440.jpg 6.93928e-10 9.8103e-21\n",
      "data/test/nevus/ISIC_0015447.jpg 0.0629424 2.0701e-05\n",
      "data/test/nevus/ISIC_0015455.jpg 0.853719 0.0974151\n",
      "data/test/nevus/ISIC_0015464.jpg 0.334804 2.48801e-06\n",
      "data/test/nevus/ISIC_0015466.jpg 0.10472 8.32225e-10\n",
      "data: test, class: nevus, 240 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015468.jpg 9.6273e-08 0.00164468\n",
      "data/test/nevus/ISIC_0015476.jpg 2.93282e-32 5.11182e-28\n",
      "data/test/nevus/ISIC_0015481.jpg 0.348357 1.47047e-07\n",
      "data/test/nevus/ISIC_0015482.jpg 0.689106 0.00011644\n",
      "data/test/nevus/ISIC_0015485.jpg 0.0484715 0.000352668\n",
      "data/test/nevus/ISIC_0015510.jpg 0.00137335 6.57377e-12\n",
      "data/test/nevus/ISIC_0015526.jpg 1.46153e-16 3.79944e-37\n",
      "data/test/nevus/ISIC_0015537.jpg 0.522564 0.468673\n",
      "data/test/nevus/ISIC_0015544.jpg 0.447949 0.0388705\n",
      "data/test/nevus/ISIC_0015559.jpg 0.323619 0.00396485\n",
      "data/test/nevus/ISIC_0015563.jpg 0.000887119 7.11961e-10\n",
      "data/test/nevus/ISIC_0015566.jpg 0.0430586 0.000218822\n",
      "data/test/nevus/ISIC_0015568.jpg 0.179958 1.79614e-05\n",
      "data/test/nevus/ISIC_0015582.jpg 1.49026e-13 2.5713e-21\n",
      "data/test/nevus/ISIC_0015593.jpg 1.44814e-22 1.0\n",
      "data/test/nevus/ISIC_0015603.jpg 9.30326e-07 1.63817e-23\n",
      "data/test/nevus/ISIC_0015607.jpg 0.00422695 0.0645948\n",
      "data/test/nevus/ISIC_0015614.jpg 0.274001 4.02523e-05\n",
      "data/test/nevus/ISIC_0015617.jpg 0.0104965 5.65632e-13\n",
      "data/test/nevus/ISIC_0015625.jpg 0.0439197 4.47005e-09\n",
      "data: test, class: nevus, 260 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015631.jpg 2.39764e-07 5.04354e-27\n",
      "data/test/nevus/ISIC_0015636.jpg 0.722703 0.0971011\n",
      "data/test/nevus/ISIC_0015638.jpg 3.31515e-17 7.06804e-09\n",
      "data/test/nevus/ISIC_0015641.jpg 5.1888e-35 0.999932\n",
      "data/test/nevus/ISIC_0015645.jpg 5.12348e-17 2.65605e-13\n",
      "data/test/nevus/ISIC_0015936.jpg 0.0438924 0.00754679\n",
      "data/test/nevus/ISIC_0015937.jpg 4.6222e-06 0.00298988\n",
      "data/test/nevus/ISIC_0015938.jpg 3.30585e-06 6.94219e-19\n",
      "data/test/nevus/ISIC_0015939.jpg 0.705666 0.0186949\n",
      "data/test/nevus/ISIC_0015940.jpg 0.0147166 0.00572714\n",
      "data/test/nevus/ISIC_0015941.jpg 3.54961e-14 2.65645e-17\n",
      "data/test/nevus/ISIC_0015942.jpg 6.24787e-07 0.704734\n",
      "data/test/nevus/ISIC_0015943.jpg 5.64542e-07 0.0483281\n",
      "data/test/nevus/ISIC_0015944.jpg 0.0165863 0.983413\n",
      "data/test/nevus/ISIC_0015945.jpg 0.000371706 0.000445684\n",
      "data/test/nevus/ISIC_0015946.jpg 0.0487113 0.00200055\n",
      "data/test/nevus/ISIC_0015947.jpg 8.21835e-06 0.00313224\n",
      "data/test/nevus/ISIC_0015948.jpg 0.00211196 7.0829e-15\n",
      "data/test/nevus/ISIC_0015949.jpg 0.00698323 4.44736e-05\n",
      "data/test/nevus/ISIC_0015950.jpg 0.0857772 0.0193594\n",
      "data: test, class: nevus, 280 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015951.jpg 1.97177e-06 0.320375\n",
      "data/test/nevus/ISIC_0015952.jpg 0.241648 0.0023243\n",
      "data/test/nevus/ISIC_0015953.jpg 0.000318769 0.999681\n",
      "data/test/nevus/ISIC_0015954.jpg 0.00149122 5.58896e-09\n",
      "data/test/nevus/ISIC_0015955.jpg 3.44009e-22 2.81755e-13\n",
      "data/test/nevus/ISIC_0015956.jpg 0.0175003 1.06471e-06\n",
      "data/test/nevus/ISIC_0015957.jpg 2.33293e-11 1.0\n",
      "data/test/nevus/ISIC_0015958.jpg 8.15322e-13 1.0\n",
      "data/test/nevus/ISIC_0015959.jpg 0.00186068 7.1252e-23\n",
      "data/test/nevus/ISIC_0015960.jpg 0.02723 8.83681e-10\n",
      "data/test/nevus/ISIC_0015961.jpg 0.239067 2.90701e-11\n",
      "data/test/nevus/ISIC_0015962.jpg 8.97948e-05 3.44419e-05\n",
      "data/test/nevus/ISIC_0015963.jpg 3.32721e-10 4.31533e-08\n",
      "data/test/nevus/ISIC_0015964.jpg 7.14578e-11 3.0315e-15\n",
      "data/test/nevus/ISIC_0015965.jpg 0.0191539 1.38239e-12\n",
      "data/test/nevus/ISIC_0015966.jpg 1.99337e-15 1.0\n",
      "data/test/nevus/ISIC_0015967.jpg 2.11776e-31 0.702952\n",
      "data/test/nevus/ISIC_0015968.jpg 0.30524 0.69476\n",
      "data/test/nevus/ISIC_0015969.jpg 3.20632e-15 0.000185816\n",
      "data/test/nevus/ISIC_0015971.jpg 0.00782761 0.0145649\n",
      "data: test, class: nevus, 300 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015972.jpg 1.94951e-11 1.0\n",
      "data/test/nevus/ISIC_0015973.jpg 6.20064e-18 2.61822e-07\n",
      "data/test/nevus/ISIC_0015974.jpg 0.000203539 0.993042\n",
      "data/test/nevus/ISIC_0015975.jpg 1.12643e-05 1.78475e-10\n",
      "data/test/nevus/ISIC_0015976.jpg 0.00992984 8.09439e-10\n",
      "data/test/nevus/ISIC_0015978.jpg 2.80153e-24 1.0\n",
      "data/test/nevus/ISIC_0015979.jpg 0.0214452 0.978242\n",
      "data/test/nevus/ISIC_0015980.jpg 1.58197e-06 1.64678e-06\n",
      "data/test/nevus/ISIC_0015981.jpg 0.426997 0.418909\n",
      "data/test/nevus/ISIC_0015982.jpg 6.56958e-05 0.00405992\n",
      "data/test/nevus/ISIC_0015983.jpg 0.00203984 0.99796\n",
      "data/test/nevus/ISIC_0015984.jpg 4.53072e-10 0.000268924\n",
      "data/test/nevus/ISIC_0015985.jpg 3.56564e-07 3.83476e-07\n",
      "data/test/nevus/ISIC_0015986.jpg 0.246784 0.122257\n",
      "data/test/nevus/ISIC_0015987.jpg 0.0395493 0.00221004\n",
      "data/test/nevus/ISIC_0015988.jpg 3.82077e-05 0.92951\n",
      "data/test/nevus/ISIC_0015989.jpg 2.22383e-11 0.0131152\n",
      "data/test/nevus/ISIC_0015990.jpg 0.025979 1.51632e-07\n",
      "data/test/nevus/ISIC_0015991.jpg 2.20324e-10 0.131213\n",
      "data/test/nevus/ISIC_0015992.jpg 0.00188801 2.37002e-16\n",
      "data: test, class: nevus, 320 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015993.jpg 0.210527 0.0625232\n",
      "data/test/nevus/ISIC_0015994.jpg 1.99837e-06 2.00652e-05\n",
      "data/test/nevus/ISIC_0015995.jpg 0.0907969 0.0093887\n",
      "data/test/nevus/ISIC_0015996.jpg 0.00606854 0.000289298\n",
      "data/test/nevus/ISIC_0015997.jpg 0.210172 3.75056e-06\n",
      "data/test/nevus/ISIC_0015998.jpg 0.107536 1.47924e-06\n",
      "data/test/nevus/ISIC_0015999.jpg 0.0276006 1.31427e-06\n",
      "data/test/nevus/ISIC_0016000.jpg 1.02126e-06 0.999997\n",
      "data/test/nevus/ISIC_0016001.jpg 0.342645 0.451155\n",
      "data/test/nevus/ISIC_0016002.jpg 2.10738e-07 0.000698133\n",
      "data/test/nevus/ISIC_0016003.jpg 0.0470481 7.86163e-07\n",
      "data/test/nevus/ISIC_0016004.jpg 4.49563e-05 0.000515858\n",
      "data/test/nevus/ISIC_0016005.jpg 7.1126e-17 1.0\n",
      "data/test/nevus/ISIC_0016006.jpg 9.16948e-10 1.0\n",
      "data/test/nevus/ISIC_0016007.jpg 0.399563 0.117672\n",
      "data/test/nevus/ISIC_0016008.jpg 0.214127 0.00790562\n",
      "data/test/nevus/ISIC_0016009.jpg 7.50534e-08 0.00025203\n",
      "data/test/nevus/ISIC_0016011.jpg 3.53583e-11 1.0\n",
      "data/test/nevus/ISIC_0016012.jpg 5.05196e-07 0.000168337\n",
      "data/test/nevus/ISIC_0016013.jpg 1.06798e-15 0.843084\n",
      "data: test, class: nevus, 340 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016014.jpg 1.56046e-06 9.92163e-07\n",
      "data/test/nevus/ISIC_0016015.jpg 4.05524e-14 2.35636e-21\n",
      "data/test/nevus/ISIC_0016016.jpg 0.0778257 0.872107\n",
      "data/test/nevus/ISIC_0016017.jpg 0.000991997 1.32696e-05\n",
      "data/test/nevus/ISIC_0016018.jpg 1.08413e-12 0.127326\n",
      "data/test/nevus/ISIC_0016019.jpg 1.85582e-09 1.0\n",
      "data/test/nevus/ISIC_0016022.jpg 0.429947 8.44157e-05\n",
      "data/test/nevus/ISIC_0016023.jpg 1.36738e-13 0.0777387\n",
      "data/test/nevus/ISIC_0016024.jpg 0.00106828 3.2928e-05\n",
      "data/test/nevus/ISIC_0016025.jpg 0.227378 1.41874e-12\n",
      "data/test/nevus/ISIC_0016026.jpg 0.309919 0.390651\n",
      "data/test/nevus/ISIC_0016027.jpg 0.0165954 0.911391\n",
      "data/test/nevus/ISIC_0016028.jpg 2.56902e-06 0.00239866\n",
      "data/test/nevus/ISIC_0016029.jpg 3.97609e-09 9.03303e-11\n",
      "data/test/nevus/ISIC_0016030.jpg 0.0161016 0.00165814\n",
      "data/test/nevus/ISIC_0016031.jpg 1.2416e-17 1.03887e-32\n",
      "data/test/nevus/ISIC_0016033.jpg 1.1103e-05 0.999977\n",
      "data/test/nevus/ISIC_0016034.jpg 0.0269184 3.10965e-05\n",
      "data/test/nevus/ISIC_0016035.jpg 7.05126e-05 0.945804\n",
      "data/test/nevus/ISIC_0016036.jpg 0.92722 9.23481e-05\n",
      "data: test, class: nevus, 360 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0016037.jpg 0.202754 0.000982413\n",
      "data/test/nevus/ISIC_0016038.jpg 4.73958e-07 2.65112e-06\n",
      "data/test/nevus/ISIC_0016040.jpg 0.138182 0.504842\n",
      "data/test/nevus/ISIC_0016041.jpg 1.18987e-09 1.0\n",
      "data/test/nevus/ISIC_0016042.jpg 0.530645 0.106994\n",
      "data/test/nevus/ISIC_0016043.jpg 0.00514422 3.70219e-05\n",
      "data/test/nevus/ISIC_0016044.jpg 1.56558e-16 1.0\n",
      "data/test/nevus/ISIC_0016045.jpg 7.31058e-06 0.407782\n",
      "data/test/nevus/ISIC_0016046.jpg 0.00261898 2.35269e-06\n",
      "data/test/nevus/ISIC_0016048.jpg 0.000786138 1.70698e-08\n",
      "data/test/nevus/ISIC_0016049.jpg 0.00756538 7.92045e-15\n",
      "data/test/nevus/ISIC_0016050.jpg 0.500211 0.00684393\n",
      "data/test/nevus/ISIC_0016051.jpg 1.09538e-13 7.68452e-21\n",
      "data/test/nevus/ISIC_0016052.jpg 0.0880613 3.23932e-08\n",
      "data/test/nevus/ISIC_0016053.jpg 9.14216e-07 1.2971e-11\n",
      "data/test/nevus/ISIC_0016054.jpg 0.0382407 0.961726\n",
      "data/test/nevus/ISIC_0016055.jpg 0.052939 7.28869e-08\n",
      "data/test/nevus/ISIC_0016056.jpg 4.55751e-05 1.51925e-06\n",
      "data/test/nevus/ISIC_0016057.jpg 0.12325 0.0383979\n",
      "data/test/nevus/ISIC_0016058.jpg 1.89009e-07 0.00207677\n",
      "data: test, class: nevus, 380 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016059.jpg 0.00121852 6.50922e-11\n",
      "data/test/nevus/ISIC_0016060.jpg 2.80386e-06 0.0684088\n",
      "data/test/nevus/ISIC_0016061.jpg 3.17659e-07 1.26229e-10\n",
      "data/test/nevus/ISIC_0016062.jpg 0.00197321 6.91116e-07\n",
      "data/test/nevus/ISIC_0016063.jpg 8.30039e-07 6.08347e-14\n",
      "data/test/nevus/ISIC_0016064.jpg 0.0320599 0.967493\n",
      "data/test/nevus/ISIC_0016065.jpg 7.37433e-05 0.509417\n",
      "data/test/nevus/ISIC_0016066.jpg 0.0858406 0.000164638\n",
      "data/test/nevus/ISIC_0016068.jpg 0.900019 0.000767088\n",
      "data/test/nevus/ISIC_0016069.jpg 0.000202453 4.79066e-05\n",
      "data/test/nevus/ISIC_0016070.jpg 2.33283e-05 0.00769728\n",
      "data/test/nevus/ISIC_0016071.jpg 0.112175 0.0220755\n",
      "data/test/nevus/ISIC_0016072.jpg 0.387809 0.0285132\n",
      "data: test, class: nevus, 393 / 393 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012086.jpg 2.00411e-06 0.999998\n",
      "data/test/seborrheic_keratosis/ISIC_0012134.jpg 0.117764 0.882236\n",
      "data/test/seborrheic_keratosis/ISIC_0012136.jpg 4.2024e-05 0.996504\n",
      "data/test/seborrheic_keratosis/ISIC_0012178.jpg 0.133353 0.866581\n",
      "data/test/seborrheic_keratosis/ISIC_0012199.jpg 0.403362 0.0181007\n",
      "data/test/seborrheic_keratosis/ISIC_0012207.jpg 4.9427e-08 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012215.jpg 0.42601 0.24005\n",
      "data/test/seborrheic_keratosis/ISIC_0012223.jpg 0.120718 0.00594159\n",
      "data/test/seborrheic_keratosis/ISIC_0012240.jpg 0.409446 0.499714\n",
      "data/test/seborrheic_keratosis/ISIC_0012248.jpg 8.88216e-06 0.99999\n",
      "data/test/seborrheic_keratosis/ISIC_0012265.jpg 0.0616336 0.000868109\n",
      "data/test/seborrheic_keratosis/ISIC_0012266.jpg 1.2364e-09 0.99867\n",
      "data/test/seborrheic_keratosis/ISIC_0012272.jpg 5.74803e-11 0.00952759\n",
      "data/test/seborrheic_keratosis/ISIC_0012273.jpg 0.338477 0.661523\n",
      "data/test/seborrheic_keratosis/ISIC_0012314.jpg 3.55076e-15 3.41875e-13\n",
      "data/test/seborrheic_keratosis/ISIC_0012323.jpg 9.78734e-05 0.999902\n",
      "data/test/seborrheic_keratosis/ISIC_0012330.jpg 0.00349905 0.853751\n",
      "data/test/seborrheic_keratosis/ISIC_0012358.jpg 0.0035706 0.99144\n",
      "data/test/seborrheic_keratosis/ISIC_0012364.jpg 1.31756e-06 0.75062\n",
      "data/test/seborrheic_keratosis/ISIC_0012372.jpg 4.69718e-10 0.672902\n",
      "data: test, class: seborrheic_keratosis, 20 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012375.jpg 0.00339531 0.996604\n",
      "data/test/seborrheic_keratosis/ISIC_0012387.jpg 1.57366e-16 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012388.jpg 6.27559e-11 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012414.jpg 0.374981 0.0916586\n",
      "data/test/seborrheic_keratosis/ISIC_0012428.jpg 0.000151097 0.999554\n",
      "data/test/seborrheic_keratosis/ISIC_0012432.jpg 1.84174e-23 0.997064\n",
      "data/test/seborrheic_keratosis/ISIC_0012447.jpg 0.00104164 0.998676\n",
      "data/test/seborrheic_keratosis/ISIC_0012448.jpg 0.000119102 0.991734\n",
      "data/test/seborrheic_keratosis/ISIC_0012510.jpg 0.107285 0.249032\n",
      "data/test/seborrheic_keratosis/ISIC_0012522.jpg 5.71579e-07 0.206787\n",
      "data/test/seborrheic_keratosis/ISIC_0012537.jpg 0.509984 0.264334\n",
      "data/test/seborrheic_keratosis/ISIC_0012548.jpg 4.98551e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012705.jpg 2.66335e-19 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012757.jpg 5.16689e-11 0.974141\n",
      "data/test/seborrheic_keratosis/ISIC_0012786.jpg 1.96819e-14 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012848.jpg 1.01338e-06 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0012852.jpg 1.1444e-05 0.760185\n",
      "data/test/seborrheic_keratosis/ISIC_0012928.jpg 1.36826e-14 0.377928\n",
      "data/test/seborrheic_keratosis/ISIC_0012955.jpg 6.33422e-05 0.999937\n",
      "data/test/seborrheic_keratosis/ISIC_0012974.jpg 1.12215e-08 1.0\n",
      "data: test, class: seborrheic_keratosis, 40 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0013030.jpg 2.52798e-17 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013035.jpg 0.00227055 0.997724\n",
      "data/test/seborrheic_keratosis/ISIC_0013085.jpg 8.60754e-27 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013169.jpg 9.15646e-05 0.999908\n",
      "data/test/seborrheic_keratosis/ISIC_0013170.jpg 9.70356e-09 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013203.jpg 3.66413e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013270.jpg 5.21916e-07 4.89986e-11\n",
      "data/test/seborrheic_keratosis/ISIC_0013271.jpg 1.16428e-06 0.737687\n",
      "data/test/seborrheic_keratosis/ISIC_0013281.jpg 5.60694e-17 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0013319.jpg 0.668214 0.0124723\n",
      "data/test/seborrheic_keratosis/ISIC_0013393.jpg 1.75507e-07 0.999998\n",
      "data/test/seborrheic_keratosis/ISIC_0013465.jpg 0.0181714 0.981825\n",
      "data/test/seborrheic_keratosis/ISIC_0013673.jpg 6.18354e-16 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013708.jpg 8.1347e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013764.jpg 0.000446435 0.999554\n",
      "data/test/seborrheic_keratosis/ISIC_0013977.jpg 4.09042e-33 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014006.jpg 1.42956e-14 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014177.jpg 3.88393e-11 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014251.jpg 1.11051e-05 0.999989\n",
      "data/test/seborrheic_keratosis/ISIC_0014278.jpg 0.079829 0.0215325\n",
      "data: test, class: seborrheic_keratosis, 60 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014386.jpg 2.44463e-08 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014392.jpg 4.12983e-11 0.810749\n",
      "data/test/seborrheic_keratosis/ISIC_0014409.jpg 5.17766e-05 2.2413e-12\n",
      "data/test/seborrheic_keratosis/ISIC_0014419.jpg 0.480219 0.466423\n",
      "data/test/seborrheic_keratosis/ISIC_0014457.jpg 8.72452e-06 5.63763e-09\n",
      "data/test/seborrheic_keratosis/ISIC_0014474.jpg 7.79654e-07 0.999945\n",
      "data/test/seborrheic_keratosis/ISIC_0014500.jpg 0.186992 0.14059\n",
      "data/test/seborrheic_keratosis/ISIC_0014503.jpg 1.83402e-11 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014567.jpg 2.07183e-14 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014574.jpg 5.58173e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014575.jpg 5.09126e-05 0.999949\n",
      "data/test/seborrheic_keratosis/ISIC_0014586.jpg 0.424473 0.0686231\n",
      "data/test/seborrheic_keratosis/ISIC_0014587.jpg 0.0 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014588.jpg 7.08239e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014590.jpg 0.814267 0.00971662\n",
      "data/test/seborrheic_keratosis/ISIC_0014600.jpg 0.620145 0.369306\n",
      "data/test/seborrheic_keratosis/ISIC_0014619.jpg 9.2953e-08 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014626.jpg 9.00776e-05 0.99991\n",
      "data/test/seborrheic_keratosis/ISIC_0014627.jpg 1.37856e-07 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014629.jpg 1.27075e-12 1.0\n",
      "data: test, class: seborrheic_keratosis, 80 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014631.jpg 6.43752e-07 0.540288\n",
      "data/test/seborrheic_keratosis/ISIC_0014634.jpg 6.09111e-05 0.999926\n",
      "data/test/seborrheic_keratosis/ISIC_0014643.jpg 2.09167e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014644.jpg 0.410086 0.00292432\n",
      "data/test/seborrheic_keratosis/ISIC_0014645.jpg 0.0147615 0.985187\n",
      "data/test/seborrheic_keratosis/ISIC_0014647.jpg 0.223514 0.665898\n",
      "data/test/seborrheic_keratosis/ISIC_0014648.jpg 3.50649e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014649.jpg 5.36449e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014652.jpg 2.84297e-05 0.999972\n",
      "data/test/seborrheic_keratosis/ISIC_0014653.jpg 6.54197e-09 1.0\n",
      "data: test, class: seborrheic_keratosis, 90 / 90 images processed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "predections_csv = open('predections.csv', 'w')\n",
    "writer = csv.writer(predections_csv, lineterminator='\\n')\n",
    "writer.writerow(['Id', 'task_1', 'task_2'])\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "labels_batch = []\n",
    "files_batch = []\n",
    "\n",
    "d_type = 'test'\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    for c in classes:\n",
    "        image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "        files = os.listdir(image_dir)\n",
    "        for i, file in enumerate(files, 1):\n",
    "            # load image and resize it to 224x224\n",
    "            file_path = os.path.join(image_dir, file)\n",
    "            img = utils.load_image(file_path)\n",
    "            \n",
    "            batch.append(img.reshape((1, 224, 224, 3)))\n",
    "            labels_batch.append(c)\n",
    "            files_batch.append(file_path)\n",
    "\n",
    "            if (len(batch) >= batch_size) or i == len(files):\n",
    "                images = np.concatenate(batch)\n",
    "\n",
    "                feed_dict = {input_: images}\n",
    "                codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "                \n",
    "                feed_dict = {inputs_: codes_batch, labels_: lb.transform(labels_batch)}\n",
    "                predections_batch = sess.run(predicted, feed_dict=feed_dict)\n",
    "\n",
    "                for ii in range(len(batch)):\n",
    "                    predection = predections_batch[ii]\n",
    "                    label = labels_batch[ii]\n",
    "                    file_id = files_batch[ii]\n",
    "                    \n",
    "                    p_melanoma = predection[0]\n",
    "                    p_seborrheic_keratosis = predection[2]\n",
    "                    \n",
    "                    print(file_id, p_melanoma, p_seborrheic_keratosis)\n",
    "                    writer.writerow([file_id, p_melanoma, p_seborrheic_keratosis])\n",
    "                    \n",
    "                batch = []\n",
    "                labels_batch = []\n",
    "                files_batch = []\n",
    "                print('data: {}, class: {}, {} / {} images processed.'.format(d_type, c, i, len(files)))\n",
    "                \n",
    "                \n",
    "predections_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
