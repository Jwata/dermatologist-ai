{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow_vgg'...\n",
      "remote: Counting objects: 113, done.\u001b[K\n",
      "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 113\u001b[K\n",
      "Receiving objects: 100% (113/113), 55.91 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# Operations for floydhub\n",
    "# !git clone https://github.com/machrisaa/tensorflow-vgg tensorflow_vgg\n",
    "# !ln -s /data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "vgg_dir = 'tensorflow_vgg/'\n",
    "vgg_name = 'vgg19'\n",
    "\n",
    "# Make sure vgg exists\n",
    "if not isdir(vgg_dir):\n",
    "    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "vgg_param_file = '{}{}.npy'.format(vgg_dir, vgg_name)\n",
    "if not isfile(vgg_param_file):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc= vgg_name + ' Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/{}.npy'.format(vgg_name),\n",
    "            vgg_param_file,\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg19\n",
    "# from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "classes = [d for d in os.listdir(train_dir) if os.path.isdir(train_dir + d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage.transform import resize\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image\n",
    "\n",
    "def vertical_flip(image):\n",
    "    image = image[::-1, :, :]\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, angle_range=(0, 180)):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.randint(*angle_range)\n",
    "    image = rotate(image, angle)\n",
    "    image = resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: train, class: melanoma, 4 / 374 images processed. data count: 20\n",
      "data: train, class: melanoma, 8 / 374 images processed. data count: 40\n",
      "data: train, class: melanoma, 12 / 374 images processed. data count: 60\n",
      "data: train, class: melanoma, 16 / 374 images processed. data count: 80\n",
      "data: train, class: melanoma, 20 / 374 images processed. data count: 100\n",
      "data: train, class: melanoma, 24 / 374 images processed. data count: 120\n",
      "data: train, class: melanoma, 28 / 374 images processed. data count: 140\n",
      "data: train, class: melanoma, 32 / 374 images processed. data count: 160\n",
      "data: train, class: melanoma, 36 / 374 images processed. data count: 180\n",
      "data: train, class: melanoma, 40 / 374 images processed. data count: 200\n",
      "data: train, class: melanoma, 44 / 374 images processed. data count: 220\n",
      "data: train, class: melanoma, 48 / 374 images processed. data count: 240\n",
      "data: train, class: melanoma, 52 / 374 images processed. data count: 260\n",
      "data: train, class: melanoma, 56 / 374 images processed. data count: 280\n",
      "data: train, class: melanoma, 60 / 374 images processed. data count: 300\n",
      "data: train, class: melanoma, 64 / 374 images processed. data count: 320\n",
      "data: train, class: melanoma, 68 / 374 images processed. data count: 340\n",
      "data: train, class: melanoma, 72 / 374 images processed. data count: 360\n",
      "data: train, class: melanoma, 76 / 374 images processed. data count: 380\n",
      "data: train, class: melanoma, 80 / 374 images processed. data count: 400\n",
      "data: train, class: melanoma, 84 / 374 images processed. data count: 420\n",
      "data: train, class: melanoma, 88 / 374 images processed. data count: 440\n",
      "data: train, class: melanoma, 92 / 374 images processed. data count: 460\n",
      "data: train, class: melanoma, 96 / 374 images processed. data count: 480\n",
      "data: train, class: melanoma, 100 / 374 images processed. data count: 500\n",
      "data: train, class: melanoma, 104 / 374 images processed. data count: 520\n",
      "data: train, class: melanoma, 108 / 374 images processed. data count: 540\n",
      "data: train, class: melanoma, 112 / 374 images processed. data count: 560\n",
      "data: train, class: melanoma, 116 / 374 images processed. data count: 580\n",
      "data: train, class: melanoma, 120 / 374 images processed. data count: 600\n",
      "data: train, class: melanoma, 124 / 374 images processed. data count: 620\n",
      "data: train, class: melanoma, 128 / 374 images processed. data count: 640\n",
      "data: train, class: melanoma, 132 / 374 images processed. data count: 660\n",
      "data: train, class: melanoma, 136 / 374 images processed. data count: 680\n",
      "data: train, class: melanoma, 140 / 374 images processed. data count: 700\n",
      "data: train, class: melanoma, 144 / 374 images processed. data count: 720\n",
      "data: train, class: melanoma, 148 / 374 images processed. data count: 740\n",
      "data: train, class: melanoma, 152 / 374 images processed. data count: 760\n",
      "data: train, class: melanoma, 156 / 374 images processed. data count: 780\n",
      "data: train, class: melanoma, 160 / 374 images processed. data count: 800\n",
      "data: train, class: melanoma, 164 / 374 images processed. data count: 820\n",
      "data: train, class: melanoma, 168 / 374 images processed. data count: 840\n",
      "data: train, class: melanoma, 172 / 374 images processed. data count: 860\n",
      "data: train, class: melanoma, 176 / 374 images processed. data count: 880\n",
      "data: train, class: melanoma, 180 / 374 images processed. data count: 900\n",
      "data: train, class: melanoma, 184 / 374 images processed. data count: 920\n",
      "data: train, class: melanoma, 188 / 374 images processed. data count: 940\n",
      "data: train, class: melanoma, 192 / 374 images processed. data count: 960\n",
      "data: train, class: melanoma, 196 / 374 images processed. data count: 980\n",
      "data: train, class: melanoma, 200 / 374 images processed. data count: 1000\n",
      "data: train, class: melanoma, 204 / 374 images processed. data count: 1020\n",
      "data: train, class: melanoma, 208 / 374 images processed. data count: 1040\n",
      "data: train, class: melanoma, 212 / 374 images processed. data count: 1060\n",
      "data: train, class: melanoma, 216 / 374 images processed. data count: 1080\n",
      "data: train, class: melanoma, 220 / 374 images processed. data count: 1100\n",
      "data: train, class: melanoma, 224 / 374 images processed. data count: 1120\n",
      "data: train, class: melanoma, 228 / 374 images processed. data count: 1140\n",
      "data: train, class: melanoma, 232 / 374 images processed. data count: 1160\n",
      "data: train, class: melanoma, 236 / 374 images processed. data count: 1180\n",
      "data: train, class: melanoma, 240 / 374 images processed. data count: 1200\n",
      "data: train, class: melanoma, 244 / 374 images processed. data count: 1220\n",
      "data: train, class: melanoma, 248 / 374 images processed. data count: 1240\n",
      "data: train, class: melanoma, 252 / 374 images processed. data count: 1260\n",
      "data: train, class: melanoma, 256 / 374 images processed. data count: 1280\n",
      "data: train, class: melanoma, 260 / 374 images processed. data count: 1300\n",
      "data: train, class: melanoma, 264 / 374 images processed. data count: 1320\n",
      "data: train, class: melanoma, 268 / 374 images processed. data count: 1340\n",
      "data: train, class: melanoma, 272 / 374 images processed. data count: 1360\n",
      "data: train, class: melanoma, 276 / 374 images processed. data count: 1380\n",
      "data: train, class: melanoma, 280 / 374 images processed. data count: 1400\n",
      "data: train, class: melanoma, 284 / 374 images processed. data count: 1420\n",
      "data: train, class: melanoma, 288 / 374 images processed. data count: 1440\n",
      "data: train, class: melanoma, 292 / 374 images processed. data count: 1460\n",
      "data: train, class: melanoma, 296 / 374 images processed. data count: 1480\n",
      "data: train, class: melanoma, 300 / 374 images processed. data count: 1500\n",
      "data: train, class: melanoma, 304 / 374 images processed. data count: 1520\n",
      "data: train, class: melanoma, 308 / 374 images processed. data count: 1540\n",
      "data: train, class: melanoma, 312 / 374 images processed. data count: 1560\n",
      "data: train, class: melanoma, 316 / 374 images processed. data count: 1580\n",
      "data: train, class: melanoma, 320 / 374 images processed. data count: 1600\n",
      "data: train, class: melanoma, 324 / 374 images processed. data count: 1620\n",
      "data: train, class: melanoma, 328 / 374 images processed. data count: 1640\n",
      "data: train, class: melanoma, 332 / 374 images processed. data count: 1660\n",
      "data: train, class: melanoma, 336 / 374 images processed. data count: 1680\n",
      "data: train, class: melanoma, 340 / 374 images processed. data count: 1700\n",
      "data: train, class: melanoma, 344 / 374 images processed. data count: 1720\n",
      "data: train, class: melanoma, 348 / 374 images processed. data count: 1740\n",
      "data: train, class: melanoma, 352 / 374 images processed. data count: 1760\n",
      "data: train, class: melanoma, 356 / 374 images processed. data count: 1780\n",
      "data: train, class: melanoma, 360 / 374 images processed. data count: 1800\n",
      "data: train, class: melanoma, 364 / 374 images processed. data count: 1820\n",
      "data: train, class: melanoma, 368 / 374 images processed. data count: 1840\n",
      "data: train, class: melanoma, 372 / 374 images processed. data count: 1860\n",
      "data: train, class: melanoma, 374 / 374 images processed. data count: 1870\n",
      "data: train, class: nevus, 20 / 1372 images processed. data count: 1890\n",
      "data: train, class: nevus, 40 / 1372 images processed. data count: 1910\n",
      "data: train, class: nevus, 60 / 1372 images processed. data count: 1930\n",
      "data: train, class: nevus, 80 / 1372 images processed. data count: 1950\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    \n",
    "    codes = None\n",
    "    labels = []\n",
    "    count = 0\n",
    "\n",
    "    for d_type in ['train', 'valid']:\n",
    "        for c in classes:\n",
    "            image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "            files = os.listdir(image_dir)\n",
    "            for i, file in enumerate(files, 1):\n",
    "                # load image and resize it to 224x224\n",
    "                file_path = os.path.join(image_dir, file)\n",
    "                img = utils.load_image(file_path)\n",
    "                batch.append(img.reshape((1, 224, 224, 3)))\n",
    "                labels.append(c)\n",
    "                \n",
    "                # data augumentation for all training data but nevus\n",
    "                if d_type == 'train' and c != 'nevus':\n",
    "                    batch.append(horizontal_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(vertical_flip(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img).reshape((1,224,224,3)))\n",
    "                    labels.append(c)\n",
    "                    batch.append(random_rotation(img, angle_range=(-180, 0)).reshape((1,224,224,3)))\n",
    "                    labels.append(c)                  \n",
    "\n",
    "                if (len(batch) >= batch_size) or i == len(files):\n",
    "                    images = np.concatenate(batch)\n",
    "\n",
    "                    feed_dict = {input_: images}\n",
    "                    codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "\n",
    "                    if codes is None:\n",
    "                        codes = codes_batch\n",
    "                    else:\n",
    "                        codes = np.concatenate((codes, codes_batch))\n",
    "\n",
    "                    count += len(batch)\n",
    "                    batch = []\n",
    "                    print('data: {}, class: {}, {} / {} images processed. data count: {}'.format(d_type, c, i, len(files), count))\n",
    "\n",
    "        # write codes to file\n",
    "        with open('{}_{}_codes'.format(vgg_name, d_type), 'w') as f:\n",
    "            codes.tofile(f)\n",
    "            codes = None\n",
    "\n",
    "        # write labels to file\n",
    "        with open('{}_{}_labels'.format(vgg_name, d_type), 'w') as f:\n",
    "            writer = csv.writer(f, delimiter='\\n')\n",
    "            writer.writerow(labels)\n",
    "            labels = []\n",
    "\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read codes and labels from file\n",
    "import csv\n",
    "\n",
    "# train data\n",
    "with open('{}_train_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    train_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_train_codes'.format(vgg_name)) as f:\n",
    "    train_x = np.fromfile(f, dtype=np.float32)\n",
    "    train_x = train_x.reshape((len(train_labels), -1))\n",
    "    \n",
    "# valid data\n",
    "with open('{}_valid_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    valid_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_valid_codes'.format(vgg_name)) as f:\n",
    "    val_x = np.fromfile(f, dtype=np.float32)\n",
    "    val_x = val_x.reshape((len(valid_labels), -1))\n",
    "    \n",
    "# test data\n",
    "with open('{}_test_labels'.format(vgg_name)) as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    test_labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('{}_test_codes'.format(vgg_name)) as f:\n",
    "    test_x = np.fromfile(f, dtype=np.float32)\n",
    "    test_x = test_x.reshape((len(test_labels), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = lb.transform(train_labels)\n",
    "val_y = lb.transform(valid_labels)\n",
    "test_y = lb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (10000, 4096) (10000, 3)\n",
      "Validation shapes (x, y): (150, 4096) (150, 3)\n",
      "Test shapes (x, y): (600, 4096) (600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, train_y.shape[1]])\n",
    "\n",
    "fc_1 = tf.contrib.layers.fully_connected(inputs_, 512)\n",
    "dropout_1 = tf.contrib.layers.dropout(fc_1)\n",
    "fc_2 = tf.contrib.layers.fully_connected(dropout_1, 128)\n",
    "dropout_2 = tf.contrib.layers.dropout(fc_2)\n",
    "    \n",
    "logits = tf.contrib.layers.fully_connected(dropout_2, train_y.shape[1], activation_fn=None)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001).minimize(cost)\n",
    "\n",
    "predicted = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: checkpoints: File exists\n",
      "Epoch: 1/500 Iteration: 0 Training loss: 6.69586\n",
      "Epoch: 1/500 Iteration: 1 Training loss: 6.86612\n",
      "Epoch: 1/500 Iteration: 2 Training loss: 4.56314\n",
      "Epoch: 1/500 Iteration: 3 Training loss: 1.46421\n",
      "Epoch: 1/500 Iteration: 4 Training loss: 0.72650\n",
      "Epoch: 0/500 Iteration: 5 Validation Acc: 0.4667\n",
      "Epoch: 2/500 Iteration: 5 Training loss: 11.11698\n",
      "Epoch: 2/500 Iteration: 6 Training loss: 5.29087\n",
      "Epoch: 2/500 Iteration: 7 Training loss: 2.64127\n",
      "Epoch: 2/500 Iteration: 8 Training loss: 1.10827\n",
      "Epoch: 2/500 Iteration: 9 Training loss: 0.58772\n",
      "Epoch: 1/500 Iteration: 10 Validation Acc: 0.4667\n",
      "Epoch: 3/500 Iteration: 10 Training loss: 8.89380\n",
      "Epoch: 3/500 Iteration: 11 Training loss: 4.54351\n",
      "Epoch: 3/500 Iteration: 12 Training loss: 2.21916\n",
      "Epoch: 3/500 Iteration: 13 Training loss: 1.02280\n",
      "Epoch: 3/500 Iteration: 14 Training loss: 0.54173\n",
      "Epoch: 2/500 Iteration: 15 Validation Acc: 0.4733\n",
      "Epoch: 4/500 Iteration: 15 Training loss: 7.04497\n",
      "Epoch: 4/500 Iteration: 16 Training loss: 3.85163\n",
      "Epoch: 4/500 Iteration: 17 Training loss: 2.01245\n",
      "Epoch: 4/500 Iteration: 18 Training loss: 0.81853\n",
      "Epoch: 4/500 Iteration: 19 Training loss: 0.45125\n",
      "Epoch: 3/500 Iteration: 20 Validation Acc: 0.4400\n",
      "Epoch: 5/500 Iteration: 20 Training loss: 6.09072\n",
      "Epoch: 5/500 Iteration: 21 Training loss: 3.33450\n",
      "Epoch: 5/500 Iteration: 22 Training loss: 1.71721\n",
      "Epoch: 5/500 Iteration: 23 Training loss: 0.83083\n",
      "Epoch: 5/500 Iteration: 24 Training loss: 0.44527\n",
      "Epoch: 4/500 Iteration: 25 Validation Acc: 0.4933\n",
      "Epoch: 6/500 Iteration: 25 Training loss: 5.24306\n",
      "Epoch: 6/500 Iteration: 26 Training loss: 2.99140\n",
      "Epoch: 6/500 Iteration: 27 Training loss: 1.56655\n",
      "Epoch: 6/500 Iteration: 28 Training loss: 0.71504\n",
      "Epoch: 6/500 Iteration: 29 Training loss: 0.41582\n",
      "Epoch: 5/500 Iteration: 30 Validation Acc: 0.5200\n",
      "Epoch: 7/500 Iteration: 30 Training loss: 4.43315\n",
      "Epoch: 7/500 Iteration: 31 Training loss: 2.72537\n",
      "Epoch: 7/500 Iteration: 32 Training loss: 1.42867\n",
      "Epoch: 7/500 Iteration: 33 Training loss: 0.65472\n",
      "Epoch: 7/500 Iteration: 34 Training loss: 0.39346\n",
      "Epoch: 6/500 Iteration: 35 Validation Acc: 0.4600\n",
      "Epoch: 8/500 Iteration: 35 Training loss: 4.00256\n",
      "Epoch: 8/500 Iteration: 36 Training loss: 2.36646\n",
      "Epoch: 8/500 Iteration: 37 Training loss: 1.31767\n",
      "Epoch: 8/500 Iteration: 38 Training loss: 0.61405\n",
      "Epoch: 8/500 Iteration: 39 Training loss: 0.39971\n",
      "Epoch: 7/500 Iteration: 40 Validation Acc: 0.4800\n",
      "Epoch: 9/500 Iteration: 40 Training loss: 3.68724\n",
      "Epoch: 9/500 Iteration: 41 Training loss: 2.22427\n",
      "Epoch: 9/500 Iteration: 42 Training loss: 1.18291\n",
      "Epoch: 9/500 Iteration: 43 Training loss: 0.60994\n",
      "Epoch: 9/500 Iteration: 44 Training loss: 0.35893\n",
      "Epoch: 8/500 Iteration: 45 Validation Acc: 0.4933\n",
      "Epoch: 10/500 Iteration: 45 Training loss: 3.32183\n",
      "Epoch: 10/500 Iteration: 46 Training loss: 2.04084\n",
      "Epoch: 10/500 Iteration: 47 Training loss: 1.13793\n",
      "Epoch: 10/500 Iteration: 48 Training loss: 0.63634\n",
      "Epoch: 10/500 Iteration: 49 Training loss: 0.40920\n",
      "Epoch: 9/500 Iteration: 50 Validation Acc: 0.4933\n",
      "Epoch: 11/500 Iteration: 50 Training loss: 3.10937\n",
      "Epoch: 11/500 Iteration: 51 Training loss: 1.99677\n",
      "Epoch: 11/500 Iteration: 52 Training loss: 1.12106\n",
      "Epoch: 11/500 Iteration: 53 Training loss: 0.58446\n",
      "Epoch: 11/500 Iteration: 54 Training loss: 0.35502\n",
      "Epoch: 10/500 Iteration: 55 Validation Acc: 0.4867\n",
      "Epoch: 12/500 Iteration: 55 Training loss: 3.44120\n",
      "Epoch: 12/500 Iteration: 56 Training loss: 1.96522\n",
      "Epoch: 12/500 Iteration: 57 Training loss: 1.07523\n",
      "Epoch: 12/500 Iteration: 58 Training loss: 0.47454\n",
      "Epoch: 12/500 Iteration: 59 Training loss: 0.27501\n",
      "Epoch: 11/500 Iteration: 60 Validation Acc: 0.5067\n",
      "Epoch: 13/500 Iteration: 60 Training loss: 4.08302\n",
      "Epoch: 13/500 Iteration: 61 Training loss: 1.86786\n",
      "Epoch: 13/500 Iteration: 62 Training loss: 1.04997\n",
      "Epoch: 13/500 Iteration: 63 Training loss: 0.50624\n",
      "Epoch: 13/500 Iteration: 64 Training loss: 0.25031\n",
      "Epoch: 12/500 Iteration: 65 Validation Acc: 0.5400\n",
      "Epoch: 14/500 Iteration: 65 Training loss: 4.10068\n",
      "Epoch: 14/500 Iteration: 66 Training loss: 2.05701\n",
      "Epoch: 14/500 Iteration: 67 Training loss: 1.44427\n",
      "Epoch: 14/500 Iteration: 68 Training loss: 0.54643\n",
      "Epoch: 14/500 Iteration: 69 Training loss: 0.22859\n",
      "Epoch: 13/500 Iteration: 70 Validation Acc: 0.5067\n",
      "Epoch: 15/500 Iteration: 70 Training loss: 4.09039\n",
      "Epoch: 15/500 Iteration: 71 Training loss: 1.92257\n",
      "Epoch: 15/500 Iteration: 72 Training loss: 0.77478\n",
      "Epoch: 15/500 Iteration: 73 Training loss: 0.46395\n",
      "Epoch: 15/500 Iteration: 74 Training loss: 0.27297\n",
      "Epoch: 14/500 Iteration: 75 Validation Acc: 0.5200\n",
      "Epoch: 16/500 Iteration: 75 Training loss: 4.26413\n",
      "Epoch: 16/500 Iteration: 76 Training loss: 1.69678\n",
      "Epoch: 16/500 Iteration: 77 Training loss: 0.96057\n",
      "Epoch: 16/500 Iteration: 78 Training loss: 0.52472\n",
      "Epoch: 16/500 Iteration: 79 Training loss: 0.33236\n",
      "Epoch: 15/500 Iteration: 80 Validation Acc: 0.5267\n",
      "Epoch: 17/500 Iteration: 80 Training loss: 3.43966\n",
      "Epoch: 17/500 Iteration: 81 Training loss: 1.62791\n",
      "Epoch: 17/500 Iteration: 82 Training loss: 0.91209\n",
      "Epoch: 17/500 Iteration: 83 Training loss: 0.54326\n",
      "Epoch: 17/500 Iteration: 84 Training loss: 0.22659\n",
      "Epoch: 16/500 Iteration: 85 Validation Acc: 0.5200\n",
      "Epoch: 18/500 Iteration: 85 Training loss: 5.21425\n",
      "Epoch: 18/500 Iteration: 86 Training loss: 1.91610\n",
      "Epoch: 18/500 Iteration: 87 Training loss: 1.03933\n",
      "Epoch: 18/500 Iteration: 88 Training loss: 0.38040\n",
      "Epoch: 18/500 Iteration: 89 Training loss: 0.22564\n",
      "Epoch: 17/500 Iteration: 90 Validation Acc: 0.4933\n",
      "Epoch: 19/500 Iteration: 90 Training loss: 4.49901\n",
      "Epoch: 19/500 Iteration: 91 Training loss: 1.83180\n",
      "Epoch: 19/500 Iteration: 92 Training loss: 0.92293\n",
      "Epoch: 19/500 Iteration: 93 Training loss: 0.43135\n",
      "Epoch: 19/500 Iteration: 94 Training loss: 0.21392\n",
      "Epoch: 18/500 Iteration: 95 Validation Acc: 0.5200\n",
      "Epoch: 20/500 Iteration: 95 Training loss: 5.28478\n",
      "Epoch: 20/500 Iteration: 96 Training loss: 1.87224\n",
      "Epoch: 20/500 Iteration: 97 Training loss: 0.98272\n",
      "Epoch: 20/500 Iteration: 98 Training loss: 0.55293\n",
      "Epoch: 20/500 Iteration: 99 Training loss: 0.30807\n",
      "Epoch: 19/500 Iteration: 100 Validation Acc: 0.5333\n",
      "Epoch: 21/500 Iteration: 100 Training loss: 4.21935\n",
      "Epoch: 21/500 Iteration: 101 Training loss: 1.74081\n",
      "Epoch: 21/500 Iteration: 102 Training loss: 0.84657\n",
      "Epoch: 21/500 Iteration: 103 Training loss: 0.47483\n",
      "Epoch: 21/500 Iteration: 104 Training loss: 0.27970\n",
      "Epoch: 20/500 Iteration: 105 Validation Acc: 0.5200\n",
      "Epoch: 22/500 Iteration: 105 Training loss: 4.58539\n",
      "Epoch: 22/500 Iteration: 106 Training loss: 2.17135\n",
      "Epoch: 22/500 Iteration: 107 Training loss: 0.80246\n",
      "Epoch: 22/500 Iteration: 108 Training loss: 0.39928\n",
      "Epoch: 22/500 Iteration: 109 Training loss: 0.14438\n",
      "Epoch: 21/500 Iteration: 110 Validation Acc: 0.5200\n",
      "Epoch: 23/500 Iteration: 110 Training loss: 5.69353\n",
      "Epoch: 23/500 Iteration: 111 Training loss: 1.88301\n",
      "Epoch: 23/500 Iteration: 112 Training loss: 0.81935\n",
      "Epoch: 23/500 Iteration: 113 Training loss: 0.52955\n",
      "Epoch: 23/500 Iteration: 114 Training loss: 0.33705\n",
      "Epoch: 22/500 Iteration: 115 Validation Acc: 0.5133\n",
      "Epoch: 24/500 Iteration: 115 Training loss: 3.48951\n",
      "Epoch: 24/500 Iteration: 116 Training loss: 1.59594\n",
      "Epoch: 24/500 Iteration: 117 Training loss: 0.76286\n",
      "Epoch: 24/500 Iteration: 118 Training loss: 0.49960\n",
      "Epoch: 24/500 Iteration: 119 Training loss: 0.30845\n",
      "Epoch: 23/500 Iteration: 120 Validation Acc: 0.5133\n",
      "Epoch: 25/500 Iteration: 120 Training loss: 4.16328\n",
      "Epoch: 25/500 Iteration: 121 Training loss: 1.68231\n",
      "Epoch: 25/500 Iteration: 122 Training loss: 0.75533\n",
      "Epoch: 25/500 Iteration: 123 Training loss: 0.49561\n",
      "Epoch: 25/500 Iteration: 124 Training loss: 0.29718\n",
      "Epoch: 24/500 Iteration: 125 Validation Acc: 0.4933\n",
      "Epoch: 26/500 Iteration: 125 Training loss: 4.87982\n",
      "Epoch: 26/500 Iteration: 126 Training loss: 2.03306\n",
      "Epoch: 26/500 Iteration: 127 Training loss: 0.86240\n",
      "Epoch: 26/500 Iteration: 128 Training loss: 0.51432\n",
      "Epoch: 26/500 Iteration: 129 Training loss: 0.33529\n",
      "Epoch: 25/500 Iteration: 130 Validation Acc: 0.5267\n",
      "Epoch: 27/500 Iteration: 130 Training loss: 4.53140\n",
      "Epoch: 27/500 Iteration: 131 Training loss: 2.17772\n",
      "Epoch: 27/500 Iteration: 132 Training loss: 1.20457\n",
      "Epoch: 27/500 Iteration: 133 Training loss: 0.44939\n",
      "Epoch: 27/500 Iteration: 134 Training loss: 0.23268\n",
      "Epoch: 26/500 Iteration: 135 Validation Acc: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/500 Iteration: 135 Training loss: 6.77899\n",
      "Epoch: 28/500 Iteration: 136 Training loss: 2.16448\n",
      "Epoch: 28/500 Iteration: 137 Training loss: 0.83942\n",
      "Epoch: 28/500 Iteration: 138 Training loss: 0.45742\n",
      "Epoch: 28/500 Iteration: 139 Training loss: 0.32292\n",
      "Epoch: 27/500 Iteration: 140 Validation Acc: 0.5067\n",
      "Epoch: 29/500 Iteration: 140 Training loss: 4.05445\n",
      "Epoch: 29/500 Iteration: 141 Training loss: 1.91020\n",
      "Epoch: 29/500 Iteration: 142 Training loss: 0.79017\n",
      "Epoch: 29/500 Iteration: 143 Training loss: 0.54760\n",
      "Epoch: 29/500 Iteration: 144 Training loss: 0.42672\n",
      "Epoch: 28/500 Iteration: 145 Validation Acc: 0.5133\n",
      "Epoch: 30/500 Iteration: 145 Training loss: 2.90660\n",
      "Epoch: 30/500 Iteration: 146 Training loss: 1.59857\n",
      "Epoch: 30/500 Iteration: 147 Training loss: 0.77780\n",
      "Epoch: 30/500 Iteration: 148 Training loss: 0.56345\n",
      "Epoch: 30/500 Iteration: 149 Training loss: 0.41986\n",
      "Epoch: 29/500 Iteration: 150 Validation Acc: 0.5000\n",
      "Epoch: 31/500 Iteration: 150 Training loss: 2.83637\n",
      "Epoch: 31/500 Iteration: 151 Training loss: 1.36474\n",
      "Epoch: 31/500 Iteration: 152 Training loss: 0.75642\n",
      "Epoch: 31/500 Iteration: 153 Training loss: 0.58973\n",
      "Epoch: 31/500 Iteration: 154 Training loss: 0.45616\n",
      "Epoch: 30/500 Iteration: 155 Validation Acc: 0.5133\n",
      "Epoch: 32/500 Iteration: 155 Training loss: 3.38121\n",
      "Epoch: 32/500 Iteration: 156 Training loss: 1.72645\n",
      "Epoch: 32/500 Iteration: 157 Training loss: 0.81501\n",
      "Epoch: 32/500 Iteration: 158 Training loss: 0.56773\n",
      "Epoch: 32/500 Iteration: 159 Training loss: 0.37424\n",
      "Epoch: 31/500 Iteration: 160 Validation Acc: 0.5067\n",
      "Epoch: 33/500 Iteration: 160 Training loss: 4.81594\n",
      "Epoch: 33/500 Iteration: 161 Training loss: 1.90818\n",
      "Epoch: 33/500 Iteration: 162 Training loss: 0.74539\n",
      "Epoch: 33/500 Iteration: 163 Training loss: 0.47381\n",
      "Epoch: 33/500 Iteration: 164 Training loss: 0.24907\n",
      "Epoch: 32/500 Iteration: 165 Validation Acc: 0.5067\n",
      "Epoch: 34/500 Iteration: 165 Training loss: 6.83936\n",
      "Epoch: 34/500 Iteration: 166 Training loss: 1.71079\n",
      "Epoch: 34/500 Iteration: 167 Training loss: 0.81051\n",
      "Epoch: 34/500 Iteration: 168 Training loss: 0.54713\n",
      "Epoch: 34/500 Iteration: 169 Training loss: 0.44252\n",
      "Epoch: 33/500 Iteration: 170 Validation Acc: 0.4933\n",
      "Epoch: 35/500 Iteration: 170 Training loss: 2.99023\n",
      "Epoch: 35/500 Iteration: 171 Training loss: 1.46883\n",
      "Epoch: 35/500 Iteration: 172 Training loss: 0.73840\n",
      "Epoch: 35/500 Iteration: 173 Training loss: 0.56113\n",
      "Epoch: 35/500 Iteration: 174 Training loss: 0.36765\n",
      "Epoch: 34/500 Iteration: 175 Validation Acc: 0.5333\n",
      "Epoch: 36/500 Iteration: 175 Training loss: 4.54858\n",
      "Epoch: 36/500 Iteration: 176 Training loss: 1.59315\n",
      "Epoch: 36/500 Iteration: 177 Training loss: 0.78334\n",
      "Epoch: 36/500 Iteration: 178 Training loss: 0.59460\n",
      "Epoch: 36/500 Iteration: 179 Training loss: 0.46896\n",
      "Epoch: 35/500 Iteration: 180 Validation Acc: 0.5067\n",
      "Epoch: 37/500 Iteration: 180 Training loss: 2.66387\n",
      "Epoch: 37/500 Iteration: 181 Training loss: 1.43176\n",
      "Epoch: 37/500 Iteration: 182 Training loss: 0.75189\n",
      "Epoch: 37/500 Iteration: 183 Training loss: 0.62661\n",
      "Epoch: 37/500 Iteration: 184 Training loss: 0.48317\n",
      "Epoch: 36/500 Iteration: 185 Validation Acc: 0.5267\n",
      "Epoch: 38/500 Iteration: 185 Training loss: 2.88962\n",
      "Epoch: 38/500 Iteration: 186 Training loss: 1.49449\n",
      "Epoch: 38/500 Iteration: 187 Training loss: 0.77720\n",
      "Epoch: 38/500 Iteration: 188 Training loss: 0.58806\n",
      "Epoch: 38/500 Iteration: 189 Training loss: 0.40556\n",
      "Epoch: 37/500 Iteration: 190 Validation Acc: 0.5133\n",
      "Epoch: 39/500 Iteration: 190 Training loss: 3.71587\n",
      "Epoch: 39/500 Iteration: 191 Training loss: 1.80524\n",
      "Epoch: 39/500 Iteration: 192 Training loss: 0.81878\n",
      "Epoch: 39/500 Iteration: 193 Training loss: 0.61925\n",
      "Epoch: 39/500 Iteration: 194 Training loss: 0.44565\n",
      "Epoch: 38/500 Iteration: 195 Validation Acc: 0.5400\n",
      "Epoch: 40/500 Iteration: 195 Training loss: 3.54584\n",
      "Epoch: 40/500 Iteration: 196 Training loss: 1.63311\n",
      "Epoch: 40/500 Iteration: 197 Training loss: 0.70704\n",
      "Epoch: 40/500 Iteration: 198 Training loss: 0.57692\n",
      "Epoch: 40/500 Iteration: 199 Training loss: 0.40442\n",
      "Epoch: 39/500 Iteration: 200 Validation Acc: 0.5067\n",
      "Epoch: 41/500 Iteration: 200 Training loss: 3.72001\n",
      "Epoch: 41/500 Iteration: 201 Training loss: 1.44422\n",
      "Epoch: 41/500 Iteration: 202 Training loss: 0.75579\n",
      "Epoch: 41/500 Iteration: 203 Training loss: 0.61730\n",
      "Epoch: 41/500 Iteration: 204 Training loss: 0.53843\n",
      "Epoch: 40/500 Iteration: 205 Validation Acc: 0.5067\n",
      "Epoch: 42/500 Iteration: 205 Training loss: 2.19965\n",
      "Epoch: 42/500 Iteration: 206 Training loss: 1.28380\n",
      "Epoch: 42/500 Iteration: 207 Training loss: 0.74661\n",
      "Epoch: 42/500 Iteration: 208 Training loss: 0.67216\n",
      "Epoch: 42/500 Iteration: 209 Training loss: 0.55148\n",
      "Epoch: 41/500 Iteration: 210 Validation Acc: 0.5200\n",
      "Epoch: 43/500 Iteration: 210 Training loss: 1.89068\n",
      "Epoch: 43/500 Iteration: 211 Training loss: 1.29196\n",
      "Epoch: 43/500 Iteration: 212 Training loss: 0.73245\n",
      "Epoch: 43/500 Iteration: 213 Training loss: 0.65451\n",
      "Epoch: 43/500 Iteration: 214 Training loss: 0.56593\n",
      "Epoch: 42/500 Iteration: 215 Validation Acc: 0.5200\n",
      "Epoch: 44/500 Iteration: 215 Training loss: 2.00173\n",
      "Epoch: 44/500 Iteration: 216 Training loss: 1.32140\n",
      "Epoch: 44/500 Iteration: 217 Training loss: 0.76275\n",
      "Epoch: 44/500 Iteration: 218 Training loss: 0.65590\n",
      "Epoch: 44/500 Iteration: 219 Training loss: 0.48934\n",
      "Epoch: 43/500 Iteration: 220 Validation Acc: 0.5267\n",
      "Epoch: 45/500 Iteration: 220 Training loss: 2.72160\n",
      "Epoch: 45/500 Iteration: 221 Training loss: 1.41916\n",
      "Epoch: 45/500 Iteration: 222 Training loss: 0.77612\n",
      "Epoch: 45/500 Iteration: 223 Training loss: 0.66505\n",
      "Epoch: 45/500 Iteration: 224 Training loss: 0.55707\n",
      "Epoch: 44/500 Iteration: 225 Validation Acc: 0.5067\n",
      "Epoch: 46/500 Iteration: 225 Training loss: 1.85572\n",
      "Epoch: 46/500 Iteration: 226 Training loss: 1.29022\n",
      "Epoch: 46/500 Iteration: 227 Training loss: 0.73849\n",
      "Epoch: 46/500 Iteration: 228 Training loss: 0.64558\n",
      "Epoch: 46/500 Iteration: 229 Training loss: 0.53703\n",
      "Epoch: 45/500 Iteration: 230 Validation Acc: 0.5200\n",
      "Epoch: 47/500 Iteration: 230 Training loss: 1.78731\n",
      "Epoch: 47/500 Iteration: 231 Training loss: 1.27322\n",
      "Epoch: 47/500 Iteration: 232 Training loss: 0.76342\n",
      "Epoch: 47/500 Iteration: 233 Training loss: 0.66207\n",
      "Epoch: 47/500 Iteration: 234 Training loss: 0.57939\n",
      "Epoch: 46/500 Iteration: 235 Validation Acc: 0.5133\n",
      "Epoch: 48/500 Iteration: 235 Training loss: 1.64775\n",
      "Epoch: 48/500 Iteration: 236 Training loss: 1.20599\n",
      "Epoch: 48/500 Iteration: 237 Training loss: 0.74107\n",
      "Epoch: 48/500 Iteration: 238 Training loss: 0.64679\n",
      "Epoch: 48/500 Iteration: 239 Training loss: 0.53415\n",
      "Epoch: 47/500 Iteration: 240 Validation Acc: 0.5133\n",
      "Epoch: 49/500 Iteration: 240 Training loss: 1.74297\n",
      "Epoch: 49/500 Iteration: 241 Training loss: 1.23877\n",
      "Epoch: 49/500 Iteration: 242 Training loss: 0.74826\n",
      "Epoch: 49/500 Iteration: 243 Training loss: 0.64021\n",
      "Epoch: 49/500 Iteration: 244 Training loss: 0.50685\n",
      "Epoch: 48/500 Iteration: 245 Validation Acc: 0.5200\n",
      "Epoch: 50/500 Iteration: 245 Training loss: 2.14267\n",
      "Epoch: 50/500 Iteration: 246 Training loss: 1.43799\n",
      "Epoch: 50/500 Iteration: 247 Training loss: 0.75948\n",
      "Epoch: 50/500 Iteration: 248 Training loss: 0.61310\n",
      "Epoch: 50/500 Iteration: 249 Training loss: 0.43013\n",
      "Epoch: 49/500 Iteration: 250 Validation Acc: 0.5200\n",
      "Epoch: 51/500 Iteration: 250 Training loss: 3.12215\n",
      "Epoch: 51/500 Iteration: 251 Training loss: 1.40264\n",
      "Epoch: 51/500 Iteration: 252 Training loss: 0.73541\n",
      "Epoch: 51/500 Iteration: 253 Training loss: 0.61291\n",
      "Epoch: 51/500 Iteration: 254 Training loss: 0.49102\n",
      "Epoch: 50/500 Iteration: 255 Validation Acc: 0.5067\n",
      "Epoch: 52/500 Iteration: 255 Training loss: 1.86514\n",
      "Epoch: 52/500 Iteration: 256 Training loss: 1.26362\n",
      "Epoch: 52/500 Iteration: 257 Training loss: 0.72124\n",
      "Epoch: 52/500 Iteration: 258 Training loss: 0.62934\n",
      "Epoch: 52/500 Iteration: 259 Training loss: 0.52966\n",
      "Epoch: 51/500 Iteration: 260 Validation Acc: 0.5200\n",
      "Epoch: 53/500 Iteration: 260 Training loss: 1.61592\n",
      "Epoch: 53/500 Iteration: 261 Training loss: 1.25869\n",
      "Epoch: 53/500 Iteration: 262 Training loss: 0.74246\n",
      "Epoch: 53/500 Iteration: 263 Training loss: 0.63300\n",
      "Epoch: 53/500 Iteration: 264 Training loss: 0.50657\n",
      "Epoch: 52/500 Iteration: 265 Validation Acc: 0.5067\n",
      "Epoch: 54/500 Iteration: 265 Training loss: 1.95833\n",
      "Epoch: 54/500 Iteration: 266 Training loss: 1.31918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/500 Iteration: 267 Training loss: 0.73483\n",
      "Epoch: 54/500 Iteration: 268 Training loss: 0.63657\n",
      "Epoch: 54/500 Iteration: 269 Training loss: 0.50221\n",
      "Epoch: 53/500 Iteration: 270 Validation Acc: 0.5267\n",
      "Epoch: 55/500 Iteration: 270 Training loss: 1.80072\n",
      "Epoch: 55/500 Iteration: 271 Training loss: 1.25537\n",
      "Epoch: 55/500 Iteration: 272 Training loss: 0.72871\n",
      "Epoch: 55/500 Iteration: 273 Training loss: 0.62626\n",
      "Epoch: 55/500 Iteration: 274 Training loss: 0.50198\n",
      "Epoch: 54/500 Iteration: 275 Validation Acc: 0.5133\n",
      "Epoch: 56/500 Iteration: 275 Training loss: 1.82496\n",
      "Epoch: 56/500 Iteration: 276 Training loss: 1.28129\n",
      "Epoch: 56/500 Iteration: 277 Training loss: 0.74241\n",
      "Epoch: 56/500 Iteration: 278 Training loss: 0.65611\n",
      "Epoch: 56/500 Iteration: 279 Training loss: 0.54979\n",
      "Epoch: 55/500 Iteration: 280 Validation Acc: 0.5133\n",
      "Epoch: 57/500 Iteration: 280 Training loss: 1.57133\n",
      "Epoch: 57/500 Iteration: 281 Training loss: 1.19172\n",
      "Epoch: 57/500 Iteration: 282 Training loss: 0.72079\n",
      "Epoch: 57/500 Iteration: 283 Training loss: 0.61792\n",
      "Epoch: 57/500 Iteration: 284 Training loss: 0.49810\n",
      "Epoch: 56/500 Iteration: 285 Validation Acc: 0.5200\n",
      "Epoch: 58/500 Iteration: 285 Training loss: 1.84421\n",
      "Epoch: 58/500 Iteration: 286 Training loss: 1.24685\n",
      "Epoch: 58/500 Iteration: 287 Training loss: 0.73061\n",
      "Epoch: 58/500 Iteration: 288 Training loss: 0.63173\n",
      "Epoch: 58/500 Iteration: 289 Training loss: 0.50891\n",
      "Epoch: 57/500 Iteration: 290 Validation Acc: 0.5200\n",
      "Epoch: 59/500 Iteration: 290 Training loss: 1.61611\n",
      "Epoch: 59/500 Iteration: 291 Training loss: 1.18778\n",
      "Epoch: 59/500 Iteration: 292 Training loss: 0.74193\n",
      "Epoch: 59/500 Iteration: 293 Training loss: 0.64313\n",
      "Epoch: 59/500 Iteration: 294 Training loss: 0.51318\n",
      "Epoch: 58/500 Iteration: 295 Validation Acc: 0.5200\n",
      "Epoch: 60/500 Iteration: 295 Training loss: 1.57191\n",
      "Epoch: 60/500 Iteration: 296 Training loss: 1.22308\n",
      "Epoch: 60/500 Iteration: 297 Training loss: 0.74413\n",
      "Epoch: 60/500 Iteration: 298 Training loss: 0.65535\n",
      "Epoch: 60/500 Iteration: 299 Training loss: 0.54190\n",
      "Epoch: 59/500 Iteration: 300 Validation Acc: 0.5200\n",
      "Epoch: 61/500 Iteration: 300 Training loss: 1.56372\n",
      "Epoch: 61/500 Iteration: 301 Training loss: 1.18857\n",
      "Epoch: 61/500 Iteration: 302 Training loss: 0.72878\n",
      "Epoch: 61/500 Iteration: 303 Training loss: 0.64145\n",
      "Epoch: 61/500 Iteration: 304 Training loss: 0.51511\n",
      "Epoch: 60/500 Iteration: 305 Validation Acc: 0.5267\n",
      "Epoch: 62/500 Iteration: 305 Training loss: 1.82610\n",
      "Epoch: 62/500 Iteration: 306 Training loss: 1.30786\n",
      "Epoch: 62/500 Iteration: 307 Training loss: 0.73746\n",
      "Epoch: 62/500 Iteration: 308 Training loss: 0.62322\n",
      "Epoch: 62/500 Iteration: 309 Training loss: 0.49185\n",
      "Epoch: 61/500 Iteration: 310 Validation Acc: 0.5200\n",
      "Epoch: 63/500 Iteration: 310 Training loss: 1.78237\n",
      "Epoch: 63/500 Iteration: 311 Training loss: 1.19885\n",
      "Epoch: 63/500 Iteration: 312 Training loss: 0.69775\n",
      "Epoch: 63/500 Iteration: 313 Training loss: 0.60684\n",
      "Epoch: 63/500 Iteration: 314 Training loss: 0.49203\n",
      "Epoch: 62/500 Iteration: 315 Validation Acc: 0.5200\n",
      "Epoch: 64/500 Iteration: 315 Training loss: 1.51866\n",
      "Epoch: 64/500 Iteration: 316 Training loss: 1.14092\n",
      "Epoch: 64/500 Iteration: 317 Training loss: 0.68163\n",
      "Epoch: 64/500 Iteration: 318 Training loss: 0.58651\n",
      "Epoch: 64/500 Iteration: 319 Training loss: 0.47765\n",
      "Epoch: 63/500 Iteration: 320 Validation Acc: 0.5267\n",
      "Epoch: 65/500 Iteration: 320 Training loss: 1.53874\n",
      "Epoch: 65/500 Iteration: 321 Training loss: 1.16825\n",
      "Epoch: 65/500 Iteration: 322 Training loss: 0.68338\n",
      "Epoch: 65/500 Iteration: 323 Training loss: 0.58894\n",
      "Epoch: 65/500 Iteration: 324 Training loss: 0.46370\n",
      "Epoch: 64/500 Iteration: 325 Validation Acc: 0.5267\n",
      "Epoch: 66/500 Iteration: 325 Training loss: 2.51638\n",
      "Epoch: 66/500 Iteration: 326 Training loss: 1.49171\n",
      "Epoch: 66/500 Iteration: 327 Training loss: 0.70383\n",
      "Epoch: 66/500 Iteration: 328 Training loss: 0.59235\n",
      "Epoch: 66/500 Iteration: 329 Training loss: 0.49415\n",
      "Epoch: 65/500 Iteration: 330 Validation Acc: 0.5267\n",
      "Epoch: 67/500 Iteration: 330 Training loss: 1.59230\n",
      "Epoch: 67/500 Iteration: 331 Training loss: 1.16525\n",
      "Epoch: 67/500 Iteration: 332 Training loss: 0.63704\n",
      "Epoch: 67/500 Iteration: 333 Training loss: 0.55317\n",
      "Epoch: 67/500 Iteration: 334 Training loss: 0.45807\n",
      "Epoch: 66/500 Iteration: 335 Validation Acc: 0.5133\n",
      "Epoch: 68/500 Iteration: 335 Training loss: 1.60867\n",
      "Epoch: 68/500 Iteration: 336 Training loss: 1.13345\n",
      "Epoch: 68/500 Iteration: 337 Training loss: 0.64892\n",
      "Epoch: 68/500 Iteration: 338 Training loss: 0.55523\n",
      "Epoch: 68/500 Iteration: 339 Training loss: 0.45499\n",
      "Epoch: 67/500 Iteration: 340 Validation Acc: 0.5133\n",
      "Epoch: 69/500 Iteration: 340 Training loss: 1.57423\n",
      "Epoch: 69/500 Iteration: 341 Training loss: 1.19214\n",
      "Epoch: 69/500 Iteration: 342 Training loss: 0.67227\n",
      "Epoch: 69/500 Iteration: 343 Training loss: 0.57719\n",
      "Epoch: 69/500 Iteration: 344 Training loss: 0.46997\n",
      "Epoch: 68/500 Iteration: 345 Validation Acc: 0.5400\n",
      "Epoch: 70/500 Iteration: 345 Training loss: 1.50636\n",
      "Epoch: 70/500 Iteration: 346 Training loss: 1.10842\n",
      "Epoch: 70/500 Iteration: 347 Training loss: 0.66389\n",
      "Epoch: 70/500 Iteration: 348 Training loss: 0.56324\n",
      "Epoch: 70/500 Iteration: 349 Training loss: 0.45730\n",
      "Epoch: 69/500 Iteration: 350 Validation Acc: 0.5200\n",
      "Epoch: 71/500 Iteration: 350 Training loss: 1.64259\n",
      "Epoch: 71/500 Iteration: 351 Training loss: 1.26129\n",
      "Epoch: 71/500 Iteration: 352 Training loss: 0.69379\n",
      "Epoch: 71/500 Iteration: 353 Training loss: 0.58253\n",
      "Epoch: 71/500 Iteration: 354 Training loss: 0.46800\n",
      "Epoch: 70/500 Iteration: 355 Validation Acc: 0.5267\n",
      "Epoch: 72/500 Iteration: 355 Training loss: 2.06749\n",
      "Epoch: 72/500 Iteration: 356 Training loss: 1.23285\n",
      "Epoch: 72/500 Iteration: 357 Training loss: 0.66100\n",
      "Epoch: 72/500 Iteration: 358 Training loss: 0.56796\n",
      "Epoch: 72/500 Iteration: 359 Training loss: 0.45512\n",
      "Epoch: 71/500 Iteration: 360 Validation Acc: 0.5200\n",
      "Epoch: 73/500 Iteration: 360 Training loss: 1.66067\n",
      "Epoch: 73/500 Iteration: 361 Training loss: 1.13266\n",
      "Epoch: 73/500 Iteration: 362 Training loss: 0.65044\n",
      "Epoch: 73/500 Iteration: 363 Training loss: 0.54716\n",
      "Epoch: 73/500 Iteration: 364 Training loss: 0.45324\n",
      "Epoch: 72/500 Iteration: 365 Validation Acc: 0.5400\n",
      "Epoch: 74/500 Iteration: 365 Training loss: 1.55747\n",
      "Epoch: 74/500 Iteration: 366 Training loss: 1.12357\n",
      "Epoch: 74/500 Iteration: 367 Training loss: 0.65303\n",
      "Epoch: 74/500 Iteration: 368 Training loss: 0.56081\n",
      "Epoch: 74/500 Iteration: 369 Training loss: 0.45352\n",
      "Epoch: 73/500 Iteration: 370 Validation Acc: 0.5133\n",
      "Epoch: 75/500 Iteration: 370 Training loss: 1.55919\n",
      "Epoch: 75/500 Iteration: 371 Training loss: 1.09857\n",
      "Epoch: 75/500 Iteration: 372 Training loss: 0.64087\n",
      "Epoch: 75/500 Iteration: 373 Training loss: 0.55225\n",
      "Epoch: 75/500 Iteration: 374 Training loss: 0.43529\n",
      "Epoch: 74/500 Iteration: 375 Validation Acc: 0.5200\n",
      "Epoch: 76/500 Iteration: 375 Training loss: 1.75327\n",
      "Epoch: 76/500 Iteration: 376 Training loss: 1.31420\n",
      "Epoch: 76/500 Iteration: 377 Training loss: 0.68555\n",
      "Epoch: 76/500 Iteration: 378 Training loss: 0.58019\n",
      "Epoch: 76/500 Iteration: 379 Training loss: 0.48367\n",
      "Epoch: 75/500 Iteration: 380 Validation Acc: 0.5200\n",
      "Epoch: 77/500 Iteration: 380 Training loss: 1.65039\n",
      "Epoch: 77/500 Iteration: 381 Training loss: 1.10310\n",
      "Epoch: 77/500 Iteration: 382 Training loss: 0.62912\n",
      "Epoch: 77/500 Iteration: 383 Training loss: 0.53065\n",
      "Epoch: 77/500 Iteration: 384 Training loss: 0.44323\n",
      "Epoch: 76/500 Iteration: 385 Validation Acc: 0.5200\n",
      "Epoch: 78/500 Iteration: 385 Training loss: 1.58393\n",
      "Epoch: 78/500 Iteration: 386 Training loss: 1.07436\n",
      "Epoch: 78/500 Iteration: 387 Training loss: 0.62748\n",
      "Epoch: 78/500 Iteration: 388 Training loss: 0.52266\n",
      "Epoch: 78/500 Iteration: 389 Training loss: 0.40793\n",
      "Epoch: 77/500 Iteration: 390 Validation Acc: 0.5267\n",
      "Epoch: 79/500 Iteration: 390 Training loss: 1.75749\n",
      "Epoch: 79/500 Iteration: 391 Training loss: 1.14216\n",
      "Epoch: 79/500 Iteration: 392 Training loss: 0.65073\n",
      "Epoch: 79/500 Iteration: 393 Training loss: 0.54169\n",
      "Epoch: 79/500 Iteration: 394 Training loss: 0.44841\n",
      "Epoch: 78/500 Iteration: 395 Validation Acc: 0.5333\n",
      "Epoch: 80/500 Iteration: 395 Training loss: 1.70134\n",
      "Epoch: 80/500 Iteration: 396 Training loss: 1.23537\n",
      "Epoch: 80/500 Iteration: 397 Training loss: 0.64024\n",
      "Epoch: 80/500 Iteration: 398 Training loss: 0.54513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/500 Iteration: 399 Training loss: 0.44696\n",
      "Epoch: 79/500 Iteration: 400 Validation Acc: 0.5133\n",
      "Epoch: 81/500 Iteration: 400 Training loss: 1.60585\n",
      "Epoch: 81/500 Iteration: 401 Training loss: 1.10187\n",
      "Epoch: 81/500 Iteration: 402 Training loss: 0.61350\n",
      "Epoch: 81/500 Iteration: 403 Training loss: 0.52065\n",
      "Epoch: 81/500 Iteration: 404 Training loss: 0.43473\n",
      "Epoch: 80/500 Iteration: 405 Validation Acc: 0.5533\n",
      "Epoch: 82/500 Iteration: 405 Training loss: 1.54474\n",
      "Epoch: 82/500 Iteration: 406 Training loss: 1.09960\n",
      "Epoch: 82/500 Iteration: 407 Training loss: 0.62198\n",
      "Epoch: 82/500 Iteration: 408 Training loss: 0.53301\n",
      "Epoch: 82/500 Iteration: 409 Training loss: 0.43885\n",
      "Epoch: 81/500 Iteration: 410 Validation Acc: 0.5267\n",
      "Epoch: 83/500 Iteration: 410 Training loss: 1.54426\n",
      "Epoch: 83/500 Iteration: 411 Training loss: 1.12583\n",
      "Epoch: 83/500 Iteration: 412 Training loss: 0.63585\n",
      "Epoch: 83/500 Iteration: 413 Training loss: 0.53037\n",
      "Epoch: 83/500 Iteration: 414 Training loss: 0.42995\n",
      "Epoch: 82/500 Iteration: 415 Validation Acc: 0.5200\n",
      "Epoch: 84/500 Iteration: 415 Training loss: 1.78293\n",
      "Epoch: 84/500 Iteration: 416 Training loss: 1.20224\n",
      "Epoch: 84/500 Iteration: 417 Training loss: 0.62417\n",
      "Epoch: 84/500 Iteration: 418 Training loss: 0.52765\n",
      "Epoch: 84/500 Iteration: 419 Training loss: 0.41220\n",
      "Epoch: 83/500 Iteration: 420 Validation Acc: 0.5267\n",
      "Epoch: 85/500 Iteration: 420 Training loss: 1.74235\n",
      "Epoch: 85/500 Iteration: 421 Training loss: 1.11580\n",
      "Epoch: 85/500 Iteration: 422 Training loss: 0.59267\n",
      "Epoch: 85/500 Iteration: 423 Training loss: 0.49512\n",
      "Epoch: 85/500 Iteration: 424 Training loss: 0.40843\n",
      "Epoch: 84/500 Iteration: 425 Validation Acc: 0.5333\n",
      "Epoch: 86/500 Iteration: 425 Training loss: 1.59810\n",
      "Epoch: 86/500 Iteration: 426 Training loss: 1.06050\n",
      "Epoch: 86/500 Iteration: 427 Training loss: 0.58042\n",
      "Epoch: 86/500 Iteration: 428 Training loss: 0.49268\n",
      "Epoch: 86/500 Iteration: 429 Training loss: 0.39962\n",
      "Epoch: 85/500 Iteration: 430 Validation Acc: 0.5267\n",
      "Epoch: 87/500 Iteration: 430 Training loss: 1.59588\n",
      "Epoch: 87/500 Iteration: 431 Training loss: 1.03673\n",
      "Epoch: 87/500 Iteration: 432 Training loss: 0.61204\n",
      "Epoch: 87/500 Iteration: 433 Training loss: 0.50967\n",
      "Epoch: 87/500 Iteration: 434 Training loss: 0.41805\n",
      "Epoch: 86/500 Iteration: 435 Validation Acc: 0.5133\n",
      "Epoch: 88/500 Iteration: 435 Training loss: 1.59374\n",
      "Epoch: 88/500 Iteration: 436 Training loss: 1.17907\n",
      "Epoch: 88/500 Iteration: 437 Training loss: 0.62250\n",
      "Epoch: 88/500 Iteration: 438 Training loss: 0.51967\n",
      "Epoch: 88/500 Iteration: 439 Training loss: 0.43483\n",
      "Epoch: 87/500 Iteration: 440 Validation Acc: 0.5333\n",
      "Epoch: 89/500 Iteration: 440 Training loss: 1.64248\n",
      "Epoch: 89/500 Iteration: 441 Training loss: 1.10253\n",
      "Epoch: 89/500 Iteration: 442 Training loss: 0.59539\n",
      "Epoch: 89/500 Iteration: 443 Training loss: 0.49812\n",
      "Epoch: 89/500 Iteration: 444 Training loss: 0.41345\n",
      "Epoch: 88/500 Iteration: 445 Validation Acc: 0.5267\n",
      "Epoch: 90/500 Iteration: 445 Training loss: 1.49555\n",
      "Epoch: 90/500 Iteration: 446 Training loss: 1.06739\n",
      "Epoch: 90/500 Iteration: 447 Training loss: 0.59531\n",
      "Epoch: 90/500 Iteration: 448 Training loss: 0.49744\n",
      "Epoch: 90/500 Iteration: 449 Training loss: 0.40714\n",
      "Epoch: 89/500 Iteration: 450 Validation Acc: 0.5267\n",
      "Epoch: 91/500 Iteration: 450 Training loss: 1.48729\n",
      "Epoch: 91/500 Iteration: 451 Training loss: 1.02447\n",
      "Epoch: 91/500 Iteration: 452 Training loss: 0.58985\n",
      "Epoch: 91/500 Iteration: 453 Training loss: 0.48754\n",
      "Epoch: 91/500 Iteration: 454 Training loss: 0.38597\n",
      "Epoch: 90/500 Iteration: 455 Validation Acc: 0.5467\n",
      "Epoch: 92/500 Iteration: 455 Training loss: 1.57824\n",
      "Epoch: 92/500 Iteration: 456 Training loss: 1.06670\n",
      "Epoch: 92/500 Iteration: 457 Training loss: 0.59858\n",
      "Epoch: 92/500 Iteration: 458 Training loss: 0.49030\n",
      "Epoch: 92/500 Iteration: 459 Training loss: 0.38481\n",
      "Epoch: 91/500 Iteration: 460 Validation Acc: 0.5400\n",
      "Epoch: 93/500 Iteration: 460 Training loss: 2.09412\n",
      "Epoch: 93/500 Iteration: 461 Training loss: 1.18667\n",
      "Epoch: 93/500 Iteration: 462 Training loss: 0.59605\n",
      "Epoch: 93/500 Iteration: 463 Training loss: 0.48816\n",
      "Epoch: 93/500 Iteration: 464 Training loss: 0.40414\n",
      "Epoch: 92/500 Iteration: 465 Validation Acc: 0.5400\n",
      "Epoch: 94/500 Iteration: 465 Training loss: 1.56631\n",
      "Epoch: 94/500 Iteration: 466 Training loss: 1.04296\n",
      "Epoch: 94/500 Iteration: 467 Training loss: 0.55033\n",
      "Epoch: 94/500 Iteration: 468 Training loss: 0.47207\n",
      "Epoch: 94/500 Iteration: 469 Training loss: 0.38341\n",
      "Epoch: 93/500 Iteration: 470 Validation Acc: 0.5333\n",
      "Epoch: 95/500 Iteration: 470 Training loss: 1.56372\n",
      "Epoch: 95/500 Iteration: 471 Training loss: 0.99754\n",
      "Epoch: 95/500 Iteration: 472 Training loss: 0.56693\n",
      "Epoch: 95/500 Iteration: 473 Training loss: 0.46422\n",
      "Epoch: 95/500 Iteration: 474 Training loss: 0.37182\n",
      "Epoch: 94/500 Iteration: 475 Validation Acc: 0.5267\n",
      "Epoch: 96/500 Iteration: 475 Training loss: 1.60740\n",
      "Epoch: 96/500 Iteration: 476 Training loss: 1.06764\n",
      "Epoch: 96/500 Iteration: 477 Training loss: 0.58684\n",
      "Epoch: 96/500 Iteration: 478 Training loss: 0.47981\n",
      "Epoch: 96/500 Iteration: 479 Training loss: 0.39517\n",
      "Epoch: 95/500 Iteration: 480 Validation Acc: 0.5333\n",
      "Epoch: 97/500 Iteration: 480 Training loss: 1.60313\n",
      "Epoch: 97/500 Iteration: 481 Training loss: 1.06805\n",
      "Epoch: 97/500 Iteration: 482 Training loss: 0.56297\n",
      "Epoch: 97/500 Iteration: 483 Training loss: 0.46769\n",
      "Epoch: 97/500 Iteration: 484 Training loss: 0.37693\n",
      "Epoch: 96/500 Iteration: 485 Validation Acc: 0.5533\n",
      "Epoch: 98/500 Iteration: 485 Training loss: 1.71830\n",
      "Epoch: 98/500 Iteration: 486 Training loss: 1.06875\n",
      "Epoch: 98/500 Iteration: 487 Training loss: 0.54986\n",
      "Epoch: 98/500 Iteration: 488 Training loss: 0.46364\n",
      "Epoch: 98/500 Iteration: 489 Training loss: 0.36911\n",
      "Epoch: 97/500 Iteration: 490 Validation Acc: 0.5533\n",
      "Epoch: 99/500 Iteration: 490 Training loss: 1.54004\n",
      "Epoch: 99/500 Iteration: 491 Training loss: 0.96787\n",
      "Epoch: 99/500 Iteration: 492 Training loss: 0.54063\n",
      "Epoch: 99/500 Iteration: 493 Training loss: 0.44684\n",
      "Epoch: 99/500 Iteration: 494 Training loss: 0.35037\n",
      "Epoch: 98/500 Iteration: 495 Validation Acc: 0.5533\n",
      "Epoch: 100/500 Iteration: 495 Training loss: 1.61379\n",
      "Epoch: 100/500 Iteration: 496 Training loss: 1.00913\n",
      "Epoch: 100/500 Iteration: 497 Training loss: 0.56347\n",
      "Epoch: 100/500 Iteration: 498 Training loss: 0.46229\n",
      "Epoch: 100/500 Iteration: 499 Training loss: 0.37356\n",
      "Epoch: 99/500 Iteration: 500 Validation Acc: 0.5200\n",
      "Epoch: 101/500 Iteration: 500 Training loss: 1.62080\n",
      "Epoch: 101/500 Iteration: 501 Training loss: 1.03174\n",
      "Epoch: 101/500 Iteration: 502 Training loss: 0.55451\n",
      "Epoch: 101/500 Iteration: 503 Training loss: 0.46253\n",
      "Epoch: 101/500 Iteration: 504 Training loss: 0.36977\n",
      "Epoch: 100/500 Iteration: 505 Validation Acc: 0.5333\n",
      "Epoch: 102/500 Iteration: 505 Training loss: 1.81948\n",
      "Epoch: 102/500 Iteration: 506 Training loss: 1.13033\n",
      "Epoch: 102/500 Iteration: 507 Training loss: 0.56453\n",
      "Epoch: 102/500 Iteration: 508 Training loss: 0.45340\n",
      "Epoch: 102/500 Iteration: 509 Training loss: 0.36435\n",
      "Epoch: 101/500 Iteration: 510 Validation Acc: 0.5667\n",
      "Epoch: 103/500 Iteration: 510 Training loss: 1.61580\n",
      "Epoch: 103/500 Iteration: 511 Training loss: 0.99133\n",
      "Epoch: 103/500 Iteration: 512 Training loss: 0.52632\n",
      "Epoch: 103/500 Iteration: 513 Training loss: 0.43193\n",
      "Epoch: 103/500 Iteration: 514 Training loss: 0.33416\n",
      "Epoch: 102/500 Iteration: 515 Validation Acc: 0.5533\n",
      "Epoch: 104/500 Iteration: 515 Training loss: 1.62213\n",
      "Epoch: 104/500 Iteration: 516 Training loss: 0.96588\n",
      "Epoch: 104/500 Iteration: 517 Training loss: 0.54181\n",
      "Epoch: 104/500 Iteration: 518 Training loss: 0.44379\n",
      "Epoch: 104/500 Iteration: 519 Training loss: 0.34401\n",
      "Epoch: 103/500 Iteration: 520 Validation Acc: 0.5533\n",
      "Epoch: 105/500 Iteration: 520 Training loss: 1.58649\n",
      "Epoch: 105/500 Iteration: 521 Training loss: 0.98384\n",
      "Epoch: 105/500 Iteration: 522 Training loss: 0.53840\n",
      "Epoch: 105/500 Iteration: 523 Training loss: 0.44822\n",
      "Epoch: 105/500 Iteration: 524 Training loss: 0.36544\n",
      "Epoch: 104/500 Iteration: 525 Validation Acc: 0.5600\n",
      "Epoch: 106/500 Iteration: 525 Training loss: 1.49167\n",
      "Epoch: 106/500 Iteration: 526 Training loss: 1.01292\n",
      "Epoch: 106/500 Iteration: 527 Training loss: 0.55533\n",
      "Epoch: 106/500 Iteration: 528 Training loss: 0.44521\n",
      "Epoch: 106/500 Iteration: 529 Training loss: 0.36824\n",
      "Epoch: 105/500 Iteration: 530 Validation Acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/500 Iteration: 530 Training loss: 1.62446\n",
      "Epoch: 107/500 Iteration: 531 Training loss: 0.98315\n",
      "Epoch: 107/500 Iteration: 532 Training loss: 0.54959\n",
      "Epoch: 107/500 Iteration: 533 Training loss: 0.42885\n",
      "Epoch: 107/500 Iteration: 534 Training loss: 0.34383\n",
      "Epoch: 106/500 Iteration: 535 Validation Acc: 0.5667\n",
      "Epoch: 108/500 Iteration: 535 Training loss: 1.61238\n",
      "Epoch: 108/500 Iteration: 536 Training loss: 0.96204\n",
      "Epoch: 108/500 Iteration: 537 Training loss: 0.52819\n",
      "Epoch: 108/500 Iteration: 538 Training loss: 0.41638\n",
      "Epoch: 108/500 Iteration: 539 Training loss: 0.33370\n",
      "Epoch: 107/500 Iteration: 540 Validation Acc: 0.5400\n",
      "Epoch: 109/500 Iteration: 540 Training loss: 1.56894\n",
      "Epoch: 109/500 Iteration: 541 Training loss: 0.96263\n",
      "Epoch: 109/500 Iteration: 542 Training loss: 0.54632\n",
      "Epoch: 109/500 Iteration: 543 Training loss: 0.43384\n",
      "Epoch: 109/500 Iteration: 544 Training loss: 0.35183\n",
      "Epoch: 108/500 Iteration: 545 Validation Acc: 0.5667\n",
      "Epoch: 110/500 Iteration: 545 Training loss: 1.43310\n",
      "Epoch: 110/500 Iteration: 546 Training loss: 0.90623\n",
      "Epoch: 110/500 Iteration: 547 Training loss: 0.52153\n",
      "Epoch: 110/500 Iteration: 548 Training loss: 0.42673\n",
      "Epoch: 110/500 Iteration: 549 Training loss: 0.32140\n",
      "Epoch: 109/500 Iteration: 550 Validation Acc: 0.5533\n",
      "Epoch: 111/500 Iteration: 550 Training loss: 2.06391\n",
      "Epoch: 111/500 Iteration: 551 Training loss: 1.03212\n",
      "Epoch: 111/500 Iteration: 552 Training loss: 0.53343\n",
      "Epoch: 111/500 Iteration: 553 Training loss: 0.43894\n",
      "Epoch: 111/500 Iteration: 554 Training loss: 0.35046\n",
      "Epoch: 110/500 Iteration: 555 Validation Acc: 0.5800\n",
      "Epoch: 112/500 Iteration: 555 Training loss: 1.58857\n",
      "Epoch: 112/500 Iteration: 556 Training loss: 0.96904\n",
      "Epoch: 112/500 Iteration: 557 Training loss: 0.52945\n",
      "Epoch: 112/500 Iteration: 558 Training loss: 0.41502\n",
      "Epoch: 112/500 Iteration: 559 Training loss: 0.33058\n",
      "Epoch: 111/500 Iteration: 560 Validation Acc: 0.5600\n",
      "Epoch: 113/500 Iteration: 560 Training loss: 1.49180\n",
      "Epoch: 113/500 Iteration: 561 Training loss: 0.89580\n",
      "Epoch: 113/500 Iteration: 562 Training loss: 0.50692\n",
      "Epoch: 113/500 Iteration: 563 Training loss: 0.41016\n",
      "Epoch: 113/500 Iteration: 564 Training loss: 0.32041\n",
      "Epoch: 112/500 Iteration: 565 Validation Acc: 0.5600\n",
      "Epoch: 114/500 Iteration: 565 Training loss: 1.49347\n",
      "Epoch: 114/500 Iteration: 566 Training loss: 0.88034\n",
      "Epoch: 114/500 Iteration: 567 Training loss: 0.52883\n",
      "Epoch: 114/500 Iteration: 568 Training loss: 0.40610\n",
      "Epoch: 114/500 Iteration: 569 Training loss: 0.32805\n",
      "Epoch: 113/500 Iteration: 570 Validation Acc: 0.5600\n",
      "Epoch: 115/500 Iteration: 570 Training loss: 1.56782\n",
      "Epoch: 115/500 Iteration: 571 Training loss: 1.14285\n",
      "Epoch: 115/500 Iteration: 572 Training loss: 0.56576\n",
      "Epoch: 115/500 Iteration: 573 Training loss: 0.44207\n",
      "Epoch: 115/500 Iteration: 574 Training loss: 0.34234\n",
      "Epoch: 114/500 Iteration: 575 Validation Acc: 0.5400\n",
      "Epoch: 116/500 Iteration: 575 Training loss: 1.80158\n",
      "Epoch: 116/500 Iteration: 576 Training loss: 0.93612\n",
      "Epoch: 116/500 Iteration: 577 Training loss: 0.49633\n",
      "Epoch: 116/500 Iteration: 578 Training loss: 0.39561\n",
      "Epoch: 116/500 Iteration: 579 Training loss: 0.31660\n",
      "Epoch: 115/500 Iteration: 580 Validation Acc: 0.6000\n",
      "Epoch: 117/500 Iteration: 580 Training loss: 1.56483\n",
      "Epoch: 117/500 Iteration: 581 Training loss: 0.85875\n",
      "Epoch: 117/500 Iteration: 582 Training loss: 0.49698\n",
      "Epoch: 117/500 Iteration: 583 Training loss: 0.39392\n",
      "Epoch: 117/500 Iteration: 584 Training loss: 0.30694\n",
      "Epoch: 116/500 Iteration: 585 Validation Acc: 0.5733\n",
      "Epoch: 118/500 Iteration: 585 Training loss: 1.49020\n",
      "Epoch: 118/500 Iteration: 586 Training loss: 0.87336\n",
      "Epoch: 118/500 Iteration: 587 Training loss: 0.50408\n",
      "Epoch: 118/500 Iteration: 588 Training loss: 0.41339\n",
      "Epoch: 118/500 Iteration: 589 Training loss: 0.33437\n",
      "Epoch: 117/500 Iteration: 590 Validation Acc: 0.6067\n",
      "Epoch: 119/500 Iteration: 590 Training loss: 1.42951\n",
      "Epoch: 119/500 Iteration: 591 Training loss: 0.86321\n",
      "Epoch: 119/500 Iteration: 592 Training loss: 0.51300\n",
      "Epoch: 119/500 Iteration: 593 Training loss: 0.41444\n",
      "Epoch: 119/500 Iteration: 594 Training loss: 0.33315\n",
      "Epoch: 118/500 Iteration: 595 Validation Acc: 0.5600\n",
      "Epoch: 120/500 Iteration: 595 Training loss: 1.42982\n",
      "Epoch: 120/500 Iteration: 596 Training loss: 0.94087\n",
      "Epoch: 120/500 Iteration: 597 Training loss: 0.53263\n",
      "Epoch: 120/500 Iteration: 598 Training loss: 0.39798\n",
      "Epoch: 120/500 Iteration: 599 Training loss: 0.31608\n",
      "Epoch: 119/500 Iteration: 600 Validation Acc: 0.5600\n",
      "Epoch: 121/500 Iteration: 600 Training loss: 1.60588\n",
      "Epoch: 121/500 Iteration: 601 Training loss: 0.92230\n",
      "Epoch: 121/500 Iteration: 602 Training loss: 0.47699\n",
      "Epoch: 121/500 Iteration: 603 Training loss: 0.39132\n",
      "Epoch: 121/500 Iteration: 604 Training loss: 0.30965\n",
      "Epoch: 120/500 Iteration: 605 Validation Acc: 0.5867\n",
      "Epoch: 122/500 Iteration: 605 Training loss: 1.49789\n",
      "Epoch: 122/500 Iteration: 606 Training loss: 0.84323\n",
      "Epoch: 122/500 Iteration: 607 Training loss: 0.50480\n",
      "Epoch: 122/500 Iteration: 608 Training loss: 0.36984\n",
      "Epoch: 122/500 Iteration: 609 Training loss: 0.28804\n",
      "Epoch: 121/500 Iteration: 610 Validation Acc: 0.5933\n",
      "Epoch: 123/500 Iteration: 610 Training loss: 1.58139\n",
      "Epoch: 123/500 Iteration: 611 Training loss: 0.80290\n",
      "Epoch: 123/500 Iteration: 612 Training loss: 0.51017\n",
      "Epoch: 123/500 Iteration: 613 Training loss: 0.37803\n",
      "Epoch: 123/500 Iteration: 614 Training loss: 0.28305\n",
      "Epoch: 122/500 Iteration: 615 Validation Acc: 0.5467\n",
      "Epoch: 124/500 Iteration: 615 Training loss: 1.82090\n",
      "Epoch: 124/500 Iteration: 616 Training loss: 0.97981\n",
      "Epoch: 124/500 Iteration: 617 Training loss: 0.53520\n",
      "Epoch: 124/500 Iteration: 618 Training loss: 0.41702\n",
      "Epoch: 124/500 Iteration: 619 Training loss: 0.33082\n",
      "Epoch: 123/500 Iteration: 620 Validation Acc: 0.5867\n",
      "Epoch: 125/500 Iteration: 620 Training loss: 1.59184\n",
      "Epoch: 125/500 Iteration: 621 Training loss: 0.88989\n",
      "Epoch: 125/500 Iteration: 622 Training loss: 0.47989\n",
      "Epoch: 125/500 Iteration: 623 Training loss: 0.39306\n",
      "Epoch: 125/500 Iteration: 624 Training loss: 0.31331\n",
      "Epoch: 124/500 Iteration: 625 Validation Acc: 0.5933\n",
      "Epoch: 126/500 Iteration: 625 Training loss: 1.41118\n",
      "Epoch: 126/500 Iteration: 626 Training loss: 0.83396\n",
      "Epoch: 126/500 Iteration: 627 Training loss: 0.48161\n",
      "Epoch: 126/500 Iteration: 628 Training loss: 0.37743\n",
      "Epoch: 126/500 Iteration: 629 Training loss: 0.28092\n",
      "Epoch: 125/500 Iteration: 630 Validation Acc: 0.6000\n",
      "Epoch: 127/500 Iteration: 630 Training loss: 1.61568\n",
      "Epoch: 127/500 Iteration: 631 Training loss: 0.82756\n",
      "Epoch: 127/500 Iteration: 632 Training loss: 0.48710\n",
      "Epoch: 127/500 Iteration: 633 Training loss: 0.38133\n",
      "Epoch: 127/500 Iteration: 634 Training loss: 0.29706\n",
      "Epoch: 126/500 Iteration: 635 Validation Acc: 0.5867\n",
      "Epoch: 128/500 Iteration: 635 Training loss: 1.51852\n",
      "Epoch: 128/500 Iteration: 636 Training loss: 0.89647\n",
      "Epoch: 128/500 Iteration: 637 Training loss: 0.48556\n",
      "Epoch: 128/500 Iteration: 638 Training loss: 0.39951\n",
      "Epoch: 128/500 Iteration: 639 Training loss: 0.32438\n",
      "Epoch: 127/500 Iteration: 640 Validation Acc: 0.5600\n",
      "Epoch: 129/500 Iteration: 640 Training loss: 1.41145\n",
      "Epoch: 129/500 Iteration: 641 Training loss: 0.84868\n",
      "Epoch: 129/500 Iteration: 642 Training loss: 0.50215\n",
      "Epoch: 129/500 Iteration: 643 Training loss: 0.37218\n",
      "Epoch: 129/500 Iteration: 644 Training loss: 0.30311\n",
      "Epoch: 128/500 Iteration: 645 Validation Acc: 0.6067\n",
      "Epoch: 130/500 Iteration: 645 Training loss: 1.46015\n",
      "Epoch: 130/500 Iteration: 646 Training loss: 0.81072\n",
      "Epoch: 130/500 Iteration: 647 Training loss: 0.46618\n",
      "Epoch: 130/500 Iteration: 648 Training loss: 0.37039\n",
      "Epoch: 130/500 Iteration: 649 Training loss: 0.28648\n",
      "Epoch: 129/500 Iteration: 650 Validation Acc: 0.6333\n",
      "Epoch: 131/500 Iteration: 650 Training loss: 1.49596\n",
      "Epoch: 131/500 Iteration: 651 Training loss: 0.81655\n",
      "Epoch: 131/500 Iteration: 652 Training loss: 0.49633\n",
      "Epoch: 131/500 Iteration: 653 Training loss: 0.36416\n",
      "Epoch: 131/500 Iteration: 654 Training loss: 0.27621\n",
      "Epoch: 130/500 Iteration: 655 Validation Acc: 0.5933\n",
      "Epoch: 132/500 Iteration: 655 Training loss: 1.57036\n",
      "Epoch: 132/500 Iteration: 656 Training loss: 0.85740\n",
      "Epoch: 132/500 Iteration: 657 Training loss: 0.48548\n",
      "Epoch: 132/500 Iteration: 658 Training loss: 0.36342\n",
      "Epoch: 132/500 Iteration: 659 Training loss: 0.29747\n",
      "Epoch: 131/500 Iteration: 660 Validation Acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133/500 Iteration: 660 Training loss: 1.52089\n",
      "Epoch: 133/500 Iteration: 661 Training loss: 0.91403\n",
      "Epoch: 133/500 Iteration: 662 Training loss: 0.47824\n",
      "Epoch: 133/500 Iteration: 663 Training loss: 0.37884\n",
      "Epoch: 133/500 Iteration: 664 Training loss: 0.30329\n",
      "Epoch: 132/500 Iteration: 665 Validation Acc: 0.5933\n",
      "Epoch: 134/500 Iteration: 665 Training loss: 1.47634\n",
      "Epoch: 134/500 Iteration: 666 Training loss: 0.79738\n",
      "Epoch: 134/500 Iteration: 667 Training loss: 0.44875\n",
      "Epoch: 134/500 Iteration: 668 Training loss: 0.35397\n",
      "Epoch: 134/500 Iteration: 669 Training loss: 0.26608\n",
      "Epoch: 133/500 Iteration: 670 Validation Acc: 0.5933\n",
      "Epoch: 135/500 Iteration: 670 Training loss: 1.51817\n",
      "Epoch: 135/500 Iteration: 671 Training loss: 0.72379\n",
      "Epoch: 135/500 Iteration: 672 Training loss: 0.48204\n",
      "Epoch: 135/500 Iteration: 673 Training loss: 0.34371\n",
      "Epoch: 135/500 Iteration: 674 Training loss: 0.27546\n",
      "Epoch: 134/500 Iteration: 675 Validation Acc: 0.5800\n",
      "Epoch: 136/500 Iteration: 675 Training loss: 1.54755\n",
      "Epoch: 136/500 Iteration: 676 Training loss: 0.84630\n",
      "Epoch: 136/500 Iteration: 677 Training loss: 0.47476\n",
      "Epoch: 136/500 Iteration: 678 Training loss: 0.37115\n",
      "Epoch: 136/500 Iteration: 679 Training loss: 0.29477\n",
      "Epoch: 135/500 Iteration: 680 Validation Acc: 0.5933\n",
      "Epoch: 137/500 Iteration: 680 Training loss: 1.76033\n",
      "Epoch: 137/500 Iteration: 681 Training loss: 0.96221\n",
      "Epoch: 137/500 Iteration: 682 Training loss: 0.48482\n",
      "Epoch: 137/500 Iteration: 683 Training loss: 0.37668\n",
      "Epoch: 137/500 Iteration: 684 Training loss: 0.29978\n",
      "Epoch: 136/500 Iteration: 685 Validation Acc: 0.6133\n",
      "Epoch: 138/500 Iteration: 685 Training loss: 1.45597\n",
      "Epoch: 138/500 Iteration: 686 Training loss: 0.83453\n",
      "Epoch: 138/500 Iteration: 687 Training loss: 0.43787\n",
      "Epoch: 138/500 Iteration: 688 Training loss: 0.34937\n",
      "Epoch: 138/500 Iteration: 689 Training loss: 0.25865\n",
      "Epoch: 137/500 Iteration: 690 Validation Acc: 0.5867\n",
      "Epoch: 139/500 Iteration: 690 Training loss: 1.53243\n",
      "Epoch: 139/500 Iteration: 691 Training loss: 0.71401\n",
      "Epoch: 139/500 Iteration: 692 Training loss: 0.47767\n",
      "Epoch: 139/500 Iteration: 693 Training loss: 0.34171\n",
      "Epoch: 139/500 Iteration: 694 Training loss: 0.26695\n",
      "Epoch: 138/500 Iteration: 695 Validation Acc: 0.6067\n",
      "Epoch: 140/500 Iteration: 695 Training loss: 1.45374\n",
      "Epoch: 140/500 Iteration: 696 Training loss: 0.77923\n",
      "Epoch: 140/500 Iteration: 697 Training loss: 0.45099\n",
      "Epoch: 140/500 Iteration: 698 Training loss: 0.35976\n",
      "Epoch: 140/500 Iteration: 699 Training loss: 0.29589\n",
      "Epoch: 139/500 Iteration: 700 Validation Acc: 0.6133\n",
      "Epoch: 141/500 Iteration: 700 Training loss: 1.38506\n",
      "Epoch: 141/500 Iteration: 701 Training loss: 0.81062\n",
      "Epoch: 141/500 Iteration: 702 Training loss: 0.44564\n",
      "Epoch: 141/500 Iteration: 703 Training loss: 0.34425\n",
      "Epoch: 141/500 Iteration: 704 Training loss: 0.27325\n",
      "Epoch: 140/500 Iteration: 705 Validation Acc: 0.6000\n",
      "Epoch: 142/500 Iteration: 705 Training loss: 1.49428\n",
      "Epoch: 142/500 Iteration: 706 Training loss: 0.78975\n",
      "Epoch: 142/500 Iteration: 707 Training loss: 0.45718\n",
      "Epoch: 142/500 Iteration: 708 Training loss: 0.33501\n",
      "Epoch: 142/500 Iteration: 709 Training loss: 0.26993\n",
      "Epoch: 141/500 Iteration: 710 Validation Acc: 0.6067\n",
      "Epoch: 143/500 Iteration: 710 Training loss: 1.39675\n",
      "Epoch: 143/500 Iteration: 711 Training loss: 0.71484\n",
      "Epoch: 143/500 Iteration: 712 Training loss: 0.44106\n",
      "Epoch: 143/500 Iteration: 713 Training loss: 0.32088\n",
      "Epoch: 143/500 Iteration: 714 Training loss: 0.24276\n",
      "Epoch: 142/500 Iteration: 715 Validation Acc: 0.6200\n",
      "Epoch: 144/500 Iteration: 715 Training loss: 1.53787\n",
      "Epoch: 144/500 Iteration: 716 Training loss: 0.68699\n",
      "Epoch: 144/500 Iteration: 717 Training loss: 0.46724\n",
      "Epoch: 144/500 Iteration: 718 Training loss: 0.31779\n",
      "Epoch: 144/500 Iteration: 719 Training loss: 0.23793\n",
      "Epoch: 143/500 Iteration: 720 Validation Acc: 0.6000\n",
      "Epoch: 145/500 Iteration: 720 Training loss: 1.68844\n",
      "Epoch: 145/500 Iteration: 721 Training loss: 0.91371\n",
      "Epoch: 145/500 Iteration: 722 Training loss: 0.49526\n",
      "Epoch: 145/500 Iteration: 723 Training loss: 0.37676\n",
      "Epoch: 145/500 Iteration: 724 Training loss: 0.30009\n",
      "Epoch: 144/500 Iteration: 725 Validation Acc: 0.6067\n",
      "Epoch: 146/500 Iteration: 725 Training loss: 1.42570\n",
      "Epoch: 146/500 Iteration: 726 Training loss: 0.71662\n",
      "Epoch: 146/500 Iteration: 727 Training loss: 0.42968\n",
      "Epoch: 146/500 Iteration: 728 Training loss: 0.33041\n",
      "Epoch: 146/500 Iteration: 729 Training loss: 0.25808\n",
      "Epoch: 145/500 Iteration: 730 Validation Acc: 0.6333\n",
      "Epoch: 147/500 Iteration: 730 Training loss: 1.41293\n",
      "Epoch: 147/500 Iteration: 731 Training loss: 0.72848\n",
      "Epoch: 147/500 Iteration: 732 Training loss: 0.44021\n",
      "Epoch: 147/500 Iteration: 733 Training loss: 0.33294\n",
      "Epoch: 147/500 Iteration: 734 Training loss: 0.26396\n",
      "Epoch: 146/500 Iteration: 735 Validation Acc: 0.6133\n",
      "Epoch: 148/500 Iteration: 735 Training loss: 1.31807\n",
      "Epoch: 148/500 Iteration: 736 Training loss: 0.72029\n",
      "Epoch: 148/500 Iteration: 737 Training loss: 0.44621\n",
      "Epoch: 148/500 Iteration: 738 Training loss: 0.33278\n",
      "Epoch: 148/500 Iteration: 739 Training loss: 0.26605\n",
      "Epoch: 147/500 Iteration: 740 Validation Acc: 0.6000\n",
      "Epoch: 149/500 Iteration: 740 Training loss: 1.41891\n",
      "Epoch: 149/500 Iteration: 741 Training loss: 0.75506\n",
      "Epoch: 149/500 Iteration: 742 Training loss: 0.44050\n",
      "Epoch: 149/500 Iteration: 743 Training loss: 0.32005\n",
      "Epoch: 149/500 Iteration: 744 Training loss: 0.24821\n",
      "Epoch: 148/500 Iteration: 745 Validation Acc: 0.6200\n",
      "Epoch: 150/500 Iteration: 745 Training loss: 1.71416\n",
      "Epoch: 150/500 Iteration: 746 Training loss: 0.82061\n",
      "Epoch: 150/500 Iteration: 747 Training loss: 0.42239\n",
      "Epoch: 150/500 Iteration: 748 Training loss: 0.32608\n",
      "Epoch: 150/500 Iteration: 749 Training loss: 0.25398\n",
      "Epoch: 149/500 Iteration: 750 Validation Acc: 0.6133\n",
      "Epoch: 151/500 Iteration: 750 Training loss: 1.39823\n",
      "Epoch: 151/500 Iteration: 751 Training loss: 0.70227\n",
      "Epoch: 151/500 Iteration: 752 Training loss: 0.41421\n",
      "Epoch: 151/500 Iteration: 753 Training loss: 0.31438\n",
      "Epoch: 151/500 Iteration: 754 Training loss: 0.24095\n",
      "Epoch: 150/500 Iteration: 755 Validation Acc: 0.6200\n",
      "Epoch: 152/500 Iteration: 755 Training loss: 1.39564\n",
      "Epoch: 152/500 Iteration: 756 Training loss: 0.65252\n",
      "Epoch: 152/500 Iteration: 757 Training loss: 0.42588\n",
      "Epoch: 152/500 Iteration: 758 Training loss: 0.30762\n",
      "Epoch: 152/500 Iteration: 759 Training loss: 0.23750\n",
      "Epoch: 151/500 Iteration: 760 Validation Acc: 0.6200\n",
      "Epoch: 153/500 Iteration: 760 Training loss: 1.38894\n",
      "Epoch: 153/500 Iteration: 761 Training loss: 0.71659\n",
      "Epoch: 153/500 Iteration: 762 Training loss: 0.46915\n",
      "Epoch: 153/500 Iteration: 763 Training loss: 0.31307\n",
      "Epoch: 153/500 Iteration: 764 Training loss: 0.24867\n",
      "Epoch: 152/500 Iteration: 765 Validation Acc: 0.5933\n",
      "Epoch: 154/500 Iteration: 765 Training loss: 1.61872\n",
      "Epoch: 154/500 Iteration: 766 Training loss: 0.79928\n",
      "Epoch: 154/500 Iteration: 767 Training loss: 0.45162\n",
      "Epoch: 154/500 Iteration: 768 Training loss: 0.33653\n",
      "Epoch: 154/500 Iteration: 769 Training loss: 0.25288\n",
      "Epoch: 153/500 Iteration: 770 Validation Acc: 0.6267\n",
      "Epoch: 155/500 Iteration: 770 Training loss: 1.69626\n",
      "Epoch: 155/500 Iteration: 771 Training loss: 0.81711\n",
      "Epoch: 155/500 Iteration: 772 Training loss: 0.41996\n",
      "Epoch: 155/500 Iteration: 773 Training loss: 0.33238\n",
      "Epoch: 155/500 Iteration: 774 Training loss: 0.26236\n",
      "Epoch: 154/500 Iteration: 775 Validation Acc: 0.6467\n",
      "Epoch: 156/500 Iteration: 775 Training loss: 1.38004\n",
      "Epoch: 156/500 Iteration: 776 Training loss: 0.67206\n",
      "Epoch: 156/500 Iteration: 777 Training loss: 0.42027\n",
      "Epoch: 156/500 Iteration: 778 Training loss: 0.30333\n",
      "Epoch: 156/500 Iteration: 779 Training loss: 0.23710\n",
      "Epoch: 155/500 Iteration: 780 Validation Acc: 0.6267\n",
      "Epoch: 157/500 Iteration: 780 Training loss: 1.56554\n",
      "Epoch: 157/500 Iteration: 781 Training loss: 0.73053\n",
      "Epoch: 157/500 Iteration: 782 Training loss: 0.42268\n",
      "Epoch: 157/500 Iteration: 783 Training loss: 0.32817\n",
      "Epoch: 157/500 Iteration: 784 Training loss: 0.24607\n",
      "Epoch: 156/500 Iteration: 785 Validation Acc: 0.6133\n",
      "Epoch: 158/500 Iteration: 785 Training loss: 1.38672\n",
      "Epoch: 158/500 Iteration: 786 Training loss: 0.66023\n",
      "Epoch: 158/500 Iteration: 787 Training loss: 0.41965\n",
      "Epoch: 158/500 Iteration: 788 Training loss: 0.31076\n",
      "Epoch: 158/500 Iteration: 789 Training loss: 0.25632\n",
      "Epoch: 157/500 Iteration: 790 Validation Acc: 0.5933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159/500 Iteration: 790 Training loss: 1.31391\n",
      "Epoch: 159/500 Iteration: 791 Training loss: 0.65527\n",
      "Epoch: 159/500 Iteration: 792 Training loss: 0.44153\n",
      "Epoch: 159/500 Iteration: 793 Training loss: 0.30976\n",
      "Epoch: 159/500 Iteration: 794 Training loss: 0.24578\n",
      "Epoch: 158/500 Iteration: 795 Validation Acc: 0.6200\n",
      "Epoch: 160/500 Iteration: 795 Training loss: 1.33322\n",
      "Epoch: 160/500 Iteration: 796 Training loss: 0.75947\n",
      "Epoch: 160/500 Iteration: 797 Training loss: 0.44198\n",
      "Epoch: 160/500 Iteration: 798 Training loss: 0.31541\n",
      "Epoch: 160/500 Iteration: 799 Training loss: 0.24913\n",
      "Epoch: 159/500 Iteration: 800 Validation Acc: 0.6067\n",
      "Epoch: 161/500 Iteration: 800 Training loss: 1.63443\n",
      "Epoch: 161/500 Iteration: 801 Training loss: 0.79420\n",
      "Epoch: 161/500 Iteration: 802 Training loss: 0.40863\n",
      "Epoch: 161/500 Iteration: 803 Training loss: 0.31813\n",
      "Epoch: 161/500 Iteration: 804 Training loss: 0.25037\n",
      "Epoch: 160/500 Iteration: 805 Validation Acc: 0.6133\n",
      "Epoch: 162/500 Iteration: 805 Training loss: 1.40566\n",
      "Epoch: 162/500 Iteration: 806 Training loss: 0.63729\n",
      "Epoch: 162/500 Iteration: 807 Training loss: 0.40903\n",
      "Epoch: 162/500 Iteration: 808 Training loss: 0.30639\n",
      "Epoch: 162/500 Iteration: 809 Training loss: 0.23908\n",
      "Epoch: 161/500 Iteration: 810 Validation Acc: 0.6200\n",
      "Epoch: 163/500 Iteration: 810 Training loss: 1.34165\n",
      "Epoch: 163/500 Iteration: 811 Training loss: 0.61810\n",
      "Epoch: 163/500 Iteration: 812 Training loss: 0.39192\n",
      "Epoch: 163/500 Iteration: 813 Training loss: 0.30436\n",
      "Epoch: 163/500 Iteration: 814 Training loss: 0.23320\n",
      "Epoch: 162/500 Iteration: 815 Validation Acc: 0.6200\n",
      "Epoch: 164/500 Iteration: 815 Training loss: 1.32821\n",
      "Epoch: 164/500 Iteration: 816 Training loss: 0.66525\n",
      "Epoch: 164/500 Iteration: 817 Training loss: 0.43153\n",
      "Epoch: 164/500 Iteration: 818 Training loss: 0.30609\n",
      "Epoch: 164/500 Iteration: 819 Training loss: 0.24978\n",
      "Epoch: 163/500 Iteration: 820 Validation Acc: 0.6533\n",
      "Epoch: 165/500 Iteration: 820 Training loss: 1.27167\n",
      "Epoch: 165/500 Iteration: 821 Training loss: 0.65597\n",
      "Epoch: 165/500 Iteration: 822 Training loss: 0.40653\n",
      "Epoch: 165/500 Iteration: 823 Training loss: 0.29866\n",
      "Epoch: 165/500 Iteration: 824 Training loss: 0.23022\n",
      "Epoch: 164/500 Iteration: 825 Validation Acc: 0.6333\n",
      "Epoch: 166/500 Iteration: 825 Training loss: 1.31756\n",
      "Epoch: 166/500 Iteration: 826 Training loss: 0.61829\n",
      "Epoch: 166/500 Iteration: 827 Training loss: 0.40165\n",
      "Epoch: 166/500 Iteration: 828 Training loss: 0.29960\n",
      "Epoch: 166/500 Iteration: 829 Training loss: 0.23502\n",
      "Epoch: 165/500 Iteration: 830 Validation Acc: 0.6200\n",
      "Epoch: 167/500 Iteration: 830 Training loss: 1.34907\n",
      "Epoch: 167/500 Iteration: 831 Training loss: 0.70347\n",
      "Epoch: 167/500 Iteration: 832 Training loss: 0.39304\n",
      "Epoch: 167/500 Iteration: 833 Training loss: 0.29235\n",
      "Epoch: 167/500 Iteration: 834 Training loss: 0.23046\n",
      "Epoch: 166/500 Iteration: 835 Validation Acc: 0.6133\n",
      "Epoch: 168/500 Iteration: 835 Training loss: 1.71078\n",
      "Epoch: 168/500 Iteration: 836 Training loss: 0.79894\n",
      "Epoch: 168/500 Iteration: 837 Training loss: 0.42222\n",
      "Epoch: 168/500 Iteration: 838 Training loss: 0.30421\n",
      "Epoch: 168/500 Iteration: 839 Training loss: 0.25496\n",
      "Epoch: 167/500 Iteration: 840 Validation Acc: 0.6267\n",
      "Epoch: 169/500 Iteration: 840 Training loss: 1.30187\n",
      "Epoch: 169/500 Iteration: 841 Training loss: 0.64064\n",
      "Epoch: 169/500 Iteration: 842 Training loss: 0.38754\n",
      "Epoch: 169/500 Iteration: 843 Training loss: 0.28756\n",
      "Epoch: 169/500 Iteration: 844 Training loss: 0.21545\n",
      "Epoch: 168/500 Iteration: 845 Validation Acc: 0.6400\n",
      "Epoch: 170/500 Iteration: 845 Training loss: 1.30367\n",
      "Epoch: 170/500 Iteration: 846 Training loss: 0.56176\n",
      "Epoch: 170/500 Iteration: 847 Training loss: 0.38637\n",
      "Epoch: 170/500 Iteration: 848 Training loss: 0.27261\n",
      "Epoch: 170/500 Iteration: 849 Training loss: 0.21027\n",
      "Epoch: 169/500 Iteration: 850 Validation Acc: 0.6067\n",
      "Epoch: 171/500 Iteration: 850 Training loss: 1.29736\n",
      "Epoch: 171/500 Iteration: 851 Training loss: 0.56930\n",
      "Epoch: 171/500 Iteration: 852 Training loss: 0.35882\n",
      "Epoch: 171/500 Iteration: 853 Training loss: 0.28098\n",
      "Epoch: 171/500 Iteration: 854 Training loss: 0.21658\n",
      "Epoch: 170/500 Iteration: 855 Validation Acc: 0.6133\n",
      "Epoch: 172/500 Iteration: 855 Training loss: 1.32394\n",
      "Epoch: 172/500 Iteration: 856 Training loss: 0.64228\n",
      "Epoch: 172/500 Iteration: 857 Training loss: 0.39031\n",
      "Epoch: 172/500 Iteration: 858 Training loss: 0.27987\n",
      "Epoch: 172/500 Iteration: 859 Training loss: 0.22333\n",
      "Epoch: 171/500 Iteration: 860 Validation Acc: 0.5933\n",
      "Epoch: 173/500 Iteration: 860 Training loss: 1.34130\n",
      "Epoch: 173/500 Iteration: 861 Training loss: 0.60734\n",
      "Epoch: 173/500 Iteration: 862 Training loss: 0.37325\n",
      "Epoch: 173/500 Iteration: 863 Training loss: 0.28575\n",
      "Epoch: 173/500 Iteration: 864 Training loss: 0.21867\n",
      "Epoch: 172/500 Iteration: 865 Validation Acc: 0.6467\n",
      "Epoch: 174/500 Iteration: 865 Training loss: 1.28814\n",
      "Epoch: 174/500 Iteration: 866 Training loss: 0.56415\n",
      "Epoch: 174/500 Iteration: 867 Training loss: 0.37082\n",
      "Epoch: 174/500 Iteration: 868 Training loss: 0.25673\n",
      "Epoch: 174/500 Iteration: 869 Training loss: 0.18966\n",
      "Epoch: 173/500 Iteration: 870 Validation Acc: 0.6000\n",
      "Epoch: 175/500 Iteration: 870 Training loss: 1.58639\n",
      "Epoch: 175/500 Iteration: 871 Training loss: 0.56814\n",
      "Epoch: 175/500 Iteration: 872 Training loss: 0.39651\n",
      "Epoch: 175/500 Iteration: 873 Training loss: 0.27040\n",
      "Epoch: 175/500 Iteration: 874 Training loss: 0.20159\n",
      "Epoch: 174/500 Iteration: 875 Validation Acc: 0.6267\n",
      "Epoch: 176/500 Iteration: 875 Training loss: 1.41994\n",
      "Epoch: 176/500 Iteration: 876 Training loss: 0.55203\n",
      "Epoch: 176/500 Iteration: 877 Training loss: 0.38037\n",
      "Epoch: 176/500 Iteration: 878 Training loss: 0.27072\n",
      "Epoch: 176/500 Iteration: 879 Training loss: 0.21887\n",
      "Epoch: 175/500 Iteration: 880 Validation Acc: 0.6333\n",
      "Epoch: 177/500 Iteration: 880 Training loss: 1.25257\n",
      "Epoch: 177/500 Iteration: 881 Training loss: 0.82446\n",
      "Epoch: 177/500 Iteration: 882 Training loss: 0.44835\n",
      "Epoch: 177/500 Iteration: 883 Training loss: 0.30343\n",
      "Epoch: 177/500 Iteration: 884 Training loss: 0.24883\n",
      "Epoch: 176/500 Iteration: 885 Validation Acc: 0.6067\n",
      "Epoch: 178/500 Iteration: 885 Training loss: 1.48881\n",
      "Epoch: 178/500 Iteration: 886 Training loss: 0.67396\n",
      "Epoch: 178/500 Iteration: 887 Training loss: 0.35394\n",
      "Epoch: 178/500 Iteration: 888 Training loss: 0.29112\n",
      "Epoch: 178/500 Iteration: 889 Training loss: 0.22219\n",
      "Epoch: 177/500 Iteration: 890 Validation Acc: 0.6067\n",
      "Epoch: 179/500 Iteration: 890 Training loss: 1.27391\n",
      "Epoch: 179/500 Iteration: 891 Training loss: 0.60889\n",
      "Epoch: 179/500 Iteration: 892 Training loss: 0.36376\n",
      "Epoch: 179/500 Iteration: 893 Training loss: 0.27829\n",
      "Epoch: 179/500 Iteration: 894 Training loss: 0.21728\n",
      "Epoch: 178/500 Iteration: 895 Validation Acc: 0.6133\n",
      "Epoch: 180/500 Iteration: 895 Training loss: 1.22010\n",
      "Epoch: 180/500 Iteration: 896 Training loss: 0.54974\n",
      "Epoch: 180/500 Iteration: 897 Training loss: 0.35366\n",
      "Epoch: 180/500 Iteration: 898 Training loss: 0.25690\n",
      "Epoch: 180/500 Iteration: 899 Training loss: 0.19283\n",
      "Epoch: 179/500 Iteration: 900 Validation Acc: 0.6133\n",
      "Epoch: 181/500 Iteration: 900 Training loss: 1.49234\n",
      "Epoch: 181/500 Iteration: 901 Training loss: 0.69767\n",
      "Epoch: 181/500 Iteration: 902 Training loss: 0.38293\n",
      "Epoch: 181/500 Iteration: 903 Training loss: 0.29151\n",
      "Epoch: 181/500 Iteration: 904 Training loss: 0.24068\n",
      "Epoch: 180/500 Iteration: 905 Validation Acc: 0.6400\n",
      "Epoch: 182/500 Iteration: 905 Training loss: 1.22966\n",
      "Epoch: 182/500 Iteration: 906 Training loss: 0.57010\n",
      "Epoch: 182/500 Iteration: 907 Training loss: 0.34201\n",
      "Epoch: 182/500 Iteration: 908 Training loss: 0.26616\n",
      "Epoch: 182/500 Iteration: 909 Training loss: 0.20016\n",
      "Epoch: 181/500 Iteration: 910 Validation Acc: 0.6333\n",
      "Epoch: 183/500 Iteration: 910 Training loss: 1.35612\n",
      "Epoch: 183/500 Iteration: 911 Training loss: 0.53073\n",
      "Epoch: 183/500 Iteration: 912 Training loss: 0.39099\n",
      "Epoch: 183/500 Iteration: 913 Training loss: 0.26153\n",
      "Epoch: 183/500 Iteration: 914 Training loss: 0.19542\n",
      "Epoch: 182/500 Iteration: 915 Validation Acc: 0.6133\n",
      "Epoch: 184/500 Iteration: 915 Training loss: 1.61311\n",
      "Epoch: 184/500 Iteration: 916 Training loss: 0.64604\n",
      "Epoch: 184/500 Iteration: 917 Training loss: 0.41812\n",
      "Epoch: 184/500 Iteration: 918 Training loss: 0.28582\n",
      "Epoch: 184/500 Iteration: 919 Training loss: 0.22454\n",
      "Epoch: 183/500 Iteration: 920 Validation Acc: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185/500 Iteration: 920 Training loss: 1.30999\n",
      "Epoch: 185/500 Iteration: 921 Training loss: 0.62272\n",
      "Epoch: 185/500 Iteration: 922 Training loss: 0.36988\n",
      "Epoch: 185/500 Iteration: 923 Training loss: 0.29706\n",
      "Epoch: 185/500 Iteration: 924 Training loss: 0.23517\n",
      "Epoch: 184/500 Iteration: 925 Validation Acc: 0.6733\n",
      "Epoch: 186/500 Iteration: 925 Training loss: 1.13180\n",
      "Epoch: 186/500 Iteration: 926 Training loss: 0.57604\n",
      "Epoch: 186/500 Iteration: 927 Training loss: 0.35984\n",
      "Epoch: 186/500 Iteration: 928 Training loss: 0.25972\n",
      "Epoch: 186/500 Iteration: 929 Training loss: 0.19348\n",
      "Epoch: 185/500 Iteration: 930 Validation Acc: 0.6267\n",
      "Epoch: 187/500 Iteration: 930 Training loss: 1.43638\n",
      "Epoch: 187/500 Iteration: 931 Training loss: 0.66913\n",
      "Epoch: 187/500 Iteration: 932 Training loss: 0.38484\n",
      "Epoch: 187/500 Iteration: 933 Training loss: 0.28554\n",
      "Epoch: 187/500 Iteration: 934 Training loss: 0.22574\n",
      "Epoch: 186/500 Iteration: 935 Validation Acc: 0.5867\n",
      "Epoch: 188/500 Iteration: 935 Training loss: 1.36497\n",
      "Epoch: 188/500 Iteration: 936 Training loss: 0.61032\n",
      "Epoch: 188/500 Iteration: 937 Training loss: 0.35493\n",
      "Epoch: 188/500 Iteration: 938 Training loss: 0.27342\n",
      "Epoch: 188/500 Iteration: 939 Training loss: 0.22825\n",
      "Epoch: 187/500 Iteration: 940 Validation Acc: 0.6733\n",
      "Epoch: 189/500 Iteration: 940 Training loss: 1.17989\n",
      "Epoch: 189/500 Iteration: 941 Training loss: 0.58480\n",
      "Epoch: 189/500 Iteration: 942 Training loss: 0.35765\n",
      "Epoch: 189/500 Iteration: 943 Training loss: 0.26892\n",
      "Epoch: 189/500 Iteration: 944 Training loss: 0.21361\n",
      "Epoch: 188/500 Iteration: 945 Validation Acc: 0.6067\n",
      "Epoch: 190/500 Iteration: 945 Training loss: 1.15425\n",
      "Epoch: 190/500 Iteration: 946 Training loss: 0.52273\n",
      "Epoch: 190/500 Iteration: 947 Training loss: 0.34310\n",
      "Epoch: 190/500 Iteration: 948 Training loss: 0.25554\n",
      "Epoch: 190/500 Iteration: 949 Training loss: 0.20158\n",
      "Epoch: 189/500 Iteration: 950 Validation Acc: 0.6200\n",
      "Epoch: 191/500 Iteration: 950 Training loss: 1.19561\n",
      "Epoch: 191/500 Iteration: 951 Training loss: 0.51743\n",
      "Epoch: 191/500 Iteration: 952 Training loss: 0.35174\n",
      "Epoch: 191/500 Iteration: 953 Training loss: 0.25236\n",
      "Epoch: 191/500 Iteration: 954 Training loss: 0.18391\n",
      "Epoch: 190/500 Iteration: 955 Validation Acc: 0.6133\n",
      "Epoch: 192/500 Iteration: 955 Training loss: 1.68108\n",
      "Epoch: 192/500 Iteration: 956 Training loss: 0.84744\n",
      "Epoch: 192/500 Iteration: 957 Training loss: 0.43608\n",
      "Epoch: 192/500 Iteration: 958 Training loss: 0.29266\n",
      "Epoch: 192/500 Iteration: 959 Training loss: 0.23765\n",
      "Epoch: 191/500 Iteration: 960 Validation Acc: 0.6200\n",
      "Epoch: 193/500 Iteration: 960 Training loss: 1.40433\n",
      "Epoch: 193/500 Iteration: 961 Training loss: 0.58130\n",
      "Epoch: 193/500 Iteration: 962 Training loss: 0.31861\n",
      "Epoch: 193/500 Iteration: 963 Training loss: 0.25698\n",
      "Epoch: 193/500 Iteration: 964 Training loss: 0.20410\n",
      "Epoch: 192/500 Iteration: 965 Validation Acc: 0.6133\n",
      "Epoch: 194/500 Iteration: 965 Training loss: 1.26009\n",
      "Epoch: 194/500 Iteration: 966 Training loss: 0.50948\n",
      "Epoch: 194/500 Iteration: 967 Training loss: 0.34227\n",
      "Epoch: 194/500 Iteration: 968 Training loss: 0.24349\n",
      "Epoch: 194/500 Iteration: 969 Training loss: 0.20235\n",
      "Epoch: 193/500 Iteration: 970 Validation Acc: 0.6400\n",
      "Epoch: 195/500 Iteration: 970 Training loss: 1.23489\n",
      "Epoch: 195/500 Iteration: 971 Training loss: 0.52865\n",
      "Epoch: 195/500 Iteration: 972 Training loss: 0.33045\n",
      "Epoch: 195/500 Iteration: 973 Training loss: 0.24811\n",
      "Epoch: 195/500 Iteration: 974 Training loss: 0.19140\n",
      "Epoch: 194/500 Iteration: 975 Validation Acc: 0.6200\n",
      "Epoch: 196/500 Iteration: 975 Training loss: 1.32883\n",
      "Epoch: 196/500 Iteration: 976 Training loss: 0.50283\n",
      "Epoch: 196/500 Iteration: 977 Training loss: 0.34655\n",
      "Epoch: 196/500 Iteration: 978 Training loss: 0.24766\n",
      "Epoch: 196/500 Iteration: 979 Training loss: 0.19814\n",
      "Epoch: 195/500 Iteration: 980 Validation Acc: 0.6267\n",
      "Epoch: 197/500 Iteration: 980 Training loss: 1.12374\n",
      "Epoch: 197/500 Iteration: 981 Training loss: 0.55575\n",
      "Epoch: 197/500 Iteration: 982 Training loss: 0.35829\n",
      "Epoch: 197/500 Iteration: 983 Training loss: 0.25420\n",
      "Epoch: 197/500 Iteration: 984 Training loss: 0.19970\n",
      "Epoch: 196/500 Iteration: 985 Validation Acc: 0.6533\n",
      "Epoch: 198/500 Iteration: 985 Training loss: 1.18936\n",
      "Epoch: 198/500 Iteration: 986 Training loss: 0.53655\n",
      "Epoch: 198/500 Iteration: 987 Training loss: 0.33762\n",
      "Epoch: 198/500 Iteration: 988 Training loss: 0.24765\n",
      "Epoch: 198/500 Iteration: 989 Training loss: 0.18565\n",
      "Epoch: 197/500 Iteration: 990 Validation Acc: 0.6267\n",
      "Epoch: 199/500 Iteration: 990 Training loss: 1.33965\n",
      "Epoch: 199/500 Iteration: 991 Training loss: 0.56202\n",
      "Epoch: 199/500 Iteration: 992 Training loss: 0.38452\n",
      "Epoch: 199/500 Iteration: 993 Training loss: 0.26161\n",
      "Epoch: 199/500 Iteration: 994 Training loss: 0.20035\n",
      "Epoch: 198/500 Iteration: 995 Validation Acc: 0.6400\n",
      "Epoch: 200/500 Iteration: 995 Training loss: 1.28088\n",
      "Epoch: 200/500 Iteration: 996 Training loss: 0.64725\n",
      "Epoch: 200/500 Iteration: 997 Training loss: 0.35919\n",
      "Epoch: 200/500 Iteration: 998 Training loss: 0.27261\n",
      "Epoch: 200/500 Iteration: 999 Training loss: 0.21914\n",
      "Epoch: 199/500 Iteration: 1000 Validation Acc: 0.6533\n",
      "Epoch: 201/500 Iteration: 1000 Training loss: 1.14537\n",
      "Epoch: 201/500 Iteration: 1001 Training loss: 0.59092\n",
      "Epoch: 201/500 Iteration: 1002 Training loss: 0.34553\n",
      "Epoch: 201/500 Iteration: 1003 Training loss: 0.25067\n",
      "Epoch: 201/500 Iteration: 1004 Training loss: 0.19594\n",
      "Epoch: 200/500 Iteration: 1005 Validation Acc: 0.6133\n",
      "Epoch: 202/500 Iteration: 1005 Training loss: 1.23342\n",
      "Epoch: 202/500 Iteration: 1006 Training loss: 0.50151\n",
      "Epoch: 202/500 Iteration: 1007 Training loss: 0.30886\n",
      "Epoch: 202/500 Iteration: 1008 Training loss: 0.23711\n",
      "Epoch: 202/500 Iteration: 1009 Training loss: 0.17381\n",
      "Epoch: 201/500 Iteration: 1010 Validation Acc: 0.6200\n",
      "Epoch: 203/500 Iteration: 1010 Training loss: 1.38555\n",
      "Epoch: 203/500 Iteration: 1011 Training loss: 0.63175\n",
      "Epoch: 203/500 Iteration: 1012 Training loss: 0.35663\n",
      "Epoch: 203/500 Iteration: 1013 Training loss: 0.27355\n",
      "Epoch: 203/500 Iteration: 1014 Training loss: 0.22514\n",
      "Epoch: 202/500 Iteration: 1015 Validation Acc: 0.6667\n",
      "Epoch: 204/500 Iteration: 1015 Training loss: 1.14313\n",
      "Epoch: 204/500 Iteration: 1016 Training loss: 0.56258\n",
      "Epoch: 204/500 Iteration: 1017 Training loss: 0.32547\n",
      "Epoch: 204/500 Iteration: 1018 Training loss: 0.25106\n",
      "Epoch: 204/500 Iteration: 1019 Training loss: 0.19045\n",
      "Epoch: 203/500 Iteration: 1020 Validation Acc: 0.6267\n",
      "Epoch: 205/500 Iteration: 1020 Training loss: 1.14576\n",
      "Epoch: 205/500 Iteration: 1021 Training loss: 0.47605\n",
      "Epoch: 205/500 Iteration: 1022 Training loss: 0.30619\n",
      "Epoch: 205/500 Iteration: 1023 Training loss: 0.22724\n",
      "Epoch: 205/500 Iteration: 1024 Training loss: 0.18024\n",
      "Epoch: 204/500 Iteration: 1025 Validation Acc: 0.6000\n",
      "Epoch: 206/500 Iteration: 1025 Training loss: 1.22148\n",
      "Epoch: 206/500 Iteration: 1026 Training loss: 0.54061\n",
      "Epoch: 206/500 Iteration: 1027 Training loss: 0.32803\n",
      "Epoch: 206/500 Iteration: 1028 Training loss: 0.23165\n",
      "Epoch: 206/500 Iteration: 1029 Training loss: 0.18622\n",
      "Epoch: 205/500 Iteration: 1030 Validation Acc: 0.6600\n",
      "Epoch: 207/500 Iteration: 1030 Training loss: 1.09711\n",
      "Epoch: 207/500 Iteration: 1031 Training loss: 0.50676\n",
      "Epoch: 207/500 Iteration: 1032 Training loss: 0.33534\n",
      "Epoch: 207/500 Iteration: 1033 Training loss: 0.23006\n",
      "Epoch: 207/500 Iteration: 1034 Training loss: 0.17879\n",
      "Epoch: 206/500 Iteration: 1035 Validation Acc: 0.6400\n",
      "Epoch: 208/500 Iteration: 1035 Training loss: 1.23338\n",
      "Epoch: 208/500 Iteration: 1036 Training loss: 0.47605\n",
      "Epoch: 208/500 Iteration: 1037 Training loss: 0.31172\n",
      "Epoch: 208/500 Iteration: 1038 Training loss: 0.22229\n",
      "Epoch: 208/500 Iteration: 1039 Training loss: 0.16950\n",
      "Epoch: 207/500 Iteration: 1040 Validation Acc: 0.6333\n",
      "Epoch: 209/500 Iteration: 1040 Training loss: 1.24544\n",
      "Epoch: 209/500 Iteration: 1041 Training loss: 0.49094\n",
      "Epoch: 209/500 Iteration: 1042 Training loss: 0.31243\n",
      "Epoch: 209/500 Iteration: 1043 Training loss: 0.24920\n",
      "Epoch: 209/500 Iteration: 1044 Training loss: 0.19898\n",
      "Epoch: 208/500 Iteration: 1045 Validation Acc: 0.6067\n",
      "Epoch: 210/500 Iteration: 1045 Training loss: 1.09184\n",
      "Epoch: 210/500 Iteration: 1046 Training loss: 0.48950\n",
      "Epoch: 210/500 Iteration: 1047 Training loss: 0.37503\n",
      "Epoch: 210/500 Iteration: 1048 Training loss: 0.22698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210/500 Iteration: 1049 Training loss: 0.17723\n",
      "Epoch: 209/500 Iteration: 1050 Validation Acc: 0.6267\n",
      "Epoch: 211/500 Iteration: 1050 Training loss: 1.22706\n",
      "Epoch: 211/500 Iteration: 1051 Training loss: 0.60347\n",
      "Epoch: 211/500 Iteration: 1052 Training loss: 0.32335\n",
      "Epoch: 211/500 Iteration: 1053 Training loss: 0.23041\n",
      "Epoch: 211/500 Iteration: 1054 Training loss: 0.17413\n",
      "Epoch: 210/500 Iteration: 1055 Validation Acc: 0.6067\n",
      "Epoch: 212/500 Iteration: 1055 Training loss: 1.36716\n",
      "Epoch: 212/500 Iteration: 1056 Training loss: 0.53719\n",
      "Epoch: 212/500 Iteration: 1057 Training loss: 0.31458\n",
      "Epoch: 212/500 Iteration: 1058 Training loss: 0.23607\n",
      "Epoch: 212/500 Iteration: 1059 Training loss: 0.18097\n",
      "Epoch: 211/500 Iteration: 1060 Validation Acc: 0.6133\n",
      "Epoch: 213/500 Iteration: 1060 Training loss: 1.12376\n",
      "Epoch: 213/500 Iteration: 1061 Training loss: 0.47158\n",
      "Epoch: 213/500 Iteration: 1062 Training loss: 0.29472\n",
      "Epoch: 213/500 Iteration: 1063 Training loss: 0.21883\n",
      "Epoch: 213/500 Iteration: 1064 Training loss: 0.17074\n",
      "Epoch: 212/500 Iteration: 1065 Validation Acc: 0.6200\n",
      "Epoch: 214/500 Iteration: 1065 Training loss: 1.19518\n",
      "Epoch: 214/500 Iteration: 1066 Training loss: 0.47119\n",
      "Epoch: 214/500 Iteration: 1067 Training loss: 0.29850\n",
      "Epoch: 214/500 Iteration: 1068 Training loss: 0.22179\n",
      "Epoch: 214/500 Iteration: 1069 Training loss: 0.17699\n",
      "Epoch: 213/500 Iteration: 1070 Validation Acc: 0.6533\n",
      "Epoch: 215/500 Iteration: 1070 Training loss: 1.11421\n",
      "Epoch: 215/500 Iteration: 1071 Training loss: 0.47594\n",
      "Epoch: 215/500 Iteration: 1072 Training loss: 0.32923\n",
      "Epoch: 215/500 Iteration: 1073 Training loss: 0.21969\n",
      "Epoch: 215/500 Iteration: 1074 Training loss: 0.17795\n",
      "Epoch: 214/500 Iteration: 1075 Validation Acc: 0.6267\n",
      "Epoch: 216/500 Iteration: 1075 Training loss: 1.20230\n",
      "Epoch: 216/500 Iteration: 1076 Training loss: 0.63262\n",
      "Epoch: 216/500 Iteration: 1077 Training loss: 0.35078\n",
      "Epoch: 216/500 Iteration: 1078 Training loss: 0.23521\n",
      "Epoch: 216/500 Iteration: 1079 Training loss: 0.17781\n",
      "Epoch: 215/500 Iteration: 1080 Validation Acc: 0.6200\n",
      "Epoch: 217/500 Iteration: 1080 Training loss: 1.23531\n",
      "Epoch: 217/500 Iteration: 1081 Training loss: 0.52570\n",
      "Epoch: 217/500 Iteration: 1082 Training loss: 0.30087\n",
      "Epoch: 217/500 Iteration: 1083 Training loss: 0.21685\n",
      "Epoch: 217/500 Iteration: 1084 Training loss: 0.17575\n",
      "Epoch: 216/500 Iteration: 1085 Validation Acc: 0.6200\n",
      "Epoch: 218/500 Iteration: 1085 Training loss: 1.14780\n",
      "Epoch: 218/500 Iteration: 1086 Training loss: 0.44703\n",
      "Epoch: 218/500 Iteration: 1087 Training loss: 0.27444\n",
      "Epoch: 218/500 Iteration: 1088 Training loss: 0.21856\n",
      "Epoch: 218/500 Iteration: 1089 Training loss: 0.15936\n",
      "Epoch: 217/500 Iteration: 1090 Validation Acc: 0.6267\n",
      "Epoch: 219/500 Iteration: 1090 Training loss: 1.20301\n",
      "Epoch: 219/500 Iteration: 1091 Training loss: 0.41654\n",
      "Epoch: 219/500 Iteration: 1092 Training loss: 0.29086\n",
      "Epoch: 219/500 Iteration: 1093 Training loss: 0.22019\n",
      "Epoch: 219/500 Iteration: 1094 Training loss: 0.17447\n",
      "Epoch: 218/500 Iteration: 1095 Validation Acc: 0.6333\n",
      "Epoch: 220/500 Iteration: 1095 Training loss: 1.04386\n",
      "Epoch: 220/500 Iteration: 1096 Training loss: 0.46809\n",
      "Epoch: 220/500 Iteration: 1097 Training loss: 0.30963\n",
      "Epoch: 220/500 Iteration: 1098 Training loss: 0.20583\n",
      "Epoch: 220/500 Iteration: 1099 Training loss: 0.16836\n",
      "Epoch: 219/500 Iteration: 1100 Validation Acc: 0.6600\n",
      "Epoch: 221/500 Iteration: 1100 Training loss: 1.04876\n",
      "Epoch: 221/500 Iteration: 1101 Training loss: 0.44570\n",
      "Epoch: 221/500 Iteration: 1102 Training loss: 0.29993\n",
      "Epoch: 221/500 Iteration: 1103 Training loss: 0.21868\n",
      "Epoch: 221/500 Iteration: 1104 Training loss: 0.16010\n",
      "Epoch: 220/500 Iteration: 1105 Validation Acc: 0.6200\n",
      "Epoch: 222/500 Iteration: 1105 Training loss: 1.13388\n",
      "Epoch: 222/500 Iteration: 1106 Training loss: 0.54512\n",
      "Epoch: 222/500 Iteration: 1107 Training loss: 0.34634\n",
      "Epoch: 222/500 Iteration: 1108 Training loss: 0.22808\n",
      "Epoch: 222/500 Iteration: 1109 Training loss: 0.18722\n",
      "Epoch: 221/500 Iteration: 1110 Validation Acc: 0.6067\n",
      "Epoch: 223/500 Iteration: 1110 Training loss: 1.14132\n",
      "Epoch: 223/500 Iteration: 1111 Training loss: 0.48971\n",
      "Epoch: 223/500 Iteration: 1112 Training loss: 0.28360\n",
      "Epoch: 223/500 Iteration: 1113 Training loss: 0.20782\n",
      "Epoch: 223/500 Iteration: 1114 Training loss: 0.16417\n",
      "Epoch: 222/500 Iteration: 1115 Validation Acc: 0.6133\n",
      "Epoch: 224/500 Iteration: 1115 Training loss: 1.06485\n",
      "Epoch: 224/500 Iteration: 1116 Training loss: 0.48802\n",
      "Epoch: 224/500 Iteration: 1117 Training loss: 0.30333\n",
      "Epoch: 224/500 Iteration: 1118 Training loss: 0.22036\n",
      "Epoch: 224/500 Iteration: 1119 Training loss: 0.16199\n",
      "Epoch: 223/500 Iteration: 1120 Validation Acc: 0.6467\n",
      "Epoch: 225/500 Iteration: 1120 Training loss: 1.03972\n",
      "Epoch: 225/500 Iteration: 1121 Training loss: 0.38660\n",
      "Epoch: 225/500 Iteration: 1122 Training loss: 0.26904\n",
      "Epoch: 225/500 Iteration: 1123 Training loss: 0.19210\n",
      "Epoch: 225/500 Iteration: 1124 Training loss: 0.14892\n",
      "Epoch: 224/500 Iteration: 1125 Validation Acc: 0.6200\n",
      "Epoch: 226/500 Iteration: 1125 Training loss: 1.44428\n",
      "Epoch: 226/500 Iteration: 1126 Training loss: 0.50162\n",
      "Epoch: 226/500 Iteration: 1127 Training loss: 0.32056\n",
      "Epoch: 226/500 Iteration: 1128 Training loss: 0.23054\n",
      "Epoch: 226/500 Iteration: 1129 Training loss: 0.16810\n",
      "Epoch: 225/500 Iteration: 1130 Validation Acc: 0.6400\n",
      "Epoch: 227/500 Iteration: 1130 Training loss: 1.07667\n",
      "Epoch: 227/500 Iteration: 1131 Training loss: 0.43043\n",
      "Epoch: 227/500 Iteration: 1132 Training loss: 0.29614\n",
      "Epoch: 227/500 Iteration: 1133 Training loss: 0.19306\n",
      "Epoch: 227/500 Iteration: 1134 Training loss: 0.16377\n",
      "Epoch: 226/500 Iteration: 1135 Validation Acc: 0.6533\n",
      "Epoch: 228/500 Iteration: 1135 Training loss: 1.15137\n",
      "Epoch: 228/500 Iteration: 1136 Training loss: 0.52231\n",
      "Epoch: 228/500 Iteration: 1137 Training loss: 0.31940\n",
      "Epoch: 228/500 Iteration: 1138 Training loss: 0.23043\n",
      "Epoch: 228/500 Iteration: 1139 Training loss: 0.18379\n",
      "Epoch: 227/500 Iteration: 1140 Validation Acc: 0.6400\n",
      "Epoch: 229/500 Iteration: 1140 Training loss: 1.10348\n",
      "Epoch: 229/500 Iteration: 1141 Training loss: 0.46187\n",
      "Epoch: 229/500 Iteration: 1142 Training loss: 0.27174\n",
      "Epoch: 229/500 Iteration: 1143 Training loss: 0.21067\n",
      "Epoch: 229/500 Iteration: 1144 Training loss: 0.16424\n",
      "Epoch: 228/500 Iteration: 1145 Validation Acc: 0.6800\n",
      "Epoch: 230/500 Iteration: 1145 Training loss: 1.06486\n",
      "Epoch: 230/500 Iteration: 1146 Training loss: 0.43673\n",
      "Epoch: 230/500 Iteration: 1147 Training loss: 0.26935\n",
      "Epoch: 230/500 Iteration: 1148 Training loss: 0.19976\n",
      "Epoch: 230/500 Iteration: 1149 Training loss: 0.14749\n",
      "Epoch: 229/500 Iteration: 1150 Validation Acc: 0.6400\n",
      "Epoch: 231/500 Iteration: 1150 Training loss: 1.04431\n",
      "Epoch: 231/500 Iteration: 1151 Training loss: 0.41277\n",
      "Epoch: 231/500 Iteration: 1152 Training loss: 0.27537\n",
      "Epoch: 231/500 Iteration: 1153 Training loss: 0.20353\n",
      "Epoch: 231/500 Iteration: 1154 Training loss: 0.14795\n",
      "Epoch: 230/500 Iteration: 1155 Validation Acc: 0.6333\n",
      "Epoch: 232/500 Iteration: 1155 Training loss: 1.10713\n",
      "Epoch: 232/500 Iteration: 1156 Training loss: 0.48950\n",
      "Epoch: 232/500 Iteration: 1157 Training loss: 0.32988\n",
      "Epoch: 232/500 Iteration: 1158 Training loss: 0.21347\n",
      "Epoch: 232/500 Iteration: 1159 Training loss: 0.16640\n",
      "Epoch: 231/500 Iteration: 1160 Validation Acc: 0.5933\n",
      "Epoch: 233/500 Iteration: 1160 Training loss: 1.14620\n",
      "Epoch: 233/500 Iteration: 1161 Training loss: 0.58543\n",
      "Epoch: 233/500 Iteration: 1162 Training loss: 0.32611\n",
      "Epoch: 233/500 Iteration: 1163 Training loss: 0.22378\n",
      "Epoch: 233/500 Iteration: 1164 Training loss: 0.17894\n",
      "Epoch: 232/500 Iteration: 1165 Validation Acc: 0.6600\n",
      "Epoch: 234/500 Iteration: 1165 Training loss: 1.05292\n",
      "Epoch: 234/500 Iteration: 1166 Training loss: 0.55371\n",
      "Epoch: 234/500 Iteration: 1167 Training loss: 0.30889\n",
      "Epoch: 234/500 Iteration: 1168 Training loss: 0.23545\n",
      "Epoch: 234/500 Iteration: 1169 Training loss: 0.17926\n",
      "Epoch: 233/500 Iteration: 1170 Validation Acc: 0.6600\n",
      "Epoch: 235/500 Iteration: 1170 Training loss: 1.01741\n",
      "Epoch: 235/500 Iteration: 1171 Training loss: 0.42881\n",
      "Epoch: 235/500 Iteration: 1172 Training loss: 0.25975\n",
      "Epoch: 235/500 Iteration: 1173 Training loss: 0.19855\n",
      "Epoch: 235/500 Iteration: 1174 Training loss: 0.16313\n",
      "Epoch: 234/500 Iteration: 1175 Validation Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 236/500 Iteration: 1175 Training loss: 1.00233\n",
      "Epoch: 236/500 Iteration: 1176 Training loss: 0.41109\n",
      "Epoch: 236/500 Iteration: 1177 Training loss: 0.24625\n",
      "Epoch: 236/500 Iteration: 1178 Training loss: 0.20189\n",
      "Epoch: 236/500 Iteration: 1179 Training loss: 0.15119\n",
      "Epoch: 235/500 Iteration: 1180 Validation Acc: 0.6400\n",
      "Epoch: 237/500 Iteration: 1180 Training loss: 1.05640\n",
      "Epoch: 237/500 Iteration: 1181 Training loss: 0.40330\n",
      "Epoch: 237/500 Iteration: 1182 Training loss: 0.27450\n",
      "Epoch: 237/500 Iteration: 1183 Training loss: 0.19467\n",
      "Epoch: 237/500 Iteration: 1184 Training loss: 0.14638\n",
      "Epoch: 236/500 Iteration: 1185 Validation Acc: 0.6333\n",
      "Epoch: 238/500 Iteration: 1185 Training loss: 1.38799\n",
      "Epoch: 238/500 Iteration: 1186 Training loss: 0.67292\n",
      "Epoch: 238/500 Iteration: 1187 Training loss: 0.38542\n",
      "Epoch: 238/500 Iteration: 1188 Training loss: 0.22386\n",
      "Epoch: 238/500 Iteration: 1189 Training loss: 0.16944\n",
      "Epoch: 237/500 Iteration: 1190 Validation Acc: 0.6067\n",
      "Epoch: 239/500 Iteration: 1190 Training loss: 1.14071\n",
      "Epoch: 239/500 Iteration: 1191 Training loss: 0.45453\n",
      "Epoch: 239/500 Iteration: 1192 Training loss: 0.26052\n",
      "Epoch: 239/500 Iteration: 1193 Training loss: 0.20996\n",
      "Epoch: 239/500 Iteration: 1194 Training loss: 0.17166\n",
      "Epoch: 238/500 Iteration: 1195 Validation Acc: 0.6667\n",
      "Epoch: 240/500 Iteration: 1195 Training loss: 0.98957\n",
      "Epoch: 240/500 Iteration: 1196 Training loss: 0.41456\n",
      "Epoch: 240/500 Iteration: 1197 Training loss: 0.25562\n",
      "Epoch: 240/500 Iteration: 1198 Training loss: 0.21150\n",
      "Epoch: 240/500 Iteration: 1199 Training loss: 0.16451\n",
      "Epoch: 239/500 Iteration: 1200 Validation Acc: 0.6533\n",
      "Epoch: 241/500 Iteration: 1200 Training loss: 0.95251\n",
      "Epoch: 241/500 Iteration: 1201 Training loss: 0.53794\n",
      "Epoch: 241/500 Iteration: 1202 Training loss: 0.32306\n",
      "Epoch: 241/500 Iteration: 1203 Training loss: 0.21464\n",
      "Epoch: 241/500 Iteration: 1204 Training loss: 0.16802\n",
      "Epoch: 240/500 Iteration: 1205 Validation Acc: 0.6467\n",
      "Epoch: 242/500 Iteration: 1205 Training loss: 1.02472\n",
      "Epoch: 242/500 Iteration: 1206 Training loss: 0.40213\n",
      "Epoch: 242/500 Iteration: 1207 Training loss: 0.23110\n",
      "Epoch: 242/500 Iteration: 1208 Training loss: 0.18540\n",
      "Epoch: 242/500 Iteration: 1209 Training loss: 0.14061\n",
      "Epoch: 241/500 Iteration: 1210 Validation Acc: 0.6600\n",
      "Epoch: 243/500 Iteration: 1210 Training loss: 1.12285\n",
      "Epoch: 243/500 Iteration: 1211 Training loss: 0.43209\n",
      "Epoch: 243/500 Iteration: 1212 Training loss: 0.27993\n",
      "Epoch: 243/500 Iteration: 1213 Training loss: 0.19334\n",
      "Epoch: 243/500 Iteration: 1214 Training loss: 0.15427\n",
      "Epoch: 242/500 Iteration: 1215 Validation Acc: 0.6467\n",
      "Epoch: 244/500 Iteration: 1215 Training loss: 1.03079\n",
      "Epoch: 244/500 Iteration: 1216 Training loss: 0.43451\n",
      "Epoch: 244/500 Iteration: 1217 Training loss: 0.27650\n",
      "Epoch: 244/500 Iteration: 1218 Training loss: 0.18845\n",
      "Epoch: 244/500 Iteration: 1219 Training loss: 0.15730\n",
      "Epoch: 243/500 Iteration: 1220 Validation Acc: 0.6467\n",
      "Epoch: 245/500 Iteration: 1220 Training loss: 0.99677\n",
      "Epoch: 245/500 Iteration: 1221 Training loss: 0.42835\n",
      "Epoch: 245/500 Iteration: 1222 Training loss: 0.26497\n",
      "Epoch: 245/500 Iteration: 1223 Training loss: 0.18064\n",
      "Epoch: 245/500 Iteration: 1224 Training loss: 0.15350\n",
      "Epoch: 244/500 Iteration: 1225 Validation Acc: 0.6267\n",
      "Epoch: 246/500 Iteration: 1225 Training loss: 1.02567\n",
      "Epoch: 246/500 Iteration: 1226 Training loss: 0.42838\n",
      "Epoch: 246/500 Iteration: 1227 Training loss: 0.26186\n",
      "Epoch: 246/500 Iteration: 1228 Training loss: 0.19276\n",
      "Epoch: 246/500 Iteration: 1229 Training loss: 0.14727\n",
      "Epoch: 245/500 Iteration: 1230 Validation Acc: 0.6533\n",
      "Epoch: 247/500 Iteration: 1230 Training loss: 1.03953\n",
      "Epoch: 247/500 Iteration: 1231 Training loss: 0.40474\n",
      "Epoch: 247/500 Iteration: 1232 Training loss: 0.28193\n",
      "Epoch: 247/500 Iteration: 1233 Training loss: 0.17831\n",
      "Epoch: 247/500 Iteration: 1234 Training loss: 0.13273\n",
      "Epoch: 246/500 Iteration: 1235 Validation Acc: 0.6267\n",
      "Epoch: 248/500 Iteration: 1235 Training loss: 1.24017\n",
      "Epoch: 248/500 Iteration: 1236 Training loss: 0.45247\n",
      "Epoch: 248/500 Iteration: 1237 Training loss: 0.28886\n",
      "Epoch: 248/500 Iteration: 1238 Training loss: 0.22441\n",
      "Epoch: 248/500 Iteration: 1239 Training loss: 0.16866\n",
      "Epoch: 247/500 Iteration: 1240 Validation Acc: 0.6533\n",
      "Epoch: 249/500 Iteration: 1240 Training loss: 0.90251\n",
      "Epoch: 249/500 Iteration: 1241 Training loss: 0.42823\n",
      "Epoch: 249/500 Iteration: 1242 Training loss: 0.29153\n",
      "Epoch: 249/500 Iteration: 1243 Training loss: 0.18560\n",
      "Epoch: 249/500 Iteration: 1244 Training loss: 0.15002\n",
      "Epoch: 248/500 Iteration: 1245 Validation Acc: 0.6333\n",
      "Epoch: 250/500 Iteration: 1245 Training loss: 0.91761\n",
      "Epoch: 250/500 Iteration: 1246 Training loss: 0.45473\n",
      "Epoch: 250/500 Iteration: 1247 Training loss: 0.28255\n",
      "Epoch: 250/500 Iteration: 1248 Training loss: 0.20113\n",
      "Epoch: 250/500 Iteration: 1249 Training loss: 0.14851\n",
      "Epoch: 249/500 Iteration: 1250 Validation Acc: 0.6533\n",
      "Epoch: 251/500 Iteration: 1250 Training loss: 1.04349\n",
      "Epoch: 251/500 Iteration: 1251 Training loss: 0.46767\n",
      "Epoch: 251/500 Iteration: 1252 Training loss: 0.27360\n",
      "Epoch: 251/500 Iteration: 1253 Training loss: 0.19886\n",
      "Epoch: 251/500 Iteration: 1254 Training loss: 0.15459\n",
      "Epoch: 250/500 Iteration: 1255 Validation Acc: 0.6467\n",
      "Epoch: 252/500 Iteration: 1255 Training loss: 1.07372\n",
      "Epoch: 252/500 Iteration: 1256 Training loss: 0.49796\n",
      "Epoch: 252/500 Iteration: 1257 Training loss: 0.28593\n",
      "Epoch: 252/500 Iteration: 1258 Training loss: 0.19338\n",
      "Epoch: 252/500 Iteration: 1259 Training loss: 0.16028\n",
      "Epoch: 251/500 Iteration: 1260 Validation Acc: 0.6333\n",
      "Epoch: 253/500 Iteration: 1260 Training loss: 0.95636\n",
      "Epoch: 253/500 Iteration: 1261 Training loss: 0.47096\n",
      "Epoch: 253/500 Iteration: 1262 Training loss: 0.25719\n",
      "Epoch: 253/500 Iteration: 1263 Training loss: 0.19182\n",
      "Epoch: 253/500 Iteration: 1264 Training loss: 0.13455\n",
      "Epoch: 252/500 Iteration: 1265 Validation Acc: 0.6267\n",
      "Epoch: 254/500 Iteration: 1265 Training loss: 1.08071\n",
      "Epoch: 254/500 Iteration: 1266 Training loss: 0.36553\n",
      "Epoch: 254/500 Iteration: 1267 Training loss: 0.24321\n",
      "Epoch: 254/500 Iteration: 1268 Training loss: 0.17903\n",
      "Epoch: 254/500 Iteration: 1269 Training loss: 0.14120\n",
      "Epoch: 253/500 Iteration: 1270 Validation Acc: 0.6000\n",
      "Epoch: 255/500 Iteration: 1270 Training loss: 1.04009\n",
      "Epoch: 255/500 Iteration: 1271 Training loss: 0.42926\n",
      "Epoch: 255/500 Iteration: 1272 Training loss: 0.25657\n",
      "Epoch: 255/500 Iteration: 1273 Training loss: 0.19479\n",
      "Epoch: 255/500 Iteration: 1274 Training loss: 0.15312\n",
      "Epoch: 254/500 Iteration: 1275 Validation Acc: 0.6333\n",
      "Epoch: 256/500 Iteration: 1275 Training loss: 0.93024\n",
      "Epoch: 256/500 Iteration: 1276 Training loss: 0.39275\n",
      "Epoch: 256/500 Iteration: 1277 Training loss: 0.24847\n",
      "Epoch: 256/500 Iteration: 1278 Training loss: 0.18220\n",
      "Epoch: 256/500 Iteration: 1279 Training loss: 0.14000\n",
      "Epoch: 255/500 Iteration: 1280 Validation Acc: 0.6133\n",
      "Epoch: 257/500 Iteration: 1280 Training loss: 0.98819\n",
      "Epoch: 257/500 Iteration: 1281 Training loss: 0.42951\n",
      "Epoch: 257/500 Iteration: 1282 Training loss: 0.30023\n",
      "Epoch: 257/500 Iteration: 1283 Training loss: 0.17677\n",
      "Epoch: 257/500 Iteration: 1284 Training loss: 0.14847\n",
      "Epoch: 256/500 Iteration: 1285 Validation Acc: 0.6400\n",
      "Epoch: 258/500 Iteration: 1285 Training loss: 0.98476\n",
      "Epoch: 258/500 Iteration: 1286 Training loss: 0.46793\n",
      "Epoch: 258/500 Iteration: 1287 Training loss: 0.26724\n",
      "Epoch: 258/500 Iteration: 1288 Training loss: 0.18774\n",
      "Epoch: 258/500 Iteration: 1289 Training loss: 0.14962\n",
      "Epoch: 257/500 Iteration: 1290 Validation Acc: 0.6467\n",
      "Epoch: 259/500 Iteration: 1290 Training loss: 1.02479\n",
      "Epoch: 259/500 Iteration: 1291 Training loss: 0.42130\n",
      "Epoch: 259/500 Iteration: 1292 Training loss: 0.25590\n",
      "Epoch: 259/500 Iteration: 1293 Training loss: 0.18699\n",
      "Epoch: 259/500 Iteration: 1294 Training loss: 0.14940\n",
      "Epoch: 258/500 Iteration: 1295 Validation Acc: 0.6800\n",
      "Epoch: 260/500 Iteration: 1295 Training loss: 0.98631\n",
      "Epoch: 260/500 Iteration: 1296 Training loss: 0.44169\n",
      "Epoch: 260/500 Iteration: 1297 Training loss: 0.24212\n",
      "Epoch: 260/500 Iteration: 1298 Training loss: 0.18614\n",
      "Epoch: 260/500 Iteration: 1299 Training loss: 0.14221\n",
      "Epoch: 259/500 Iteration: 1300 Validation Acc: 0.6600\n",
      "Epoch: 261/500 Iteration: 1300 Training loss: 1.05379\n",
      "Epoch: 261/500 Iteration: 1301 Training loss: 0.43755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 261/500 Iteration: 1302 Training loss: 0.26059\n",
      "Epoch: 261/500 Iteration: 1303 Training loss: 0.19412\n",
      "Epoch: 261/500 Iteration: 1304 Training loss: 0.14912\n",
      "Epoch: 260/500 Iteration: 1305 Validation Acc: 0.6267\n",
      "Epoch: 262/500 Iteration: 1305 Training loss: 0.91317\n",
      "Epoch: 262/500 Iteration: 1306 Training loss: 0.38622\n",
      "Epoch: 262/500 Iteration: 1307 Training loss: 0.25506\n",
      "Epoch: 262/500 Iteration: 1308 Training loss: 0.17150\n",
      "Epoch: 262/500 Iteration: 1309 Training loss: 0.13253\n",
      "Epoch: 261/500 Iteration: 1310 Validation Acc: 0.6200\n",
      "Epoch: 263/500 Iteration: 1310 Training loss: 1.03542\n",
      "Epoch: 263/500 Iteration: 1311 Training loss: 0.36256\n",
      "Epoch: 263/500 Iteration: 1312 Training loss: 0.23459\n",
      "Epoch: 263/500 Iteration: 1313 Training loss: 0.16150\n",
      "Epoch: 263/500 Iteration: 1314 Training loss: 0.13098\n",
      "Epoch: 262/500 Iteration: 1315 Validation Acc: 0.6200\n",
      "Epoch: 264/500 Iteration: 1315 Training loss: 1.23958\n",
      "Epoch: 264/500 Iteration: 1316 Training loss: 0.44618\n",
      "Epoch: 264/500 Iteration: 1317 Training loss: 0.28269\n",
      "Epoch: 264/500 Iteration: 1318 Training loss: 0.18762\n",
      "Epoch: 264/500 Iteration: 1319 Training loss: 0.13729\n",
      "Epoch: 263/500 Iteration: 1320 Validation Acc: 0.6200\n",
      "Epoch: 265/500 Iteration: 1320 Training loss: 1.17629\n",
      "Epoch: 265/500 Iteration: 1321 Training loss: 0.39436\n",
      "Epoch: 265/500 Iteration: 1322 Training loss: 0.26632\n",
      "Epoch: 265/500 Iteration: 1323 Training loss: 0.18489\n",
      "Epoch: 265/500 Iteration: 1324 Training loss: 0.14527\n",
      "Epoch: 264/500 Iteration: 1325 Validation Acc: 0.6467\n",
      "Epoch: 266/500 Iteration: 1325 Training loss: 0.91715\n",
      "Epoch: 266/500 Iteration: 1326 Training loss: 0.42822\n",
      "Epoch: 266/500 Iteration: 1327 Training loss: 0.27887\n",
      "Epoch: 266/500 Iteration: 1328 Training loss: 0.18105\n",
      "Epoch: 266/500 Iteration: 1329 Training loss: 0.14377\n",
      "Epoch: 265/500 Iteration: 1330 Validation Acc: 0.6200\n",
      "Epoch: 267/500 Iteration: 1330 Training loss: 0.86372\n",
      "Epoch: 267/500 Iteration: 1331 Training loss: 0.36297\n",
      "Epoch: 267/500 Iteration: 1332 Training loss: 0.24411\n",
      "Epoch: 267/500 Iteration: 1333 Training loss: 0.17723\n",
      "Epoch: 267/500 Iteration: 1334 Training loss: 0.13225\n",
      "Epoch: 266/500 Iteration: 1335 Validation Acc: 0.6400\n",
      "Epoch: 268/500 Iteration: 1335 Training loss: 0.87997\n",
      "Epoch: 268/500 Iteration: 1336 Training loss: 0.36908\n",
      "Epoch: 268/500 Iteration: 1337 Training loss: 0.21540\n",
      "Epoch: 268/500 Iteration: 1338 Training loss: 0.17243\n",
      "Epoch: 268/500 Iteration: 1339 Training loss: 0.13313\n",
      "Epoch: 267/500 Iteration: 1340 Validation Acc: 0.6267\n",
      "Epoch: 269/500 Iteration: 1340 Training loss: 1.18781\n",
      "Epoch: 269/500 Iteration: 1341 Training loss: 0.49247\n",
      "Epoch: 269/500 Iteration: 1342 Training loss: 0.27427\n",
      "Epoch: 269/500 Iteration: 1343 Training loss: 0.18081\n",
      "Epoch: 269/500 Iteration: 1344 Training loss: 0.14455\n",
      "Epoch: 268/500 Iteration: 1345 Validation Acc: 0.6600\n",
      "Epoch: 270/500 Iteration: 1345 Training loss: 1.11369\n",
      "Epoch: 270/500 Iteration: 1346 Training loss: 0.46297\n",
      "Epoch: 270/500 Iteration: 1347 Training loss: 0.23202\n",
      "Epoch: 270/500 Iteration: 1348 Training loss: 0.18945\n",
      "Epoch: 270/500 Iteration: 1349 Training loss: 0.13607\n",
      "Epoch: 269/500 Iteration: 1350 Validation Acc: 0.6600\n",
      "Epoch: 271/500 Iteration: 1350 Training loss: 0.86237\n",
      "Epoch: 271/500 Iteration: 1351 Training loss: 0.39774\n",
      "Epoch: 271/500 Iteration: 1352 Training loss: 0.25307\n",
      "Epoch: 271/500 Iteration: 1353 Training loss: 0.17497\n",
      "Epoch: 271/500 Iteration: 1354 Training loss: 0.14027\n",
      "Epoch: 270/500 Iteration: 1355 Validation Acc: 0.6267\n",
      "Epoch: 272/500 Iteration: 1355 Training loss: 0.86047\n",
      "Epoch: 272/500 Iteration: 1356 Training loss: 0.34597\n",
      "Epoch: 272/500 Iteration: 1357 Training loss: 0.21431\n",
      "Epoch: 272/500 Iteration: 1358 Training loss: 0.16299\n",
      "Epoch: 272/500 Iteration: 1359 Training loss: 0.12234\n",
      "Epoch: 271/500 Iteration: 1360 Validation Acc: 0.6467\n",
      "Epoch: 273/500 Iteration: 1360 Training loss: 0.91071\n",
      "Epoch: 273/500 Iteration: 1361 Training loss: 0.37862\n",
      "Epoch: 273/500 Iteration: 1362 Training loss: 0.22997\n",
      "Epoch: 273/500 Iteration: 1363 Training loss: 0.16940\n",
      "Epoch: 273/500 Iteration: 1364 Training loss: 0.13218\n",
      "Epoch: 272/500 Iteration: 1365 Validation Acc: 0.6200\n",
      "Epoch: 274/500 Iteration: 1365 Training loss: 1.20779\n",
      "Epoch: 274/500 Iteration: 1366 Training loss: 0.45682\n",
      "Epoch: 274/500 Iteration: 1367 Training loss: 0.31276\n",
      "Epoch: 274/500 Iteration: 1368 Training loss: 0.19745\n",
      "Epoch: 274/500 Iteration: 1369 Training loss: 0.15930\n",
      "Epoch: 273/500 Iteration: 1370 Validation Acc: 0.6400\n",
      "Epoch: 275/500 Iteration: 1370 Training loss: 0.90969\n",
      "Epoch: 275/500 Iteration: 1371 Training loss: 0.38755\n",
      "Epoch: 275/500 Iteration: 1372 Training loss: 0.23104\n",
      "Epoch: 275/500 Iteration: 1373 Training loss: 0.18597\n",
      "Epoch: 275/500 Iteration: 1374 Training loss: 0.13297\n",
      "Epoch: 274/500 Iteration: 1375 Validation Acc: 0.6467\n",
      "Epoch: 276/500 Iteration: 1375 Training loss: 0.85337\n",
      "Epoch: 276/500 Iteration: 1376 Training loss: 0.35717\n",
      "Epoch: 276/500 Iteration: 1377 Training loss: 0.23875\n",
      "Epoch: 276/500 Iteration: 1378 Training loss: 0.16841\n",
      "Epoch: 276/500 Iteration: 1379 Training loss: 0.13046\n",
      "Epoch: 275/500 Iteration: 1380 Validation Acc: 0.6400\n",
      "Epoch: 277/500 Iteration: 1380 Training loss: 0.89825\n",
      "Epoch: 277/500 Iteration: 1381 Training loss: 0.38042\n",
      "Epoch: 277/500 Iteration: 1382 Training loss: 0.21613\n",
      "Epoch: 277/500 Iteration: 1383 Training loss: 0.16616\n",
      "Epoch: 277/500 Iteration: 1384 Training loss: 0.13410\n",
      "Epoch: 276/500 Iteration: 1385 Validation Acc: 0.6400\n",
      "Epoch: 278/500 Iteration: 1385 Training loss: 0.86218\n",
      "Epoch: 278/500 Iteration: 1386 Training loss: 0.35649\n",
      "Epoch: 278/500 Iteration: 1387 Training loss: 0.21625\n",
      "Epoch: 278/500 Iteration: 1388 Training loss: 0.16141\n",
      "Epoch: 278/500 Iteration: 1389 Training loss: 0.12003\n",
      "Epoch: 277/500 Iteration: 1390 Validation Acc: 0.6400\n",
      "Epoch: 279/500 Iteration: 1390 Training loss: 0.93677\n",
      "Epoch: 279/500 Iteration: 1391 Training loss: 0.40679\n",
      "Epoch: 279/500 Iteration: 1392 Training loss: 0.24996\n",
      "Epoch: 279/500 Iteration: 1393 Training loss: 0.17155\n",
      "Epoch: 279/500 Iteration: 1394 Training loss: 0.13774\n",
      "Epoch: 278/500 Iteration: 1395 Validation Acc: 0.6267\n",
      "Epoch: 280/500 Iteration: 1395 Training loss: 0.87972\n",
      "Epoch: 280/500 Iteration: 1396 Training loss: 0.39580\n",
      "Epoch: 280/500 Iteration: 1397 Training loss: 0.24438\n",
      "Epoch: 280/500 Iteration: 1398 Training loss: 0.16696\n",
      "Epoch: 280/500 Iteration: 1399 Training loss: 0.13833\n",
      "Epoch: 279/500 Iteration: 1400 Validation Acc: 0.6467\n",
      "Epoch: 281/500 Iteration: 1400 Training loss: 0.90505\n",
      "Epoch: 281/500 Iteration: 1401 Training loss: 0.31891\n",
      "Epoch: 281/500 Iteration: 1402 Training loss: 0.20503\n",
      "Epoch: 281/500 Iteration: 1403 Training loss: 0.15280\n",
      "Epoch: 281/500 Iteration: 1404 Training loss: 0.12115\n",
      "Epoch: 280/500 Iteration: 1405 Validation Acc: 0.6400\n",
      "Epoch: 282/500 Iteration: 1405 Training loss: 0.91064\n",
      "Epoch: 282/500 Iteration: 1406 Training loss: 0.34655\n",
      "Epoch: 282/500 Iteration: 1407 Training loss: 0.24049\n",
      "Epoch: 282/500 Iteration: 1408 Training loss: 0.15938\n",
      "Epoch: 282/500 Iteration: 1409 Training loss: 0.13112\n",
      "Epoch: 281/500 Iteration: 1410 Validation Acc: 0.6200\n",
      "Epoch: 283/500 Iteration: 1410 Training loss: 0.94478\n",
      "Epoch: 283/500 Iteration: 1411 Training loss: 0.55547\n",
      "Epoch: 283/500 Iteration: 1412 Training loss: 0.28063\n",
      "Epoch: 283/500 Iteration: 1413 Training loss: 0.17786\n",
      "Epoch: 283/500 Iteration: 1414 Training loss: 0.14282\n",
      "Epoch: 282/500 Iteration: 1415 Validation Acc: 0.6200\n",
      "Epoch: 284/500 Iteration: 1415 Training loss: 1.15754\n",
      "Epoch: 284/500 Iteration: 1416 Training loss: 0.41461\n",
      "Epoch: 284/500 Iteration: 1417 Training loss: 0.23314\n",
      "Epoch: 284/500 Iteration: 1418 Training loss: 0.17021\n",
      "Epoch: 284/500 Iteration: 1419 Training loss: 0.13023\n",
      "Epoch: 283/500 Iteration: 1420 Validation Acc: 0.6400\n",
      "Epoch: 285/500 Iteration: 1420 Training loss: 0.89868\n",
      "Epoch: 285/500 Iteration: 1421 Training loss: 0.38450\n",
      "Epoch: 285/500 Iteration: 1422 Training loss: 0.26793\n",
      "Epoch: 285/500 Iteration: 1423 Training loss: 0.16247\n",
      "Epoch: 285/500 Iteration: 1424 Training loss: 0.14283\n",
      "Epoch: 284/500 Iteration: 1425 Validation Acc: 0.6333\n",
      "Epoch: 286/500 Iteration: 1425 Training loss: 0.85921\n",
      "Epoch: 286/500 Iteration: 1426 Training loss: 0.33976\n",
      "Epoch: 286/500 Iteration: 1427 Training loss: 0.21333\n",
      "Epoch: 286/500 Iteration: 1428 Training loss: 0.15540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286/500 Iteration: 1429 Training loss: 0.12793\n",
      "Epoch: 285/500 Iteration: 1430 Validation Acc: 0.6600\n",
      "Epoch: 287/500 Iteration: 1430 Training loss: 0.78969\n",
      "Epoch: 287/500 Iteration: 1431 Training loss: 0.35385\n",
      "Epoch: 287/500 Iteration: 1432 Training loss: 0.22804\n",
      "Epoch: 287/500 Iteration: 1433 Training loss: 0.15491\n",
      "Epoch: 287/500 Iteration: 1434 Training loss: 0.12996\n",
      "Epoch: 286/500 Iteration: 1435 Validation Acc: 0.6467\n",
      "Epoch: 288/500 Iteration: 1435 Training loss: 0.78175\n",
      "Epoch: 288/500 Iteration: 1436 Training loss: 0.29470\n",
      "Epoch: 288/500 Iteration: 1437 Training loss: 0.20217\n",
      "Epoch: 288/500 Iteration: 1438 Training loss: 0.14868\n",
      "Epoch: 288/500 Iteration: 1439 Training loss: 0.11130\n",
      "Epoch: 287/500 Iteration: 1440 Validation Acc: 0.6200\n",
      "Epoch: 289/500 Iteration: 1440 Training loss: 0.86633\n",
      "Epoch: 289/500 Iteration: 1441 Training loss: 0.40212\n",
      "Epoch: 289/500 Iteration: 1442 Training loss: 0.23281\n",
      "Epoch: 289/500 Iteration: 1443 Training loss: 0.15547\n",
      "Epoch: 289/500 Iteration: 1444 Training loss: 0.11990\n",
      "Epoch: 288/500 Iteration: 1445 Validation Acc: 0.6267\n",
      "Epoch: 290/500 Iteration: 1445 Training loss: 1.39032\n",
      "Epoch: 290/500 Iteration: 1446 Training loss: 0.46262\n",
      "Epoch: 290/500 Iteration: 1447 Training loss: 0.26279\n",
      "Epoch: 290/500 Iteration: 1448 Training loss: 0.18002\n",
      "Epoch: 290/500 Iteration: 1449 Training loss: 0.13828\n",
      "Epoch: 289/500 Iteration: 1450 Validation Acc: 0.6133\n",
      "Epoch: 291/500 Iteration: 1450 Training loss: 0.94952\n",
      "Epoch: 291/500 Iteration: 1451 Training loss: 0.37300\n",
      "Epoch: 291/500 Iteration: 1452 Training loss: 0.21887\n",
      "Epoch: 291/500 Iteration: 1453 Training loss: 0.16716\n",
      "Epoch: 291/500 Iteration: 1454 Training loss: 0.13245\n",
      "Epoch: 290/500 Iteration: 1455 Validation Acc: 0.6533\n",
      "Epoch: 292/500 Iteration: 1455 Training loss: 0.92595\n",
      "Epoch: 292/500 Iteration: 1456 Training loss: 0.34919\n",
      "Epoch: 292/500 Iteration: 1457 Training loss: 0.20859\n",
      "Epoch: 292/500 Iteration: 1458 Training loss: 0.17517\n",
      "Epoch: 292/500 Iteration: 1459 Training loss: 0.12237\n",
      "Epoch: 291/500 Iteration: 1460 Validation Acc: 0.6467\n",
      "Epoch: 293/500 Iteration: 1460 Training loss: 0.77815\n",
      "Epoch: 293/500 Iteration: 1461 Training loss: 0.38532\n",
      "Epoch: 293/500 Iteration: 1462 Training loss: 0.30916\n",
      "Epoch: 293/500 Iteration: 1463 Training loss: 0.16731\n",
      "Epoch: 293/500 Iteration: 1464 Training loss: 0.13642\n",
      "Epoch: 292/500 Iteration: 1465 Validation Acc: 0.6600\n",
      "Epoch: 294/500 Iteration: 1465 Training loss: 0.82669\n",
      "Epoch: 294/500 Iteration: 1466 Training loss: 0.31963\n",
      "Epoch: 294/500 Iteration: 1467 Training loss: 0.17601\n",
      "Epoch: 294/500 Iteration: 1468 Training loss: 0.15783\n",
      "Epoch: 294/500 Iteration: 1469 Training loss: 0.10545\n",
      "Epoch: 293/500 Iteration: 1470 Validation Acc: 0.6467\n",
      "Epoch: 295/500 Iteration: 1470 Training loss: 0.95317\n",
      "Epoch: 295/500 Iteration: 1471 Training loss: 0.37418\n",
      "Epoch: 295/500 Iteration: 1472 Training loss: 0.21356\n",
      "Epoch: 295/500 Iteration: 1473 Training loss: 0.16073\n",
      "Epoch: 295/500 Iteration: 1474 Training loss: 0.12676\n",
      "Epoch: 294/500 Iteration: 1475 Validation Acc: 0.6933\n",
      "Epoch: 296/500 Iteration: 1475 Training loss: 0.90937\n",
      "Epoch: 296/500 Iteration: 1476 Training loss: 0.47248\n",
      "Epoch: 296/500 Iteration: 1477 Training loss: 0.25760\n",
      "Epoch: 296/500 Iteration: 1478 Training loss: 0.17633\n",
      "Epoch: 296/500 Iteration: 1479 Training loss: 0.13920\n",
      "Epoch: 295/500 Iteration: 1480 Validation Acc: 0.6733\n",
      "Epoch: 297/500 Iteration: 1480 Training loss: 0.90590\n",
      "Epoch: 297/500 Iteration: 1481 Training loss: 0.37860\n",
      "Epoch: 297/500 Iteration: 1482 Training loss: 0.19331\n",
      "Epoch: 297/500 Iteration: 1483 Training loss: 0.16281\n",
      "Epoch: 297/500 Iteration: 1484 Training loss: 0.10897\n",
      "Epoch: 296/500 Iteration: 1485 Validation Acc: 0.6467\n",
      "Epoch: 298/500 Iteration: 1485 Training loss: 0.96732\n",
      "Epoch: 298/500 Iteration: 1486 Training loss: 0.34679\n",
      "Epoch: 298/500 Iteration: 1487 Training loss: 0.22861\n",
      "Epoch: 298/500 Iteration: 1488 Training loss: 0.15021\n",
      "Epoch: 298/500 Iteration: 1489 Training loss: 0.12744\n",
      "Epoch: 297/500 Iteration: 1490 Validation Acc: 0.6267\n",
      "Epoch: 299/500 Iteration: 1490 Training loss: 0.95541\n",
      "Epoch: 299/500 Iteration: 1491 Training loss: 0.51145\n",
      "Epoch: 299/500 Iteration: 1492 Training loss: 0.26415\n",
      "Epoch: 299/500 Iteration: 1493 Training loss: 0.17036\n",
      "Epoch: 299/500 Iteration: 1494 Training loss: 0.13909\n",
      "Epoch: 298/500 Iteration: 1495 Validation Acc: 0.6733\n",
      "Epoch: 300/500 Iteration: 1495 Training loss: 0.76772\n",
      "Epoch: 300/500 Iteration: 1496 Training loss: 0.31741\n",
      "Epoch: 300/500 Iteration: 1497 Training loss: 0.17180\n",
      "Epoch: 300/500 Iteration: 1498 Training loss: 0.14720\n",
      "Epoch: 300/500 Iteration: 1499 Training loss: 0.11794\n",
      "Epoch: 299/500 Iteration: 1500 Validation Acc: 0.6600\n",
      "Epoch: 301/500 Iteration: 1500 Training loss: 0.75108\n",
      "Epoch: 301/500 Iteration: 1501 Training loss: 0.29003\n",
      "Epoch: 301/500 Iteration: 1502 Training loss: 0.20354\n",
      "Epoch: 301/500 Iteration: 1503 Training loss: 0.13355\n",
      "Epoch: 301/500 Iteration: 1504 Training loss: 0.10418\n",
      "Epoch: 300/500 Iteration: 1505 Validation Acc: 0.6400\n",
      "Epoch: 302/500 Iteration: 1505 Training loss: 0.90225\n",
      "Epoch: 302/500 Iteration: 1506 Training loss: 0.30008\n",
      "Epoch: 302/500 Iteration: 1507 Training loss: 0.19592\n",
      "Epoch: 302/500 Iteration: 1508 Training loss: 0.14629\n",
      "Epoch: 302/500 Iteration: 1509 Training loss: 0.10993\n",
      "Epoch: 301/500 Iteration: 1510 Validation Acc: 0.6533\n",
      "Epoch: 303/500 Iteration: 1510 Training loss: 0.76679\n",
      "Epoch: 303/500 Iteration: 1511 Training loss: 0.32863\n",
      "Epoch: 303/500 Iteration: 1512 Training loss: 0.22654\n",
      "Epoch: 303/500 Iteration: 1513 Training loss: 0.13427\n",
      "Epoch: 303/500 Iteration: 1514 Training loss: 0.10152\n",
      "Epoch: 302/500 Iteration: 1515 Validation Acc: 0.6267\n",
      "Epoch: 304/500 Iteration: 1515 Training loss: 1.12134\n",
      "Epoch: 304/500 Iteration: 1516 Training loss: 0.62373\n",
      "Epoch: 304/500 Iteration: 1517 Training loss: 0.32890\n",
      "Epoch: 304/500 Iteration: 1518 Training loss: 0.18183\n",
      "Epoch: 304/500 Iteration: 1519 Training loss: 0.14155\n",
      "Epoch: 303/500 Iteration: 1520 Validation Acc: 0.6200\n",
      "Epoch: 305/500 Iteration: 1520 Training loss: 0.87077\n",
      "Epoch: 305/500 Iteration: 1521 Training loss: 0.36266\n",
      "Epoch: 305/500 Iteration: 1522 Training loss: 0.20346\n",
      "Epoch: 305/500 Iteration: 1523 Training loss: 0.15981\n",
      "Epoch: 305/500 Iteration: 1524 Training loss: 0.12729\n",
      "Epoch: 304/500 Iteration: 1525 Validation Acc: 0.5933\n",
      "Epoch: 306/500 Iteration: 1525 Training loss: 0.82238\n",
      "Epoch: 306/500 Iteration: 1526 Training loss: 0.30923\n",
      "Epoch: 306/500 Iteration: 1527 Training loss: 0.18047\n",
      "Epoch: 306/500 Iteration: 1528 Training loss: 0.14985\n",
      "Epoch: 306/500 Iteration: 1529 Training loss: 0.11475\n",
      "Epoch: 305/500 Iteration: 1530 Validation Acc: 0.6333\n",
      "Epoch: 307/500 Iteration: 1530 Training loss: 0.78256\n",
      "Epoch: 307/500 Iteration: 1531 Training loss: 0.30873\n",
      "Epoch: 307/500 Iteration: 1532 Training loss: 0.17927\n",
      "Epoch: 307/500 Iteration: 1533 Training loss: 0.16124\n",
      "Epoch: 307/500 Iteration: 1534 Training loss: 0.10934\n",
      "Epoch: 306/500 Iteration: 1535 Validation Acc: 0.6533\n",
      "Epoch: 308/500 Iteration: 1535 Training loss: 0.85643\n",
      "Epoch: 308/500 Iteration: 1536 Training loss: 0.29197\n",
      "Epoch: 308/500 Iteration: 1537 Training loss: 0.19929\n",
      "Epoch: 308/500 Iteration: 1538 Training loss: 0.14930\n",
      "Epoch: 308/500 Iteration: 1539 Training loss: 0.12363\n",
      "Epoch: 307/500 Iteration: 1540 Validation Acc: 0.6600\n",
      "Epoch: 309/500 Iteration: 1540 Training loss: 0.76461\n",
      "Epoch: 309/500 Iteration: 1541 Training loss: 0.36779\n",
      "Epoch: 309/500 Iteration: 1542 Training loss: 0.20467\n",
      "Epoch: 309/500 Iteration: 1543 Training loss: 0.14735\n",
      "Epoch: 309/500 Iteration: 1544 Training loss: 0.11218\n",
      "Epoch: 308/500 Iteration: 1545 Validation Acc: 0.6000\n",
      "Epoch: 310/500 Iteration: 1545 Training loss: 0.87534\n",
      "Epoch: 310/500 Iteration: 1546 Training loss: 0.33841\n",
      "Epoch: 310/500 Iteration: 1547 Training loss: 0.21879\n",
      "Epoch: 310/500 Iteration: 1548 Training loss: 0.14893\n",
      "Epoch: 310/500 Iteration: 1549 Training loss: 0.11645\n",
      "Epoch: 309/500 Iteration: 1550 Validation Acc: 0.6600\n",
      "Epoch: 311/500 Iteration: 1550 Training loss: 0.85396\n",
      "Epoch: 311/500 Iteration: 1551 Training loss: 0.31777\n",
      "Epoch: 311/500 Iteration: 1552 Training loss: 0.20706\n",
      "Epoch: 311/500 Iteration: 1553 Training loss: 0.15675\n",
      "Epoch: 311/500 Iteration: 1554 Training loss: 0.12114\n",
      "Epoch: 310/500 Iteration: 1555 Validation Acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 312/500 Iteration: 1555 Training loss: 0.71845\n",
      "Epoch: 312/500 Iteration: 1556 Training loss: 0.35554\n",
      "Epoch: 312/500 Iteration: 1557 Training loss: 0.28836\n",
      "Epoch: 312/500 Iteration: 1558 Training loss: 0.14590\n",
      "Epoch: 312/500 Iteration: 1559 Training loss: 0.10032\n",
      "Epoch: 311/500 Iteration: 1560 Validation Acc: 0.6600\n",
      "Epoch: 313/500 Iteration: 1560 Training loss: 0.83135\n",
      "Epoch: 313/500 Iteration: 1561 Training loss: 0.35678\n",
      "Epoch: 313/500 Iteration: 1562 Training loss: 0.19543\n",
      "Epoch: 313/500 Iteration: 1563 Training loss: 0.14000\n",
      "Epoch: 313/500 Iteration: 1564 Training loss: 0.12004\n",
      "Epoch: 312/500 Iteration: 1565 Validation Acc: 0.6533\n",
      "Epoch: 314/500 Iteration: 1565 Training loss: 0.76195\n",
      "Epoch: 314/500 Iteration: 1566 Training loss: 0.31706\n",
      "Epoch: 314/500 Iteration: 1567 Training loss: 0.18348\n",
      "Epoch: 314/500 Iteration: 1568 Training loss: 0.14480\n",
      "Epoch: 314/500 Iteration: 1569 Training loss: 0.10993\n",
      "Epoch: 313/500 Iteration: 1570 Validation Acc: 0.6400\n",
      "Epoch: 315/500 Iteration: 1570 Training loss: 0.88174\n",
      "Epoch: 315/500 Iteration: 1571 Training loss: 0.31404\n",
      "Epoch: 315/500 Iteration: 1572 Training loss: 0.17845\n",
      "Epoch: 315/500 Iteration: 1573 Training loss: 0.14148\n",
      "Epoch: 315/500 Iteration: 1574 Training loss: 0.10709\n",
      "Epoch: 314/500 Iteration: 1575 Validation Acc: 0.6400\n",
      "Epoch: 316/500 Iteration: 1575 Training loss: 0.86402\n",
      "Epoch: 316/500 Iteration: 1576 Training loss: 0.32942\n",
      "Epoch: 316/500 Iteration: 1577 Training loss: 0.20790\n",
      "Epoch: 316/500 Iteration: 1578 Training loss: 0.14282\n",
      "Epoch: 316/500 Iteration: 1579 Training loss: 0.11395\n",
      "Epoch: 315/500 Iteration: 1580 Validation Acc: 0.6333\n",
      "Epoch: 317/500 Iteration: 1580 Training loss: 0.82499\n",
      "Epoch: 317/500 Iteration: 1581 Training loss: 0.35010\n",
      "Epoch: 317/500 Iteration: 1582 Training loss: 0.20758\n",
      "Epoch: 317/500 Iteration: 1583 Training loss: 0.13358\n",
      "Epoch: 317/500 Iteration: 1584 Training loss: 0.11133\n",
      "Epoch: 316/500 Iteration: 1585 Validation Acc: 0.6200\n",
      "Epoch: 318/500 Iteration: 1585 Training loss: 1.00933\n",
      "Epoch: 318/500 Iteration: 1586 Training loss: 0.42154\n",
      "Epoch: 318/500 Iteration: 1587 Training loss: 0.28081\n",
      "Epoch: 318/500 Iteration: 1588 Training loss: 0.16482\n",
      "Epoch: 318/500 Iteration: 1589 Training loss: 0.13436\n",
      "Epoch: 317/500 Iteration: 1590 Validation Acc: 0.6867\n",
      "Epoch: 319/500 Iteration: 1590 Training loss: 0.74994\n",
      "Epoch: 319/500 Iteration: 1591 Training loss: 0.35906\n",
      "Epoch: 319/500 Iteration: 1592 Training loss: 0.22300\n",
      "Epoch: 319/500 Iteration: 1593 Training loss: 0.14931\n",
      "Epoch: 319/500 Iteration: 1594 Training loss: 0.12151\n",
      "Epoch: 318/500 Iteration: 1595 Validation Acc: 0.6600\n",
      "Epoch: 320/500 Iteration: 1595 Training loss: 0.74335\n",
      "Epoch: 320/500 Iteration: 1596 Training loss: 0.28926\n",
      "Epoch: 320/500 Iteration: 1597 Training loss: 0.18343\n",
      "Epoch: 320/500 Iteration: 1598 Training loss: 0.14285\n",
      "Epoch: 320/500 Iteration: 1599 Training loss: 0.10609\n",
      "Epoch: 319/500 Iteration: 1600 Validation Acc: 0.6333\n",
      "Epoch: 321/500 Iteration: 1600 Training loss: 0.87447\n",
      "Epoch: 321/500 Iteration: 1601 Training loss: 0.43439\n",
      "Epoch: 321/500 Iteration: 1602 Training loss: 0.21630\n",
      "Epoch: 321/500 Iteration: 1603 Training loss: 0.16453\n",
      "Epoch: 321/500 Iteration: 1604 Training loss: 0.13552\n",
      "Epoch: 320/500 Iteration: 1605 Validation Acc: 0.6533\n",
      "Epoch: 322/500 Iteration: 1605 Training loss: 0.72044\n",
      "Epoch: 322/500 Iteration: 1606 Training loss: 0.37112\n",
      "Epoch: 322/500 Iteration: 1607 Training loss: 0.19097\n",
      "Epoch: 322/500 Iteration: 1608 Training loss: 0.13333\n",
      "Epoch: 322/500 Iteration: 1609 Training loss: 0.10812\n",
      "Epoch: 321/500 Iteration: 1610 Validation Acc: 0.6400\n",
      "Epoch: 323/500 Iteration: 1610 Training loss: 0.89049\n",
      "Epoch: 323/500 Iteration: 1611 Training loss: 0.32151\n",
      "Epoch: 323/500 Iteration: 1612 Training loss: 0.19571\n",
      "Epoch: 323/500 Iteration: 1613 Training loss: 0.15640\n",
      "Epoch: 323/500 Iteration: 1614 Training loss: 0.12284\n",
      "Epoch: 322/500 Iteration: 1615 Validation Acc: 0.6667\n",
      "Epoch: 324/500 Iteration: 1615 Training loss: 0.75941\n",
      "Epoch: 324/500 Iteration: 1616 Training loss: 0.34898\n",
      "Epoch: 324/500 Iteration: 1617 Training loss: 0.20572\n",
      "Epoch: 324/500 Iteration: 1618 Training loss: 0.14106\n",
      "Epoch: 324/500 Iteration: 1619 Training loss: 0.11124\n",
      "Epoch: 323/500 Iteration: 1620 Validation Acc: 0.6200\n",
      "Epoch: 325/500 Iteration: 1620 Training loss: 0.84155\n",
      "Epoch: 325/500 Iteration: 1621 Training loss: 0.34549\n",
      "Epoch: 325/500 Iteration: 1622 Training loss: 0.20574\n",
      "Epoch: 325/500 Iteration: 1623 Training loss: 0.15002\n",
      "Epoch: 325/500 Iteration: 1624 Training loss: 0.11346\n",
      "Epoch: 324/500 Iteration: 1625 Validation Acc: 0.6400\n",
      "Epoch: 326/500 Iteration: 1625 Training loss: 0.73424\n",
      "Epoch: 326/500 Iteration: 1626 Training loss: 0.28440\n",
      "Epoch: 326/500 Iteration: 1627 Training loss: 0.16294\n",
      "Epoch: 326/500 Iteration: 1628 Training loss: 0.13809\n",
      "Epoch: 326/500 Iteration: 1629 Training loss: 0.10289\n",
      "Epoch: 325/500 Iteration: 1630 Validation Acc: 0.6333\n",
      "Epoch: 327/500 Iteration: 1630 Training loss: 0.69410\n",
      "Epoch: 327/500 Iteration: 1631 Training loss: 0.26202\n",
      "Epoch: 327/500 Iteration: 1632 Training loss: 0.19326\n",
      "Epoch: 327/500 Iteration: 1633 Training loss: 0.12501\n",
      "Epoch: 327/500 Iteration: 1634 Training loss: 0.10731\n",
      "Epoch: 326/500 Iteration: 1635 Validation Acc: 0.6267\n",
      "Epoch: 328/500 Iteration: 1635 Training loss: 0.72128\n",
      "Epoch: 328/500 Iteration: 1636 Training loss: 0.29977\n",
      "Epoch: 328/500 Iteration: 1637 Training loss: 0.20212\n",
      "Epoch: 328/500 Iteration: 1638 Training loss: 0.12519\n",
      "Epoch: 328/500 Iteration: 1639 Training loss: 0.10613\n",
      "Epoch: 327/500 Iteration: 1640 Validation Acc: 0.6933\n",
      "Epoch: 329/500 Iteration: 1640 Training loss: 0.78432\n",
      "Epoch: 329/500 Iteration: 1641 Training loss: 0.29566\n",
      "Epoch: 329/500 Iteration: 1642 Training loss: 0.17733\n",
      "Epoch: 329/500 Iteration: 1643 Training loss: 0.14185\n",
      "Epoch: 329/500 Iteration: 1644 Training loss: 0.10134\n",
      "Epoch: 328/500 Iteration: 1645 Validation Acc: 0.6133\n",
      "Epoch: 330/500 Iteration: 1645 Training loss: 0.81992\n",
      "Epoch: 330/500 Iteration: 1646 Training loss: 0.43445\n",
      "Epoch: 330/500 Iteration: 1647 Training loss: 0.22300\n",
      "Epoch: 330/500 Iteration: 1648 Training loss: 0.13785\n",
      "Epoch: 330/500 Iteration: 1649 Training loss: 0.11396\n",
      "Epoch: 329/500 Iteration: 1650 Validation Acc: 0.6267\n",
      "Epoch: 331/500 Iteration: 1650 Training loss: 1.02172\n",
      "Epoch: 331/500 Iteration: 1651 Training loss: 0.37912\n",
      "Epoch: 331/500 Iteration: 1652 Training loss: 0.20621\n",
      "Epoch: 331/500 Iteration: 1653 Training loss: 0.14409\n",
      "Epoch: 331/500 Iteration: 1654 Training loss: 0.10937\n",
      "Epoch: 330/500 Iteration: 1655 Validation Acc: 0.6133\n",
      "Epoch: 332/500 Iteration: 1655 Training loss: 0.76570\n",
      "Epoch: 332/500 Iteration: 1656 Training loss: 0.30217\n",
      "Epoch: 332/500 Iteration: 1657 Training loss: 0.18271\n",
      "Epoch: 332/500 Iteration: 1658 Training loss: 0.14704\n",
      "Epoch: 332/500 Iteration: 1659 Training loss: 0.11413\n",
      "Epoch: 331/500 Iteration: 1660 Validation Acc: 0.6667\n",
      "Epoch: 333/500 Iteration: 1660 Training loss: 0.68824\n",
      "Epoch: 333/500 Iteration: 1661 Training loss: 0.26988\n",
      "Epoch: 333/500 Iteration: 1662 Training loss: 0.17862\n",
      "Epoch: 333/500 Iteration: 1663 Training loss: 0.12910\n",
      "Epoch: 333/500 Iteration: 1664 Training loss: 0.10079\n",
      "Epoch: 332/500 Iteration: 1665 Validation Acc: 0.6600\n",
      "Epoch: 334/500 Iteration: 1665 Training loss: 0.73814\n",
      "Epoch: 334/500 Iteration: 1666 Training loss: 0.29757\n",
      "Epoch: 334/500 Iteration: 1667 Training loss: 0.19325\n",
      "Epoch: 334/500 Iteration: 1668 Training loss: 0.12995\n",
      "Epoch: 334/500 Iteration: 1669 Training loss: 0.10357\n",
      "Epoch: 333/500 Iteration: 1670 Validation Acc: 0.6267\n",
      "Epoch: 335/500 Iteration: 1670 Training loss: 0.83092\n",
      "Epoch: 335/500 Iteration: 1671 Training loss: 0.29605\n",
      "Epoch: 335/500 Iteration: 1672 Training loss: 0.17401\n",
      "Epoch: 335/500 Iteration: 1673 Training loss: 0.12898\n",
      "Epoch: 335/500 Iteration: 1674 Training loss: 0.09326\n",
      "Epoch: 334/500 Iteration: 1675 Validation Acc: 0.6133\n",
      "Epoch: 336/500 Iteration: 1675 Training loss: 0.83818\n",
      "Epoch: 336/500 Iteration: 1676 Training loss: 0.27157\n",
      "Epoch: 336/500 Iteration: 1677 Training loss: 0.19901\n",
      "Epoch: 336/500 Iteration: 1678 Training loss: 0.13535\n",
      "Epoch: 336/500 Iteration: 1679 Training loss: 0.09947\n",
      "Epoch: 335/500 Iteration: 1680 Validation Acc: 0.6067\n",
      "Epoch: 337/500 Iteration: 1680 Training loss: 1.29672\n",
      "Epoch: 337/500 Iteration: 1681 Training loss: 0.53543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 337/500 Iteration: 1682 Training loss: 0.33959\n",
      "Epoch: 337/500 Iteration: 1683 Training loss: 0.19989\n",
      "Epoch: 337/500 Iteration: 1684 Training loss: 0.14740\n",
      "Epoch: 336/500 Iteration: 1685 Validation Acc: 0.6467\n",
      "Epoch: 338/500 Iteration: 1685 Training loss: 0.77892\n",
      "Epoch: 338/500 Iteration: 1686 Training loss: 0.37543\n",
      "Epoch: 338/500 Iteration: 1687 Training loss: 0.24992\n",
      "Epoch: 338/500 Iteration: 1688 Training loss: 0.15294\n",
      "Epoch: 338/500 Iteration: 1689 Training loss: 0.12815\n",
      "Epoch: 337/500 Iteration: 1690 Validation Acc: 0.6667\n",
      "Epoch: 339/500 Iteration: 1690 Training loss: 0.69957\n",
      "Epoch: 339/500 Iteration: 1691 Training loss: 0.30453\n",
      "Epoch: 339/500 Iteration: 1692 Training loss: 0.18018\n",
      "Epoch: 339/500 Iteration: 1693 Training loss: 0.14271\n",
      "Epoch: 339/500 Iteration: 1694 Training loss: 0.11710\n",
      "Epoch: 338/500 Iteration: 1695 Validation Acc: 0.6333\n",
      "Epoch: 340/500 Iteration: 1695 Training loss: 0.61348\n",
      "Epoch: 340/500 Iteration: 1696 Training loss: 0.29651\n",
      "Epoch: 340/500 Iteration: 1697 Training loss: 0.18551\n",
      "Epoch: 340/500 Iteration: 1698 Training loss: 0.13339\n",
      "Epoch: 340/500 Iteration: 1699 Training loss: 0.10059\n",
      "Epoch: 339/500 Iteration: 1700 Validation Acc: 0.6533\n",
      "Epoch: 341/500 Iteration: 1700 Training loss: 0.77065\n",
      "Epoch: 341/500 Iteration: 1701 Training loss: 0.28776\n",
      "Epoch: 341/500 Iteration: 1702 Training loss: 0.16243\n",
      "Epoch: 341/500 Iteration: 1703 Training loss: 0.13165\n",
      "Epoch: 341/500 Iteration: 1704 Training loss: 0.09821\n",
      "Epoch: 340/500 Iteration: 1705 Validation Acc: 0.6800\n",
      "Epoch: 342/500 Iteration: 1705 Training loss: 0.74385\n",
      "Epoch: 342/500 Iteration: 1706 Training loss: 0.32504\n",
      "Epoch: 342/500 Iteration: 1707 Training loss: 0.18136\n",
      "Epoch: 342/500 Iteration: 1708 Training loss: 0.14956\n",
      "Epoch: 342/500 Iteration: 1709 Training loss: 0.09683\n",
      "Epoch: 341/500 Iteration: 1710 Validation Acc: 0.6400\n",
      "Epoch: 343/500 Iteration: 1710 Training loss: 0.80475\n",
      "Epoch: 343/500 Iteration: 1711 Training loss: 0.31805\n",
      "Epoch: 343/500 Iteration: 1712 Training loss: 0.17904\n",
      "Epoch: 343/500 Iteration: 1713 Training loss: 0.13726\n",
      "Epoch: 343/500 Iteration: 1714 Training loss: 0.10976\n",
      "Epoch: 342/500 Iteration: 1715 Validation Acc: 0.6467\n",
      "Epoch: 344/500 Iteration: 1715 Training loss: 1.10375\n",
      "Epoch: 344/500 Iteration: 1716 Training loss: 0.52549\n",
      "Epoch: 344/500 Iteration: 1717 Training loss: 0.27008\n",
      "Epoch: 344/500 Iteration: 1718 Training loss: 0.15256\n",
      "Epoch: 344/500 Iteration: 1719 Training loss: 0.11965\n",
      "Epoch: 343/500 Iteration: 1720 Validation Acc: 0.6200\n",
      "Epoch: 345/500 Iteration: 1720 Training loss: 0.81782\n",
      "Epoch: 345/500 Iteration: 1721 Training loss: 0.36210\n",
      "Epoch: 345/500 Iteration: 1722 Training loss: 0.19558\n",
      "Epoch: 345/500 Iteration: 1723 Training loss: 0.13798\n",
      "Epoch: 345/500 Iteration: 1724 Training loss: 0.11415\n",
      "Epoch: 344/500 Iteration: 1725 Validation Acc: 0.6667\n",
      "Epoch: 346/500 Iteration: 1725 Training loss: 0.71207\n",
      "Epoch: 346/500 Iteration: 1726 Training loss: 0.30493\n",
      "Epoch: 346/500 Iteration: 1727 Training loss: 0.18798\n",
      "Epoch: 346/500 Iteration: 1728 Training loss: 0.13725\n",
      "Epoch: 346/500 Iteration: 1729 Training loss: 0.10701\n",
      "Epoch: 345/500 Iteration: 1730 Validation Acc: 0.6467\n",
      "Epoch: 347/500 Iteration: 1730 Training loss: 0.65687\n",
      "Epoch: 347/500 Iteration: 1731 Training loss: 0.25745\n",
      "Epoch: 347/500 Iteration: 1732 Training loss: 0.14945\n",
      "Epoch: 347/500 Iteration: 1733 Training loss: 0.12620\n",
      "Epoch: 347/500 Iteration: 1734 Training loss: 0.09087\n",
      "Epoch: 346/500 Iteration: 1735 Validation Acc: 0.6333\n",
      "Epoch: 348/500 Iteration: 1735 Training loss: 0.63243\n",
      "Epoch: 348/500 Iteration: 1736 Training loss: 0.24710\n",
      "Epoch: 348/500 Iteration: 1737 Training loss: 0.16382\n",
      "Epoch: 348/500 Iteration: 1738 Training loss: 0.12353\n",
      "Epoch: 348/500 Iteration: 1739 Training loss: 0.08913\n",
      "Epoch: 347/500 Iteration: 1740 Validation Acc: 0.6867\n",
      "Epoch: 349/500 Iteration: 1740 Training loss: 0.67890\n",
      "Epoch: 349/500 Iteration: 1741 Training loss: 0.28908\n",
      "Epoch: 349/500 Iteration: 1742 Training loss: 0.16674\n",
      "Epoch: 349/500 Iteration: 1743 Training loss: 0.12998\n",
      "Epoch: 349/500 Iteration: 1744 Training loss: 0.08324\n",
      "Epoch: 348/500 Iteration: 1745 Validation Acc: 0.6467\n",
      "Epoch: 350/500 Iteration: 1745 Training loss: 0.93189\n",
      "Epoch: 350/500 Iteration: 1746 Training loss: 0.32762\n",
      "Epoch: 350/500 Iteration: 1747 Training loss: 0.22681\n",
      "Epoch: 350/500 Iteration: 1748 Training loss: 0.14346\n",
      "Epoch: 350/500 Iteration: 1749 Training loss: 0.10061\n",
      "Epoch: 349/500 Iteration: 1750 Validation Acc: 0.6267\n",
      "Epoch: 351/500 Iteration: 1750 Training loss: 0.75952\n",
      "Epoch: 351/500 Iteration: 1751 Training loss: 0.29507\n",
      "Epoch: 351/500 Iteration: 1752 Training loss: 0.18400\n",
      "Epoch: 351/500 Iteration: 1753 Training loss: 0.13156\n",
      "Epoch: 351/500 Iteration: 1754 Training loss: 0.10599\n",
      "Epoch: 350/500 Iteration: 1755 Validation Acc: 0.6733\n",
      "Epoch: 352/500 Iteration: 1755 Training loss: 0.66200\n",
      "Epoch: 352/500 Iteration: 1756 Training loss: 0.43401\n",
      "Epoch: 352/500 Iteration: 1757 Training loss: 0.26315\n",
      "Epoch: 352/500 Iteration: 1758 Training loss: 0.12937\n",
      "Epoch: 352/500 Iteration: 1759 Training loss: 0.10030\n",
      "Epoch: 351/500 Iteration: 1760 Validation Acc: 0.6267\n",
      "Epoch: 353/500 Iteration: 1760 Training loss: 0.83918\n",
      "Epoch: 353/500 Iteration: 1761 Training loss: 0.34089\n",
      "Epoch: 353/500 Iteration: 1762 Training loss: 0.17805\n",
      "Epoch: 353/500 Iteration: 1763 Training loss: 0.14088\n",
      "Epoch: 353/500 Iteration: 1764 Training loss: 0.11125\n",
      "Epoch: 352/500 Iteration: 1765 Validation Acc: 0.6800\n",
      "Epoch: 354/500 Iteration: 1765 Training loss: 0.75361\n",
      "Epoch: 354/500 Iteration: 1766 Training loss: 0.29875\n",
      "Epoch: 354/500 Iteration: 1767 Training loss: 0.19454\n",
      "Epoch: 354/500 Iteration: 1768 Training loss: 0.14155\n",
      "Epoch: 354/500 Iteration: 1769 Training loss: 0.09280\n",
      "Epoch: 353/500 Iteration: 1770 Validation Acc: 0.6667\n",
      "Epoch: 355/500 Iteration: 1770 Training loss: 0.74248\n",
      "Epoch: 355/500 Iteration: 1771 Training loss: 0.26136\n",
      "Epoch: 355/500 Iteration: 1772 Training loss: 0.15298\n",
      "Epoch: 355/500 Iteration: 1773 Training loss: 0.11921\n",
      "Epoch: 355/500 Iteration: 1774 Training loss: 0.08910\n",
      "Epoch: 354/500 Iteration: 1775 Validation Acc: 0.6200\n",
      "Epoch: 356/500 Iteration: 1775 Training loss: 0.72093\n",
      "Epoch: 356/500 Iteration: 1776 Training loss: 0.26761\n",
      "Epoch: 356/500 Iteration: 1777 Training loss: 0.16297\n",
      "Epoch: 356/500 Iteration: 1778 Training loss: 0.12929\n",
      "Epoch: 356/500 Iteration: 1779 Training loss: 0.10198\n",
      "Epoch: 355/500 Iteration: 1780 Validation Acc: 0.6533\n",
      "Epoch: 357/500 Iteration: 1780 Training loss: 0.58211\n",
      "Epoch: 357/500 Iteration: 1781 Training loss: 0.26280\n",
      "Epoch: 357/500 Iteration: 1782 Training loss: 0.18295\n",
      "Epoch: 357/500 Iteration: 1783 Training loss: 0.11467\n",
      "Epoch: 357/500 Iteration: 1784 Training loss: 0.08866\n",
      "Epoch: 356/500 Iteration: 1785 Validation Acc: 0.6267\n",
      "Epoch: 358/500 Iteration: 1785 Training loss: 0.68869\n",
      "Epoch: 358/500 Iteration: 1786 Training loss: 0.42701\n",
      "Epoch: 358/500 Iteration: 1787 Training loss: 0.29882\n",
      "Epoch: 358/500 Iteration: 1788 Training loss: 0.13523\n",
      "Epoch: 358/500 Iteration: 1789 Training loss: 0.10526\n",
      "Epoch: 357/500 Iteration: 1790 Validation Acc: 0.6467\n",
      "Epoch: 359/500 Iteration: 1790 Training loss: 0.88855\n",
      "Epoch: 359/500 Iteration: 1791 Training loss: 0.37187\n",
      "Epoch: 359/500 Iteration: 1792 Training loss: 0.19195\n",
      "Epoch: 359/500 Iteration: 1793 Training loss: 0.13808\n",
      "Epoch: 359/500 Iteration: 1794 Training loss: 0.10114\n",
      "Epoch: 358/500 Iteration: 1795 Validation Acc: 0.6400\n",
      "Epoch: 360/500 Iteration: 1795 Training loss: 0.73746\n",
      "Epoch: 360/500 Iteration: 1796 Training loss: 0.28247\n",
      "Epoch: 360/500 Iteration: 1797 Training loss: 0.16119\n",
      "Epoch: 360/500 Iteration: 1798 Training loss: 0.13080\n",
      "Epoch: 360/500 Iteration: 1799 Training loss: 0.09997\n",
      "Epoch: 359/500 Iteration: 1800 Validation Acc: 0.6400\n",
      "Epoch: 361/500 Iteration: 1800 Training loss: 0.86146\n",
      "Epoch: 361/500 Iteration: 1801 Training loss: 0.29456\n",
      "Epoch: 361/500 Iteration: 1802 Training loss: 0.15614\n",
      "Epoch: 361/500 Iteration: 1803 Training loss: 0.13528\n",
      "Epoch: 361/500 Iteration: 1804 Training loss: 0.08967\n",
      "Epoch: 360/500 Iteration: 1805 Validation Acc: 0.6467\n",
      "Epoch: 362/500 Iteration: 1805 Training loss: 0.78152\n",
      "Epoch: 362/500 Iteration: 1806 Training loss: 0.25556\n",
      "Epoch: 362/500 Iteration: 1807 Training loss: 0.18126\n",
      "Epoch: 362/500 Iteration: 1808 Training loss: 0.13346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 362/500 Iteration: 1809 Training loss: 0.10760\n",
      "Epoch: 361/500 Iteration: 1810 Validation Acc: 0.6533\n",
      "Epoch: 363/500 Iteration: 1810 Training loss: 0.74691\n",
      "Epoch: 363/500 Iteration: 1811 Training loss: 0.29903\n",
      "Epoch: 363/500 Iteration: 1812 Training loss: 0.16872\n",
      "Epoch: 363/500 Iteration: 1813 Training loss: 0.12864\n",
      "Epoch: 363/500 Iteration: 1814 Training loss: 0.10540\n",
      "Epoch: 362/500 Iteration: 1815 Validation Acc: 0.6733\n",
      "Epoch: 364/500 Iteration: 1815 Training loss: 0.60327\n",
      "Epoch: 364/500 Iteration: 1816 Training loss: 0.27606\n",
      "Epoch: 364/500 Iteration: 1817 Training loss: 0.23882\n",
      "Epoch: 364/500 Iteration: 1818 Training loss: 0.12548\n",
      "Epoch: 364/500 Iteration: 1819 Training loss: 0.09700\n",
      "Epoch: 363/500 Iteration: 1820 Validation Acc: 0.6733\n",
      "Epoch: 365/500 Iteration: 1820 Training loss: 0.70994\n",
      "Epoch: 365/500 Iteration: 1821 Training loss: 0.26487\n",
      "Epoch: 365/500 Iteration: 1822 Training loss: 0.14389\n",
      "Epoch: 365/500 Iteration: 1823 Training loss: 0.12227\n",
      "Epoch: 365/500 Iteration: 1824 Training loss: 0.09599\n",
      "Epoch: 364/500 Iteration: 1825 Validation Acc: 0.6733\n",
      "Epoch: 366/500 Iteration: 1825 Training loss: 0.67850\n",
      "Epoch: 366/500 Iteration: 1826 Training loss: 0.32705\n",
      "Epoch: 366/500 Iteration: 1827 Training loss: 0.18280\n",
      "Epoch: 366/500 Iteration: 1828 Training loss: 0.13374\n",
      "Epoch: 366/500 Iteration: 1829 Training loss: 0.10433\n",
      "Epoch: 365/500 Iteration: 1830 Validation Acc: 0.6533\n",
      "Epoch: 367/500 Iteration: 1830 Training loss: 0.68954\n",
      "Epoch: 367/500 Iteration: 1831 Training loss: 0.34961\n",
      "Epoch: 367/500 Iteration: 1832 Training loss: 0.19488\n",
      "Epoch: 367/500 Iteration: 1833 Training loss: 0.12796\n",
      "Epoch: 367/500 Iteration: 1834 Training loss: 0.09499\n",
      "Epoch: 366/500 Iteration: 1835 Validation Acc: 0.6333\n",
      "Epoch: 368/500 Iteration: 1835 Training loss: 0.71211\n",
      "Epoch: 368/500 Iteration: 1836 Training loss: 0.28836\n",
      "Epoch: 368/500 Iteration: 1837 Training loss: 0.16805\n",
      "Epoch: 368/500 Iteration: 1838 Training loss: 0.12786\n",
      "Epoch: 368/500 Iteration: 1839 Training loss: 0.09694\n",
      "Epoch: 367/500 Iteration: 1840 Validation Acc: 0.6533\n",
      "Epoch: 369/500 Iteration: 1840 Training loss: 0.63561\n",
      "Epoch: 369/500 Iteration: 1841 Training loss: 0.23952\n",
      "Epoch: 369/500 Iteration: 1842 Training loss: 0.14754\n",
      "Epoch: 369/500 Iteration: 1843 Training loss: 0.11394\n",
      "Epoch: 369/500 Iteration: 1844 Training loss: 0.08073\n",
      "Epoch: 368/500 Iteration: 1845 Validation Acc: 0.6533\n",
      "Epoch: 370/500 Iteration: 1845 Training loss: 0.77810\n",
      "Epoch: 370/500 Iteration: 1846 Training loss: 0.25520\n",
      "Epoch: 370/500 Iteration: 1847 Training loss: 0.18045\n",
      "Epoch: 370/500 Iteration: 1848 Training loss: 0.12064\n",
      "Epoch: 370/500 Iteration: 1849 Training loss: 0.07705\n",
      "Epoch: 369/500 Iteration: 1850 Validation Acc: 0.6733\n",
      "Epoch: 371/500 Iteration: 1850 Training loss: 1.24691\n",
      "Epoch: 371/500 Iteration: 1851 Training loss: 0.45089\n",
      "Epoch: 371/500 Iteration: 1852 Training loss: 0.22850\n",
      "Epoch: 371/500 Iteration: 1853 Training loss: 0.16051\n",
      "Epoch: 371/500 Iteration: 1854 Training loss: 0.12502\n",
      "Epoch: 370/500 Iteration: 1855 Validation Acc: 0.6400\n",
      "Epoch: 372/500 Iteration: 1855 Training loss: 0.72413\n",
      "Epoch: 372/500 Iteration: 1856 Training loss: 0.33278\n",
      "Epoch: 372/500 Iteration: 1857 Training loss: 0.17776\n",
      "Epoch: 372/500 Iteration: 1858 Training loss: 0.13609\n",
      "Epoch: 372/500 Iteration: 1859 Training loss: 0.10232\n",
      "Epoch: 371/500 Iteration: 1860 Validation Acc: 0.6133\n",
      "Epoch: 373/500 Iteration: 1860 Training loss: 0.60229\n",
      "Epoch: 373/500 Iteration: 1861 Training loss: 0.25587\n",
      "Epoch: 373/500 Iteration: 1862 Training loss: 0.16504\n",
      "Epoch: 373/500 Iteration: 1863 Training loss: 0.12075\n",
      "Epoch: 373/500 Iteration: 1864 Training loss: 0.09690\n",
      "Epoch: 372/500 Iteration: 1865 Validation Acc: 0.6600\n",
      "Epoch: 374/500 Iteration: 1865 Training loss: 0.58660\n",
      "Epoch: 374/500 Iteration: 1866 Training loss: 0.26423\n",
      "Epoch: 374/500 Iteration: 1867 Training loss: 0.16679\n",
      "Epoch: 374/500 Iteration: 1868 Training loss: 0.11572\n",
      "Epoch: 374/500 Iteration: 1869 Training loss: 0.08200\n",
      "Epoch: 373/500 Iteration: 1870 Validation Acc: 0.6733\n",
      "Epoch: 375/500 Iteration: 1870 Training loss: 0.64658\n",
      "Epoch: 375/500 Iteration: 1871 Training loss: 0.29292\n",
      "Epoch: 375/500 Iteration: 1872 Training loss: 0.19916\n",
      "Epoch: 375/500 Iteration: 1873 Training loss: 0.12446\n",
      "Epoch: 375/500 Iteration: 1874 Training loss: 0.09589\n",
      "Epoch: 374/500 Iteration: 1875 Validation Acc: 0.6533\n",
      "Epoch: 376/500 Iteration: 1875 Training loss: 0.71624\n",
      "Epoch: 376/500 Iteration: 1876 Training loss: 0.29815\n",
      "Epoch: 376/500 Iteration: 1877 Training loss: 0.16114\n",
      "Epoch: 376/500 Iteration: 1878 Training loss: 0.11877\n",
      "Epoch: 376/500 Iteration: 1879 Training loss: 0.08060\n",
      "Epoch: 375/500 Iteration: 1880 Validation Acc: 0.6533\n",
      "Epoch: 377/500 Iteration: 1880 Training loss: 0.85546\n",
      "Epoch: 377/500 Iteration: 1881 Training loss: 0.28250\n",
      "Epoch: 377/500 Iteration: 1882 Training loss: 0.17332\n",
      "Epoch: 377/500 Iteration: 1883 Training loss: 0.13449\n",
      "Epoch: 377/500 Iteration: 1884 Training loss: 0.10382\n",
      "Epoch: 376/500 Iteration: 1885 Validation Acc: 0.6200\n",
      "Epoch: 378/500 Iteration: 1885 Training loss: 1.11942\n",
      "Epoch: 378/500 Iteration: 1886 Training loss: 0.53439\n",
      "Epoch: 378/500 Iteration: 1887 Training loss: 0.35666\n",
      "Epoch: 378/500 Iteration: 1888 Training loss: 0.15806\n",
      "Epoch: 378/500 Iteration: 1889 Training loss: 0.11977\n",
      "Epoch: 377/500 Iteration: 1890 Validation Acc: 0.6267\n",
      "Epoch: 379/500 Iteration: 1890 Training loss: 0.77695\n",
      "Epoch: 379/500 Iteration: 1891 Training loss: 0.32593\n",
      "Epoch: 379/500 Iteration: 1892 Training loss: 0.17866\n",
      "Epoch: 379/500 Iteration: 1893 Training loss: 0.14341\n",
      "Epoch: 379/500 Iteration: 1894 Training loss: 0.11288\n",
      "Epoch: 378/500 Iteration: 1895 Validation Acc: 0.6600\n",
      "Epoch: 380/500 Iteration: 1895 Training loss: 0.55774\n",
      "Epoch: 380/500 Iteration: 1896 Training loss: 0.24814\n",
      "Epoch: 380/500 Iteration: 1897 Training loss: 0.15014\n",
      "Epoch: 380/500 Iteration: 1898 Training loss: 0.11972\n",
      "Epoch: 380/500 Iteration: 1899 Training loss: 0.09480\n",
      "Epoch: 379/500 Iteration: 1900 Validation Acc: 0.6267\n",
      "Epoch: 381/500 Iteration: 1900 Training loss: 0.58967\n",
      "Epoch: 381/500 Iteration: 1901 Training loss: 0.25039\n",
      "Epoch: 381/500 Iteration: 1902 Training loss: 0.15248\n",
      "Epoch: 381/500 Iteration: 1903 Training loss: 0.11620\n",
      "Epoch: 381/500 Iteration: 1904 Training loss: 0.09900\n",
      "Epoch: 380/500 Iteration: 1905 Validation Acc: 0.6333\n",
      "Epoch: 382/500 Iteration: 1905 Training loss: 0.56472\n",
      "Epoch: 382/500 Iteration: 1906 Training loss: 0.20375\n",
      "Epoch: 382/500 Iteration: 1907 Training loss: 0.15420\n",
      "Epoch: 382/500 Iteration: 1908 Training loss: 0.12009\n",
      "Epoch: 382/500 Iteration: 1909 Training loss: 0.08342\n",
      "Epoch: 381/500 Iteration: 1910 Validation Acc: 0.6733\n",
      "Epoch: 383/500 Iteration: 1910 Training loss: 0.64813\n",
      "Epoch: 383/500 Iteration: 1911 Training loss: 0.26549\n",
      "Epoch: 383/500 Iteration: 1912 Training loss: 0.18010\n",
      "Epoch: 383/500 Iteration: 1913 Training loss: 0.11825\n",
      "Epoch: 383/500 Iteration: 1914 Training loss: 0.07143\n",
      "Epoch: 382/500 Iteration: 1915 Validation Acc: 0.6400\n",
      "Epoch: 384/500 Iteration: 1915 Training loss: 0.80536\n",
      "Epoch: 384/500 Iteration: 1916 Training loss: 0.25626\n",
      "Epoch: 384/500 Iteration: 1917 Training loss: 0.14254\n",
      "Epoch: 384/500 Iteration: 1918 Training loss: 0.12956\n",
      "Epoch: 384/500 Iteration: 1919 Training loss: 0.09396\n",
      "Epoch: 383/500 Iteration: 1920 Validation Acc: 0.6667\n",
      "Epoch: 385/500 Iteration: 1920 Training loss: 0.64072\n",
      "Epoch: 385/500 Iteration: 1921 Training loss: 0.33082\n",
      "Epoch: 385/500 Iteration: 1922 Training loss: 0.19247\n",
      "Epoch: 385/500 Iteration: 1923 Training loss: 0.12756\n",
      "Epoch: 385/500 Iteration: 1924 Training loss: 0.10076\n",
      "Epoch: 384/500 Iteration: 1925 Validation Acc: 0.6733\n",
      "Epoch: 386/500 Iteration: 1925 Training loss: 0.57075\n",
      "Epoch: 386/500 Iteration: 1926 Training loss: 0.25887\n",
      "Epoch: 386/500 Iteration: 1927 Training loss: 0.14439\n",
      "Epoch: 386/500 Iteration: 1928 Training loss: 0.10986\n",
      "Epoch: 386/500 Iteration: 1929 Training loss: 0.09064\n",
      "Epoch: 385/500 Iteration: 1930 Validation Acc: 0.6333\n",
      "Epoch: 387/500 Iteration: 1930 Training loss: 0.60098\n",
      "Epoch: 387/500 Iteration: 1931 Training loss: 0.30260\n",
      "Epoch: 387/500 Iteration: 1932 Training loss: 0.18631\n",
      "Epoch: 387/500 Iteration: 1933 Training loss: 0.11330\n",
      "Epoch: 387/500 Iteration: 1934 Training loss: 0.08403\n",
      "Epoch: 386/500 Iteration: 1935 Validation Acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 388/500 Iteration: 1935 Training loss: 0.61869\n",
      "Epoch: 388/500 Iteration: 1936 Training loss: 0.24598\n",
      "Epoch: 388/500 Iteration: 1937 Training loss: 0.14295\n",
      "Epoch: 388/500 Iteration: 1938 Training loss: 0.11884\n",
      "Epoch: 388/500 Iteration: 1939 Training loss: 0.08304\n",
      "Epoch: 387/500 Iteration: 1940 Validation Acc: 0.6400\n",
      "Epoch: 389/500 Iteration: 1940 Training loss: 0.69061\n",
      "Epoch: 389/500 Iteration: 1941 Training loss: 0.24317\n",
      "Epoch: 389/500 Iteration: 1942 Training loss: 0.13547\n",
      "Epoch: 389/500 Iteration: 1943 Training loss: 0.11116\n",
      "Epoch: 389/500 Iteration: 1944 Training loss: 0.08186\n",
      "Epoch: 388/500 Iteration: 1945 Validation Acc: 0.6133\n",
      "Epoch: 390/500 Iteration: 1945 Training loss: 0.70518\n",
      "Epoch: 390/500 Iteration: 1946 Training loss: 0.29288\n",
      "Epoch: 390/500 Iteration: 1947 Training loss: 0.18292\n",
      "Epoch: 390/500 Iteration: 1948 Training loss: 0.12084\n",
      "Epoch: 390/500 Iteration: 1949 Training loss: 0.08030\n",
      "Epoch: 389/500 Iteration: 1950 Validation Acc: 0.6400\n",
      "Epoch: 391/500 Iteration: 1950 Training loss: 0.59663\n",
      "Epoch: 391/500 Iteration: 1951 Training loss: 0.24887\n",
      "Epoch: 391/500 Iteration: 1952 Training loss: 0.15705\n",
      "Epoch: 391/500 Iteration: 1953 Training loss: 0.10950\n",
      "Epoch: 391/500 Iteration: 1954 Training loss: 0.08162\n",
      "Epoch: 390/500 Iteration: 1955 Validation Acc: 0.6400\n",
      "Epoch: 392/500 Iteration: 1955 Training loss: 0.60154\n",
      "Epoch: 392/500 Iteration: 1956 Training loss: 0.25273\n",
      "Epoch: 392/500 Iteration: 1957 Training loss: 0.17775\n",
      "Epoch: 392/500 Iteration: 1958 Training loss: 0.10594\n",
      "Epoch: 392/500 Iteration: 1959 Training loss: 0.08496\n",
      "Epoch: 391/500 Iteration: 1960 Validation Acc: 0.6667\n",
      "Epoch: 393/500 Iteration: 1960 Training loss: 0.80568\n",
      "Epoch: 393/500 Iteration: 1961 Training loss: 0.26898\n",
      "Epoch: 393/500 Iteration: 1962 Training loss: 0.16512\n",
      "Epoch: 393/500 Iteration: 1963 Training loss: 0.11231\n",
      "Epoch: 393/500 Iteration: 1964 Training loss: 0.07671\n",
      "Epoch: 392/500 Iteration: 1965 Validation Acc: 0.6733\n",
      "Epoch: 394/500 Iteration: 1965 Training loss: 0.88810\n",
      "Epoch: 394/500 Iteration: 1966 Training loss: 0.51690\n",
      "Epoch: 394/500 Iteration: 1967 Training loss: 0.36499\n",
      "Epoch: 394/500 Iteration: 1968 Training loss: 0.14692\n",
      "Epoch: 394/500 Iteration: 1969 Training loss: 0.11695\n",
      "Epoch: 393/500 Iteration: 1970 Validation Acc: 0.6467\n",
      "Epoch: 395/500 Iteration: 1970 Training loss: 0.68342\n",
      "Epoch: 395/500 Iteration: 1971 Training loss: 0.28712\n",
      "Epoch: 395/500 Iteration: 1972 Training loss: 0.14104\n",
      "Epoch: 395/500 Iteration: 1973 Training loss: 0.13106\n",
      "Epoch: 395/500 Iteration: 1974 Training loss: 0.09329\n",
      "Epoch: 394/500 Iteration: 1975 Validation Acc: 0.6667\n",
      "Epoch: 396/500 Iteration: 1975 Training loss: 0.61827\n",
      "Epoch: 396/500 Iteration: 1976 Training loss: 0.25495\n",
      "Epoch: 396/500 Iteration: 1977 Training loss: 0.13808\n",
      "Epoch: 396/500 Iteration: 1978 Training loss: 0.11541\n",
      "Epoch: 396/500 Iteration: 1979 Training loss: 0.10735\n",
      "Epoch: 395/500 Iteration: 1980 Validation Acc: 0.6400\n",
      "Epoch: 397/500 Iteration: 1980 Training loss: 0.58859\n",
      "Epoch: 397/500 Iteration: 1981 Training loss: 0.25116\n",
      "Epoch: 397/500 Iteration: 1982 Training loss: 0.16518\n",
      "Epoch: 397/500 Iteration: 1983 Training loss: 0.10479\n",
      "Epoch: 397/500 Iteration: 1984 Training loss: 0.08245\n",
      "Epoch: 396/500 Iteration: 1985 Validation Acc: 0.6733\n",
      "Epoch: 398/500 Iteration: 1985 Training loss: 0.52965\n",
      "Epoch: 398/500 Iteration: 1986 Training loss: 0.21403\n",
      "Epoch: 398/500 Iteration: 1987 Training loss: 0.12424\n",
      "Epoch: 398/500 Iteration: 1988 Training loss: 0.10378\n",
      "Epoch: 398/500 Iteration: 1989 Training loss: 0.08394\n",
      "Epoch: 397/500 Iteration: 1990 Validation Acc: 0.6533\n",
      "Epoch: 399/500 Iteration: 1990 Training loss: 0.57656\n",
      "Epoch: 399/500 Iteration: 1991 Training loss: 0.22941\n",
      "Epoch: 399/500 Iteration: 1992 Training loss: 0.13618\n",
      "Epoch: 399/500 Iteration: 1993 Training loss: 0.09515\n",
      "Epoch: 399/500 Iteration: 1994 Training loss: 0.07952\n",
      "Epoch: 398/500 Iteration: 1995 Validation Acc: 0.6267\n",
      "Epoch: 400/500 Iteration: 1995 Training loss: 0.69454\n",
      "Epoch: 400/500 Iteration: 1996 Training loss: 0.25656\n",
      "Epoch: 400/500 Iteration: 1997 Training loss: 0.13714\n",
      "Epoch: 400/500 Iteration: 1998 Training loss: 0.10897\n",
      "Epoch: 400/500 Iteration: 1999 Training loss: 0.07828\n",
      "Epoch: 399/500 Iteration: 2000 Validation Acc: 0.6333\n",
      "Epoch: 401/500 Iteration: 2000 Training loss: 0.61930\n",
      "Epoch: 401/500 Iteration: 2001 Training loss: 0.25208\n",
      "Epoch: 401/500 Iteration: 2002 Training loss: 0.15701\n",
      "Epoch: 401/500 Iteration: 2003 Training loss: 0.09825\n",
      "Epoch: 401/500 Iteration: 2004 Training loss: 0.07537\n",
      "Epoch: 400/500 Iteration: 2005 Validation Acc: 0.6400\n",
      "Epoch: 402/500 Iteration: 2005 Training loss: 0.72518\n",
      "Epoch: 402/500 Iteration: 2006 Training loss: 0.25576\n",
      "Epoch: 402/500 Iteration: 2007 Training loss: 0.17467\n",
      "Epoch: 402/500 Iteration: 2008 Training loss: 0.11828\n",
      "Epoch: 402/500 Iteration: 2009 Training loss: 0.09466\n",
      "Epoch: 401/500 Iteration: 2010 Validation Acc: 0.6933\n",
      "Epoch: 403/500 Iteration: 2010 Training loss: 1.02973\n",
      "Epoch: 403/500 Iteration: 2011 Training loss: 0.32290\n",
      "Epoch: 403/500 Iteration: 2012 Training loss: 0.18969\n",
      "Epoch: 403/500 Iteration: 2013 Training loss: 0.14361\n",
      "Epoch: 403/500 Iteration: 2014 Training loss: 0.11112\n",
      "Epoch: 402/500 Iteration: 2015 Validation Acc: 0.6533\n",
      "Epoch: 404/500 Iteration: 2015 Training loss: 0.70633\n",
      "Epoch: 404/500 Iteration: 2016 Training loss: 0.36231\n",
      "Epoch: 404/500 Iteration: 2017 Training loss: 0.29060\n",
      "Epoch: 404/500 Iteration: 2018 Training loss: 0.12115\n",
      "Epoch: 404/500 Iteration: 2019 Training loss: 0.09805\n",
      "Epoch: 403/500 Iteration: 2020 Validation Acc: 0.6067\n",
      "Epoch: 405/500 Iteration: 2020 Training loss: 0.79917\n",
      "Epoch: 405/500 Iteration: 2021 Training loss: 0.34622\n",
      "Epoch: 405/500 Iteration: 2022 Training loss: 0.17342\n",
      "Epoch: 405/500 Iteration: 2023 Training loss: 0.12875\n",
      "Epoch: 405/500 Iteration: 2024 Training loss: 0.10130\n",
      "Epoch: 404/500 Iteration: 2025 Validation Acc: 0.6467\n",
      "Epoch: 406/500 Iteration: 2025 Training loss: 0.58376\n",
      "Epoch: 406/500 Iteration: 2026 Training loss: 0.33891\n",
      "Epoch: 406/500 Iteration: 2027 Training loss: 0.15335\n",
      "Epoch: 406/500 Iteration: 2028 Training loss: 0.11762\n",
      "Epoch: 406/500 Iteration: 2029 Training loss: 0.09215\n",
      "Epoch: 405/500 Iteration: 2030 Validation Acc: 0.6600\n",
      "Epoch: 407/500 Iteration: 2030 Training loss: 0.55040\n",
      "Epoch: 407/500 Iteration: 2031 Training loss: 0.25158\n",
      "Epoch: 407/500 Iteration: 2032 Training loss: 0.12228\n",
      "Epoch: 407/500 Iteration: 2033 Training loss: 0.10557\n",
      "Epoch: 407/500 Iteration: 2034 Training loss: 0.07366\n",
      "Epoch: 406/500 Iteration: 2035 Validation Acc: 0.6800\n",
      "Epoch: 408/500 Iteration: 2035 Training loss: 0.57603\n",
      "Epoch: 408/500 Iteration: 2036 Training loss: 0.24257\n",
      "Epoch: 408/500 Iteration: 2037 Training loss: 0.14997\n",
      "Epoch: 408/500 Iteration: 2038 Training loss: 0.11454\n",
      "Epoch: 408/500 Iteration: 2039 Training loss: 0.08923\n",
      "Epoch: 407/500 Iteration: 2040 Validation Acc: 0.6800\n",
      "Epoch: 409/500 Iteration: 2040 Training loss: 0.61210\n",
      "Epoch: 409/500 Iteration: 2041 Training loss: 0.65228\n",
      "Epoch: 409/500 Iteration: 2042 Training loss: 0.23441\n",
      "Epoch: 409/500 Iteration: 2043 Training loss: 0.11965\n",
      "Epoch: 409/500 Iteration: 2044 Training loss: 0.08750\n",
      "Epoch: 408/500 Iteration: 2045 Validation Acc: 0.6533\n",
      "Epoch: 410/500 Iteration: 2045 Training loss: 0.78005\n",
      "Epoch: 410/500 Iteration: 2046 Training loss: 0.29095\n",
      "Epoch: 410/500 Iteration: 2047 Training loss: 0.15289\n",
      "Epoch: 410/500 Iteration: 2048 Training loss: 0.11726\n",
      "Epoch: 410/500 Iteration: 2049 Training loss: 0.09361\n",
      "Epoch: 409/500 Iteration: 2050 Validation Acc: 0.6933\n",
      "Epoch: 411/500 Iteration: 2050 Training loss: 0.59773\n",
      "Epoch: 411/500 Iteration: 2051 Training loss: 0.22694\n",
      "Epoch: 411/500 Iteration: 2052 Training loss: 0.14926\n",
      "Epoch: 411/500 Iteration: 2053 Training loss: 0.10718\n",
      "Epoch: 411/500 Iteration: 2054 Training loss: 0.09340\n",
      "Epoch: 410/500 Iteration: 2055 Validation Acc: 0.6533\n",
      "Epoch: 412/500 Iteration: 2055 Training loss: 0.72859\n",
      "Epoch: 412/500 Iteration: 2056 Training loss: 0.32254\n",
      "Epoch: 412/500 Iteration: 2057 Training loss: 0.14055\n",
      "Epoch: 412/500 Iteration: 2058 Training loss: 0.12070\n",
      "Epoch: 412/500 Iteration: 2059 Training loss: 0.09605\n",
      "Epoch: 411/500 Iteration: 2060 Validation Acc: 0.6333\n",
      "Epoch: 413/500 Iteration: 2060 Training loss: 0.56122\n",
      "Epoch: 413/500 Iteration: 2061 Training loss: 0.21324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 413/500 Iteration: 2062 Training loss: 0.12220\n",
      "Epoch: 413/500 Iteration: 2063 Training loss: 0.10682\n",
      "Epoch: 413/500 Iteration: 2064 Training loss: 0.08525\n",
      "Epoch: 412/500 Iteration: 2065 Validation Acc: 0.6400\n",
      "Epoch: 414/500 Iteration: 2065 Training loss: 0.51745\n",
      "Epoch: 414/500 Iteration: 2066 Training loss: 0.20589\n",
      "Epoch: 414/500 Iteration: 2067 Training loss: 0.11889\n",
      "Epoch: 414/500 Iteration: 2068 Training loss: 0.10322\n",
      "Epoch: 414/500 Iteration: 2069 Training loss: 0.07336\n",
      "Epoch: 413/500 Iteration: 2070 Validation Acc: 0.6867\n",
      "Epoch: 415/500 Iteration: 2070 Training loss: 0.56628\n",
      "Epoch: 415/500 Iteration: 2071 Training loss: 0.24940\n",
      "Epoch: 415/500 Iteration: 2072 Training loss: 0.14863\n",
      "Epoch: 415/500 Iteration: 2073 Training loss: 0.09851\n",
      "Epoch: 415/500 Iteration: 2074 Training loss: 0.06953\n",
      "Epoch: 414/500 Iteration: 2075 Validation Acc: 0.6600\n",
      "Epoch: 416/500 Iteration: 2075 Training loss: 0.64517\n",
      "Epoch: 416/500 Iteration: 2076 Training loss: 0.32373\n",
      "Epoch: 416/500 Iteration: 2077 Training loss: 0.16124\n",
      "Epoch: 416/500 Iteration: 2078 Training loss: 0.11369\n",
      "Epoch: 416/500 Iteration: 2079 Training loss: 0.08282\n",
      "Epoch: 415/500 Iteration: 2080 Validation Acc: 0.6467\n",
      "Epoch: 417/500 Iteration: 2080 Training loss: 0.59595\n",
      "Epoch: 417/500 Iteration: 2081 Training loss: 0.21512\n",
      "Epoch: 417/500 Iteration: 2082 Training loss: 0.13902\n",
      "Epoch: 417/500 Iteration: 2083 Training loss: 0.10069\n",
      "Epoch: 417/500 Iteration: 2084 Training loss: 0.08575\n",
      "Epoch: 416/500 Iteration: 2085 Validation Acc: 0.6667\n",
      "Epoch: 418/500 Iteration: 2085 Training loss: 0.60674\n",
      "Epoch: 418/500 Iteration: 2086 Training loss: 0.25005\n",
      "Epoch: 418/500 Iteration: 2087 Training loss: 0.18300\n",
      "Epoch: 418/500 Iteration: 2088 Training loss: 0.10603\n",
      "Epoch: 418/500 Iteration: 2089 Training loss: 0.09036\n",
      "Epoch: 417/500 Iteration: 2090 Validation Acc: 0.6400\n",
      "Epoch: 419/500 Iteration: 2090 Training loss: 0.65060\n",
      "Epoch: 419/500 Iteration: 2091 Training loss: 0.33954\n",
      "Epoch: 419/500 Iteration: 2092 Training loss: 0.18614\n",
      "Epoch: 419/500 Iteration: 2093 Training loss: 0.09932\n",
      "Epoch: 419/500 Iteration: 2094 Training loss: 0.07946\n",
      "Epoch: 418/500 Iteration: 2095 Validation Acc: 0.6533\n",
      "Epoch: 420/500 Iteration: 2095 Training loss: 0.59750\n",
      "Epoch: 420/500 Iteration: 2096 Training loss: 0.25180\n",
      "Epoch: 420/500 Iteration: 2097 Training loss: 0.12709\n",
      "Epoch: 420/500 Iteration: 2098 Training loss: 0.11462\n",
      "Epoch: 420/500 Iteration: 2099 Training loss: 0.07405\n",
      "Epoch: 419/500 Iteration: 2100 Validation Acc: 0.6867\n",
      "Epoch: 421/500 Iteration: 2100 Training loss: 0.53869\n",
      "Epoch: 421/500 Iteration: 2101 Training loss: 0.20549\n",
      "Epoch: 421/500 Iteration: 2102 Training loss: 0.12894\n",
      "Epoch: 421/500 Iteration: 2103 Training loss: 0.10302\n",
      "Epoch: 421/500 Iteration: 2104 Training loss: 0.06931\n",
      "Epoch: 420/500 Iteration: 2105 Validation Acc: 0.6667\n",
      "Epoch: 422/500 Iteration: 2105 Training loss: 0.58908\n",
      "Epoch: 422/500 Iteration: 2106 Training loss: 0.20063\n",
      "Epoch: 422/500 Iteration: 2107 Training loss: 0.13565\n",
      "Epoch: 422/500 Iteration: 2108 Training loss: 0.09887\n",
      "Epoch: 422/500 Iteration: 2109 Training loss: 0.07011\n",
      "Epoch: 421/500 Iteration: 2110 Validation Acc: 0.6467\n",
      "Epoch: 423/500 Iteration: 2110 Training loss: 0.58418\n",
      "Epoch: 423/500 Iteration: 2111 Training loss: 0.24431\n",
      "Epoch: 423/500 Iteration: 2112 Training loss: 0.13437\n",
      "Epoch: 423/500 Iteration: 2113 Training loss: 0.10443\n",
      "Epoch: 423/500 Iteration: 2114 Training loss: 0.07917\n",
      "Epoch: 422/500 Iteration: 2115 Validation Acc: 0.6267\n",
      "Epoch: 424/500 Iteration: 2115 Training loss: 0.55153\n",
      "Epoch: 424/500 Iteration: 2116 Training loss: 0.30933\n",
      "Epoch: 424/500 Iteration: 2117 Training loss: 0.18097\n",
      "Epoch: 424/500 Iteration: 2118 Training loss: 0.09674\n",
      "Epoch: 424/500 Iteration: 2119 Training loss: 0.07714\n",
      "Epoch: 423/500 Iteration: 2120 Validation Acc: 0.6667\n",
      "Epoch: 425/500 Iteration: 2120 Training loss: 0.65253\n",
      "Epoch: 425/500 Iteration: 2121 Training loss: 0.32132\n",
      "Epoch: 425/500 Iteration: 2122 Training loss: 0.19576\n",
      "Epoch: 425/500 Iteration: 2123 Training loss: 0.10161\n",
      "Epoch: 425/500 Iteration: 2124 Training loss: 0.07853\n",
      "Epoch: 424/500 Iteration: 2125 Validation Acc: 0.6267\n",
      "Epoch: 426/500 Iteration: 2125 Training loss: 0.52886\n",
      "Epoch: 426/500 Iteration: 2126 Training loss: 0.18724\n",
      "Epoch: 426/500 Iteration: 2127 Training loss: 0.13501\n",
      "Epoch: 426/500 Iteration: 2128 Training loss: 0.09361\n",
      "Epoch: 426/500 Iteration: 2129 Training loss: 0.06945\n",
      "Epoch: 425/500 Iteration: 2130 Validation Acc: 0.6600\n",
      "Epoch: 427/500 Iteration: 2130 Training loss: 0.68168\n",
      "Epoch: 427/500 Iteration: 2131 Training loss: 0.25501\n",
      "Epoch: 427/500 Iteration: 2132 Training loss: 0.14376\n",
      "Epoch: 427/500 Iteration: 2133 Training loss: 0.11029\n",
      "Epoch: 427/500 Iteration: 2134 Training loss: 0.08675\n",
      "Epoch: 426/500 Iteration: 2135 Validation Acc: 0.6333\n",
      "Epoch: 428/500 Iteration: 2135 Training loss: 0.54099\n",
      "Epoch: 428/500 Iteration: 2136 Training loss: 0.28793\n",
      "Epoch: 428/500 Iteration: 2137 Training loss: 0.17029\n",
      "Epoch: 428/500 Iteration: 2138 Training loss: 0.10505\n",
      "Epoch: 428/500 Iteration: 2139 Training loss: 0.07534\n",
      "Epoch: 427/500 Iteration: 2140 Validation Acc: 0.6600\n",
      "Epoch: 429/500 Iteration: 2140 Training loss: 0.70298\n",
      "Epoch: 429/500 Iteration: 2141 Training loss: 0.25083\n",
      "Epoch: 429/500 Iteration: 2142 Training loss: 0.14599\n",
      "Epoch: 429/500 Iteration: 2143 Training loss: 0.11942\n",
      "Epoch: 429/500 Iteration: 2144 Training loss: 0.08034\n",
      "Epoch: 428/500 Iteration: 2145 Validation Acc: 0.6667\n",
      "Epoch: 430/500 Iteration: 2145 Training loss: 0.51918\n",
      "Epoch: 430/500 Iteration: 2146 Training loss: 0.20971\n",
      "Epoch: 430/500 Iteration: 2147 Training loss: 0.16031\n",
      "Epoch: 430/500 Iteration: 2148 Training loss: 0.10090\n",
      "Epoch: 430/500 Iteration: 2149 Training loss: 0.07671\n",
      "Epoch: 429/500 Iteration: 2150 Validation Acc: 0.6667\n",
      "Epoch: 431/500 Iteration: 2150 Training loss: 0.56866\n",
      "Epoch: 431/500 Iteration: 2151 Training loss: 0.38831\n",
      "Epoch: 431/500 Iteration: 2152 Training loss: 0.20919\n",
      "Epoch: 431/500 Iteration: 2153 Training loss: 0.10090\n",
      "Epoch: 431/500 Iteration: 2154 Training loss: 0.07449\n",
      "Epoch: 430/500 Iteration: 2155 Validation Acc: 0.6267\n",
      "Epoch: 432/500 Iteration: 2155 Training loss: 0.88166\n",
      "Epoch: 432/500 Iteration: 2156 Training loss: 0.28992\n",
      "Epoch: 432/500 Iteration: 2157 Training loss: 0.14894\n",
      "Epoch: 432/500 Iteration: 2158 Training loss: 0.12470\n",
      "Epoch: 432/500 Iteration: 2159 Training loss: 0.09001\n",
      "Epoch: 431/500 Iteration: 2160 Validation Acc: 0.6467\n",
      "Epoch: 433/500 Iteration: 2160 Training loss: 0.62930\n",
      "Epoch: 433/500 Iteration: 2161 Training loss: 0.23313\n",
      "Epoch: 433/500 Iteration: 2162 Training loss: 0.13273\n",
      "Epoch: 433/500 Iteration: 2163 Training loss: 0.11469\n",
      "Epoch: 433/500 Iteration: 2164 Training loss: 0.08221\n",
      "Epoch: 432/500 Iteration: 2165 Validation Acc: 0.6533\n",
      "Epoch: 434/500 Iteration: 2165 Training loss: 0.54421\n",
      "Epoch: 434/500 Iteration: 2166 Training loss: 0.20776\n",
      "Epoch: 434/500 Iteration: 2167 Training loss: 0.12736\n",
      "Epoch: 434/500 Iteration: 2168 Training loss: 0.09653\n",
      "Epoch: 434/500 Iteration: 2169 Training loss: 0.07363\n",
      "Epoch: 433/500 Iteration: 2170 Validation Acc: 0.6467\n",
      "Epoch: 435/500 Iteration: 2170 Training loss: 0.56169\n",
      "Epoch: 435/500 Iteration: 2171 Training loss: 0.18661\n",
      "Epoch: 435/500 Iteration: 2172 Training loss: 0.12873\n",
      "Epoch: 435/500 Iteration: 2173 Training loss: 0.09485\n",
      "Epoch: 435/500 Iteration: 2174 Training loss: 0.07651\n",
      "Epoch: 434/500 Iteration: 2175 Validation Acc: 0.6467\n",
      "Epoch: 436/500 Iteration: 2175 Training loss: 0.55198\n",
      "Epoch: 436/500 Iteration: 2176 Training loss: 0.24695\n",
      "Epoch: 436/500 Iteration: 2177 Training loss: 0.13176\n",
      "Epoch: 436/500 Iteration: 2178 Training loss: 0.09878\n",
      "Epoch: 436/500 Iteration: 2179 Training loss: 0.06729\n",
      "Epoch: 435/500 Iteration: 2180 Validation Acc: 0.6200\n",
      "Epoch: 437/500 Iteration: 2180 Training loss: 0.60930\n",
      "Epoch: 437/500 Iteration: 2181 Training loss: 0.22108\n",
      "Epoch: 437/500 Iteration: 2182 Training loss: 0.16092\n",
      "Epoch: 437/500 Iteration: 2183 Training loss: 0.09315\n",
      "Epoch: 437/500 Iteration: 2184 Training loss: 0.06860\n",
      "Epoch: 436/500 Iteration: 2185 Validation Acc: 0.6133\n",
      "Epoch: 438/500 Iteration: 2185 Training loss: 1.50422\n",
      "Epoch: 438/500 Iteration: 2186 Training loss: 0.45001\n",
      "Epoch: 438/500 Iteration: 2187 Training loss: 0.15496\n",
      "Epoch: 438/500 Iteration: 2188 Training loss: 0.14046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 438/500 Iteration: 2189 Training loss: 0.09164\n",
      "Epoch: 437/500 Iteration: 2190 Validation Acc: 0.6200\n",
      "Epoch: 439/500 Iteration: 2190 Training loss: 0.73565\n",
      "Epoch: 439/500 Iteration: 2191 Training loss: 0.29005\n",
      "Epoch: 439/500 Iteration: 2192 Training loss: 0.19784\n",
      "Epoch: 439/500 Iteration: 2193 Training loss: 0.11075\n",
      "Epoch: 439/500 Iteration: 2194 Training loss: 0.08197\n",
      "Epoch: 438/500 Iteration: 2195 Validation Acc: 0.6133\n",
      "Epoch: 440/500 Iteration: 2195 Training loss: 0.74086\n",
      "Epoch: 440/500 Iteration: 2196 Training loss: 0.21904\n",
      "Epoch: 440/500 Iteration: 2197 Training loss: 0.15496\n",
      "Epoch: 440/500 Iteration: 2198 Training loss: 0.12642\n",
      "Epoch: 440/500 Iteration: 2199 Training loss: 0.10523\n",
      "Epoch: 439/500 Iteration: 2200 Validation Acc: 0.6400\n",
      "Epoch: 441/500 Iteration: 2200 Training loss: 0.49999\n",
      "Epoch: 441/500 Iteration: 2201 Training loss: 0.30603\n",
      "Epoch: 441/500 Iteration: 2202 Training loss: 0.17817\n",
      "Epoch: 441/500 Iteration: 2203 Training loss: 0.11227\n",
      "Epoch: 441/500 Iteration: 2204 Training loss: 0.10564\n",
      "Epoch: 440/500 Iteration: 2205 Validation Acc: 0.6800\n",
      "Epoch: 442/500 Iteration: 2205 Training loss: 0.46858\n",
      "Epoch: 442/500 Iteration: 2206 Training loss: 0.26852\n",
      "Epoch: 442/500 Iteration: 2207 Training loss: 0.12924\n",
      "Epoch: 442/500 Iteration: 2208 Training loss: 0.11039\n",
      "Epoch: 442/500 Iteration: 2209 Training loss: 0.08156\n",
      "Epoch: 441/500 Iteration: 2210 Validation Acc: 0.6733\n",
      "Epoch: 443/500 Iteration: 2210 Training loss: 0.46801\n",
      "Epoch: 443/500 Iteration: 2211 Training loss: 0.19879\n",
      "Epoch: 443/500 Iteration: 2212 Training loss: 0.10990\n",
      "Epoch: 443/500 Iteration: 2213 Training loss: 0.08668\n",
      "Epoch: 443/500 Iteration: 2214 Training loss: 0.07634\n",
      "Epoch: 442/500 Iteration: 2215 Validation Acc: 0.6400\n",
      "Epoch: 444/500 Iteration: 2215 Training loss: 0.54401\n",
      "Epoch: 444/500 Iteration: 2216 Training loss: 0.20221\n",
      "Epoch: 444/500 Iteration: 2217 Training loss: 0.13795\n",
      "Epoch: 444/500 Iteration: 2218 Training loss: 0.09158\n",
      "Epoch: 444/500 Iteration: 2219 Training loss: 0.07040\n",
      "Epoch: 443/500 Iteration: 2220 Validation Acc: 0.6400\n",
      "Epoch: 445/500 Iteration: 2220 Training loss: 0.53138\n",
      "Epoch: 445/500 Iteration: 2221 Training loss: 0.32298\n",
      "Epoch: 445/500 Iteration: 2222 Training loss: 0.15767\n",
      "Epoch: 445/500 Iteration: 2223 Training loss: 0.10484\n",
      "Epoch: 445/500 Iteration: 2224 Training loss: 0.08449\n",
      "Epoch: 444/500 Iteration: 2225 Validation Acc: 0.6600\n",
      "Epoch: 446/500 Iteration: 2225 Training loss: 0.58376\n",
      "Epoch: 446/500 Iteration: 2226 Training loss: 0.20606\n",
      "Epoch: 446/500 Iteration: 2227 Training loss: 0.11839\n",
      "Epoch: 446/500 Iteration: 2228 Training loss: 0.08398\n",
      "Epoch: 446/500 Iteration: 2229 Training loss: 0.06858\n",
      "Epoch: 445/500 Iteration: 2230 Validation Acc: 0.6067\n",
      "Epoch: 447/500 Iteration: 2230 Training loss: 0.57597\n",
      "Epoch: 447/500 Iteration: 2231 Training loss: 0.19761\n",
      "Epoch: 447/500 Iteration: 2232 Training loss: 0.13543\n",
      "Epoch: 447/500 Iteration: 2233 Training loss: 0.09834\n",
      "Epoch: 447/500 Iteration: 2234 Training loss: 0.07943\n",
      "Epoch: 446/500 Iteration: 2235 Validation Acc: 0.6000\n",
      "Epoch: 448/500 Iteration: 2235 Training loss: 0.59246\n",
      "Epoch: 448/500 Iteration: 2236 Training loss: 0.32456\n",
      "Epoch: 448/500 Iteration: 2237 Training loss: 0.17919\n",
      "Epoch: 448/500 Iteration: 2238 Training loss: 0.09949\n",
      "Epoch: 448/500 Iteration: 2239 Training loss: 0.07275\n",
      "Epoch: 447/500 Iteration: 2240 Validation Acc: 0.6600\n",
      "Epoch: 449/500 Iteration: 2240 Training loss: 0.63493\n",
      "Epoch: 449/500 Iteration: 2241 Training loss: 0.21237\n",
      "Epoch: 449/500 Iteration: 2242 Training loss: 0.14430\n",
      "Epoch: 449/500 Iteration: 2243 Training loss: 0.09510\n",
      "Epoch: 449/500 Iteration: 2244 Training loss: 0.08573\n",
      "Epoch: 448/500 Iteration: 2245 Validation Acc: 0.6333\n",
      "Epoch: 450/500 Iteration: 2245 Training loss: 0.46177\n",
      "Epoch: 450/500 Iteration: 2246 Training loss: 0.23601\n",
      "Epoch: 450/500 Iteration: 2247 Training loss: 0.15432\n",
      "Epoch: 450/500 Iteration: 2248 Training loss: 0.09125\n",
      "Epoch: 450/500 Iteration: 2249 Training loss: 0.07134\n",
      "Epoch: 449/500 Iteration: 2250 Validation Acc: 0.6333\n",
      "Epoch: 451/500 Iteration: 2250 Training loss: 0.62786\n",
      "Epoch: 451/500 Iteration: 2251 Training loss: 0.22613\n",
      "Epoch: 451/500 Iteration: 2252 Training loss: 0.13647\n",
      "Epoch: 451/500 Iteration: 2253 Training loss: 0.10455\n",
      "Epoch: 451/500 Iteration: 2254 Training loss: 0.07235\n",
      "Epoch: 450/500 Iteration: 2255 Validation Acc: 0.6333\n",
      "Epoch: 452/500 Iteration: 2255 Training loss: 0.59339\n",
      "Epoch: 452/500 Iteration: 2256 Training loss: 0.27050\n",
      "Epoch: 452/500 Iteration: 2257 Training loss: 0.16742\n",
      "Epoch: 452/500 Iteration: 2258 Training loss: 0.09633\n",
      "Epoch: 452/500 Iteration: 2259 Training loss: 0.06092\n",
      "Epoch: 451/500 Iteration: 2260 Validation Acc: 0.6733\n",
      "Epoch: 453/500 Iteration: 2260 Training loss: 0.67122\n",
      "Epoch: 453/500 Iteration: 2261 Training loss: 0.24082\n",
      "Epoch: 453/500 Iteration: 2262 Training loss: 0.14727\n",
      "Epoch: 453/500 Iteration: 2263 Training loss: 0.11500\n",
      "Epoch: 453/500 Iteration: 2264 Training loss: 0.07760\n",
      "Epoch: 452/500 Iteration: 2265 Validation Acc: 0.6333\n",
      "Epoch: 454/500 Iteration: 2265 Training loss: 0.53134\n",
      "Epoch: 454/500 Iteration: 2266 Training loss: 0.28745\n",
      "Epoch: 454/500 Iteration: 2267 Training loss: 0.15052\n",
      "Epoch: 454/500 Iteration: 2268 Training loss: 0.11170\n",
      "Epoch: 454/500 Iteration: 2269 Training loss: 0.07457\n",
      "Epoch: 453/500 Iteration: 2270 Validation Acc: 0.6200\n",
      "Epoch: 455/500 Iteration: 2270 Training loss: 0.52064\n",
      "Epoch: 455/500 Iteration: 2271 Training loss: 0.18862\n",
      "Epoch: 455/500 Iteration: 2272 Training loss: 0.11077\n",
      "Epoch: 455/500 Iteration: 2273 Training loss: 0.10334\n",
      "Epoch: 455/500 Iteration: 2274 Training loss: 0.07220\n",
      "Epoch: 454/500 Iteration: 2275 Validation Acc: 0.6400\n",
      "Epoch: 456/500 Iteration: 2275 Training loss: 0.49785\n",
      "Epoch: 456/500 Iteration: 2276 Training loss: 0.21903\n",
      "Epoch: 456/500 Iteration: 2277 Training loss: 0.14010\n",
      "Epoch: 456/500 Iteration: 2278 Training loss: 0.09595\n",
      "Epoch: 456/500 Iteration: 2279 Training loss: 0.07329\n",
      "Epoch: 455/500 Iteration: 2280 Validation Acc: 0.6333\n",
      "Epoch: 457/500 Iteration: 2280 Training loss: 0.54575\n",
      "Epoch: 457/500 Iteration: 2281 Training loss: 0.24295\n",
      "Epoch: 457/500 Iteration: 2282 Training loss: 0.13946\n",
      "Epoch: 457/500 Iteration: 2283 Training loss: 0.09440\n",
      "Epoch: 457/500 Iteration: 2284 Training loss: 0.06451\n",
      "Epoch: 456/500 Iteration: 2285 Validation Acc: 0.6000\n",
      "Epoch: 458/500 Iteration: 2285 Training loss: 0.63162\n",
      "Epoch: 458/500 Iteration: 2286 Training loss: 0.35921\n",
      "Epoch: 458/500 Iteration: 2287 Training loss: 0.18762\n",
      "Epoch: 458/500 Iteration: 2288 Training loss: 0.10731\n",
      "Epoch: 458/500 Iteration: 2289 Training loss: 0.08672\n",
      "Epoch: 457/500 Iteration: 2290 Validation Acc: 0.6667\n",
      "Epoch: 459/500 Iteration: 2290 Training loss: 0.60503\n",
      "Epoch: 459/500 Iteration: 2291 Training loss: 0.20752\n",
      "Epoch: 459/500 Iteration: 2292 Training loss: 0.13971\n",
      "Epoch: 459/500 Iteration: 2293 Training loss: 0.10293\n",
      "Epoch: 459/500 Iteration: 2294 Training loss: 0.08051\n",
      "Epoch: 458/500 Iteration: 2295 Validation Acc: 0.6267\n",
      "Epoch: 460/500 Iteration: 2295 Training loss: 0.55427\n",
      "Epoch: 460/500 Iteration: 2296 Training loss: 0.19857\n",
      "Epoch: 460/500 Iteration: 2297 Training loss: 0.11412\n",
      "Epoch: 460/500 Iteration: 2298 Training loss: 0.09743\n",
      "Epoch: 460/500 Iteration: 2299 Training loss: 0.07657\n",
      "Epoch: 459/500 Iteration: 2300 Validation Acc: 0.6533\n",
      "Epoch: 461/500 Iteration: 2300 Training loss: 0.45949\n",
      "Epoch: 461/500 Iteration: 2301 Training loss: 0.17670\n",
      "Epoch: 461/500 Iteration: 2302 Training loss: 0.13408\n",
      "Epoch: 461/500 Iteration: 2303 Training loss: 0.08232\n",
      "Epoch: 461/500 Iteration: 2304 Training loss: 0.05898\n",
      "Epoch: 460/500 Iteration: 2305 Validation Acc: 0.6400\n",
      "Epoch: 462/500 Iteration: 2305 Training loss: 0.73494\n",
      "Epoch: 462/500 Iteration: 2306 Training loss: 0.22683\n",
      "Epoch: 462/500 Iteration: 2307 Training loss: 0.11709\n",
      "Epoch: 462/500 Iteration: 2308 Training loss: 0.09459\n",
      "Epoch: 462/500 Iteration: 2309 Training loss: 0.06100\n",
      "Epoch: 461/500 Iteration: 2310 Validation Acc: 0.6533\n",
      "Epoch: 463/500 Iteration: 2310 Training loss: 0.65574\n",
      "Epoch: 463/500 Iteration: 2311 Training loss: 0.24325\n",
      "Epoch: 463/500 Iteration: 2312 Training loss: 0.18208\n",
      "Epoch: 463/500 Iteration: 2313 Training loss: 0.11291\n",
      "Epoch: 463/500 Iteration: 2314 Training loss: 0.09171\n",
      "Epoch: 462/500 Iteration: 2315 Validation Acc: 0.6533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 464/500 Iteration: 2315 Training loss: 0.44654\n",
      "Epoch: 464/500 Iteration: 2316 Training loss: 0.26304\n",
      "Epoch: 464/500 Iteration: 2317 Training loss: 0.13998\n",
      "Epoch: 464/500 Iteration: 2318 Training loss: 0.10036\n",
      "Epoch: 464/500 Iteration: 2319 Training loss: 0.07983\n",
      "Epoch: 463/500 Iteration: 2320 Validation Acc: 0.6867\n",
      "Epoch: 465/500 Iteration: 2320 Training loss: 0.42658\n",
      "Epoch: 465/500 Iteration: 2321 Training loss: 0.18742\n",
      "Epoch: 465/500 Iteration: 2322 Training loss: 0.11804\n",
      "Epoch: 465/500 Iteration: 2323 Training loss: 0.08645\n",
      "Epoch: 465/500 Iteration: 2324 Training loss: 0.06538\n",
      "Epoch: 464/500 Iteration: 2325 Validation Acc: 0.6400\n",
      "Epoch: 466/500 Iteration: 2325 Training loss: 0.48511\n",
      "Epoch: 466/500 Iteration: 2326 Training loss: 0.21710\n",
      "Epoch: 466/500 Iteration: 2327 Training loss: 0.13494\n",
      "Epoch: 466/500 Iteration: 2328 Training loss: 0.08045\n",
      "Epoch: 466/500 Iteration: 2329 Training loss: 0.07240\n",
      "Epoch: 465/500 Iteration: 2330 Validation Acc: 0.6467\n",
      "Epoch: 467/500 Iteration: 2330 Training loss: 0.47749\n",
      "Epoch: 467/500 Iteration: 2331 Training loss: 0.19094\n",
      "Epoch: 467/500 Iteration: 2332 Training loss: 0.11153\n",
      "Epoch: 467/500 Iteration: 2333 Training loss: 0.07614\n",
      "Epoch: 467/500 Iteration: 2334 Training loss: 0.06129\n",
      "Epoch: 466/500 Iteration: 2335 Validation Acc: 0.6600\n",
      "Epoch: 468/500 Iteration: 2335 Training loss: 0.95072\n",
      "Epoch: 468/500 Iteration: 2336 Training loss: 0.59538\n",
      "Epoch: 468/500 Iteration: 2337 Training loss: 0.39261\n",
      "Epoch: 468/500 Iteration: 2338 Training loss: 0.10882\n",
      "Epoch: 468/500 Iteration: 2339 Training loss: 0.07730\n",
      "Epoch: 467/500 Iteration: 2340 Validation Acc: 0.6267\n",
      "Epoch: 469/500 Iteration: 2340 Training loss: 0.76948\n",
      "Epoch: 469/500 Iteration: 2341 Training loss: 0.32811\n",
      "Epoch: 469/500 Iteration: 2342 Training loss: 0.16216\n",
      "Epoch: 469/500 Iteration: 2343 Training loss: 0.11978\n",
      "Epoch: 469/500 Iteration: 2344 Training loss: 0.09817\n",
      "Epoch: 468/500 Iteration: 2345 Validation Acc: 0.6133\n",
      "Epoch: 470/500 Iteration: 2345 Training loss: 0.44908\n",
      "Epoch: 470/500 Iteration: 2346 Training loss: 0.19314\n",
      "Epoch: 470/500 Iteration: 2347 Training loss: 0.10302\n",
      "Epoch: 470/500 Iteration: 2348 Training loss: 0.09393\n",
      "Epoch: 470/500 Iteration: 2349 Training loss: 0.07196\n",
      "Epoch: 469/500 Iteration: 2350 Validation Acc: 0.6667\n",
      "Epoch: 471/500 Iteration: 2350 Training loss: 0.53551\n",
      "Epoch: 471/500 Iteration: 2351 Training loss: 0.22417\n",
      "Epoch: 471/500 Iteration: 2352 Training loss: 0.12290\n",
      "Epoch: 471/500 Iteration: 2353 Training loss: 0.09999\n",
      "Epoch: 471/500 Iteration: 2354 Training loss: 0.07933\n",
      "Epoch: 470/500 Iteration: 2355 Validation Acc: 0.6533\n",
      "Epoch: 472/500 Iteration: 2355 Training loss: 0.43825\n",
      "Epoch: 472/500 Iteration: 2356 Training loss: 0.16563\n",
      "Epoch: 472/500 Iteration: 2357 Training loss: 0.09221\n",
      "Epoch: 472/500 Iteration: 2358 Training loss: 0.08738\n",
      "Epoch: 472/500 Iteration: 2359 Training loss: 0.06065\n",
      "Epoch: 471/500 Iteration: 2360 Validation Acc: 0.6133\n",
      "Epoch: 473/500 Iteration: 2360 Training loss: 0.50321\n",
      "Epoch: 473/500 Iteration: 2361 Training loss: 0.17381\n",
      "Epoch: 473/500 Iteration: 2362 Training loss: 0.11852\n",
      "Epoch: 473/500 Iteration: 2363 Training loss: 0.08127\n",
      "Epoch: 473/500 Iteration: 2364 Training loss: 0.06726\n",
      "Epoch: 472/500 Iteration: 2365 Validation Acc: 0.6133\n",
      "Epoch: 474/500 Iteration: 2365 Training loss: 0.61240\n",
      "Epoch: 474/500 Iteration: 2366 Training loss: 0.29548\n",
      "Epoch: 474/500 Iteration: 2367 Training loss: 0.13171\n",
      "Epoch: 474/500 Iteration: 2368 Training loss: 0.10231\n",
      "Epoch: 474/500 Iteration: 2369 Training loss: 0.07969\n",
      "Epoch: 473/500 Iteration: 2370 Validation Acc: 0.6333\n",
      "Epoch: 475/500 Iteration: 2370 Training loss: 0.52200\n",
      "Epoch: 475/500 Iteration: 2371 Training loss: 0.19047\n",
      "Epoch: 475/500 Iteration: 2372 Training loss: 0.12109\n",
      "Epoch: 475/500 Iteration: 2373 Training loss: 0.10162\n",
      "Epoch: 475/500 Iteration: 2374 Training loss: 0.07065\n",
      "Epoch: 474/500 Iteration: 2375 Validation Acc: 0.6267\n",
      "Epoch: 476/500 Iteration: 2375 Training loss: 0.41969\n",
      "Epoch: 476/500 Iteration: 2376 Training loss: 0.20164\n",
      "Epoch: 476/500 Iteration: 2377 Training loss: 0.13091\n",
      "Epoch: 476/500 Iteration: 2378 Training loss: 0.08759\n",
      "Epoch: 476/500 Iteration: 2379 Training loss: 0.05878\n",
      "Epoch: 475/500 Iteration: 2380 Validation Acc: 0.6267\n",
      "Epoch: 477/500 Iteration: 2380 Training loss: 0.55678\n",
      "Epoch: 477/500 Iteration: 2381 Training loss: 0.23573\n",
      "Epoch: 477/500 Iteration: 2382 Training loss: 0.16087\n",
      "Epoch: 477/500 Iteration: 2383 Training loss: 0.09216\n",
      "Epoch: 477/500 Iteration: 2384 Training loss: 0.06095\n",
      "Epoch: 476/500 Iteration: 2385 Validation Acc: 0.6667\n",
      "Epoch: 478/500 Iteration: 2385 Training loss: 0.70154\n",
      "Epoch: 478/500 Iteration: 2386 Training loss: 0.31252\n",
      "Epoch: 478/500 Iteration: 2387 Training loss: 0.13052\n",
      "Epoch: 478/500 Iteration: 2388 Training loss: 0.10187\n",
      "Epoch: 478/500 Iteration: 2389 Training loss: 0.06846\n",
      "Epoch: 477/500 Iteration: 2390 Validation Acc: 0.6600\n",
      "Epoch: 479/500 Iteration: 2390 Training loss: 0.55660\n",
      "Epoch: 479/500 Iteration: 2391 Training loss: 0.28522\n",
      "Epoch: 479/500 Iteration: 2392 Training loss: 0.14952\n",
      "Epoch: 479/500 Iteration: 2393 Training loss: 0.10101\n",
      "Epoch: 479/500 Iteration: 2394 Training loss: 0.08166\n",
      "Epoch: 478/500 Iteration: 2395 Validation Acc: 0.6200\n",
      "Epoch: 480/500 Iteration: 2395 Training loss: 0.55385\n",
      "Epoch: 480/500 Iteration: 2396 Training loss: 0.29339\n",
      "Epoch: 480/500 Iteration: 2397 Training loss: 0.14202\n",
      "Epoch: 480/500 Iteration: 2398 Training loss: 0.09460\n",
      "Epoch: 480/500 Iteration: 2399 Training loss: 0.06443\n",
      "Epoch: 479/500 Iteration: 2400 Validation Acc: 0.7000\n",
      "Epoch: 481/500 Iteration: 2400 Training loss: 0.53566\n",
      "Epoch: 481/500 Iteration: 2401 Training loss: 0.18983\n",
      "Epoch: 481/500 Iteration: 2402 Training loss: 0.11465\n",
      "Epoch: 481/500 Iteration: 2403 Training loss: 0.09836\n",
      "Epoch: 481/500 Iteration: 2404 Training loss: 0.06629\n",
      "Epoch: 480/500 Iteration: 2405 Validation Acc: 0.6667\n",
      "Epoch: 482/500 Iteration: 2405 Training loss: 0.51105\n",
      "Epoch: 482/500 Iteration: 2406 Training loss: 0.22101\n",
      "Epoch: 482/500 Iteration: 2407 Training loss: 0.12513\n",
      "Epoch: 482/500 Iteration: 2408 Training loss: 0.08108\n",
      "Epoch: 482/500 Iteration: 2409 Training loss: 0.05945\n",
      "Epoch: 481/500 Iteration: 2410 Validation Acc: 0.6400\n",
      "Epoch: 483/500 Iteration: 2410 Training loss: 0.50433\n",
      "Epoch: 483/500 Iteration: 2411 Training loss: 0.19071\n",
      "Epoch: 483/500 Iteration: 2412 Training loss: 0.20357\n",
      "Epoch: 483/500 Iteration: 2413 Training loss: 0.09005\n",
      "Epoch: 483/500 Iteration: 2414 Training loss: 0.06568\n",
      "Epoch: 482/500 Iteration: 2415 Validation Acc: 0.6400\n",
      "Epoch: 484/500 Iteration: 2415 Training loss: 0.57332\n",
      "Epoch: 484/500 Iteration: 2416 Training loss: 0.22741\n",
      "Epoch: 484/500 Iteration: 2417 Training loss: 0.11000\n",
      "Epoch: 484/500 Iteration: 2418 Training loss: 0.09226\n",
      "Epoch: 484/500 Iteration: 2419 Training loss: 0.07328\n",
      "Epoch: 483/500 Iteration: 2420 Validation Acc: 0.6267\n",
      "Epoch: 485/500 Iteration: 2420 Training loss: 0.41645\n",
      "Epoch: 485/500 Iteration: 2421 Training loss: 0.16866\n",
      "Epoch: 485/500 Iteration: 2422 Training loss: 0.11072\n",
      "Epoch: 485/500 Iteration: 2423 Training loss: 0.08640\n",
      "Epoch: 485/500 Iteration: 2424 Training loss: 0.05604\n",
      "Epoch: 484/500 Iteration: 2425 Validation Acc: 0.6133\n",
      "Epoch: 486/500 Iteration: 2425 Training loss: 0.64302\n",
      "Epoch: 486/500 Iteration: 2426 Training loss: 0.20185\n",
      "Epoch: 486/500 Iteration: 2427 Training loss: 0.12072\n",
      "Epoch: 486/500 Iteration: 2428 Training loss: 0.09703\n",
      "Epoch: 486/500 Iteration: 2429 Training loss: 0.06543\n",
      "Epoch: 485/500 Iteration: 2430 Validation Acc: 0.6867\n",
      "Epoch: 487/500 Iteration: 2430 Training loss: 0.77911\n",
      "Epoch: 487/500 Iteration: 2431 Training loss: 0.40909\n",
      "Epoch: 487/500 Iteration: 2432 Training loss: 0.27561\n",
      "Epoch: 487/500 Iteration: 2433 Training loss: 0.11919\n",
      "Epoch: 487/500 Iteration: 2434 Training loss: 0.08482\n",
      "Epoch: 486/500 Iteration: 2435 Validation Acc: 0.6400\n",
      "Epoch: 488/500 Iteration: 2435 Training loss: 0.48566\n",
      "Epoch: 488/500 Iteration: 2436 Training loss: 0.18547\n",
      "Epoch: 488/500 Iteration: 2437 Training loss: 0.11982\n",
      "Epoch: 488/500 Iteration: 2438 Training loss: 0.10656\n",
      "Epoch: 488/500 Iteration: 2439 Training loss: 0.06939\n",
      "Epoch: 487/500 Iteration: 2440 Validation Acc: 0.6667\n",
      "Epoch: 489/500 Iteration: 2440 Training loss: 0.47487\n",
      "Epoch: 489/500 Iteration: 2441 Training loss: 0.21035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 489/500 Iteration: 2442 Training loss: 0.11089\n",
      "Epoch: 489/500 Iteration: 2443 Training loss: 0.08776\n",
      "Epoch: 489/500 Iteration: 2444 Training loss: 0.06800\n",
      "Epoch: 488/500 Iteration: 2445 Validation Acc: 0.6133\n",
      "Epoch: 490/500 Iteration: 2445 Training loss: 0.38632\n",
      "Epoch: 490/500 Iteration: 2446 Training loss: 0.19297\n",
      "Epoch: 490/500 Iteration: 2447 Training loss: 0.13960\n",
      "Epoch: 490/500 Iteration: 2448 Training loss: 0.07962\n",
      "Epoch: 490/500 Iteration: 2449 Training loss: 0.06957\n",
      "Epoch: 489/500 Iteration: 2450 Validation Acc: 0.6400\n",
      "Epoch: 491/500 Iteration: 2450 Training loss: 0.42705\n",
      "Epoch: 491/500 Iteration: 2451 Training loss: 0.14004\n",
      "Epoch: 491/500 Iteration: 2452 Training loss: 0.10751\n",
      "Epoch: 491/500 Iteration: 2453 Training loss: 0.07806\n",
      "Epoch: 491/500 Iteration: 2454 Training loss: 0.05049\n",
      "Epoch: 490/500 Iteration: 2455 Validation Acc: 0.6667\n",
      "Epoch: 492/500 Iteration: 2455 Training loss: 0.61922\n",
      "Epoch: 492/500 Iteration: 2456 Training loss: 0.22393\n",
      "Epoch: 492/500 Iteration: 2457 Training loss: 0.15774\n",
      "Epoch: 492/500 Iteration: 2458 Training loss: 0.08861\n",
      "Epoch: 492/500 Iteration: 2459 Training loss: 0.06597\n",
      "Epoch: 491/500 Iteration: 2460 Validation Acc: 0.6400\n",
      "Epoch: 493/500 Iteration: 2460 Training loss: 0.71826\n",
      "Epoch: 493/500 Iteration: 2461 Training loss: 0.26712\n",
      "Epoch: 493/500 Iteration: 2462 Training loss: 0.13461\n",
      "Epoch: 493/500 Iteration: 2463 Training loss: 0.10715\n",
      "Epoch: 493/500 Iteration: 2464 Training loss: 0.07227\n",
      "Epoch: 492/500 Iteration: 2465 Validation Acc: 0.6333\n",
      "Epoch: 494/500 Iteration: 2465 Training loss: 0.86815\n",
      "Epoch: 494/500 Iteration: 2466 Training loss: 0.26018\n",
      "Epoch: 494/500 Iteration: 2467 Training loss: 0.17012\n",
      "Epoch: 494/500 Iteration: 2468 Training loss: 0.13284\n",
      "Epoch: 494/500 Iteration: 2469 Training loss: 0.10321\n",
      "Epoch: 493/500 Iteration: 2470 Validation Acc: 0.6333\n",
      "Epoch: 495/500 Iteration: 2470 Training loss: 0.46330\n",
      "Epoch: 495/500 Iteration: 2471 Training loss: 0.40394\n",
      "Epoch: 495/500 Iteration: 2472 Training loss: 0.18920\n",
      "Epoch: 495/500 Iteration: 2473 Training loss: 0.11041\n",
      "Epoch: 495/500 Iteration: 2474 Training loss: 0.08526\n",
      "Epoch: 494/500 Iteration: 2475 Validation Acc: 0.6067\n",
      "Epoch: 496/500 Iteration: 2475 Training loss: 0.43983\n",
      "Epoch: 496/500 Iteration: 2476 Training loss: 0.21572\n",
      "Epoch: 496/500 Iteration: 2477 Training loss: 0.11704\n",
      "Epoch: 496/500 Iteration: 2478 Training loss: 0.09305\n",
      "Epoch: 496/500 Iteration: 2479 Training loss: 0.07051\n",
      "Epoch: 495/500 Iteration: 2480 Validation Acc: 0.6400\n",
      "Epoch: 497/500 Iteration: 2480 Training loss: 0.41411\n",
      "Epoch: 497/500 Iteration: 2481 Training loss: 0.17524\n",
      "Epoch: 497/500 Iteration: 2482 Training loss: 0.11480\n",
      "Epoch: 497/500 Iteration: 2483 Training loss: 0.09121\n",
      "Epoch: 497/500 Iteration: 2484 Training loss: 0.06160\n",
      "Epoch: 496/500 Iteration: 2485 Validation Acc: 0.6267\n",
      "Epoch: 498/500 Iteration: 2485 Training loss: 0.49390\n",
      "Epoch: 498/500 Iteration: 2486 Training loss: 0.17696\n",
      "Epoch: 498/500 Iteration: 2487 Training loss: 0.12156\n",
      "Epoch: 498/500 Iteration: 2488 Training loss: 0.08322\n",
      "Epoch: 498/500 Iteration: 2489 Training loss: 0.06824\n",
      "Epoch: 497/500 Iteration: 2490 Validation Acc: 0.6600\n",
      "Epoch: 499/500 Iteration: 2490 Training loss: 0.52649\n",
      "Epoch: 499/500 Iteration: 2491 Training loss: 0.45819\n",
      "Epoch: 499/500 Iteration: 2492 Training loss: 0.23483\n",
      "Epoch: 499/500 Iteration: 2493 Training loss: 0.11754\n",
      "Epoch: 499/500 Iteration: 2494 Training loss: 0.08898\n",
      "Epoch: 498/500 Iteration: 2495 Validation Acc: 0.6000\n",
      "Epoch: 500/500 Iteration: 2495 Training loss: 0.56217\n",
      "Epoch: 500/500 Iteration: 2496 Training loss: 0.23352\n",
      "Epoch: 500/500 Iteration: 2497 Training loss: 0.11790\n",
      "Epoch: 500/500 Iteration: 2498 Training loss: 0.10333\n",
      "Epoch: 500/500 Iteration: 2499 Training loss: 0.06045\n",
      "Epoch: 499/500 Iteration: 2500 Validation Acc: 0.6667\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "\n",
    "epochs = 200\n",
    "iteration = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y, n_batches=5):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x, labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    saver.save(sess, \"checkpoints/skin_diseases.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/skin_diseases.ckpt\n",
      "Test accuracy: 0.6683\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/skin_diseases.ckpt\n",
      "/Users/junji/Development/udacity-deeplearning/dermatologist-ai/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junji/miniconda3/envs/dermatologist-ai/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/melanoma/ISIC_0012258.jpg 0.00361936 0.000269527\n",
      "data/test/melanoma/ISIC_0012356.jpg 0.0923471 0.000624971\n",
      "data/test/melanoma/ISIC_0012369.jpg 0.000113873 1.0719e-11\n",
      "data/test/melanoma/ISIC_0012395.jpg 6.12498e-06 0.999994\n",
      "data/test/melanoma/ISIC_0012425.jpg 8.47347e-15 1.39262e-14\n",
      "data/test/melanoma/ISIC_0012758.jpg 9.33658e-15 0.0\n",
      "data/test/melanoma/ISIC_0012989.jpg 0.999901 9.90492e-05\n",
      "data/test/melanoma/ISIC_0013072.jpg 0.999772 3.892e-08\n",
      "data/test/melanoma/ISIC_0013073.jpg 0.930656 4.90784e-06\n",
      "data/test/melanoma/ISIC_0013242.jpg 1.13367e-08 2.48399e-09\n",
      "data/test/melanoma/ISIC_0013277.jpg 0.579325 0.299182\n",
      "data/test/melanoma/ISIC_0013321.jpg 9.61952e-15 1.0\n",
      "data/test/melanoma/ISIC_0013374.jpg 0.999034 6.12571e-13\n",
      "data/test/melanoma/ISIC_0013411.jpg 1.92135e-14 8.51128e-14\n",
      "data/test/melanoma/ISIC_0013414.jpg 2.21044e-23 2.51126e-30\n",
      "data/test/melanoma/ISIC_0013455.jpg 7.87752e-07 2.05998e-29\n",
      "data/test/melanoma/ISIC_0013457.jpg 0.790798 0.2092\n",
      "data/test/melanoma/ISIC_0013459.jpg 0.959632 0.0240819\n",
      "data/test/melanoma/ISIC_0013472.jpg 0.0758467 2.31355e-14\n",
      "data/test/melanoma/ISIC_0013473.jpg 9.97801e-17 1.0\n",
      "data: test, class: melanoma, 20 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013565.jpg 0.341474 0.277711\n",
      "data/test/melanoma/ISIC_0013577.jpg 0.00180522 0.998195\n",
      "data/test/melanoma/ISIC_0013588.jpg 0.0109773 0.989023\n",
      "data/test/melanoma/ISIC_0013615.jpg 2.5636e-05 0.998114\n",
      "data/test/melanoma/ISIC_0013617.jpg 0.297647 0.162854\n",
      "data/test/melanoma/ISIC_0013636.jpg 4.03218e-07 8.91121e-28\n",
      "data/test/melanoma/ISIC_0013678.jpg 4.99492e-21 1.0\n",
      "data/test/melanoma/ISIC_0013696.jpg 0.949859 0.0436679\n",
      "data/test/melanoma/ISIC_0013733.jpg 8.88544e-15 0.0\n",
      "data/test/melanoma/ISIC_0013739.jpg 7.20311e-24 1.0\n",
      "data/test/melanoma/ISIC_0013766.jpg 0.000632969 8.23633e-22\n",
      "data/test/melanoma/ISIC_0013767.jpg 3.27982e-07 2.88844e-07\n",
      "data/test/melanoma/ISIC_0013813.jpg 0.41563 0.58437\n",
      "data/test/melanoma/ISIC_0013814.jpg 0.999743 0.000257085\n",
      "data/test/melanoma/ISIC_0013833.jpg 0.0712839 0.436869\n",
      "data/test/melanoma/ISIC_0013842.jpg 1.17579e-14 4.46518e-12\n",
      "data/test/melanoma/ISIC_0013867.jpg 0.20587 0.00201519\n",
      "data/test/melanoma/ISIC_0013908.jpg 5.41775e-11 1.0\n",
      "data/test/melanoma/ISIC_0013917.jpg 0.118785 1.64204e-12\n",
      "data/test/melanoma/ISIC_0013925.jpg 1.19788e-05 0.999988\n",
      "data: test, class: melanoma, 40 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0013948.jpg 4.70556e-09 3.23226e-05\n",
      "data/test/melanoma/ISIC_0013953.jpg 0.00366868 0.0518468\n",
      "data/test/melanoma/ISIC_0013987.jpg 0.890704 0.091736\n",
      "data/test/melanoma/ISIC_0013988.jpg 0.00280359 0.997196\n",
      "data/test/melanoma/ISIC_0014027.jpg 3.60962e-07 0.854834\n",
      "data/test/melanoma/ISIC_0014059.jpg 5.4336e-07 5.36021e-18\n",
      "data/test/melanoma/ISIC_0014077.jpg 0.966576 0.00111791\n",
      "data/test/melanoma/ISIC_0014103.jpg 5.46794e-23 2.14154e-38\n",
      "data/test/melanoma/ISIC_0014110.jpg 0.207719 0.000324451\n",
      "data/test/melanoma/ISIC_0014129.jpg 0.00593192 7.95351e-06\n",
      "data/test/melanoma/ISIC_0014148.jpg 0.996279 0.00260401\n",
      "data/test/melanoma/ISIC_0014160.jpg 0.0921674 1.62447e-13\n",
      "data/test/melanoma/ISIC_0014181.jpg 1.91614e-09 1.0\n",
      "data/test/melanoma/ISIC_0014186.jpg 2.99957e-06 0.0284704\n",
      "data/test/melanoma/ISIC_0014219.jpg 3.92285e-05 2.69289e-15\n",
      "data/test/melanoma/ISIC_0014221.jpg 2.73178e-10 5.79022e-34\n",
      "data/test/melanoma/ISIC_0014233.jpg 7.47497e-08 0.999991\n",
      "data/test/melanoma/ISIC_0014255.jpg 2.2409e-13 0.0\n",
      "data/test/melanoma/ISIC_0014270.jpg 0.511239 0.000915046\n",
      "data/test/melanoma/ISIC_0014284.jpg 0.00033573 1.2917e-07\n",
      "data: test, class: melanoma, 60 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014288.jpg 0.988141 0.00976867\n",
      "data/test/melanoma/ISIC_0014319.jpg 0.736424 0.00944978\n",
      "data/test/melanoma/ISIC_0014336.jpg 0.855901 0.141371\n",
      "data/test/melanoma/ISIC_0014349.jpg 0.78353 0.194206\n",
      "data/test/melanoma/ISIC_0014369.jpg 0.00890536 1.46003e-09\n",
      "data/test/melanoma/ISIC_0014423.jpg 0.0179015 0.173781\n",
      "data/test/melanoma/ISIC_0014434.jpg 9.76049e-10 0.999818\n",
      "data/test/melanoma/ISIC_0014454.jpg 0.531751 1.3181e-10\n",
      "data/test/melanoma/ISIC_0014478.jpg 4.29187e-05 8.48196e-16\n",
      "data/test/melanoma/ISIC_0014489.jpg 0.998613 3.76884e-06\n",
      "data/test/melanoma/ISIC_0014506.jpg 0.982126 0.0177619\n",
      "data/test/melanoma/ISIC_0014513.jpg 0.135999 0.229961\n",
      "data/test/melanoma/ISIC_0014541.jpg 0.00308444 6.33949e-24\n",
      "data/test/melanoma/ISIC_0014542.jpg 6.12387e-16 8.99665e-13\n",
      "data/test/melanoma/ISIC_0014546.jpg 0.303104 0.061855\n",
      "data/test/melanoma/ISIC_0014548.jpg 0.0121579 1.38631e-20\n",
      "data/test/melanoma/ISIC_0014559.jpg 0.175594 4.10478e-06\n",
      "data/test/melanoma/ISIC_0014663.jpg 0.968085 0.027145\n",
      "data/test/melanoma/ISIC_0014666.jpg 0.00218503 0.0853902\n",
      "data/test/melanoma/ISIC_0014695.jpg 0.00569885 0.584733\n",
      "data: test, class: melanoma, 80 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0014703.jpg 0.213234 8.42661e-10\n",
      "data/test/melanoma/ISIC_0014727.jpg 1.2541e-12 4.51421e-36\n",
      "data/test/melanoma/ISIC_0014766.jpg 0.261559 0.330813\n",
      "data/test/melanoma/ISIC_0014772.jpg 0.969178 7.34938e-07\n",
      "data/test/melanoma/ISIC_0014784.jpg 1.73533e-07 0.34514\n",
      "data/test/melanoma/ISIC_0014790.jpg 1.69733e-08 1.5989e-17\n",
      "data/test/melanoma/ISIC_0014800.jpg 0.0010278 6.93031e-13\n",
      "data/test/melanoma/ISIC_0014826.jpg 0.0343036 1.86392e-26\n",
      "data/test/melanoma/ISIC_0014862.jpg 6.35031e-05 4.70795e-09\n",
      "data/test/melanoma/ISIC_0014872.jpg 8.77178e-10 0.742682\n",
      "data/test/melanoma/ISIC_0014883.jpg 3.50407e-18 0.0\n",
      "data/test/melanoma/ISIC_0014912.jpg 0.0350768 3.56862e-06\n",
      "data/test/melanoma/ISIC_0014928.jpg 2.61388e-12 6.157e-37\n",
      "data/test/melanoma/ISIC_0014932.jpg 0.0252275 1.22578e-10\n",
      "data/test/melanoma/ISIC_0014963.jpg 1.0 1.49191e-30\n",
      "data/test/melanoma/ISIC_0014982.jpg 0.30851 0.00387064\n",
      "data/test/melanoma/ISIC_0015004.jpg 0.000510524 3.24612e-09\n",
      "data/test/melanoma/ISIC_0015041.jpg 1.0 0.0\n",
      "data/test/melanoma/ISIC_0015046.jpg 8.27425e-12 0.999754\n",
      "data/test/melanoma/ISIC_0015050.jpg 0.536424 0.371417\n",
      "data: test, class: melanoma, 100 / 117 images processed.\n",
      "data/test/melanoma/ISIC_0015071.jpg 1.0 1.50135e-34\n",
      "data/test/melanoma/ISIC_0015115.jpg 0.000947153 8.60627e-16\n",
      "data/test/melanoma/ISIC_0015119.jpg 1.0 3.382e-08\n",
      "data/test/melanoma/ISIC_0015127.jpg 0.999991 6.12662e-23\n",
      "data/test/melanoma/ISIC_0015132.jpg 0.0213716 2.07412e-12\n",
      "data/test/melanoma/ISIC_0015133.jpg 0.995933 4.61037e-10\n",
      "data/test/melanoma/ISIC_0015136.jpg 0.314282 5.5989e-09\n",
      "data/test/melanoma/ISIC_0015142.jpg 0.999998 1.49467e-06\n",
      "data/test/melanoma/ISIC_0015156.jpg 1.0 4.39338e-11\n",
      "data/test/melanoma/ISIC_0015163.jpg 0.00020781 1.65226e-12\n",
      "data/test/melanoma/ISIC_0015167.jpg 1.98216e-16 1.0\n",
      "data/test/melanoma/ISIC_0015180.jpg 7.24485e-06 0.986713\n",
      "data/test/melanoma/ISIC_0015185.jpg 7.99401e-05 2.01713e-22\n",
      "data/test/melanoma/ISIC_0015193.jpg 0.00272386 1.88061e-07\n",
      "data/test/melanoma/ISIC_0015206.jpg 1.0 0.0\n",
      "data/test/melanoma/ISIC_0015229.jpg 0.850757 0.149243\n",
      "data/test/melanoma/ISIC_0015251.jpg 0.999631 6.19783e-23\n",
      "data: test, class: melanoma, 117 / 117 images processed.\n",
      "data/test/nevus/ISIC_0012092.jpg 0.918492 8.10058e-07\n",
      "data/test/nevus/ISIC_0012095.jpg 1.74326e-14 0.0\n",
      "data/test/nevus/ISIC_0012147.jpg 4.11349e-16 5.22052e-12\n",
      "data/test/nevus/ISIC_0012149.jpg 7.85134e-09 6.12101e-07\n",
      "data/test/nevus/ISIC_0012152.jpg 4.85805e-13 0.999996\n",
      "data/test/nevus/ISIC_0012216.jpg 0.0190369 3.94439e-08\n",
      "data/test/nevus/ISIC_0012357.jpg 0.245283 0.0514012\n",
      "data/test/nevus/ISIC_0012484.jpg 0.239212 0.407631\n",
      "data/test/nevus/ISIC_0012493.jpg 1.486e-36 0.0\n",
      "data/test/nevus/ISIC_0012551.jpg 1.56041e-15 5.26702e-38\n",
      "data/test/nevus/ISIC_0012654.jpg 2.00744e-05 3.29793e-20\n",
      "data/test/nevus/ISIC_0012656.jpg 7.97228e-14 0.0\n",
      "data/test/nevus/ISIC_0012708.jpg 2.22146e-09 1.6157e-23\n",
      "data/test/nevus/ISIC_0012722.jpg 1.10828e-29 1.23128e-33\n",
      "data/test/nevus/ISIC_0012803.jpg 0.194829 3.03301e-08\n",
      "data/test/nevus/ISIC_0012836.jpg 6.61765e-07 2.17384e-28\n",
      "data/test/nevus/ISIC_0012837.jpg 0.030669 0.964617\n",
      "data/test/nevus/ISIC_0012903.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0012904.jpg 1.68679e-24 0.0\n",
      "data/test/nevus/ISIC_0012941.jpg 0.0 0.0\n",
      "data: test, class: nevus, 20 / 393 images processed.\n",
      "data/test/nevus/ISIC_0012967.jpg 1.89294e-17 0.0\n",
      "data/test/nevus/ISIC_0013045.jpg 0.00175993 5.00692e-16\n",
      "data/test/nevus/ISIC_0013070.jpg 9.37396e-11 1.66648e-22\n",
      "data/test/nevus/ISIC_0013109.jpg 1.36571e-12 1.05907e-06\n",
      "data/test/nevus/ISIC_0013159.jpg 0.210181 0.00023897\n",
      "data/test/nevus/ISIC_0013164.jpg 6.00581e-17 9.76555e-18\n",
      "data/test/nevus/ISIC_0013176.jpg 1.44874e-06 1.16182e-16\n",
      "data/test/nevus/ISIC_0013191.jpg 6.2833e-17 0.000161423\n",
      "data/test/nevus/ISIC_0013216.jpg 1.20112e-07 6.92821e-05\n",
      "data/test/nevus/ISIC_0013226.jpg 4.67591e-29 0.0\n",
      "data/test/nevus/ISIC_0013230.jpg 4.13487e-08 7.2613e-09\n",
      "data/test/nevus/ISIC_0013269.jpg 0.959756 0.00144224\n",
      "data/test/nevus/ISIC_0013291.jpg 1.23186e-06 1.02679e-17\n",
      "data/test/nevus/ISIC_0013325.jpg 7.64641e-08 5.52972e-35\n",
      "data/test/nevus/ISIC_0013399.jpg 3.14474e-33 0.0\n",
      "data/test/nevus/ISIC_0013416.jpg 1.21225e-16 0.0\n",
      "data/test/nevus/ISIC_0013511.jpg 0.00105983 0.718578\n",
      "data/test/nevus/ISIC_0013512.jpg 2.64769e-22 0.0\n",
      "data/test/nevus/ISIC_0013529.jpg 0.000491501 8.50911e-14\n",
      "data/test/nevus/ISIC_0013600.jpg 1.23274e-06 3.70393e-26\n",
      "data: test, class: nevus, 40 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0013602.jpg 0.26213 6.8468e-35\n",
      "data/test/nevus/ISIC_0013738.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0013794.jpg 2.48409e-31 0.0\n",
      "data/test/nevus/ISIC_0013809.jpg 0.417699 2.21799e-05\n",
      "data/test/nevus/ISIC_0013891.jpg 0.256449 0.000503481\n",
      "data/test/nevus/ISIC_0013897.jpg 0.821308 0.00225695\n",
      "data/test/nevus/ISIC_0013911.jpg 4.46607e-15 1.0\n",
      "data/test/nevus/ISIC_0013966.jpg 1.56015e-05 4.12999e-13\n",
      "data/test/nevus/ISIC_0013998.jpg 1.85589e-11 1.20949e-14\n",
      "data/test/nevus/ISIC_0014090.jpg 2.99469e-21 7.29733e-34\n",
      "data/test/nevus/ISIC_0014117.jpg 0.00276094 2.01743e-08\n",
      "data/test/nevus/ISIC_0014470.jpg 1.50293e-14 0.999909\n",
      "data/test/nevus/ISIC_0014675.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014677.jpg 1.25407e-37 0.0\n",
      "data/test/nevus/ISIC_0014687.jpg 0.00448983 1.00596e-06\n",
      "data/test/nevus/ISIC_0014693.jpg 1.0 1.13948e-09\n",
      "data/test/nevus/ISIC_0014697.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014698.jpg 3.28989e-20 0.0\n",
      "data/test/nevus/ISIC_0014720.jpg 1.36765e-05 4.39687e-15\n",
      "data/test/nevus/ISIC_0014725.jpg 5.15459e-05 8.50491e-20\n",
      "data: test, class: nevus, 60 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014728.jpg 8.92527e-08 5.46272e-26\n",
      "data/test/nevus/ISIC_0014729.jpg 0.432568 0.567338\n",
      "data/test/nevus/ISIC_0014740.jpg 1.0 4.48683e-10\n",
      "data/test/nevus/ISIC_0014743.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014746.jpg 2.12358e-06 0.000598688\n",
      "data/test/nevus/ISIC_0014749.jpg 0.00688409 1.9871e-12\n",
      "data/test/nevus/ISIC_0014753.jpg 7.9629e-06 1.10949e-12\n",
      "data/test/nevus/ISIC_0014755.jpg 3.08908e-06 1.77742e-13\n",
      "data/test/nevus/ISIC_0014765.jpg 4.65517e-18 0.0\n",
      "data/test/nevus/ISIC_0014768.jpg 4.10424e-17 0.0\n",
      "data/test/nevus/ISIC_0014773.jpg 0.126618 3.03134e-10\n",
      "data/test/nevus/ISIC_0014780.jpg 4.13487e-10 0.0\n",
      "data/test/nevus/ISIC_0014786.jpg 0.153513 0.00340046\n",
      "data/test/nevus/ISIC_0014787.jpg 0.000101664 7.52574e-14\n",
      "data/test/nevus/ISIC_0014792.jpg 5.90058e-15 2.8406e-28\n",
      "data/test/nevus/ISIC_0014796.jpg 2.71069e-11 0.0\n",
      "data/test/nevus/ISIC_0014798.jpg 3.18473e-14 0.0\n",
      "data/test/nevus/ISIC_0014807.jpg 1.42231e-18 0.0\n",
      "data/test/nevus/ISIC_0014814.jpg 1.23557e-11 8.73591e-22\n",
      "data/test/nevus/ISIC_0014815.jpg 0.000695541 2.75429e-16\n",
      "data: test, class: nevus, 80 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014820.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014822.jpg 3.20029e-10 9.72474e-16\n",
      "data/test/nevus/ISIC_0014833.jpg 0.0265393 4.02627e-14\n",
      "data/test/nevus/ISIC_0014835.jpg 1.2223e-13 0.0\n",
      "data/test/nevus/ISIC_0014844.jpg 2.34839e-11 8.23331e-38\n",
      "data/test/nevus/ISIC_0014853.jpg 9.07921e-35 0.0\n",
      "data/test/nevus/ISIC_0014854.jpg 6.30084e-11 0.0\n",
      "data/test/nevus/ISIC_0014863.jpg 2.23539e-09 3.17922e-11\n",
      "data/test/nevus/ISIC_0014867.jpg 2.81896e-22 0.0\n",
      "data/test/nevus/ISIC_0014868.jpg 3.48948e-08 0.999512\n",
      "data/test/nevus/ISIC_0014876.jpg 1.25556e-16 0.0\n",
      "data/test/nevus/ISIC_0014879.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014901.jpg 1.01709e-05 6.07404e-33\n",
      "data/test/nevus/ISIC_0014907.jpg 7.52943e-12 0.0\n",
      "data/test/nevus/ISIC_0014910.jpg 4.61151e-11 0.0\n",
      "data/test/nevus/ISIC_0014921.jpg 2.13853e-11 0.0\n",
      "data/test/nevus/ISIC_0014927.jpg 8.40953e-06 4.88031e-15\n",
      "data/test/nevus/ISIC_0014936.jpg 0.0140948 7.47649e-08\n",
      "data/test/nevus/ISIC_0014938.jpg 1.0 0.0\n",
      "data/test/nevus/ISIC_0014940.jpg 1.64242e-08 1.55016e-25\n",
      "data: test, class: nevus, 100 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014941.jpg 4.25319e-11 7.36011e-21\n",
      "data/test/nevus/ISIC_0014942.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014943.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014944.jpg 1.84486e-06 4.43352e-26\n",
      "data/test/nevus/ISIC_0014947.jpg 0.000631203 0.0\n",
      "data/test/nevus/ISIC_0014948.jpg 0.0371558 4.59912e-07\n",
      "data/test/nevus/ISIC_0014949.jpg 5.43682e-18 0.0\n",
      "data/test/nevus/ISIC_0014952.jpg 4.04987e-07 5.24149e-12\n",
      "data/test/nevus/ISIC_0014955.jpg 4.05948e-06 0.0\n",
      "data/test/nevus/ISIC_0014956.jpg 6.47379e-07 1.49433e-08\n",
      "data/test/nevus/ISIC_0014957.jpg 3.91602e-13 7.76351e-31\n",
      "data/test/nevus/ISIC_0014958.jpg 2.33656e-09 2.89804e-23\n",
      "data/test/nevus/ISIC_0014959.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0014961.jpg 2.98095e-06 2.78372e-27\n",
      "data/test/nevus/ISIC_0014962.jpg 4.2679e-22 3.99189e-24\n",
      "data/test/nevus/ISIC_0014964.jpg 1.25051e-05 2.46622e-14\n",
      "data/test/nevus/ISIC_0014966.jpg 4.99615e-06 8.58235e-35\n",
      "data/test/nevus/ISIC_0014968.jpg 8.40231e-05 2.86722e-29\n",
      "data/test/nevus/ISIC_0014969.jpg 3.48677e-36 0.0\n",
      "data/test/nevus/ISIC_0014973.jpg 2.37081e-08 5.52269e-26\n",
      "data: test, class: nevus, 120 / 393 images processed.\n",
      "data/test/nevus/ISIC_0014974.jpg 8.66767e-21 0.0\n",
      "data/test/nevus/ISIC_0014977.jpg 6.20776e-17 0.0\n",
      "data/test/nevus/ISIC_0014992.jpg 1.61362e-13 2.06914e-36\n",
      "data/test/nevus/ISIC_0014994.jpg 9.57958e-19 0.0\n",
      "data/test/nevus/ISIC_0014998.jpg 1.44118e-12 2.16858e-30\n",
      "data/test/nevus/ISIC_0015002.jpg 2.26712e-12 2.40291e-09\n",
      "data/test/nevus/ISIC_0015003.jpg 0.0208069 1.83393e-07\n",
      "data/test/nevus/ISIC_0015007.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015008.jpg 0.0 1.0\n",
      "data/test/nevus/ISIC_0015009.jpg 0.000114356 0.0182525\n",
      "data/test/nevus/ISIC_0015011.jpg 7.47788e-19 1.0\n",
      "data/test/nevus/ISIC_0015013.jpg 0.850273 0.010769\n",
      "data/test/nevus/ISIC_0015015.jpg 1.91436e-05 3.96501e-27\n",
      "data/test/nevus/ISIC_0015016.jpg 1.04743e-09 5.80288e-28\n",
      "data/test/nevus/ISIC_0015018.jpg 0.00063876 4.52799e-18\n",
      "data/test/nevus/ISIC_0015019.jpg 0.10123 7.66154e-05\n",
      "data/test/nevus/ISIC_0015020.jpg 0.127396 1.19363e-07\n",
      "data/test/nevus/ISIC_0015021.jpg 3.40551e-21 0.0\n",
      "data/test/nevus/ISIC_0015023.jpg 1.87738e-05 6.33649e-24\n",
      "data/test/nevus/ISIC_0015026.jpg 0.0 0.0\n",
      "data: test, class: nevus, 140 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015030.jpg 1.10361e-17 0.0\n",
      "data/test/nevus/ISIC_0015031.jpg 1.60077e-37 0.0\n",
      "data/test/nevus/ISIC_0015034.jpg 4.84218e-17 0.0\n",
      "data/test/nevus/ISIC_0015035.jpg 2.14953e-25 0.0\n",
      "data/test/nevus/ISIC_0015037.jpg 0.00011838 5.16899e-15\n",
      "data/test/nevus/ISIC_0015040.jpg 2.9259e-28 0.0\n",
      "data/test/nevus/ISIC_0015051.jpg 0.0422892 1.96347e-13\n",
      "data/test/nevus/ISIC_0015056.jpg 0.0404509 5.7776e-14\n",
      "data/test/nevus/ISIC_0015057.jpg 7.08301e-07 8.07586e-34\n",
      "data/test/nevus/ISIC_0015060.jpg 1.60939e-05 4.94734e-22\n",
      "data/test/nevus/ISIC_0015064.jpg 0.0121535 2.45782e-17\n",
      "data/test/nevus/ISIC_0015078.jpg 3.47057e-06 0.999985\n",
      "data/test/nevus/ISIC_0015089.jpg 2.09304e-21 0.0\n",
      "data/test/nevus/ISIC_0015102.jpg 1.13983e-30 0.999998\n",
      "data/test/nevus/ISIC_0015118.jpg 0.0249663 0.00923192\n",
      "data/test/nevus/ISIC_0015125.jpg 2.89208e-12 0.0\n",
      "data/test/nevus/ISIC_0015129.jpg 0.000170426 0.99983\n",
      "data/test/nevus/ISIC_0015130.jpg 1.0 1.51099e-08\n",
      "data/test/nevus/ISIC_0015139.jpg 1.67933e-06 0.0\n",
      "data/test/nevus/ISIC_0015140.jpg 0.0231863 2.90442e-13\n",
      "data: test, class: nevus, 160 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015146.jpg 1.98021e-37 0.0\n",
      "data/test/nevus/ISIC_0015149.jpg 0.152245 1.17197e-16\n",
      "data/test/nevus/ISIC_0015150.jpg 1.44706e-13 0.0\n",
      "data/test/nevus/ISIC_0015152.jpg 7.62872e-18 6.14667e-15\n",
      "data/test/nevus/ISIC_0015155.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015157.jpg 9.49198e-29 0.0\n",
      "data/test/nevus/ISIC_0015160.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015161.jpg 1.21184e-15 0.129277\n",
      "data/test/nevus/ISIC_0015171.jpg 1.16247e-06 4.8191e-05\n",
      "data/test/nevus/ISIC_0015173.jpg 0.0226123 0.00172219\n",
      "data/test/nevus/ISIC_0015174.jpg 0.129133 5.0433e-12\n",
      "data/test/nevus/ISIC_0015175.jpg 1.94243e-19 0.0\n",
      "data/test/nevus/ISIC_0015176.jpg 0.744093 0.22188\n",
      "data/test/nevus/ISIC_0015179.jpg 0.000415655 1.14541e-15\n",
      "data/test/nevus/ISIC_0015184.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015201.jpg 0.00107312 2.40643e-19\n",
      "data/test/nevus/ISIC_0015202.jpg 9.4095e-34 0.0\n",
      "data/test/nevus/ISIC_0015203.jpg 2.23946e-06 1.77291e-07\n",
      "data/test/nevus/ISIC_0015207.jpg 0.0848309 5.92614e-10\n",
      "data/test/nevus/ISIC_0015208.jpg 0.0893468 3.45774e-06\n",
      "data: test, class: nevus, 180 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015212.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015215.jpg 1.4469e-06 1.89688e-25\n",
      "data/test/nevus/ISIC_0015216.jpg 0.00338001 9.87158e-13\n",
      "data/test/nevus/ISIC_0015217.jpg 3.19772e-30 0.0\n",
      "data/test/nevus/ISIC_0015218.jpg 5.30755e-13 0.0\n",
      "data/test/nevus/ISIC_0015223.jpg 1.32999e-25 0.0\n",
      "data/test/nevus/ISIC_0015224.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015226.jpg 6.58973e-10 7.44874e-24\n",
      "data/test/nevus/ISIC_0015232.jpg 1.82806e-12 9.97424e-17\n",
      "data/test/nevus/ISIC_0015237.jpg 0.999987 1.27612e-05\n",
      "data/test/nevus/ISIC_0015241.jpg 3.61539e-21 0.0\n",
      "data/test/nevus/ISIC_0015244.jpg 0.0474377 1.47368e-14\n",
      "data/test/nevus/ISIC_0015245.jpg 1.88518e-11 1.45074e-11\n",
      "data/test/nevus/ISIC_0015250.jpg 0.151625 0.848367\n",
      "data/test/nevus/ISIC_0015254.jpg 0.186491 0.0498522\n",
      "data/test/nevus/ISIC_0015255.jpg 2.11977e-07 4.83288e-16\n",
      "data/test/nevus/ISIC_0015258.jpg 1.0 8.36851e-33\n",
      "data/test/nevus/ISIC_0015264.jpg 2.0937e-36 0.0\n",
      "data/test/nevus/ISIC_0015270.jpg 0.000451755 2.5278e-07\n",
      "data/test/nevus/ISIC_0015273.jpg 0.0 0.0\n",
      "data: test, class: nevus, 200 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0015274.jpg 0.123458 1.10607e-10\n",
      "data/test/nevus/ISIC_0015276.jpg 3.4326e-11 0.0\n",
      "data/test/nevus/ISIC_0015279.jpg 6.07124e-22 1.5614e-35\n",
      "data/test/nevus/ISIC_0015283.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015291.jpg 1.8002e-29 0.0\n",
      "data/test/nevus/ISIC_0015293.jpg 1.83167e-26 0.0\n",
      "data/test/nevus/ISIC_0015298.jpg 1.01447e-22 0.0\n",
      "data/test/nevus/ISIC_0015309.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015310.jpg 3.71594e-11 1.37066e-28\n",
      "data/test/nevus/ISIC_0015311.jpg 2.35275e-08 0.994787\n",
      "data/test/nevus/ISIC_0015312.jpg 0.106445 5.80767e-05\n",
      "data/test/nevus/ISIC_0015330.jpg 2.4146e-11 2.87893e-17\n",
      "data/test/nevus/ISIC_0015331.jpg 3.81116e-29 0.0\n",
      "data/test/nevus/ISIC_0015347.jpg 2.36268e-10 0.0\n",
      "data/test/nevus/ISIC_0015353.jpg 0.000283289 0.9995\n",
      "data/test/nevus/ISIC_0015355.jpg 1.15946e-16 4.84059e-33\n",
      "data/test/nevus/ISIC_0015357.jpg 8.61728e-24 0.0\n",
      "data/test/nevus/ISIC_0015360.jpg 3.20156e-09 0.0\n",
      "data/test/nevus/ISIC_0015363.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015364.jpg 1.97897e-18 1.43099e-16\n",
      "data: test, class: nevus, 220 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015368.jpg 0.27908 1.52983e-06\n",
      "data/test/nevus/ISIC_0015369.jpg 1.70377e-18 0.0\n",
      "data/test/nevus/ISIC_0015383.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015386.jpg 0.0513382 0.00483363\n",
      "data/test/nevus/ISIC_0015390.jpg 6.93796e-07 0.654064\n",
      "data/test/nevus/ISIC_0015395.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015403.jpg 0.267358 2.80414e-14\n",
      "data/test/nevus/ISIC_0015404.jpg 2.84635e-06 3.87793e-17\n",
      "data/test/nevus/ISIC_0015411.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015412.jpg 0.999974 2.89654e-34\n",
      "data/test/nevus/ISIC_0015416.jpg 0.0680417 2.9055e-05\n",
      "data/test/nevus/ISIC_0015417.jpg 2.77843e-06 3.99707e-34\n",
      "data/test/nevus/ISIC_0015418.jpg 4.97176e-32 0.0\n",
      "data/test/nevus/ISIC_0015419.jpg 0.000261903 0.000198904\n",
      "data/test/nevus/ISIC_0015436.jpg 1.09858e-08 0.0\n",
      "data/test/nevus/ISIC_0015440.jpg 3.73234e-31 0.0\n",
      "data/test/nevus/ISIC_0015447.jpg 1.28135e-07 9.73172e-22\n",
      "data/test/nevus/ISIC_0015455.jpg 0.121032 2.32522e-24\n",
      "data/test/nevus/ISIC_0015464.jpg 0.0014895 2.96746e-22\n",
      "data/test/nevus/ISIC_0015466.jpg 9.46624e-11 0.0\n",
      "data: test, class: nevus, 240 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015468.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015476.jpg 1.54269e-31 0.0\n",
      "data/test/nevus/ISIC_0015481.jpg 1.0 3.05848e-10\n",
      "data/test/nevus/ISIC_0015482.jpg 0.00465144 1.67392e-07\n",
      "data/test/nevus/ISIC_0015485.jpg 4.37233e-07 5.12942e-18\n",
      "data/test/nevus/ISIC_0015510.jpg 1.4084e-18 0.0\n",
      "data/test/nevus/ISIC_0015526.jpg 9.69963e-13 0.0\n",
      "data/test/nevus/ISIC_0015537.jpg 0.000982759 0.00143462\n",
      "data/test/nevus/ISIC_0015544.jpg 0.000181818 0.98613\n",
      "data/test/nevus/ISIC_0015559.jpg 0.0955179 1.95321e-08\n",
      "data/test/nevus/ISIC_0015563.jpg 4.02409e-19 0.0\n",
      "data/test/nevus/ISIC_0015566.jpg 1.71098e-15 0.0\n",
      "data/test/nevus/ISIC_0015568.jpg 0.00025166 1.31251e-16\n",
      "data/test/nevus/ISIC_0015582.jpg 1.87293e-31 0.0\n",
      "data/test/nevus/ISIC_0015593.jpg 1.30196e-22 1.01946e-23\n",
      "data/test/nevus/ISIC_0015603.jpg 7.25265e-05 7.65014e-18\n",
      "data/test/nevus/ISIC_0015607.jpg 3.60601e-08 0.999828\n",
      "data/test/nevus/ISIC_0015614.jpg 0.310603 0.232707\n",
      "data/test/nevus/ISIC_0015617.jpg 0.0559755 4.73673e-06\n",
      "data/test/nevus/ISIC_0015625.jpg 9.5253e-08 2.7295e-21\n",
      "data: test, class: nevus, 260 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015631.jpg 1.48679e-05 2.25101e-16\n",
      "data/test/nevus/ISIC_0015636.jpg 0.87995 0.0904837\n",
      "data/test/nevus/ISIC_0015638.jpg 2.62489e-36 0.0\n",
      "data/test/nevus/ISIC_0015641.jpg 7.17057e-12 1.5415e-17\n",
      "data/test/nevus/ISIC_0015645.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015936.jpg 5.0628e-07 3.94398e-34\n",
      "data/test/nevus/ISIC_0015937.jpg 6.55526e-08 2.63179e-28\n",
      "data/test/nevus/ISIC_0015938.jpg 3.63331e-18 0.0\n",
      "data/test/nevus/ISIC_0015939.jpg 0.796097 0.000119924\n",
      "data/test/nevus/ISIC_0015940.jpg 4.84197e-14 8.84499e-38\n",
      "data/test/nevus/ISIC_0015941.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015942.jpg 1.33696e-12 3.24028e-14\n",
      "data/test/nevus/ISIC_0015943.jpg 6.8585e-09 3.41129e-11\n",
      "data/test/nevus/ISIC_0015944.jpg 6.30479e-07 0.999999\n",
      "data/test/nevus/ISIC_0015945.jpg 1.10785e-08 3.27181e-17\n",
      "data/test/nevus/ISIC_0015946.jpg 1.38352e-06 2.59402e-30\n",
      "data/test/nevus/ISIC_0015947.jpg 0.000239826 1.45346e-14\n",
      "data/test/nevus/ISIC_0015948.jpg 1.1176e-21 0.0\n",
      "data/test/nevus/ISIC_0015949.jpg 6.02236e-06 2.89752e-10\n",
      "data/test/nevus/ISIC_0015950.jpg 0.00100804 5.86755e-07\n",
      "data: test, class: nevus, 280 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015951.jpg 1.05556e-08 3.25971e-20\n",
      "data/test/nevus/ISIC_0015952.jpg 0.00212128 7.32132e-06\n",
      "data/test/nevus/ISIC_0015953.jpg 3.43662e-12 0.775991\n",
      "data/test/nevus/ISIC_0015954.jpg 2.20985e-15 0.0\n",
      "data/test/nevus/ISIC_0015955.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015956.jpg 4.598e-27 0.0\n",
      "data/test/nevus/ISIC_0015957.jpg 1.2975e-09 1.0\n",
      "data/test/nevus/ISIC_0015958.jpg 1.71811e-13 0.999992\n",
      "data/test/nevus/ISIC_0015959.jpg 2.09485e-24 0.0\n",
      "data/test/nevus/ISIC_0015960.jpg 2.43191e-16 0.0\n",
      "data/test/nevus/ISIC_0015961.jpg 2.87181e-07 7.40427e-29\n",
      "data/test/nevus/ISIC_0015962.jpg 1.25103e-05 8.24693e-12\n",
      "data/test/nevus/ISIC_0015963.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0015964.jpg 1.59021e-20 0.0\n",
      "data/test/nevus/ISIC_0015965.jpg 5.72687e-06 9.84685e-18\n",
      "data/test/nevus/ISIC_0015966.jpg 1.37518e-21 6.58627e-22\n",
      "data/test/nevus/ISIC_0015967.jpg 0.000228869 1.06736e-05\n",
      "data/test/nevus/ISIC_0015968.jpg 0.990046 0.00925483\n",
      "data/test/nevus/ISIC_0015969.jpg 6.95941e-13 5.42556e-22\n",
      "data/test/nevus/ISIC_0015971.jpg 0.000444207 2.30459e-17\n",
      "data: test, class: nevus, 300 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015972.jpg 2.84787e-21 0.999998\n",
      "data/test/nevus/ISIC_0015973.jpg 4.31476e-21 0.0\n",
      "data/test/nevus/ISIC_0015974.jpg 6.11551e-10 5.29144e-07\n",
      "data/test/nevus/ISIC_0015975.jpg 1.56035e-08 9.53484e-35\n",
      "data/test/nevus/ISIC_0015976.jpg 7.35142e-12 0.0\n",
      "data/test/nevus/ISIC_0015978.jpg 8.65114e-14 8.05689e-18\n",
      "data/test/nevus/ISIC_0015979.jpg 3.23007e-18 1.0\n",
      "data/test/nevus/ISIC_0015980.jpg 6.4502e-17 0.0\n",
      "data/test/nevus/ISIC_0015981.jpg 0.256174 0.115799\n",
      "data/test/nevus/ISIC_0015982.jpg 3.86129e-08 2.62308e-07\n",
      "data/test/nevus/ISIC_0015983.jpg 1.12196e-11 4.71949e-07\n",
      "data/test/nevus/ISIC_0015984.jpg 8.55656e-23 0.969153\n",
      "data/test/nevus/ISIC_0015985.jpg 1.27678e-17 0.0\n",
      "data/test/nevus/ISIC_0015986.jpg 9.51552e-07 7.23025e-07\n",
      "data/test/nevus/ISIC_0015987.jpg 9.39956e-07 1.69565e-07\n",
      "data/test/nevus/ISIC_0015988.jpg 3.6004e-12 0.0\n",
      "data/test/nevus/ISIC_0015989.jpg 9.15289e-15 7.51166e-15\n",
      "data/test/nevus/ISIC_0015990.jpg 1.89726e-10 0.0\n",
      "data/test/nevus/ISIC_0015991.jpg 1.11719e-07 1.96263e-06\n",
      "data/test/nevus/ISIC_0015992.jpg 7.26028e-22 0.0\n",
      "data: test, class: nevus, 320 / 393 images processed.\n",
      "data/test/nevus/ISIC_0015993.jpg 0.149517 9.6419e-05\n",
      "data/test/nevus/ISIC_0015994.jpg 0.290102 0.212656\n",
      "data/test/nevus/ISIC_0015995.jpg 0.304796 0.000793508\n",
      "data/test/nevus/ISIC_0015996.jpg 0.00303448 1.35544e-20\n",
      "data/test/nevus/ISIC_0015997.jpg 5.58317e-10 5.87664e-36\n",
      "data/test/nevus/ISIC_0015998.jpg 4.07561e-05 8.83731e-24\n",
      "data/test/nevus/ISIC_0015999.jpg 0.00320006 3.4311e-16\n",
      "data/test/nevus/ISIC_0016000.jpg 8.14878e-08 0.574699\n",
      "data/test/nevus/ISIC_0016001.jpg 0.660197 9.47507e-10\n",
      "data/test/nevus/ISIC_0016002.jpg 4.34756e-07 2.66695e-12\n",
      "data/test/nevus/ISIC_0016003.jpg 1.30268e-22 0.0\n",
      "data/test/nevus/ISIC_0016004.jpg 4.93707e-06 1.9333e-32\n",
      "data/test/nevus/ISIC_0016005.jpg 3.73421e-23 1.54699e-17\n",
      "data/test/nevus/ISIC_0016006.jpg 2.83377e-36 1.0\n",
      "data/test/nevus/ISIC_0016007.jpg 0.00188475 1.74813e-16\n",
      "data/test/nevus/ISIC_0016008.jpg 0.831948 0.160589\n",
      "data/test/nevus/ISIC_0016009.jpg 4.9647e-28 0.0\n",
      "data/test/nevus/ISIC_0016011.jpg 9.37065e-31 4.3563e-09\n",
      "data/test/nevus/ISIC_0016012.jpg 8.31632e-17 0.0\n",
      "data/test/nevus/ISIC_0016013.jpg 2.09951e-12 0.108549\n",
      "data: test, class: nevus, 340 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016014.jpg 9.53132e-05 2.22658e-14\n",
      "data/test/nevus/ISIC_0016015.jpg 5.60307e-24 0.0\n",
      "data/test/nevus/ISIC_0016016.jpg 0.857419 0.142581\n",
      "data/test/nevus/ISIC_0016017.jpg 6.82591e-08 0.0\n",
      "data/test/nevus/ISIC_0016018.jpg 5.6166e-23 0.0\n",
      "data/test/nevus/ISIC_0016019.jpg 8.18869e-19 1.0\n",
      "data/test/nevus/ISIC_0016022.jpg 9.46854e-05 6.4859e-29\n",
      "data/test/nevus/ISIC_0016023.jpg 7.66828e-10 1.35075e-08\n",
      "data/test/nevus/ISIC_0016024.jpg 0.0178385 3.96461e-27\n",
      "data/test/nevus/ISIC_0016025.jpg 1.0 1.89667e-09\n",
      "data/test/nevus/ISIC_0016026.jpg 0.0222693 0.301514\n",
      "data/test/nevus/ISIC_0016027.jpg 0.00358755 0.0489146\n",
      "data/test/nevus/ISIC_0016028.jpg 9.73712e-34 1.69948e-34\n",
      "data/test/nevus/ISIC_0016029.jpg 4.99801e-27 0.0\n",
      "data/test/nevus/ISIC_0016030.jpg 6.35318e-10 1.0131e-28\n",
      "data/test/nevus/ISIC_0016031.jpg 2.36401e-26 0.0\n",
      "data/test/nevus/ISIC_0016033.jpg 1.84704e-06 0.974808\n",
      "data/test/nevus/ISIC_0016034.jpg 6.78946e-15 2.67608e-23\n",
      "data/test/nevus/ISIC_0016035.jpg 4.48023e-09 4.88422e-07\n",
      "data/test/nevus/ISIC_0016036.jpg 0.439377 0.000267151\n",
      "data: test, class: nevus, 360 / 393 images processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/nevus/ISIC_0016037.jpg 0.197178 0.00189706\n",
      "data/test/nevus/ISIC_0016038.jpg 1.19373e-09 1.97639e-25\n",
      "data/test/nevus/ISIC_0016040.jpg 9.95452e-09 1.97141e-11\n",
      "data/test/nevus/ISIC_0016041.jpg 6.22418e-15 1.0\n",
      "data/test/nevus/ISIC_0016042.jpg 1.71338e-08 6.97376e-07\n",
      "data/test/nevus/ISIC_0016043.jpg 1.55799e-09 5.78939e-32\n",
      "data/test/nevus/ISIC_0016044.jpg 1.33503e-28 2.46856e-08\n",
      "data/test/nevus/ISIC_0016045.jpg 0.007813 0.0320226\n",
      "data/test/nevus/ISIC_0016046.jpg 8.87052e-05 2.65367e-20\n",
      "data/test/nevus/ISIC_0016048.jpg 1.14387e-08 2.13594e-27\n",
      "data/test/nevus/ISIC_0016049.jpg 0.0872385 3.55602e-12\n",
      "data/test/nevus/ISIC_0016050.jpg 0.253877 2.24478e-06\n",
      "data/test/nevus/ISIC_0016051.jpg 8.43852e-26 0.0\n",
      "data/test/nevus/ISIC_0016052.jpg 0.371365 0.00781877\n",
      "data/test/nevus/ISIC_0016053.jpg 9.40263e-11 7.28465e-25\n",
      "data/test/nevus/ISIC_0016054.jpg 5.08074e-05 0.999487\n",
      "data/test/nevus/ISIC_0016055.jpg 2.69768e-08 5.71192e-26\n",
      "data/test/nevus/ISIC_0016056.jpg 2.18853e-09 1.30082e-16\n",
      "data/test/nevus/ISIC_0016057.jpg 0.0124208 1.08593e-12\n",
      "data/test/nevus/ISIC_0016058.jpg 3.98726e-13 0.0\n",
      "data: test, class: nevus, 380 / 393 images processed.\n",
      "data/test/nevus/ISIC_0016059.jpg 1.12423e-10 1.45504e-28\n",
      "data/test/nevus/ISIC_0016060.jpg 3.96978e-10 1.44355e-17\n",
      "data/test/nevus/ISIC_0016061.jpg 0.0 0.0\n",
      "data/test/nevus/ISIC_0016062.jpg 5.35527e-07 5.6959e-28\n",
      "data/test/nevus/ISIC_0016063.jpg 0.434818 1.63203e-06\n",
      "data/test/nevus/ISIC_0016064.jpg 0.0156557 0.00088092\n",
      "data/test/nevus/ISIC_0016065.jpg 2.30336e-06 3.11291e-08\n",
      "data/test/nevus/ISIC_0016066.jpg 0.412665 0.0100392\n",
      "data/test/nevus/ISIC_0016068.jpg 0.997175 6.68224e-08\n",
      "data/test/nevus/ISIC_0016069.jpg 9.53514e-06 7.89233e-25\n",
      "data/test/nevus/ISIC_0016070.jpg 2.76462e-27 0.0\n",
      "data/test/nevus/ISIC_0016071.jpg 0.0236296 3.0802e-11\n",
      "data/test/nevus/ISIC_0016072.jpg 0.501217 0.00667397\n",
      "data: test, class: nevus, 393 / 393 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012086.jpg 7.89582e-15 9.9225e-28\n",
      "data/test/seborrheic_keratosis/ISIC_0012134.jpg 2.18e-06 0.999998\n",
      "data/test/seborrheic_keratosis/ISIC_0012136.jpg 3.16239e-07 0.999962\n",
      "data/test/seborrheic_keratosis/ISIC_0012178.jpg 0.961169 0.0388315\n",
      "data/test/seborrheic_keratosis/ISIC_0012199.jpg 0.3938 0.0680488\n",
      "data/test/seborrheic_keratosis/ISIC_0012207.jpg 7.50496e-10 0.999921\n",
      "data/test/seborrheic_keratosis/ISIC_0012215.jpg 0.418211 0.228015\n",
      "data/test/seborrheic_keratosis/ISIC_0012223.jpg 0.87433 0.00103023\n",
      "data/test/seborrheic_keratosis/ISIC_0012240.jpg 0.929462 0.0704779\n",
      "data/test/seborrheic_keratosis/ISIC_0012248.jpg 5.37237e-18 7.99812e-19\n",
      "data/test/seborrheic_keratosis/ISIC_0012265.jpg 6.47195e-05 6.49968e-18\n",
      "data/test/seborrheic_keratosis/ISIC_0012266.jpg 2.52525e-13 6.63728e-12\n",
      "data/test/seborrheic_keratosis/ISIC_0012272.jpg 5.59113e-20 0.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012273.jpg 5.75541e-07 0.999999\n",
      "data/test/seborrheic_keratosis/ISIC_0012314.jpg 6.72621e-32 0.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012323.jpg 9.07938e-20 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012330.jpg 0.359888 4.96294e-16\n",
      "data/test/seborrheic_keratosis/ISIC_0012358.jpg 7.08846e-11 1.03088e-07\n",
      "data/test/seborrheic_keratosis/ISIC_0012364.jpg 7.42851e-09 0.914207\n",
      "data/test/seborrheic_keratosis/ISIC_0012372.jpg 4.36063e-34 1.76366e-20\n",
      "data: test, class: seborrheic_keratosis, 20 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0012375.jpg 1.75977e-06 5.51171e-06\n",
      "data/test/seborrheic_keratosis/ISIC_0012387.jpg 2.53277e-20 0.999712\n",
      "data/test/seborrheic_keratosis/ISIC_0012388.jpg 3.61528e-11 1.0934e-07\n",
      "data/test/seborrheic_keratosis/ISIC_0012414.jpg 0.060898 0.0109621\n",
      "data/test/seborrheic_keratosis/ISIC_0012428.jpg 2.98579e-22 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012432.jpg 0.0 0.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012447.jpg 3.57882e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012448.jpg 6.0771e-28 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012510.jpg 0.63399 0.00101288\n",
      "data/test/seborrheic_keratosis/ISIC_0012522.jpg 3.75873e-05 4.94931e-22\n",
      "data/test/seborrheic_keratosis/ISIC_0012537.jpg 0.0225691 0.00639423\n",
      "data/test/seborrheic_keratosis/ISIC_0012548.jpg 6.29773e-10 0.999992\n",
      "data/test/seborrheic_keratosis/ISIC_0012705.jpg 3.97475e-11 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012757.jpg 3.74813e-13 0.998298\n",
      "data/test/seborrheic_keratosis/ISIC_0012786.jpg 1.52139e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0012848.jpg 0.453186 0.519073\n",
      "data/test/seborrheic_keratosis/ISIC_0012852.jpg 4.58886e-17 0.999599\n",
      "data/test/seborrheic_keratosis/ISIC_0012928.jpg 6.35675e-16 5.85776e-18\n",
      "data/test/seborrheic_keratosis/ISIC_0012955.jpg 4.28039e-14 0.373703\n",
      "data/test/seborrheic_keratosis/ISIC_0012974.jpg 7.31009e-12 0.99996\n",
      "data: test, class: seborrheic_keratosis, 40 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0013030.jpg 2.35045e-33 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013035.jpg 0.000968177 0.125063\n",
      "data/test/seborrheic_keratosis/ISIC_0013085.jpg 0.0 0.702368\n",
      "data/test/seborrheic_keratosis/ISIC_0013169.jpg 1.13202e-13 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013170.jpg 1.63057e-11 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013203.jpg 2.16019e-19 0.00139567\n",
      "data/test/seborrheic_keratosis/ISIC_0013270.jpg 3.22532e-06 7.62008e-13\n",
      "data/test/seborrheic_keratosis/ISIC_0013271.jpg 0.0578809 0.00480749\n",
      "data/test/seborrheic_keratosis/ISIC_0013281.jpg 3.72473e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013319.jpg 0.624801 0.323234\n",
      "data/test/seborrheic_keratosis/ISIC_0013393.jpg 4.01252e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013465.jpg 1.05309e-08 0.998689\n",
      "data/test/seborrheic_keratosis/ISIC_0013673.jpg 1.11179e-14 4.14256e-05\n",
      "data/test/seborrheic_keratosis/ISIC_0013708.jpg 2.58287e-12 0.000410255\n",
      "data/test/seborrheic_keratosis/ISIC_0013764.jpg 9.05607e-12 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0013977.jpg 0.0 3.34363e-08\n",
      "data/test/seborrheic_keratosis/ISIC_0014006.jpg 9.34592e-37 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014177.jpg 7.74021e-10 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014251.jpg 1.08604e-16 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014278.jpg 0.0269081 3.82873e-09\n",
      "data: test, class: seborrheic_keratosis, 60 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014386.jpg 0.00704373 0.992427\n",
      "data/test/seborrheic_keratosis/ISIC_0014392.jpg 0.628509 0.371491\n",
      "data/test/seborrheic_keratosis/ISIC_0014409.jpg 0.119926 3.18971e-12\n",
      "data/test/seborrheic_keratosis/ISIC_0014419.jpg 0.438575 1.81242e-07\n",
      "data/test/seborrheic_keratosis/ISIC_0014457.jpg 2.70068e-07 3.73118e-18\n",
      "data/test/seborrheic_keratosis/ISIC_0014474.jpg 1.72634e-32 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014500.jpg 0.301349 0.000451061\n",
      "data/test/seborrheic_keratosis/ISIC_0014503.jpg 6.44423e-19 0.999994\n",
      "data/test/seborrheic_keratosis/ISIC_0014567.jpg 5.09026e-35 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014574.jpg 4.24381e-14 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014575.jpg 6.55836e-24 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014586.jpg 4.34309e-10 3.28416e-28\n",
      "data/test/seborrheic_keratosis/ISIC_0014587.jpg 0.0 0.997485\n",
      "data/test/seborrheic_keratosis/ISIC_0014588.jpg 0.0 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014590.jpg 6.25436e-06 0.298808\n",
      "data/test/seborrheic_keratosis/ISIC_0014600.jpg 0.000257421 0.999424\n",
      "data/test/seborrheic_keratosis/ISIC_0014619.jpg 6.87302e-15 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014626.jpg 3.26393e-31 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014627.jpg 1.33467e-22 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014629.jpg 1.25336e-23 1.0\n",
      "data: test, class: seborrheic_keratosis, 80 / 90 images processed.\n",
      "data/test/seborrheic_keratosis/ISIC_0014631.jpg 1.0633e-13 0.0031474\n",
      "data/test/seborrheic_keratosis/ISIC_0014634.jpg 1.70465e-29 2.16244e-32\n",
      "data/test/seborrheic_keratosis/ISIC_0014643.jpg 1.92261e-25 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014644.jpg 0.987077 5.63914e-05\n",
      "data/test/seborrheic_keratosis/ISIC_0014645.jpg 3.59699e-15 1.0\n",
      "data/test/seborrheic_keratosis/ISIC_0014647.jpg 0.201389 0.704633\n",
      "data/test/seborrheic_keratosis/ISIC_0014648.jpg 5.91765e-14 0.0932797\n",
      "data/test/seborrheic_keratosis/ISIC_0014649.jpg 1.85291e-29 1.13884e-20\n",
      "data/test/seborrheic_keratosis/ISIC_0014652.jpg 3.81735e-14 0.999669\n",
      "data/test/seborrheic_keratosis/ISIC_0014653.jpg 7.06276e-26 1.0\n",
      "data: test, class: seborrheic_keratosis, 90 / 90 images processed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "predections_csv = open('predections.csv', 'w')\n",
    "writer = csv.writer(predections_csv, lineterminator='\\n')\n",
    "writer.writerow(['Id', 'task_1', 'task_2'])\n",
    "\n",
    "batch_size = 20\n",
    "batch = []\n",
    "labels_batch = []\n",
    "files_batch = []\n",
    "\n",
    "d_type = 'test'\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    vgg = vgg19.Vgg19()\n",
    "    # vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "    \n",
    "    for c in classes:\n",
    "        image_dir = '{}{}/{}/'.format(data_dir, d_type, c) # e.g. data/train/melanoma/\n",
    "        files = os.listdir(image_dir)\n",
    "        for i, file in enumerate(files, 1):\n",
    "            # load image and resize it to 224x224\n",
    "            file_path = os.path.join(image_dir, file)\n",
    "            img = utils.load_image(file_path)\n",
    "            \n",
    "            batch.append(img.reshape((1, 224, 224, 3)))\n",
    "            labels_batch.append(c)\n",
    "            files_batch.append(file_path)\n",
    "\n",
    "            if (len(batch) >= batch_size) or i == len(files):\n",
    "                images = np.concatenate(batch)\n",
    "\n",
    "                feed_dict = {input_: images}\n",
    "                codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "                \n",
    "                feed_dict = {inputs_: codes_batch, labels_: lb.transform(labels_batch)}\n",
    "                predections_batch = sess.run(predicted, feed_dict=feed_dict)\n",
    "\n",
    "                for ii in range(len(batch)):\n",
    "                    predection = predections_batch[ii]\n",
    "                    label = labels_batch[ii]\n",
    "                    file_id = files_batch[ii]\n",
    "                    \n",
    "                    p_melanoma = predection[0]\n",
    "                    p_seborrheic_keratosis = predection[2]\n",
    "                    \n",
    "                    print(file_id, p_melanoma, p_seborrheic_keratosis)\n",
    "                    writer.writerow([file_id, p_melanoma, p_seborrheic_keratosis])\n",
    "                    \n",
    "                batch = []\n",
    "                labels_batch = []\n",
    "                files_batch = []\n",
    "                print('data: {}, class: {}, {} / {} images processed.'.format(d_type, c, i, len(files)))\n",
    "                \n",
    "                \n",
    "predections_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
